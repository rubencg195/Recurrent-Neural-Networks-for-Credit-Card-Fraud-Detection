Versions
Tensorflow :  2.1.0
Pandas     :  0.24.2
Numpy      :  0.24.2
Sklearn    :  0.22.1
NO GPUs available
CMD: pwd
OUT: /home/ec2-user/SageMaker
----------
CMD: ls
OUT: banksim1.zip
bs140513_032310.csv
bsNET140513_032310.csv
err.txt
kernel-setup.err
kernel-setup.out
kernel-setup.sh
labels_hash.data
log.txt
lost+found
Makefile
results
rnn_data.data
rnn_fraud_cust_batches_v1.py
RNN_Fraud_Detection.ipynb
rnn_mod_data.data
scaler.data
SlidingWindow-RNN_Fraud_Detection.ipynb
SlidingWindow-RNN_Fraud_Detection.py
X_test.data
X_train.data
X_val.data
y_test.data
y_train.data
y_val.data
----------
CMD: ./trin
OUT: [Errno 2] No such file or directory: './trin': './trin'
----------

    DATA PREPROCESSING
    DOWNLOAD FROM KAGGLE: False
    GENERATE DATA:        False
    READ FROM CLOUD:      False
    SAVE TO CLOUD:        False



_ _ _ _ _ _ _ _ _ _  IMPORT DATA FROM CSV _ _ _ _ _ _ _ _ _ _ 


Deleting the columns 'zipcodeOri','zipMerchant' because all the fields are equal.


Data Shape: (594643, 8) 

Preview: 

    step       customer  age gender       merchant             category  amount  fraud
0  0     'C1093826151'  '4'  'M'    'M348934600'   'es_transportation'  4.55    0    
1  0     'C352968107'   '2'  'M'    'M348934600'   'es_transportation'  39.68   0    
2  0     'C2054744914'  '4'  'F'    'M1823072687'  'es_transportation'  26.89   0    
3  0     'C1760612790'  '3'  'M'    'M348934600'   'es_transportation'  17.25   0    
4  0     'C757503768'   '5'  'M'    'M348934600'   'es_transportation'  35.72   0     

 Data Information: 

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 594643 entries, 0 to 594642
Data columns (total 8 columns):
step        594643 non-null int64
customer    594643 non-null object
age         594643 non-null object
gender      594643 non-null object
merchant    594643 non-null object
category    594643 non-null object
amount      594643 non-null float64
fraud       594643 non-null int64
dtypes: float64(1), int64(2), object(5)
memory usage: 36.3+ MB

None
Does it has null values? False


_ _ _ _ _ _ _ _ _ _   READ DATA LOCALLY  _ _ _ _ _ _ _ _ _ _ 




SHAPES & KEYS:
    X_train          : (285428, 25, 12)
    y_train          : (285428,)
    X_test           : (237858, 25, 12)
    y_test           : (237858,)
    X_val            : (71357, 25, 12)
    y_val            : (71357,)
    labels_hash Keys : dict_keys(['customer', 'age', 'gender', 'merchant', 'category'])
    


_ _ _ _ _ _ _ _ _ _  INITIALIZING GRID SEARCH RNN MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________
        input_shape :  (25, 12)
        output_dim  :  1
        main scoring:  recall
        all scoring :  ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
        early_stopping_monitor   : val_recall
        model_checkpoint_monitor : val_recall
        verbose: 2
        
rnn_hidden_layers : [0, 1]
rnn_hidden_layers_neurons : [50, 100]
hidden_layers : [2]
hidden_layers_neurons : [100, 200]
loss : ['binary_crossentropy']
optimizer : ['adam']
modelType : ['LSTM', 'GRU']
epochs : [50]
output_layer_activation : ['sigmoid']
rnn_layer_activation : ['sigmoid']
hidden_layer_activation : ['sigmoid']
dropout : [True]
dropout_rate : [0.2]





_ _ _ _ _ _ _ _ _ _  TRAINING RNN _ _ _ _ _ _ _ _ _ _ 



        Class weights: 
[ 0.50613724 41.23490321]
{0: 0.506137243010707, 1: 41.23490320716556}

        for classes: 
[0. 1.]

        # Frauds: 3461
        # of Non-Frauds: 281967
        
INPUTS
        X:      (285428, 25, 12)
        y:      (285428,)
        X_test: (237858, 25, 12)
        y_test: (237858,)
        
Fitting 10 folds for each of 16 candidates, totalling 160 fits
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4ae0787f28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4ae07a32b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4ae07a3470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4ae07a3860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4ae07a3b00>, <tensorflow.python.keras.metrics.Precision object at 0x7f4ae07a3eb8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4ae076f198>, <tensorflow.python.keras.metrics.AUC object at 0x7f4ae076f4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4ae0787ac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae0787b70>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4ae0787be0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4ae0787c18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4ae0787c88>]
          

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 50)                12600     
_________________________________________________________________
dense (Dense)                (None, 100)               5100      
_________________________________________________________________
activation (Activation)      (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout (Dropout)            (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall improved from -inf to 0.32335, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 107s - loss: 0.0455 - tp: 539.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 2587.0000 - accuracy: 0.9881 - precision: 0.5379 - recall: 0.1724 - auc: 0.8851 - val_loss: 0.0298 - val_tp: 918.0000 - val_fp: 369.0000 - val_tn: 234650.0000 - val_fn: 1921.0000 - val_accuracy: 0.9904 - val_precision: 0.7133 - val_recall: 0.3234 - val_auc: 0.9633
256885/256885 - 107s - loss: 0.0455 - tp: 539.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 2587.0000 - accuracy: 0.9881 - precision: 0.5379 - recall: 0.1724 - auc: 0.8851 - val_loss: 0.0298 - val_tp: 918.0000 - val_fp: 369.0000 - val_tn: 234650.0000 - val_fn: 1921.0000 - val_accuracy: 0.9904 - val_precision: 0.7133 - val_recall: 0.3234 - val_auc: 0.9633
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.32335 to 0.65657, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 103s - loss: 0.0268 - tp: 1405.0000 - fp: 415.0000 - tn: 253344.0000 - fn: 1721.0000 - accuracy: 0.9917 - precision: 0.7720 - recall: 0.4495 - auc: 0.9624 - val_loss: 0.0220 - val_tp: 1864.0000 - val_fp: 636.0000 - val_tn: 234383.0000 - val_fn: 975.0000 - val_accuracy: 0.9932 - val_precision: 0.7456 - val_recall: 0.6566 - val_auc: 0.9860
256885/256885 - 103s - loss: 0.0268 - tp: 1405.0000 - fp: 415.0000 - tn: 253344.0000 - fn: 1721.0000 - accuracy: 0.9917 - precision: 0.7720 - recall: 0.4495 - auc: 0.9624 - val_loss: 0.0220 - val_tp: 1864.0000 - val_fp: 636.0000 - val_tn: 234383.0000 - val_fn: 975.0000 - val_accuracy: 0.9932 - val_precision: 0.7456 - val_recall: 0.6566 - val_auc: 0.9860
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a9c347390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a9c2d9f60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a9c2e3320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a9c2e3ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a9c2e3d68>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a9c2e3f98>, <tensorflow.python.keras.metrics.Recall object at 0x7f4abc351400>, <tensorflow.python.keras.metrics.AUC object at 0x7f4abc351710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4ae0787b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae0787c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4ae0787dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4ae0787e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4ae0787ef0>]
          

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_3 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_3 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_4 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_5 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 106s - loss: 0.0430 - tp: 558.0000 - fp: 339.0000 - tn: 253419.0000 - fn: 2569.0000 - accuracy: 0.9887 - precision: 0.6221 - recall: 0.1784 - auc: 0.9010 - val_loss: 0.0290 - val_tp: 913.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1926.0000 - val_accuracy: 0.9904 - val_precision: 0.7183 - val_recall: 0.3216 - val_auc: 0.9660
256885/256885 - 106s - loss: 0.0430 - tp: 558.0000 - fp: 339.0000 - tn: 253419.0000 - fn: 2569.0000 - accuracy: 0.9887 - precision: 0.6221 - recall: 0.1784 - auc: 0.9010 - val_loss: 0.0290 - val_tp: 913.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1926.0000 - val_accuracy: 0.9904 - val_precision: 0.7183 - val_recall: 0.3216 - val_auc: 0.9660
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0257 - tp: 1485.0000 - fp: 456.0000 - tn: 253302.0000 - fn: 1642.0000 - accuracy: 0.9918 - precision: 0.7651 - recall: 0.4749 - auc: 0.9669 - val_loss: 0.0205 - val_tp: 1515.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1324.0000 - val_accuracy: 0.9933 - val_precision: 0.8487 - val_recall: 0.5336 - val_auc: 0.9761
256885/256885 - 103s - loss: 0.0257 - tp: 1485.0000 - fp: 456.0000 - tn: 253302.0000 - fn: 1642.0000 - accuracy: 0.9918 - precision: 0.7651 - recall: 0.4749 - auc: 0.9669 - val_loss: 0.0205 - val_tp: 1515.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1324.0000 - val_accuracy: 0.9933 - val_precision: 0.8487 - val_recall: 0.5336 - val_auc: 0.9761
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4abc489550>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4abc489f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4ae022d0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a9c05f710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a9c408630>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a9c0b5f28>, <tensorflow.python.keras.metrics.Recall object at 0x7f4ae021bf98>, <tensorflow.python.keras.metrics.AUC object at 0x7f4ae021b048>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4ae0787dd8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae038bf60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4abc4dbe10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a9c343128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4abc489dd8>]
          

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_6 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_6 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 106s - loss: 0.0442 - tp: 513.0000 - fp: 428.0000 - tn: 253341.0000 - fn: 2603.0000 - accuracy: 0.9882 - precision: 0.5452 - recall: 0.1646 - auc: 0.8942 - val_loss: 0.0294 - val_tp: 946.0000 - val_fp: 421.0000 - val_tn: 234598.0000 - val_fn: 1893.0000 - val_accuracy: 0.9903 - val_precision: 0.6920 - val_recall: 0.3332 - val_auc: 0.9682
256885/256885 - 106s - loss: 0.0442 - tp: 513.0000 - fp: 428.0000 - tn: 253341.0000 - fn: 2603.0000 - accuracy: 0.9882 - precision: 0.5452 - recall: 0.1646 - auc: 0.8942 - val_loss: 0.0294 - val_tp: 946.0000 - val_fp: 421.0000 - val_tn: 234598.0000 - val_fn: 1893.0000 - val_accuracy: 0.9903 - val_precision: 0.6920 - val_recall: 0.3332 - val_auc: 0.9682
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0262 - tp: 1401.0000 - fp: 437.0000 - tn: 253332.0000 - fn: 1715.0000 - accuracy: 0.9916 - precision: 0.7622 - recall: 0.4496 - auc: 0.9671 - val_loss: 0.0202 - val_tp: 1725.0000 - val_fp: 377.0000 - val_tn: 234642.0000 - val_fn: 1114.0000 - val_accuracy: 0.9937 - val_precision: 0.8206 - val_recall: 0.6076 - val_auc: 0.9850
256885/256885 - 103s - loss: 0.0262 - tp: 1401.0000 - fp: 437.0000 - tn: 253332.0000 - fn: 1715.0000 - accuracy: 0.9916 - precision: 0.7622 - recall: 0.4496 - auc: 0.9671 - val_loss: 0.0202 - val_tp: 1725.0000 - val_fp: 377.0000 - val_tn: 234642.0000 - val_fn: 1114.0000 - val_accuracy: 0.9937 - val_precision: 0.8206 - val_recall: 0.6076 - val_auc: 0.9850
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4ae029fe10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a9c35b908>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4ae0287e10>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a9c4a64e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a9c4a6780>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a9c4a6b38>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a9c4a6dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a9c4d1128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a9c343128>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4abc489e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4abc489c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4abc489b00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4abc4dbef0>]
          

Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_3 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_9 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_9 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_10 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_11 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 106s - loss: 0.0441 - tp: 525.0000 - fp: 353.0000 - tn: 253439.0000 - fn: 2568.0000 - accuracy: 0.9886 - precision: 0.5979 - recall: 0.1697 - auc: 0.8915 - val_loss: 0.0304 - val_tp: 779.0000 - val_fp: 275.0000 - val_tn: 234744.0000 - val_fn: 2060.0000 - val_accuracy: 0.9902 - val_precision: 0.7391 - val_recall: 0.2744 - val_auc: 0.9588
256885/256885 - 106s - loss: 0.0441 - tp: 525.0000 - fp: 353.0000 - tn: 253439.0000 - fn: 2568.0000 - accuracy: 0.9886 - precision: 0.5979 - recall: 0.1697 - auc: 0.8915 - val_loss: 0.0304 - val_tp: 779.0000 - val_fp: 275.0000 - val_tn: 234744.0000 - val_fn: 2060.0000 - val_accuracy: 0.9902 - val_precision: 0.7391 - val_recall: 0.2744 - val_auc: 0.9588
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0258 - tp: 1446.0000 - fp: 422.0000 - tn: 253370.0000 - fn: 1647.0000 - accuracy: 0.9919 - precision: 0.7741 - recall: 0.4675 - auc: 0.9663 - val_loss: 0.0204 - val_tp: 1671.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1168.0000 - val_accuracy: 0.9933 - val_precision: 0.7961 - val_recall: 0.5886 - val_auc: 0.9791
256885/256885 - 103s - loss: 0.0258 - tp: 1446.0000 - fp: 422.0000 - tn: 253370.0000 - fn: 1647.0000 - accuracy: 0.9919 - precision: 0.7741 - recall: 0.4675 - auc: 0.9663 - val_loss: 0.0204 - val_tp: 1671.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1168.0000 - val_accuracy: 0.9933 - val_precision: 0.7961 - val_recall: 0.5886 - val_auc: 0.9791
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c1db710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4abc599c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4abc599ac8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a9c10e860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a9c10eda0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a9c10ee48>, <tensorflow.python.keras.metrics.Recall object at 0x7f4ae04b4ef0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4ae051f668>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4ae02aa898>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae045c470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4ae045cb70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4ae045c3c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4ae045c940>]
          

Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_4 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_12 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_12 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 108s - loss: 0.0429 - tp: 581.0000 - fp: 348.0000 - tn: 253391.0000 - fn: 2565.0000 - accuracy: 0.9887 - precision: 0.6254 - recall: 0.1847 - auc: 0.9004 - val_loss: 0.0294 - val_tp: 723.0000 - val_fp: 240.0000 - val_tn: 234779.0000 - val_fn: 2116.0000 - val_accuracy: 0.9901 - val_precision: 0.7508 - val_recall: 0.2547 - val_auc: 0.9654
256885/256885 - 108s - loss: 0.0429 - tp: 581.0000 - fp: 348.0000 - tn: 253391.0000 - fn: 2565.0000 - accuracy: 0.9887 - precision: 0.6254 - recall: 0.1847 - auc: 0.9004 - val_loss: 0.0294 - val_tp: 723.0000 - val_fp: 240.0000 - val_tn: 234779.0000 - val_fn: 2116.0000 - val_accuracy: 0.9901 - val_precision: 0.7508 - val_recall: 0.2547 - val_auc: 0.9654
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0253 - tp: 1538.0000 - fp: 436.0000 - tn: 253303.0000 - fn: 1608.0000 - accuracy: 0.9920 - precision: 0.7791 - recall: 0.4889 - auc: 0.9660 - val_loss: 0.0231 - val_tp: 1327.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 1512.0000 - val_accuracy: 0.9929 - val_precision: 0.8829 - val_recall: 0.4674 - val_auc: 0.9569
256885/256885 - 103s - loss: 0.0253 - tp: 1538.0000 - fp: 436.0000 - tn: 253303.0000 - fn: 1608.0000 - accuracy: 0.9920 - precision: 0.7791 - recall: 0.4889 - auc: 0.9660 - val_loss: 0.0231 - val_tp: 1327.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 1512.0000 - val_accuracy: 0.9929 - val_precision: 0.8829 - val_recall: 0.4674 - val_auc: 0.9569
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a406e0048>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a7c110160>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a407611d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a40761d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a40757940>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a40757b70>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a40757a90>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a40757780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4ae045cb70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae045ca90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4ae045c9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a5c1db828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a406f1860>]
          

Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_5 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_15 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_15 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_16 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_17 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 107s - loss: 0.0444 - tp: 545.0000 - fp: 410.0000 - tn: 253368.0000 - fn: 2562.0000 - accuracy: 0.9884 - precision: 0.5707 - recall: 0.1754 - auc: 0.8869 - val_loss: 0.0300 - val_tp: 896.0000 - val_fp: 392.0000 - val_tn: 234627.0000 - val_fn: 1943.0000 - val_accuracy: 0.9902 - val_precision: 0.6957 - val_recall: 0.3156 - val_auc: 0.9623
256885/256885 - 107s - loss: 0.0444 - tp: 545.0000 - fp: 410.0000 - tn: 253368.0000 - fn: 2562.0000 - accuracy: 0.9884 - precision: 0.5707 - recall: 0.1754 - auc: 0.8869 - val_loss: 0.0300 - val_tp: 896.0000 - val_fp: 392.0000 - val_tn: 234627.0000 - val_fn: 1943.0000 - val_accuracy: 0.9902 - val_precision: 0.6957 - val_recall: 0.3156 - val_auc: 0.9623
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0266 - tp: 1418.0000 - fp: 446.0000 - tn: 253332.0000 - fn: 1689.0000 - accuracy: 0.9917 - precision: 0.7607 - recall: 0.4564 - auc: 0.9641 - val_loss: 0.0207 - val_tp: 1743.0000 - val_fp: 554.0000 - val_tn: 234465.0000 - val_fn: 1096.0000 - val_accuracy: 0.9931 - val_precision: 0.7588 - val_recall: 0.6139 - val_auc: 0.9811
256885/256885 - 103s - loss: 0.0266 - tp: 1418.0000 - fp: 446.0000 - tn: 253332.0000 - fn: 1689.0000 - accuracy: 0.9917 - precision: 0.7607 - recall: 0.4564 - auc: 0.9641 - val_loss: 0.0207 - val_tp: 1743.0000 - val_fp: 554.0000 - val_tn: 234465.0000 - val_fn: 1096.0000 - val_accuracy: 0.9931 - val_precision: 0.7588 - val_recall: 0.6139 - val_auc: 0.9811
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a401cbd30>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a401e85f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4ae039bb70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4ae039ba58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4ae039b438>, <tensorflow.python.keras.metrics.Precision object at 0x7f4ae039bf60>, <tensorflow.python.keras.metrics.Recall object at 0x7f4ae039b8d0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a7c0438d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a406d5cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4ae045c9b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4ae045ca90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4ae04664e0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a40745b00>]
          

Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_6 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_18 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_18 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 106s - loss: 0.0431 - tp: 589.0000 - fp: 347.0000 - tn: 253447.0000 - fn: 2502.0000 - accuracy: 0.9889 - precision: 0.6293 - recall: 0.1906 - auc: 0.8952 - val_loss: 0.0295 - val_tp: 1051.0000 - val_fp: 505.0000 - val_tn: 234514.0000 - val_fn: 1788.0000 - val_accuracy: 0.9904 - val_precision: 0.6754 - val_recall: 0.3702 - val_auc: 0.9719
256885/256885 - 106s - loss: 0.0431 - tp: 589.0000 - fp: 347.0000 - tn: 253447.0000 - fn: 2502.0000 - accuracy: 0.9889 - precision: 0.6293 - recall: 0.1906 - auc: 0.8952 - val_loss: 0.0295 - val_tp: 1051.0000 - val_fp: 505.0000 - val_tn: 234514.0000 - val_fn: 1788.0000 - val_accuracy: 0.9904 - val_precision: 0.6754 - val_recall: 0.3702 - val_auc: 0.9719
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0253 - tp: 1482.0000 - fp: 408.0000 - tn: 253386.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7841 - recall: 0.4795 - auc: 0.9669 - val_loss: 0.0197 - val_tp: 1682.0000 - val_fp: 365.0000 - val_tn: 234654.0000 - val_fn: 1157.0000 - val_accuracy: 0.9936 - val_precision: 0.8217 - val_recall: 0.5925 - val_auc: 0.9818
256885/256885 - 103s - loss: 0.0253 - tp: 1482.0000 - fp: 408.0000 - tn: 253386.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7841 - recall: 0.4795 - auc: 0.9669 - val_loss: 0.0197 - val_tp: 1682.0000 - val_fp: 365.0000 - val_tn: 234654.0000 - val_fn: 1157.0000 - val_accuracy: 0.9936 - val_precision: 0.8217 - val_recall: 0.5925 - val_auc: 0.9818
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c4376d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a5c1f1518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a5c1e5358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c1e55c0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c1e5518>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a5c1e5f28>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a5c1e5198>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a5c1db668>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4abc3521d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a407474e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a40747400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a40747518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a7c3aa160>]
          

Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_7 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_21 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_21 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_22 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_23 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 106s - loss: 0.0444 - tp: 520.0000 - fp: 348.0000 - tn: 253426.0000 - fn: 2591.0000 - accuracy: 0.9886 - precision: 0.5991 - recall: 0.1671 - auc: 0.8925 - val_loss: 0.0298 - val_tp: 742.0000 - val_fp: 245.0000 - val_tn: 234774.0000 - val_fn: 2097.0000 - val_accuracy: 0.9902 - val_precision: 0.7518 - val_recall: 0.2614 - val_auc: 0.9686
256885/256885 - 106s - loss: 0.0444 - tp: 520.0000 - fp: 348.0000 - tn: 253426.0000 - fn: 2591.0000 - accuracy: 0.9886 - precision: 0.5991 - recall: 0.1671 - auc: 0.8925 - val_loss: 0.0298 - val_tp: 742.0000 - val_fp: 245.0000 - val_tn: 234774.0000 - val_fn: 2097.0000 - val_accuracy: 0.9902 - val_precision: 0.7518 - val_recall: 0.2614 - val_auc: 0.9686
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 103s - loss: 0.0254 - tp: 1511.0000 - fp: 402.0000 - tn: 253372.0000 - fn: 1600.0000 - accuracy: 0.9922 - precision: 0.7899 - recall: 0.4857 - auc: 0.9691 - val_loss: 0.0199 - val_tp: 1719.0000 - val_fp: 354.0000 - val_tn: 234665.0000 - val_fn: 1120.0000 - val_accuracy: 0.9938 - val_precision: 0.8292 - val_recall: 0.6055 - val_auc: 0.9839
256885/256885 - 103s - loss: 0.0254 - tp: 1511.0000 - fp: 402.0000 - tn: 253372.0000 - fn: 1600.0000 - accuracy: 0.9922 - precision: 0.7899 - recall: 0.4857 - auc: 0.9691 - val_loss: 0.0199 - val_tp: 1719.0000 - val_fp: 354.0000 - val_tn: 234665.0000 - val_fn: 1120.0000 - val_accuracy: 0.9938 - val_precision: 0.8292 - val_recall: 0.6055 - val_auc: 0.9839
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a1d252d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1d29de10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a1d25e668>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a1d25ee48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a1d1ee128>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a1d1ee4e0>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a1d1ee780>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a1d1eea90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4abc57fd30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a40747518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a7c0bfc18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a7c0f8b38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a1d2a62b0>]
          

Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_8 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_24 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_24 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_25 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_26 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256886/256886 - 107s - loss: 0.0442 - tp: 540.0000 - fp: 424.0000 - tn: 253354.0000 - fn: 2568.0000 - accuracy: 0.9884 - precision: 0.5602 - recall: 0.1737 - auc: 0.8922 - val_loss: 0.0294 - val_tp: 748.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2091.0000 - val_accuracy: 0.9902 - val_precision: 0.7540 - val_recall: 0.2635 - val_auc: 0.9699
256886/256886 - 107s - loss: 0.0442 - tp: 540.0000 - fp: 424.0000 - tn: 253354.0000 - fn: 2568.0000 - accuracy: 0.9884 - precision: 0.5602 - recall: 0.1737 - auc: 0.8922 - val_loss: 0.0294 - val_tp: 748.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2091.0000 - val_accuracy: 0.9902 - val_precision: 0.7540 - val_recall: 0.2635 - val_auc: 0.9699
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256886/256886 - 103s - loss: 0.0261 - tp: 1399.0000 - fp: 415.0000 - tn: 253363.0000 - fn: 1709.0000 - accuracy: 0.9917 - precision: 0.7712 - recall: 0.4501 - auc: 0.9642 - val_loss: 0.0254 - val_tp: 1290.0000 - val_fp: 201.0000 - val_tn: 234818.0000 - val_fn: 1549.0000 - val_accuracy: 0.9926 - val_precision: 0.8652 - val_recall: 0.4544 - val_auc: 0.9434
256886/256886 - 103s - loss: 0.0261 - tp: 1399.0000 - fp: 415.0000 - tn: 253363.0000 - fn: 1709.0000 - accuracy: 0.9917 - precision: 0.7712 - recall: 0.4501 - auc: 0.9642 - val_loss: 0.0254 - val_tp: 1290.0000 - val_fp: 201.0000 - val_tn: 234818.0000 - val_fn: 1549.0000 - val_accuracy: 0.9926 - val_precision: 0.8652 - val_recall: 0.4544 - val_auc: 0.9434
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a9c466d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a9c466f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4ae010ea20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a1c3d2438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a40182b00>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a1c3e3b00>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a40778ba8>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a407784a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a7c0bfc18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c498240>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a9c467ef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a9c466c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a9c466ef0>]
          

Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_27 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_27 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_28 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_29 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256886/256886 - 106s - loss: 0.0418 - tp: 599.0000 - fp: 374.0000 - tn: 253388.0000 - fn: 2525.0000 - accuracy: 0.9887 - precision: 0.6156 - recall: 0.1917 - auc: 0.9053 - val_loss: 0.0284 - val_tp: 890.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1949.0000 - val_accuracy: 0.9905 - val_precision: 0.7404 - val_recall: 0.3135 - val_auc: 0.9671
256886/256886 - 106s - loss: 0.0418 - tp: 599.0000 - fp: 374.0000 - tn: 253388.0000 - fn: 2525.0000 - accuracy: 0.9887 - precision: 0.6156 - recall: 0.1917 - auc: 0.9053 - val_loss: 0.0284 - val_tp: 890.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1949.0000 - val_accuracy: 0.9905 - val_precision: 0.7404 - val_recall: 0.3135 - val_auc: 0.9671
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256886/256886 - 103s - loss: 0.0254 - tp: 1511.0000 - fp: 452.0000 - tn: 253310.0000 - fn: 1613.0000 - accuracy: 0.9920 - precision: 0.7697 - recall: 0.4837 - auc: 0.9683 - val_loss: 0.0203 - val_tp: 1564.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1275.0000 - val_accuracy: 0.9932 - val_precision: 0.8219 - val_recall: 0.5509 - val_auc: 0.9797
256886/256886 - 103s - loss: 0.0254 - tp: 1511.0000 - fp: 452.0000 - tn: 253310.0000 - fn: 1613.0000 - accuracy: 0.9920 - precision: 0.7697 - recall: 0.4837 - auc: 0.9683 - val_loss: 0.0203 - val_tp: 1564.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1275.0000 - val_accuracy: 0.9932 - val_precision: 0.8219 - val_recall: 0.5509 - val_auc: 0.9797
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4abc3bcf98>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a7c444278>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a7c439160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a7c439e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a7c439940>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a7c439630>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a7c476b38>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a7c476cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a9c466f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a9c466da0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a9c466b70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a9c466550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a40747518>]
          

Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_10 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_30 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_30 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_31 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_32 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 132s - loss: 0.0475 - tp: 492.0000 - fp: 433.0000 - tn: 253326.0000 - fn: 2634.0000 - accuracy: 0.9881 - precision: 0.5319 - recall: 0.1574 - auc: 0.8673 - val_loss: 0.0329 - val_tp: 636.0000 - val_fp: 163.0000 - val_tn: 234856.0000 - val_fn: 2203.0000 - val_accuracy: 0.9901 - val_precision: 0.7960 - val_recall: 0.2240 - val_auc: 0.9418
256885/256885 - 132s - loss: 0.0475 - tp: 492.0000 - fp: 433.0000 - tn: 253326.0000 - fn: 2634.0000 - accuracy: 0.9881 - precision: 0.5319 - recall: 0.1574 - auc: 0.8673 - val_loss: 0.0329 - val_tp: 636.0000 - val_fp: 163.0000 - val_tn: 234856.0000 - val_fn: 2203.0000 - val_accuracy: 0.9901 - val_precision: 0.7960 - val_recall: 0.2240 - val_auc: 0.9418
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.65657
256885/256885 - 129s - loss: 0.0260 - tp: 1489.0000 - fp: 428.0000 - tn: 253331.0000 - fn: 1637.0000 - accuracy: 0.9920 - precision: 0.7767 - recall: 0.4763 - auc: 0.9632 - val_loss: 0.0233 - val_tp: 1353.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1486.0000 - val_accuracy: 0.9930 - val_precision: 0.8780 - val_recall: 0.4766 - val_auc: 0.9565
256885/256885 - 129s - loss: 0.0260 - tp: 1489.0000 - fp: 428.0000 - tn: 253331.0000 - fn: 1637.0000 - accuracy: 0.9920 - precision: 0.7767 - recall: 0.4763 - auc: 0.9632 - val_loss: 0.0233 - val_tp: 1353.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1486.0000 - val_accuracy: 0.9930 - val_precision: 0.8780 - val_recall: 0.4766 - val_auc: 0.9565
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a4039ba90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a40372978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a5c6bb0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c6bbda0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c6bb390>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a5c6bb470>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a5c6bb898>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a7c44ad68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a9c466da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a9c466e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a9c466550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a403b1c18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a40251898>]
          

Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_11 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_33 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_33 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_34 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_35 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.65657
256885/256885 - 132s - loss: 0.0433 - tp: 558.0000 - fp: 345.0000 - tn: 253413.0000 - fn: 2569.0000 - accuracy: 0.9887 - precision: 0.6179 - recall: 0.1784 - auc: 0.8978 - val_loss: 0.0313 - val_tp: 814.0000 - val_fp: 295.0000 - val_tn: 234724.0000 - val_fn: 2025.0000 - val_accuracy: 0.9902 - val_precision: 0.7340 - val_recall: 0.2867 - val_auc: 0.9488
256885/256885 - 132s - loss: 0.0433 - tp: 558.0000 - fp: 345.0000 - tn: 253413.0000 - fn: 2569.0000 - accuracy: 0.9887 - precision: 0.6179 - recall: 0.1784 - auc: 0.8978 - val_loss: 0.0313 - val_tp: 814.0000 - val_fp: 295.0000 - val_tn: 234724.0000 - val_fn: 2025.0000 - val_accuracy: 0.9902 - val_precision: 0.7340 - val_recall: 0.2867 - val_auc: 0.9488
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.65657 to 0.68404, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 128s - loss: 0.0262 - tp: 1445.0000 - fp: 432.0000 - tn: 253326.0000 - fn: 1682.0000 - accuracy: 0.9918 - precision: 0.7698 - recall: 0.4621 - auc: 0.9668 - val_loss: 0.0222 - val_tp: 1942.0000 - val_fp: 695.0000 - val_tn: 234324.0000 - val_fn: 897.0000 - val_accuracy: 0.9933 - val_precision: 0.7364 - val_recall: 0.6840 - val_auc: 0.9864
256885/256885 - 128s - loss: 0.0262 - tp: 1445.0000 - fp: 432.0000 - tn: 253326.0000 - fn: 1682.0000 - accuracy: 0.9918 - precision: 0.7698 - recall: 0.4621 - auc: 0.9668 - val_loss: 0.0222 - val_tp: 1942.0000 - val_fp: 695.0000 - val_tn: 234324.0000 - val_fn: 897.0000 - val_accuracy: 0.9933 - val_precision: 0.7364 - val_recall: 0.6840 - val_auc: 0.9864
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a40772668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1c3d26a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a1c3d2fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a1c3d2978>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a1c3d2710>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a1c3d2ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a7c168a20>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a04353c50>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c6dbb00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4abc4a0198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a407728d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a40772898>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a40772400>]
          

Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_36 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_36 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_37 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_38 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.68404
256885/256885 - 132s - loss: 0.0431 - tp: 573.0000 - fp: 376.0000 - tn: 253393.0000 - fn: 2543.0000 - accuracy: 0.9886 - precision: 0.6038 - recall: 0.1839 - auc: 0.8968 - val_loss: 0.0425 - val_tp: 428.0000 - val_fp: 98.0000 - val_tn: 234921.0000 - val_fn: 2411.0000 - val_accuracy: 0.9895 - val_precision: 0.8137 - val_recall: 0.1508 - val_auc: 0.8726
256885/256885 - 132s - loss: 0.0431 - tp: 573.0000 - fp: 376.0000 - tn: 253393.0000 - fn: 2543.0000 - accuracy: 0.9886 - precision: 0.6038 - recall: 0.1839 - auc: 0.8968 - val_loss: 0.0425 - val_tp: 428.0000 - val_fp: 98.0000 - val_tn: 234921.0000 - val_fn: 2411.0000 - val_accuracy: 0.9895 - val_precision: 0.8137 - val_recall: 0.1508 - val_auc: 0.8726
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.68404
256885/256885 - 128s - loss: 0.0254 - tp: 1492.0000 - fp: 406.0000 - tn: 253363.0000 - fn: 1624.0000 - accuracy: 0.9921 - precision: 0.7861 - recall: 0.4788 - auc: 0.9659 - val_loss: 0.0199 - val_tp: 1704.0000 - val_fp: 419.0000 - val_tn: 234600.0000 - val_fn: 1135.0000 - val_accuracy: 0.9935 - val_precision: 0.8026 - val_recall: 0.6002 - val_auc: 0.9816
256885/256885 - 128s - loss: 0.0254 - tp: 1492.0000 - fp: 406.0000 - tn: 253363.0000 - fn: 1624.0000 - accuracy: 0.9921 - precision: 0.7861 - recall: 0.4788 - auc: 0.9659 - val_loss: 0.0199 - val_tp: 1704.0000 - val_fp: 419.0000 - val_tn: 234600.0000 - val_fn: 1135.0000 - val_accuracy: 0.9935 - val_precision: 0.8026 - val_recall: 0.6002 - val_auc: 0.9816
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a1d285630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a04114c88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a04114d68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a04114eb8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a040a7198>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a040a7550>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a040a77f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a040a7b00>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a407726a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a40772400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a40772ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a40772be0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a0416fac8>]
          

Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_39 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_39 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_40 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_41 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.68404
256885/256885 - 132s - loss: 0.0448 - tp: 572.0000 - fp: 439.0000 - tn: 253353.0000 - fn: 2521.0000 - accuracy: 0.9885 - precision: 0.5658 - recall: 0.1849 - auc: 0.8791 - val_loss: 0.0294 - val_tp: 802.0000 - val_fp: 267.0000 - val_tn: 234752.0000 - val_fn: 2037.0000 - val_accuracy: 0.9903 - val_precision: 0.7502 - val_recall: 0.2825 - val_auc: 0.9632
256885/256885 - 132s - loss: 0.0448 - tp: 572.0000 - fp: 439.0000 - tn: 253353.0000 - fn: 2521.0000 - accuracy: 0.9885 - precision: 0.5658 - recall: 0.1849 - auc: 0.8791 - val_loss: 0.0294 - val_tp: 802.0000 - val_fp: 267.0000 - val_tn: 234752.0000 - val_fn: 2037.0000 - val_accuracy: 0.9903 - val_precision: 0.7502 - val_recall: 0.2825 - val_auc: 0.9632
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.68404
256885/256885 - 129s - loss: 0.0255 - tp: 1498.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 1595.0000 - accuracy: 0.9922 - precision: 0.7880 - recall: 0.4843 - auc: 0.9648 - val_loss: 0.0206 - val_tp: 1828.0000 - val_fp: 482.0000 - val_tn: 234537.0000 - val_fn: 1011.0000 - val_accuracy: 0.9937 - val_precision: 0.7913 - val_recall: 0.6439 - val_auc: 0.9868
256885/256885 - 129s - loss: 0.0255 - tp: 1498.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 1595.0000 - accuracy: 0.9922 - precision: 0.7880 - recall: 0.4843 - auc: 0.9648 - val_loss: 0.0206 - val_tp: 1828.0000 - val_fp: 482.0000 - val_tn: 234537.0000 - val_fn: 1011.0000 - val_accuracy: 0.9937 - val_precision: 0.7913 - val_recall: 0.6439 - val_auc: 0.9868
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a7c221a20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a041646a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a041b2ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a041b2a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a041b2710>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a5c4f5860>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a04071470>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a041c13c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a40772400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c3a74e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c3a7860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a5c3a7b00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a5c3a7828>]
          

Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_14 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_42 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_42 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_43 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_44 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.68404
256885/256885 - 132s - loss: 0.0463 - tp: 548.0000 - fp: 438.0000 - tn: 253301.0000 - fn: 2598.0000 - accuracy: 0.9882 - precision: 0.5558 - recall: 0.1742 - auc: 0.8750 - val_loss: 0.0305 - val_tp: 693.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 2146.0000 - val_accuracy: 0.9901 - val_precision: 0.7734 - val_recall: 0.2441 - val_auc: 0.9597
256885/256885 - 132s - loss: 0.0463 - tp: 548.0000 - fp: 438.0000 - tn: 253301.0000 - fn: 2598.0000 - accuracy: 0.9882 - precision: 0.5558 - recall: 0.1742 - auc: 0.8750 - val_loss: 0.0305 - val_tp: 693.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 2146.0000 - val_accuracy: 0.9901 - val_precision: 0.7734 - val_recall: 0.2441 - val_auc: 0.9597
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.68404 to 0.69391, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 129s - loss: 0.0267 - tp: 1450.0000 - fp: 422.0000 - tn: 253317.0000 - fn: 1696.0000 - accuracy: 0.9918 - precision: 0.7746 - recall: 0.4609 - auc: 0.9661 - val_loss: 0.0226 - val_tp: 1970.0000 - val_fp: 793.0000 - val_tn: 234226.0000 - val_fn: 869.0000 - val_accuracy: 0.9930 - val_precision: 0.7130 - val_recall: 0.6939 - val_auc: 0.9852
256885/256885 - 129s - loss: 0.0267 - tp: 1450.0000 - fp: 422.0000 - tn: 253317.0000 - fn: 1696.0000 - accuracy: 0.9918 - precision: 0.7746 - recall: 0.4609 - auc: 0.9661 - val_loss: 0.0226 - val_tp: 1970.0000 - val_fp: 793.0000 - val_tn: 234226.0000 - val_fn: 869.0000 - val_accuracy: 0.9930 - val_precision: 0.7130 - val_recall: 0.6939 - val_auc: 0.9852
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a40420860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a40420dd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a40420be0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a0406ae80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a04128748>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a04128d30>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a7c393630>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a7c3936d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c3a74e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c3a7828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c3a7518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a7c2210f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4abc43ccc0>]
          

Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_15 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_45 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_45 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_46 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_47 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256885/256885 - 132s - loss: 0.0440 - tp: 582.0000 - fp: 329.0000 - tn: 253449.0000 - fn: 2525.0000 - accuracy: 0.9889 - precision: 0.6389 - recall: 0.1873 - auc: 0.8881 - val_loss: 0.0343 - val_tp: 1378.0000 - val_fp: 990.0000 - val_tn: 234029.0000 - val_fn: 1461.0000 - val_accuracy: 0.9897 - val_precision: 0.5819 - val_recall: 0.4854 - val_auc: 0.9758
256885/256885 - 132s - loss: 0.0440 - tp: 582.0000 - fp: 329.0000 - tn: 253449.0000 - fn: 2525.0000 - accuracy: 0.9889 - precision: 0.6389 - recall: 0.1873 - auc: 0.8881 - val_loss: 0.0343 - val_tp: 1378.0000 - val_fp: 990.0000 - val_tn: 234029.0000 - val_fn: 1461.0000 - val_accuracy: 0.9897 - val_precision: 0.5819 - val_recall: 0.4854 - val_auc: 0.9758
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256885/256885 - 129s - loss: 0.0258 - tp: 1510.0000 - fp: 419.0000 - tn: 253359.0000 - fn: 1597.0000 - accuracy: 0.9922 - precision: 0.7828 - recall: 0.4860 - auc: 0.9639 - val_loss: 0.0219 - val_tp: 1740.0000 - val_fp: 350.0000 - val_tn: 234669.0000 - val_fn: 1099.0000 - val_accuracy: 0.9939 - val_precision: 0.8325 - val_recall: 0.6129 - val_auc: 0.9873
256885/256885 - 129s - loss: 0.0258 - tp: 1510.0000 - fp: 419.0000 - tn: 253359.0000 - fn: 1597.0000 - accuracy: 0.9922 - precision: 0.7828 - recall: 0.4860 - auc: 0.9639 - val_loss: 0.0219 - val_tp: 1740.0000 - val_fp: 350.0000 - val_tn: 234669.0000 - val_fn: 1099.0000 - val_accuracy: 0.9939 - val_precision: 0.8325 - val_recall: 0.6129 - val_auc: 0.9873
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a04622c88>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a0465c208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a0465cba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a041e7710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a041e7240>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a041f9c88>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a041f9e48>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a041ff908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4abc43ccc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9efb470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a7c221e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a5c056780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a04622c50>]
          

Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_16 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_48 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_48 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_49 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_50 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256885/256885 - 132s - loss: 0.0455 - tp: 514.0000 - fp: 418.0000 - tn: 253376.0000 - fn: 2577.0000 - accuracy: 0.9883 - precision: 0.5515 - recall: 0.1663 - auc: 0.8752 - val_loss: 0.0311 - val_tp: 811.0000 - val_fp: 274.0000 - val_tn: 234745.0000 - val_fn: 2028.0000 - val_accuracy: 0.9903 - val_precision: 0.7475 - val_recall: 0.2857 - val_auc: 0.9453
256885/256885 - 132s - loss: 0.0455 - tp: 514.0000 - fp: 418.0000 - tn: 253376.0000 - fn: 2577.0000 - accuracy: 0.9883 - precision: 0.5515 - recall: 0.1663 - auc: 0.8752 - val_loss: 0.0311 - val_tp: 811.0000 - val_fp: 274.0000 - val_tn: 234745.0000 - val_fn: 2028.0000 - val_accuracy: 0.9903 - val_precision: 0.7475 - val_recall: 0.2857 - val_auc: 0.9453
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256885/256885 - 128s - loss: 0.0251 - tp: 1541.0000 - fp: 395.0000 - tn: 253399.0000 - fn: 1550.0000 - accuracy: 0.9924 - precision: 0.7960 - recall: 0.4985 - auc: 0.9656 - val_loss: 0.0218 - val_tp: 1456.0000 - val_fp: 245.0000 - val_tn: 234774.0000 - val_fn: 1383.0000 - val_accuracy: 0.9932 - val_precision: 0.8560 - val_recall: 0.5129 - val_auc: 0.9638
256885/256885 - 128s - loss: 0.0251 - tp: 1541.0000 - fp: 395.0000 - tn: 253399.0000 - fn: 1550.0000 - accuracy: 0.9924 - precision: 0.7960 - recall: 0.4985 - auc: 0.9656 - val_loss: 0.0218 - val_tp: 1456.0000 - val_fp: 245.0000 - val_tn: 234774.0000 - val_fn: 1383.0000 - val_accuracy: 0.9932 - val_precision: 0.8560 - val_recall: 0.5129 - val_auc: 0.9638
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a7c6bbc18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1c121080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a1c121e10>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c7df400>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e1e956d8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a1c119240>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a1c119908>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a1c119c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c056780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ebe91898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49ebb3fda0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49ebb3f780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ebb3ff98>]
          

Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_17 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_51 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_51 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_52 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_53 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256885/256885 - 131s - loss: 0.0431 - tp: 547.0000 - fp: 357.0000 - tn: 253417.0000 - fn: 2564.0000 - accuracy: 0.9886 - precision: 0.6051 - recall: 0.1758 - auc: 0.8992 - val_loss: 0.0294 - val_tp: 773.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 2066.0000 - val_accuracy: 0.9902 - val_precision: 0.7483 - val_recall: 0.2723 - val_auc: 0.9661
256885/256885 - 131s - loss: 0.0431 - tp: 547.0000 - fp: 357.0000 - tn: 253417.0000 - fn: 2564.0000 - accuracy: 0.9886 - precision: 0.6051 - recall: 0.1758 - auc: 0.8992 - val_loss: 0.0294 - val_tp: 773.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 2066.0000 - val_accuracy: 0.9902 - val_precision: 0.7483 - val_recall: 0.2723 - val_auc: 0.9661
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256885/256885 - 129s - loss: 0.0252 - tp: 1513.0000 - fp: 453.0000 - tn: 253321.0000 - fn: 1598.0000 - accuracy: 0.9920 - precision: 0.7696 - recall: 0.4863 - auc: 0.9668 - val_loss: 0.0204 - val_tp: 1582.0000 - val_fp: 306.0000 - val_tn: 234713.0000 - val_fn: 1257.0000 - val_accuracy: 0.9934 - val_precision: 0.8379 - val_recall: 0.5572 - val_auc: 0.9727
256885/256885 - 129s - loss: 0.0252 - tp: 1513.0000 - fp: 453.0000 - tn: 253321.0000 - fn: 1598.0000 - accuracy: 0.9920 - precision: 0.7696 - recall: 0.4863 - auc: 0.9668 - val_loss: 0.0204 - val_tp: 1582.0000 - val_fp: 306.0000 - val_tn: 234713.0000 - val_fn: 1257.0000 - val_accuracy: 0.9934 - val_precision: 0.8379 - val_recall: 0.5572 - val_auc: 0.9727
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a041834a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a041839e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a041837b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a04183b38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a041835f8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a043bc0b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a043bc438>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a043bcf60>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49ebb3fda0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a1d7f1cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a1d7da780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a04183320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a04183358>]
          

Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_18 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_54 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_54 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_55 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_56 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256886/256886 - 132s - loss: 0.0430 - tp: 559.0000 - fp: 347.0000 - tn: 253431.0000 - fn: 2549.0000 - accuracy: 0.9887 - precision: 0.6170 - recall: 0.1799 - auc: 0.8971 - val_loss: 0.0304 - val_tp: 782.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 2057.0000 - val_accuracy: 0.9902 - val_precision: 0.7426 - val_recall: 0.2754 - val_auc: 0.9549
256886/256886 - 132s - loss: 0.0430 - tp: 559.0000 - fp: 347.0000 - tn: 253431.0000 - fn: 2549.0000 - accuracy: 0.9887 - precision: 0.6170 - recall: 0.1799 - auc: 0.8971 - val_loss: 0.0304 - val_tp: 782.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 2057.0000 - val_accuracy: 0.9902 - val_precision: 0.7426 - val_recall: 0.2754 - val_auc: 0.9549
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256886/256886 - 128s - loss: 0.0256 - tp: 1497.0000 - fp: 441.0000 - tn: 253337.0000 - fn: 1611.0000 - accuracy: 0.9920 - precision: 0.7724 - recall: 0.4817 - auc: 0.9646 - val_loss: 0.0225 - val_tp: 1347.0000 - val_fp: 201.0000 - val_tn: 234818.0000 - val_fn: 1492.0000 - val_accuracy: 0.9929 - val_precision: 0.8702 - val_recall: 0.4745 - val_auc: 0.9632
256886/256886 - 128s - loss: 0.0256 - tp: 1497.0000 - fp: 441.0000 - tn: 253337.0000 - fn: 1611.0000 - accuracy: 0.9920 - precision: 0.7724 - recall: 0.4817 - auc: 0.9646 - val_loss: 0.0225 - val_tp: 1347.0000 - val_fp: 201.0000 - val_tn: 234818.0000 - val_fn: 1492.0000 - val_accuracy: 0.9929 - val_precision: 0.8702 - val_recall: 0.4745 - val_auc: 0.9632
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a1c330978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e7ec4470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a1c2f8828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a1c2f8f98>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eaa1a2e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eaa1a6a0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eaa1a940>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eaa1ac50>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49ea9c2c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a04183358>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a041832e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a04183400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ebe8fe80>]
          

Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_19 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_57 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_57 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_58 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_59 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256886/256886 - 131s - loss: 0.0445 - tp: 553.0000 - fp: 386.0000 - tn: 253376.0000 - fn: 2571.0000 - accuracy: 0.9885 - precision: 0.5889 - recall: 0.1770 - auc: 0.8882 - val_loss: 0.0320 - val_tp: 1381.0000 - val_fp: 893.0000 - val_tn: 234126.0000 - val_fn: 1458.0000 - val_accuracy: 0.9901 - val_precision: 0.6073 - val_recall: 0.4864 - val_auc: 0.9767
256886/256886 - 131s - loss: 0.0445 - tp: 553.0000 - fp: 386.0000 - tn: 253376.0000 - fn: 2571.0000 - accuracy: 0.9885 - precision: 0.5889 - recall: 0.1770 - auc: 0.8882 - val_loss: 0.0320 - val_tp: 1381.0000 - val_fp: 893.0000 - val_tn: 234126.0000 - val_fn: 1458.0000 - val_accuracy: 0.9901 - val_precision: 0.6073 - val_recall: 0.4864 - val_auc: 0.9767
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256886/256886 - 129s - loss: 0.0255 - tp: 1515.0000 - fp: 420.0000 - tn: 253342.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7829 - recall: 0.4850 - auc: 0.9670 - val_loss: 0.0198 - val_tp: 1684.0000 - val_fp: 324.0000 - val_tn: 234695.0000 - val_fn: 1155.0000 - val_accuracy: 0.9938 - val_precision: 0.8386 - val_recall: 0.5932 - val_auc: 0.9795
256886/256886 - 129s - loss: 0.0255 - tp: 1515.0000 - fp: 420.0000 - tn: 253342.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7829 - recall: 0.4850 - auc: 0.9670 - val_loss: 0.0198 - val_tp: 1684.0000 - val_fp: 324.0000 - val_tn: 234695.0000 - val_fn: 1155.0000 - val_accuracy: 0.9938 - val_precision: 0.8386 - val_recall: 0.5932 - val_auc: 0.9795
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a402c5c18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb2143c8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb18af98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb18ae48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a04183400>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb1499b0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb1494a8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb149b70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a1c306908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a1c330e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a1c306860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb415c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb2251d0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb1702b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb170550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb1707f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb170a90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb170d30>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb170fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb1093c8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb1096d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb45c4a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb17ec18>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb1aff98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb1afcc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb1af940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb0cd0b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb0cd358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb0cd5f8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb0cd898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb0cdb38>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb0cdef0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb0d71d0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb0d74e0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb170240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb149780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb149940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb149f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb13d9e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb0a56a0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb0a59b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb0a5c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb0a5ef0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb0b61d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb0b6588>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb0b6828>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb0b6b38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb0cd048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb0e8128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb0e8160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb0a5748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb0a5710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb00bef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a5c5352b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a5c535550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c5357f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c535a90>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a5c535e48>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb021128>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb021438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb0a54e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb048780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb048908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb048828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb00bf28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a402d9ac8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a402d9eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a402d9860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a402d92b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a0460dcf8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb13df28>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb1737f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb1af9e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb00beb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a402d9828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a402d9240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a402d9400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a402d95c0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb13df28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb08c860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb455cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb149748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb164cc0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a402d93c8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a402d9f28>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a402d9588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a402d9be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a1c330e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb238d68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb183da0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb475198>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e7fad208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1c21d6a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a402d9710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a402d9cc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a402d9470>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a402d90b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb164dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb1afbe0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb1eca90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb070e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb149748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb149f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb149518>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb13df60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1c224ef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb1af9e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb164f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a402d94a8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a402d97b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a402d9908>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a1c21d4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb455c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a1c1b9d30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a1c1d0e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a1c1d0fd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a1c1d0f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a1c1b9390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a402b3d30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a402d96a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a402d98d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a402d90b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a402d9eb8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb1afbe0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a1c224940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb125ef0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a1c170da0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a1c160390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a1c160d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a1c21d4a8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a1c170cc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a1c224eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb1afcc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb164f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a402d98d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a402d9d30>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a402d9da0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a402b3a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a1c1b9e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e1e6f470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb13dfd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb13ddd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb13de48>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a7c3ef748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a7c3ef9e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a7c3ef4e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a7c3f1198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a7c3f1e48>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a7c3f1d30>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a7c3f17f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a7c3f1400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a1c1706a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a40300cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a40300e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a40300438>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a40300198>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c48fe48>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a5c48fba8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a5c48fb38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c48f6a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c48f9b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a04441be0>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a04441b38>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a044410f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a7c3ef518>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c47ab00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a40300470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a402d9080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a402d99b0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c7d8b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e1e727b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e1e72a20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e1e72f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e1e72080>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e1e72828>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a40404898>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a404043c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c48f400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a7c3ef128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a044375f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a04437b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a5c7d8f98>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a4018eeb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a4018eb38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a4018e780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a4018e390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77be0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e9b77b00>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9b77ac8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9b770b8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c7d8a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c056320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c056160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a4018e978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a4018e908>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e9b77160>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9b77400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9b77080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9b77208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77a58>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a4018e860>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a4018eb00>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a4018e630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a4018e438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c7d8a58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c056160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9af4a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e9b77048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c5a53c8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a4018e9e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a4018e828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a4018eb38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b777f0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e9b77400>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9b77780>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9b77c50>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e9b771d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9b39cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9b39d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9b397b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e9b39a20>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e9b77358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9b77be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9b77da0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9b77320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77438>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a4018e6d8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a4018e908>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a4018ed68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a5c5a50f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c645320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c645630>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a5c645160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a5c6450f0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a4018e4a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a4018e630>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a4018e748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a4018e278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77550>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e9b77518>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9b779b0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9b77780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e1e692b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a5c5d7c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a5c5d78d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e7ec61d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e7ec6358>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb8eb208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9b776d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9b775c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9b77860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77668>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a4018eb00>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a4018eef0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a4018e400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e7ec6a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb8a2278>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a041d9dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a041d9208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a041d9c88>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb8a2390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a4018e710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a4018efd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a4018e588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9b77da0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e9b77358>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9b77f60>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9b777f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb8eb0f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eab467b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb8eb7b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eab55550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eab55c50>]
          

Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 50)                9600      
_________________________________________________________________
dense_60 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_60 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_61 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_62 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256885/256885 - 111s - loss: 0.0445 - tp: 558.0000 - fp: 374.0000 - tn: 253385.0000 - fn: 2568.0000 - accuracy: 0.9885 - precision: 0.5987 - recall: 0.1785 - auc: 0.8890 - val_loss: 0.0306 - val_tp: 636.0000 - val_fp: 177.0000 - val_tn: 234842.0000 - val_fn: 2203.0000 - val_accuracy: 0.9900 - val_precision: 0.7823 - val_recall: 0.2240 - val_auc: 0.9600
256885/256885 - 111s - loss: 0.0445 - tp: 558.0000 - fp: 374.0000 - tn: 253385.0000 - fn: 2568.0000 - accuracy: 0.9885 - precision: 0.5987 - recall: 0.1785 - auc: 0.8890 - val_loss: 0.0306 - val_tp: 636.0000 - val_fp: 177.0000 - val_tn: 234842.0000 - val_fn: 2203.0000 - val_accuracy: 0.9900 - val_precision: 0.7823 - val_recall: 0.2240 - val_auc: 0.9600
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.69391
256885/256885 - 108s - loss: 0.0258 - tp: 1470.0000 - fp: 413.0000 - tn: 253346.0000 - fn: 1656.0000 - accuracy: 0.9919 - precision: 0.7807 - recall: 0.4702 - auc: 0.9684 - val_loss: 0.0203 - val_tp: 1654.0000 - val_fp: 394.0000 - val_tn: 234625.0000 - val_fn: 1185.0000 - val_accuracy: 0.9934 - val_precision: 0.8076 - val_recall: 0.5826 - val_auc: 0.9797
256885/256885 - 108s - loss: 0.0258 - tp: 1470.0000 - fp: 413.0000 - tn: 253346.0000 - fn: 1656.0000 - accuracy: 0.9919 - precision: 0.7807 - recall: 0.4702 - auc: 0.9684 - val_loss: 0.0203 - val_tp: 1654.0000 - val_fp: 394.0000 - val_tn: 234625.0000 - val_fn: 1185.0000 - val_accuracy: 0.9934 - val_precision: 0.8076 - val_recall: 0.5826 - val_auc: 0.9797
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eafcccc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eafe8be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ebcae048>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49ebcae1d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c0be2e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a041834e0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ebc079b0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ebc07a90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eab55550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ebc01fd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49ead5eb70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49ebc7bf60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e9b770b8>]
          

Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_63 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_63 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_64 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_65 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.69391
256885/256885 - 111s - loss: 0.0422 - tp: 589.0000 - fp: 363.0000 - tn: 253395.0000 - fn: 2538.0000 - accuracy: 0.9887 - precision: 0.6187 - recall: 0.1884 - auc: 0.9063 - val_loss: 0.0302 - val_tp: 1171.0000 - val_fp: 576.0000 - val_tn: 234443.0000 - val_fn: 1668.0000 - val_accuracy: 0.9906 - val_precision: 0.6703 - val_recall: 0.4125 - val_auc: 0.9749
256885/256885 - 111s - loss: 0.0422 - tp: 589.0000 - fp: 363.0000 - tn: 253395.0000 - fn: 2538.0000 - accuracy: 0.9887 - precision: 0.6187 - recall: 0.1884 - auc: 0.9063 - val_loss: 0.0302 - val_tp: 1171.0000 - val_fp: 576.0000 - val_tn: 234443.0000 - val_fn: 1668.0000 - val_accuracy: 0.9906 - val_precision: 0.6703 - val_recall: 0.4125 - val_auc: 0.9749
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.69391 to 0.73054, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 108s - loss: 0.0250 - tp: 1541.0000 - fp: 417.0000 - tn: 253341.0000 - fn: 1586.0000 - accuracy: 0.9922 - precision: 0.7870 - recall: 0.4928 - auc: 0.9700 - val_loss: 0.0245 - val_tp: 2074.0000 - val_fp: 1052.0000 - val_tn: 233967.0000 - val_fn: 765.0000 - val_accuracy: 0.9924 - val_precision: 0.6635 - val_recall: 0.7305 - val_auc: 0.9874
256885/256885 - 108s - loss: 0.0250 - tp: 1541.0000 - fp: 417.0000 - tn: 253341.0000 - fn: 1586.0000 - accuracy: 0.9922 - precision: 0.7870 - recall: 0.4928 - auc: 0.9700 - val_loss: 0.0245 - val_tp: 2074.0000 - val_fp: 1052.0000 - val_tn: 233967.0000 - val_fn: 765.0000 - val_accuracy: 0.9924 - val_precision: 0.6635 - val_recall: 0.7305 - val_auc: 0.9874
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a5c4de240>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a5c57d048>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a4029f940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a4029fa58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a4029f3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a4029fe48>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a4029f198>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eacce358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49ebc7bf60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ead5e2b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49ead5eb70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eac77908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eabf5d68>]
          

Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_2 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_66 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_66 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_67 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_68 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 111s - loss: 0.0429 - tp: 516.0000 - fp: 299.0000 - tn: 253470.0000 - fn: 2600.0000 - accuracy: 0.9887 - precision: 0.6331 - recall: 0.1656 - auc: 0.9030 - val_loss: 0.0299 - val_tp: 771.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2068.0000 - val_accuracy: 0.9903 - val_precision: 0.7687 - val_recall: 0.2716 - val_auc: 0.9566
256885/256885 - 111s - loss: 0.0429 - tp: 516.0000 - fp: 299.0000 - tn: 253470.0000 - fn: 2600.0000 - accuracy: 0.9887 - precision: 0.6331 - recall: 0.1656 - auc: 0.9030 - val_loss: 0.0299 - val_tp: 771.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2068.0000 - val_accuracy: 0.9903 - val_precision: 0.7687 - val_recall: 0.2716 - val_auc: 0.9566
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0246 - tp: 1557.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 1559.0000 - accuracy: 0.9924 - precision: 0.7956 - recall: 0.4997 - auc: 0.9684 - val_loss: 0.0211 - val_tp: 1465.0000 - val_fp: 199.0000 - val_tn: 234820.0000 - val_fn: 1374.0000 - val_accuracy: 0.9934 - val_precision: 0.8804 - val_recall: 0.5160 - val_auc: 0.9662
256885/256885 - 108s - loss: 0.0246 - tp: 1557.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 1559.0000 - accuracy: 0.9924 - precision: 0.7956 - recall: 0.4997 - auc: 0.9684 - val_loss: 0.0211 - val_tp: 1465.0000 - val_fp: 199.0000 - val_tn: 234820.0000 - val_fn: 1374.0000 - val_accuracy: 0.9934 - val_precision: 0.8804 - val_recall: 0.5160 - val_auc: 0.9662
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ea690668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ea775358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ea775518>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9ade940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ea687828>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ea687a90>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ea6879e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea687048>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eabf5e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ebc88898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a043a15f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb8eb320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ebc01fd0>]
          

Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_3 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_69 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_69 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_70 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_71 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 111s - loss: 0.0448 - tp: 515.0000 - fp: 424.0000 - tn: 253368.0000 - fn: 2578.0000 - accuracy: 0.9883 - precision: 0.5485 - recall: 0.1665 - auc: 0.8816 - val_loss: 0.0311 - val_tp: 1040.0000 - val_fp: 532.0000 - val_tn: 234487.0000 - val_fn: 1799.0000 - val_accuracy: 0.9902 - val_precision: 0.6616 - val_recall: 0.3663 - val_auc: 0.9673
256885/256885 - 111s - loss: 0.0448 - tp: 515.0000 - fp: 424.0000 - tn: 253368.0000 - fn: 2578.0000 - accuracy: 0.9883 - precision: 0.5485 - recall: 0.1665 - auc: 0.8816 - val_loss: 0.0311 - val_tp: 1040.0000 - val_fp: 532.0000 - val_tn: 234487.0000 - val_fn: 1799.0000 - val_accuracy: 0.9902 - val_precision: 0.6616 - val_recall: 0.3663 - val_auc: 0.9673
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0274 - tp: 1307.0000 - fp: 394.0000 - tn: 253398.0000 - fn: 1786.0000 - accuracy: 0.9915 - precision: 0.7684 - recall: 0.4226 - auc: 0.9655 - val_loss: 0.0234 - val_tp: 1321.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 1518.0000 - val_accuracy: 0.9925 - val_precision: 0.8366 - val_recall: 0.4653 - val_auc: 0.9661
256885/256885 - 108s - loss: 0.0274 - tp: 1307.0000 - fp: 394.0000 - tn: 253398.0000 - fn: 1786.0000 - accuracy: 0.9915 - precision: 0.7684 - recall: 0.4226 - auc: 0.9655 - val_loss: 0.0234 - val_tp: 1321.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 1518.0000 - val_accuracy: 0.9925 - val_precision: 0.8366 - val_recall: 0.4653 - val_auc: 0.9661
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4a402b3940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a402b31d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eac2a7f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb46f8d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb45cdd8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb45c8d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb45c710>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea0484e0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb8eb7b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ebc88358>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a402b3160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a402b3f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a402b3f28>]
          

Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_4 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_72 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_72 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_73 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_74 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 111s - loss: 0.0466 - tp: 520.0000 - fp: 495.0000 - tn: 253244.0000 - fn: 2626.0000 - accuracy: 0.9879 - precision: 0.5123 - recall: 0.1653 - auc: 0.8825 - val_loss: 0.0302 - val_tp: 754.0000 - val_fp: 262.0000 - val_tn: 234757.0000 - val_fn: 2085.0000 - val_accuracy: 0.9901 - val_precision: 0.7421 - val_recall: 0.2656 - val_auc: 0.9671
256885/256885 - 111s - loss: 0.0466 - tp: 520.0000 - fp: 495.0000 - tn: 253244.0000 - fn: 2626.0000 - accuracy: 0.9879 - precision: 0.5123 - recall: 0.1653 - auc: 0.8825 - val_loss: 0.0302 - val_tp: 754.0000 - val_fp: 262.0000 - val_tn: 234757.0000 - val_fn: 2085.0000 - val_accuracy: 0.9901 - val_precision: 0.7421 - val_recall: 0.2656 - val_auc: 0.9671
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0264 - tp: 1459.0000 - fp: 407.0000 - tn: 253332.0000 - fn: 1687.0000 - accuracy: 0.9918 - precision: 0.7819 - recall: 0.4638 - auc: 0.9688 - val_loss: 0.0204 - val_tp: 1664.0000 - val_fp: 380.0000 - val_tn: 234639.0000 - val_fn: 1175.0000 - val_accuracy: 0.9935 - val_precision: 0.8141 - val_recall: 0.5861 - val_auc: 0.9779
256885/256885 - 108s - loss: 0.0264 - tp: 1459.0000 - fp: 407.0000 - tn: 253332.0000 - fn: 1687.0000 - accuracy: 0.9918 - precision: 0.7819 - recall: 0.4638 - auc: 0.9688 - val_loss: 0.0204 - val_tp: 1664.0000 - val_fp: 380.0000 - val_tn: 234639.0000 - val_fn: 1175.0000 - val_accuracy: 0.9935 - val_precision: 0.8141 - val_recall: 0.5861 - val_auc: 0.9779
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb4e6b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb7abda0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb7abe80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb7abfd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb7bf2b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb7bf668>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb7bf908>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb7bfc18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a402b3f60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4a402b3278>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a402b3fd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a402b3e80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb8eb7b8>]
          

Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_5 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_75 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_75 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_76 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_77 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 111s - loss: 0.0436 - tp: 549.0000 - fp: 322.0000 - tn: 253456.0000 - fn: 2558.0000 - accuracy: 0.9888 - precision: 0.6303 - recall: 0.1767 - auc: 0.8952 - val_loss: 0.0300 - val_tp: 912.0000 - val_fp: 382.0000 - val_tn: 234637.0000 - val_fn: 1927.0000 - val_accuracy: 0.9903 - val_precision: 0.7048 - val_recall: 0.3212 - val_auc: 0.9637
256885/256885 - 111s - loss: 0.0436 - tp: 549.0000 - fp: 322.0000 - tn: 253456.0000 - fn: 2558.0000 - accuracy: 0.9888 - precision: 0.6303 - recall: 0.1767 - auc: 0.8952 - val_loss: 0.0300 - val_tp: 912.0000 - val_fp: 382.0000 - val_tn: 234637.0000 - val_fn: 1927.0000 - val_accuracy: 0.9903 - val_precision: 0.7048 - val_recall: 0.3212 - val_auc: 0.9637
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0269 - tp: 1359.0000 - fp: 418.0000 - tn: 253360.0000 - fn: 1748.0000 - accuracy: 0.9916 - precision: 0.7648 - recall: 0.4374 - auc: 0.9658 - val_loss: 0.0217 - val_tp: 1621.0000 - val_fp: 422.0000 - val_tn: 234597.0000 - val_fn: 1218.0000 - val_accuracy: 0.9931 - val_precision: 0.7934 - val_recall: 0.5710 - val_auc: 0.9846
256885/256885 - 108s - loss: 0.0269 - tp: 1359.0000 - fp: 418.0000 - tn: 253360.0000 - fn: 1748.0000 - accuracy: 0.9916 - precision: 0.7648 - recall: 0.4374 - auc: 0.9658 - val_loss: 0.0217 - val_tp: 1621.0000 - val_fp: 422.0000 - val_tn: 234597.0000 - val_fn: 1218.0000 - val_accuracy: 0.9931 - val_precision: 0.7934 - val_recall: 0.5710 - val_auc: 0.9846
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d6cc0cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9c162b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a1c08b0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9943470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9943c18>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e9943240>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9943f98>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9943780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a402b3fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e99b6fd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e99b6a90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d6eabb38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d6ea0518>]
          

Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_6 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_78 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_78 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_79 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_26 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_80 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 112s - loss: 0.0421 - tp: 576.0000 - fp: 356.0000 - tn: 253438.0000 - fn: 2515.0000 - accuracy: 0.9888 - precision: 0.6180 - recall: 0.1863 - auc: 0.9009 - val_loss: 0.0314 - val_tp: 779.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2060.0000 - val_accuracy: 0.9903 - val_precision: 0.7512 - val_recall: 0.2744 - val_auc: 0.9440
256885/256885 - 112s - loss: 0.0421 - tp: 576.0000 - fp: 356.0000 - tn: 253438.0000 - fn: 2515.0000 - accuracy: 0.9888 - precision: 0.6180 - recall: 0.1863 - auc: 0.9009 - val_loss: 0.0314 - val_tp: 779.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2060.0000 - val_accuracy: 0.9903 - val_precision: 0.7512 - val_recall: 0.2744 - val_auc: 0.9440
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0251 - tp: 1510.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1581.0000 - accuracy: 0.9922 - precision: 0.7860 - recall: 0.4885 - auc: 0.9648 - val_loss: 0.0209 - val_tp: 1497.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1342.0000 - val_accuracy: 0.9933 - val_precision: 0.8603 - val_recall: 0.5273 - val_auc: 0.9714
256885/256885 - 108s - loss: 0.0251 - tp: 1510.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1581.0000 - accuracy: 0.9922 - precision: 0.7860 - recall: 0.4885 - auc: 0.9648 - val_loss: 0.0209 - val_tp: 1497.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1342.0000 - val_accuracy: 0.9933 - val_precision: 0.8603 - val_recall: 0.5273 - val_auc: 0.9714
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d6df87f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a4030b6d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a5c5f3b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a5c5f31d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a5c5f3ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a5c5f3f60>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a1c2ed828>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a1c2ed5f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e99b6fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d6ea0518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e99b6f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e810f8d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb912860>]
          

Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_7 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_81 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_81 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_82 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_83 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 111s - loss: 0.0435 - tp: 542.0000 - fp: 304.0000 - tn: 253470.0000 - fn: 2569.0000 - accuracy: 0.9888 - precision: 0.6407 - recall: 0.1742 - auc: 0.8958 - val_loss: 0.0281 - val_tp: 921.0000 - val_fp: 302.0000 - val_tn: 234717.0000 - val_fn: 1918.0000 - val_accuracy: 0.9907 - val_precision: 0.7531 - val_recall: 0.3244 - val_auc: 0.9672
256885/256885 - 111s - loss: 0.0435 - tp: 542.0000 - fp: 304.0000 - tn: 253470.0000 - fn: 2569.0000 - accuracy: 0.9888 - precision: 0.6407 - recall: 0.1742 - auc: 0.8958 - val_loss: 0.0281 - val_tp: 921.0000 - val_fp: 302.0000 - val_tn: 234717.0000 - val_fn: 1918.0000 - val_accuracy: 0.9907 - val_precision: 0.7531 - val_recall: 0.3244 - val_auc: 0.9672
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0246 - tp: 1539.0000 - fp: 385.0000 - tn: 253389.0000 - fn: 1572.0000 - accuracy: 0.9924 - precision: 0.7999 - recall: 0.4947 - auc: 0.9690 - val_loss: 0.0198 - val_tp: 1859.0000 - val_fp: 499.0000 - val_tn: 234520.0000 - val_fn: 980.0000 - val_accuracy: 0.9938 - val_precision: 0.7884 - val_recall: 0.6548 - val_auc: 0.9822
256885/256885 - 108s - loss: 0.0246 - tp: 1539.0000 - fp: 385.0000 - tn: 253389.0000 - fn: 1572.0000 - accuracy: 0.9924 - precision: 0.7999 - recall: 0.4947 - auc: 0.9690 - val_loss: 0.0198 - val_tp: 1859.0000 - val_fp: 499.0000 - val_tn: 234520.0000 - val_fn: 980.0000 - val_accuracy: 0.9938 - val_precision: 0.7884 - val_recall: 0.6548 - val_auc: 0.9822
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d714aeb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e1cebf60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e1d01da0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e1d01a58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e1d015f8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e1d01668>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e1d01780>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9cdd0f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e810f828>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e99f6a90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49ea2d7cc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d7147a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d714af28>]
          

Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_8 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_84 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_84 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_85 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_28 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_86 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256886/256886 - 111s - loss: 0.0429 - tp: 534.0000 - fp: 312.0000 - tn: 253466.0000 - fn: 2574.0000 - accuracy: 0.9888 - precision: 0.6312 - recall: 0.1718 - auc: 0.8995 - val_loss: 0.0365 - val_tp: 1318.0000 - val_fp: 971.0000 - val_tn: 234048.0000 - val_fn: 1521.0000 - val_accuracy: 0.9895 - val_precision: 0.5758 - val_recall: 0.4642 - val_auc: 0.9750
256886/256886 - 111s - loss: 0.0429 - tp: 534.0000 - fp: 312.0000 - tn: 253466.0000 - fn: 2574.0000 - accuracy: 0.9888 - precision: 0.6312 - recall: 0.1718 - auc: 0.8995 - val_loss: 0.0365 - val_tp: 1318.0000 - val_fp: 971.0000 - val_tn: 234048.0000 - val_fn: 1521.0000 - val_accuracy: 0.9895 - val_precision: 0.5758 - val_recall: 0.4642 - val_auc: 0.9750
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256886/256886 - 108s - loss: 0.0264 - tp: 1381.0000 - fp: 428.0000 - tn: 253350.0000 - fn: 1727.0000 - accuracy: 0.9916 - precision: 0.7634 - recall: 0.4443 - auc: 0.9663 - val_loss: 0.0232 - val_tp: 1805.0000 - val_fp: 650.0000 - val_tn: 234369.0000 - val_fn: 1034.0000 - val_accuracy: 0.9929 - val_precision: 0.7352 - val_recall: 0.6358 - val_auc: 0.9860
256886/256886 - 108s - loss: 0.0264 - tp: 1381.0000 - fp: 428.0000 - tn: 253350.0000 - fn: 1727.0000 - accuracy: 0.9916 - precision: 0.7634 - recall: 0.4443 - auc: 0.9663 - val_loss: 0.0232 - val_tp: 1805.0000 - val_fp: 650.0000 - val_tn: 234369.0000 - val_fn: 1034.0000 - val_accuracy: 0.9929 - val_precision: 0.7352 - val_recall: 0.6358 - val_auc: 0.9860
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ebbf9588>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a5c6592e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb5df630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb5bdb00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49eb5bd208>, <tensorflow.python.keras.metrics.Precision object at 0x7f49eb5bd390>, <tensorflow.python.keras.metrics.Recall object at 0x7f49eb5bd1d0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb5bdeb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d714acc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb503748>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb5037b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb503208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb503e80>]
          

Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_9 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_87 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_87 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_88 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_29 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_89 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256886/256886 - 111s - loss: 0.0417 - tp: 598.0000 - fp: 293.0000 - tn: 253469.0000 - fn: 2526.0000 - accuracy: 0.9890 - precision: 0.6712 - recall: 0.1914 - auc: 0.9098 - val_loss: 0.0272 - val_tp: 1367.0000 - val_fp: 576.0000 - val_tn: 234443.0000 - val_fn: 1472.0000 - val_accuracy: 0.9914 - val_precision: 0.7036 - val_recall: 0.4815 - val_auc: 0.9748
256886/256886 - 111s - loss: 0.0417 - tp: 598.0000 - fp: 293.0000 - tn: 253469.0000 - fn: 2526.0000 - accuracy: 0.9890 - precision: 0.6712 - recall: 0.1914 - auc: 0.9098 - val_loss: 0.0272 - val_tp: 1367.0000 - val_fp: 576.0000 - val_tn: 234443.0000 - val_fn: 1472.0000 - val_accuracy: 0.9914 - val_precision: 0.7036 - val_recall: 0.4815 - val_auc: 0.9748
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256886/256886 - 108s - loss: 0.0238 - tp: 1657.0000 - fp: 395.0000 - tn: 253367.0000 - fn: 1467.0000 - accuracy: 0.9928 - precision: 0.8075 - recall: 0.5304 - auc: 0.9694 - val_loss: 0.0194 - val_tp: 1747.0000 - val_fp: 323.0000 - val_tn: 234696.0000 - val_fn: 1092.0000 - val_accuracy: 0.9941 - val_precision: 0.8440 - val_recall: 0.6154 - val_auc: 0.9826
256886/256886 - 108s - loss: 0.0238 - tp: 1657.0000 - fp: 395.0000 - tn: 253367.0000 - fn: 1467.0000 - accuracy: 0.9928 - precision: 0.8075 - recall: 0.5304 - auc: 0.9694 - val_loss: 0.0194 - val_tp: 1747.0000 - val_fp: 323.0000 - val_tn: 234696.0000 - val_fn: 1092.0000 - val_accuracy: 0.9941 - val_precision: 0.8440 - val_recall: 0.6154 - val_auc: 0.9826
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ead40898>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ea3a8c88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49eb2c92e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49eb2e6d30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ead21390>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ead217f0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ead21a90>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ead21da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb503208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb503278>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb503550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb503da0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ea3ae550>]
          

Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_90 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_90 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_91 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_91 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_30 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_92 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_92 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0411 - tp: 658.0000 - fp: 358.0000 - tn: 253401.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6476 - recall: 0.2105 - auc: 0.9098 - val_loss: 0.0275 - val_tp: 1144.0000 - val_fp: 454.0000 - val_tn: 234565.0000 - val_fn: 1695.0000 - val_accuracy: 0.9910 - val_precision: 0.7159 - val_recall: 0.4030 - val_auc: 0.9663
256885/256885 - 128s - loss: 0.0411 - tp: 658.0000 - fp: 358.0000 - tn: 253401.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6476 - recall: 0.2105 - auc: 0.9098 - val_loss: 0.0275 - val_tp: 1144.0000 - val_fp: 454.0000 - val_tn: 234565.0000 - val_fn: 1695.0000 - val_accuracy: 0.9910 - val_precision: 0.7159 - val_recall: 0.4030 - val_auc: 0.9663
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 126s - loss: 0.0245 - tp: 1613.0000 - fp: 456.0000 - tn: 253303.0000 - fn: 1513.0000 - accuracy: 0.9923 - precision: 0.7796 - recall: 0.5160 - auc: 0.9682 - val_loss: 0.0226 - val_tp: 1403.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1436.0000 - val_accuracy: 0.9932 - val_precision: 0.8818 - val_recall: 0.4942 - val_auc: 0.9568
256885/256885 - 126s - loss: 0.0245 - tp: 1613.0000 - fp: 456.0000 - tn: 253303.0000 - fn: 1513.0000 - accuracy: 0.9923 - precision: 0.7796 - recall: 0.5160 - auc: 0.9682 - val_loss: 0.0226 - val_tp: 1403.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1436.0000 - val_accuracy: 0.9932 - val_precision: 0.8818 - val_recall: 0.4942 - val_auc: 0.9568
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8cdaeb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8cdaba8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d6a9fcf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8cfea90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8c98160>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8c98b00>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8c985c0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8c98cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb503550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d714a9b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb503cc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d40ced30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d6b18b38>]
          

Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_11 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_93 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_93 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_94 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_94 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_31 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_95 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_95 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0435 - tp: 582.0000 - fp: 395.0000 - tn: 253363.0000 - fn: 2545.0000 - accuracy: 0.9886 - precision: 0.5957 - recall: 0.1861 - auc: 0.8977 - val_loss: 0.0334 - val_tp: 1519.0000 - val_fp: 1245.0000 - val_tn: 233774.0000 - val_fn: 1320.0000 - val_accuracy: 0.9892 - val_precision: 0.5496 - val_recall: 0.5350 - val_auc: 0.9770
256885/256885 - 128s - loss: 0.0435 - tp: 582.0000 - fp: 395.0000 - tn: 253363.0000 - fn: 2545.0000 - accuracy: 0.9886 - precision: 0.5957 - recall: 0.1861 - auc: 0.8977 - val_loss: 0.0334 - val_tp: 1519.0000 - val_fp: 1245.0000 - val_tn: 233774.0000 - val_fn: 1320.0000 - val_accuracy: 0.9892 - val_precision: 0.5496 - val_recall: 0.5350 - val_auc: 0.9770
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 125s - loss: 0.0251 - tp: 1522.0000 - fp: 415.0000 - tn: 253343.0000 - fn: 1605.0000 - accuracy: 0.9921 - precision: 0.7858 - recall: 0.4867 - auc: 0.9664 - val_loss: 0.0203 - val_tp: 1814.0000 - val_fp: 527.0000 - val_tn: 234492.0000 - val_fn: 1025.0000 - val_accuracy: 0.9935 - val_precision: 0.7749 - val_recall: 0.6390 - val_auc: 0.9828
256885/256885 - 125s - loss: 0.0251 - tp: 1522.0000 - fp: 415.0000 - tn: 253343.0000 - fn: 1605.0000 - accuracy: 0.9921 - precision: 0.7858 - recall: 0.4867 - auc: 0.9664 - val_loss: 0.0203 - val_tp: 1814.0000 - val_fp: 527.0000 - val_tn: 234492.0000 - val_fn: 1025.0000 - val_accuracy: 0.9935 - val_precision: 0.7749 - val_recall: 0.6390 - val_auc: 0.9828
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d6c8d390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8ccc4a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8ccc828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8d10048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8d102b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8d10dd8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8d10ba8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8d104a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d6ac9a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ea007c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8d307b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8cdae80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8cdac50>]
          

Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_12 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_96 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_96 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_97 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_97 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_32 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_98 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_98 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0453 - tp: 505.0000 - fp: 482.0000 - tn: 253287.0000 - fn: 2611.0000 - accuracy: 0.9880 - precision: 0.5117 - recall: 0.1621 - auc: 0.8911 - val_loss: 0.0290 - val_tp: 762.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2077.0000 - val_accuracy: 0.9902 - val_precision: 0.7575 - val_recall: 0.2684 - val_auc: 0.9662
256885/256885 - 128s - loss: 0.0453 - tp: 505.0000 - fp: 482.0000 - tn: 253287.0000 - fn: 2611.0000 - accuracy: 0.9880 - precision: 0.5117 - recall: 0.1621 - auc: 0.8911 - val_loss: 0.0290 - val_tp: 762.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2077.0000 - val_accuracy: 0.9902 - val_precision: 0.7575 - val_recall: 0.2684 - val_auc: 0.9662
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 125s - loss: 0.0249 - tp: 1504.0000 - fp: 426.0000 - tn: 253343.0000 - fn: 1612.0000 - accuracy: 0.9921 - precision: 0.7793 - recall: 0.4827 - auc: 0.9686 - val_loss: 0.0197 - val_tp: 1623.0000 - val_fp: 266.0000 - val_tn: 234753.0000 - val_fn: 1216.0000 - val_accuracy: 0.9938 - val_precision: 0.8592 - val_recall: 0.5717 - val_auc: 0.9753
256885/256885 - 125s - loss: 0.0249 - tp: 1504.0000 - fp: 426.0000 - tn: 253343.0000 - fn: 1612.0000 - accuracy: 0.9921 - precision: 0.7793 - recall: 0.4827 - auc: 0.9686 - val_loss: 0.0197 - val_tp: 1623.0000 - val_fp: 266.0000 - val_tn: 234753.0000 - val_fn: 1216.0000 - val_accuracy: 0.9938 - val_precision: 0.8592 - val_recall: 0.5717 - val_auc: 0.9753
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb318630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d6c75588>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d6c750b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d6c75208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9c167b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d6f0a048>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d40d2748>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d40d22e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e9c160b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9c1ac50>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a1c08b400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e1d002e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eabf5b00>]
          

Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_13 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_99 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_99 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_100 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_100 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_33 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_101 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_101 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0424 - tp: 613.0000 - fp: 321.0000 - tn: 253471.0000 - fn: 2480.0000 - accuracy: 0.9891 - precision: 0.6563 - recall: 0.1982 - auc: 0.8971 - val_loss: 0.0336 - val_tp: 611.0000 - val_fp: 165.0000 - val_tn: 234854.0000 - val_fn: 2228.0000 - val_accuracy: 0.9899 - val_precision: 0.7874 - val_recall: 0.2152 - val_auc: 0.9326
256885/256885 - 128s - loss: 0.0424 - tp: 613.0000 - fp: 321.0000 - tn: 253471.0000 - fn: 2480.0000 - accuracy: 0.9891 - precision: 0.6563 - recall: 0.1982 - auc: 0.8971 - val_loss: 0.0336 - val_tp: 611.0000 - val_fp: 165.0000 - val_tn: 234854.0000 - val_fn: 2228.0000 - val_accuracy: 0.9899 - val_precision: 0.7874 - val_recall: 0.2152 - val_auc: 0.9326
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 124s - loss: 0.0255 - tp: 1484.0000 - fp: 421.0000 - tn: 253371.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7790 - recall: 0.4798 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1779.0000 - val_fp: 526.0000 - val_tn: 234493.0000 - val_fn: 1060.0000 - val_accuracy: 0.9933 - val_precision: 0.7718 - val_recall: 0.6266 - val_auc: 0.9813
256885/256885 - 124s - loss: 0.0255 - tp: 1484.0000 - fp: 421.0000 - tn: 253371.0000 - fn: 1609.0000 - accuracy: 0.9921 - precision: 0.7790 - recall: 0.4798 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1779.0000 - val_fp: 526.0000 - val_tn: 234493.0000 - val_fn: 1060.0000 - val_accuracy: 0.9933 - val_precision: 0.7718 - val_recall: 0.6266 - val_auc: 0.9813
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8527a90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9494c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9494e80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e949e6a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e949e940>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e949ecf8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e949ef98>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e94b12e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a1c08b400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ead70630>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9ade748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8a6dba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8532b38>]
          

Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_102 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_102 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_103 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_103 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_34 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_104 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_104 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 127s - loss: 0.0426 - tp: 608.0000 - fp: 346.0000 - tn: 253393.0000 - fn: 2538.0000 - accuracy: 0.9888 - precision: 0.6373 - recall: 0.1933 - auc: 0.9001 - val_loss: 0.0281 - val_tp: 1111.0000 - val_fp: 461.0000 - val_tn: 234558.0000 - val_fn: 1728.0000 - val_accuracy: 0.9908 - val_precision: 0.7067 - val_recall: 0.3913 - val_auc: 0.9667
256885/256885 - 127s - loss: 0.0426 - tp: 608.0000 - fp: 346.0000 - tn: 253393.0000 - fn: 2538.0000 - accuracy: 0.9888 - precision: 0.6373 - recall: 0.1933 - auc: 0.9001 - val_loss: 0.0281 - val_tp: 1111.0000 - val_fp: 461.0000 - val_tn: 234558.0000 - val_fn: 1728.0000 - val_accuracy: 0.9908 - val_precision: 0.7067 - val_recall: 0.3913 - val_auc: 0.9667
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 126s - loss: 0.0247 - tp: 1593.0000 - fp: 433.0000 - tn: 253306.0000 - fn: 1553.0000 - accuracy: 0.9923 - precision: 0.7863 - recall: 0.5064 - auc: 0.9690 - val_loss: 0.0197 - val_tp: 1817.0000 - val_fp: 441.0000 - val_tn: 234578.0000 - val_fn: 1022.0000 - val_accuracy: 0.9938 - val_precision: 0.8047 - val_recall: 0.6400 - val_auc: 0.9842
256885/256885 - 126s - loss: 0.0247 - tp: 1593.0000 - fp: 433.0000 - tn: 253306.0000 - fn: 1553.0000 - accuracy: 0.9923 - precision: 0.7863 - recall: 0.5064 - auc: 0.9690 - val_loss: 0.0197 - val_tp: 1817.0000 - val_fp: 441.0000 - val_tn: 234578.0000 - val_fn: 1022.0000 - val_accuracy: 0.9938 - val_precision: 0.8047 - val_recall: 0.6400 - val_auc: 0.9842
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e92706d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e91cc668>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a041c6908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4a041c6c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4a041c6b00>, <tensorflow.python.keras.metrics.Precision object at 0x7f4a04256240>, <tensorflow.python.keras.metrics.Recall object at 0x7f4a042564e0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49eb99b8d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e94faf60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e94faf28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c3415dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8246ac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d4138668>]
          

Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_15 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_105 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_105 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_106 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_106 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_35 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_107 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_107 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0439 - tp: 574.0000 - fp: 418.0000 - tn: 253360.0000 - fn: 2533.0000 - accuracy: 0.9885 - precision: 0.5786 - recall: 0.1847 - auc: 0.8929 - val_loss: 0.0288 - val_tp: 1072.0000 - val_fp: 427.0000 - val_tn: 234592.0000 - val_fn: 1767.0000 - val_accuracy: 0.9908 - val_precision: 0.7151 - val_recall: 0.3776 - val_auc: 0.9564
256885/256885 - 128s - loss: 0.0439 - tp: 574.0000 - fp: 418.0000 - tn: 253360.0000 - fn: 2533.0000 - accuracy: 0.9885 - precision: 0.5786 - recall: 0.1847 - auc: 0.8929 - val_loss: 0.0288 - val_tp: 1072.0000 - val_fp: 427.0000 - val_tn: 234592.0000 - val_fn: 1767.0000 - val_accuracy: 0.9908 - val_precision: 0.7151 - val_recall: 0.3776 - val_auc: 0.9564
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 125s - loss: 0.0245 - tp: 1590.0000 - fp: 413.0000 - tn: 253365.0000 - fn: 1517.0000 - accuracy: 0.9925 - precision: 0.7938 - recall: 0.5117 - auc: 0.9674 - val_loss: 0.0196 - val_tp: 1886.0000 - val_fp: 465.0000 - val_tn: 234554.0000 - val_fn: 953.0000 - val_accuracy: 0.9940 - val_precision: 0.8022 - val_recall: 0.6643 - val_auc: 0.9858
256885/256885 - 125s - loss: 0.0245 - tp: 1590.0000 - fp: 413.0000 - tn: 253365.0000 - fn: 1517.0000 - accuracy: 0.9925 - precision: 0.7938 - recall: 0.5117 - auc: 0.9674 - val_loss: 0.0196 - val_tp: 1886.0000 - val_fp: 465.0000 - val_tn: 234554.0000 - val_fn: 953.0000 - val_accuracy: 0.9940 - val_precision: 0.8022 - val_recall: 0.6643 - val_auc: 0.9858
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 24s
256885/256885 - 24s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb3bf3c8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49eb6792e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ead570b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49ead57dd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ead57710>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ead57240>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ead57978>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d69e1160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3415dd8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d4138668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8246a90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e94e7cf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e99c2828>]
          

Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_16 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_108 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_108 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_109 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_109 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_36 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_110 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_110 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0432 - tp: 570.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 2521.0000 - accuracy: 0.9886 - precision: 0.5834 - recall: 0.1844 - auc: 0.8986 - val_loss: 0.0289 - val_tp: 862.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1977.0000 - val_accuracy: 0.9905 - val_precision: 0.7522 - val_recall: 0.3036 - val_auc: 0.9630
256885/256885 - 128s - loss: 0.0432 - tp: 570.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 2521.0000 - accuracy: 0.9886 - precision: 0.5834 - recall: 0.1844 - auc: 0.8986 - val_loss: 0.0289 - val_tp: 862.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1977.0000 - val_accuracy: 0.9905 - val_precision: 0.7522 - val_recall: 0.3036 - val_auc: 0.9630
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 126s - loss: 0.0249 - tp: 1531.0000 - fp: 412.0000 - tn: 253382.0000 - fn: 1560.0000 - accuracy: 0.9923 - precision: 0.7880 - recall: 0.4953 - auc: 0.9668 - val_loss: 0.0206 - val_tp: 1445.0000 - val_fp: 226.0000 - val_tn: 234793.0000 - val_fn: 1394.0000 - val_accuracy: 0.9932 - val_precision: 0.8648 - val_recall: 0.5090 - val_auc: 0.9799
256885/256885 - 126s - loss: 0.0249 - tp: 1531.0000 - fp: 412.0000 - tn: 253382.0000 - fn: 1560.0000 - accuracy: 0.9923 - precision: 0.7880 - recall: 0.4953 - auc: 0.9668 - val_loss: 0.0206 - val_tp: 1445.0000 - val_fp: 226.0000 - val_tn: 234793.0000 - val_fn: 1394.0000 - val_accuracy: 0.9932 - val_precision: 0.8648 - val_recall: 0.5090 - val_auc: 0.9799
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ea089a20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d40186a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d40185c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d4018080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8a36940>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e7ff9d30>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e95c3c50>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e95c3860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8246a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ea0c5ef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c3f725c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e820fc88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e820f1d0>]
          

Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_17 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_111 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_111 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_112 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_112 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_37 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_113 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_113 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 128s - loss: 0.0423 - tp: 602.0000 - fp: 307.0000 - tn: 253467.0000 - fn: 2509.0000 - accuracy: 0.9890 - precision: 0.6623 - recall: 0.1935 - auc: 0.9021 - val_loss: 0.0300 - val_tp: 965.0000 - val_fp: 366.0000 - val_tn: 234653.0000 - val_fn: 1874.0000 - val_accuracy: 0.9906 - val_precision: 0.7250 - val_recall: 0.3399 - val_auc: 0.9495
256885/256885 - 128s - loss: 0.0423 - tp: 602.0000 - fp: 307.0000 - tn: 253467.0000 - fn: 2509.0000 - accuracy: 0.9890 - precision: 0.6623 - recall: 0.1935 - auc: 0.9021 - val_loss: 0.0300 - val_tp: 965.0000 - val_fp: 366.0000 - val_tn: 234653.0000 - val_fn: 1874.0000 - val_accuracy: 0.9906 - val_precision: 0.7250 - val_recall: 0.3399 - val_auc: 0.9495
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 125s - loss: 0.0248 - tp: 1547.0000 - fp: 452.0000 - tn: 253322.0000 - fn: 1564.0000 - accuracy: 0.9922 - precision: 0.7739 - recall: 0.4973 - auc: 0.9682 - val_loss: 0.0350 - val_tp: 1061.0000 - val_fp: 109.0000 - val_tn: 234910.0000 - val_fn: 1778.0000 - val_accuracy: 0.9921 - val_precision: 0.9068 - val_recall: 0.3737 - val_auc: 0.8894
256885/256885 - 125s - loss: 0.0248 - tp: 1547.0000 - fp: 452.0000 - tn: 253322.0000 - fn: 1564.0000 - accuracy: 0.9922 - precision: 0.7739 - recall: 0.4973 - auc: 0.9682 - val_loss: 0.0350 - val_tp: 1061.0000 - val_fp: 109.0000 - val_tn: 234910.0000 - val_fn: 1778.0000 - val_accuracy: 0.9921 - val_precision: 0.9068 - val_recall: 0.3737 - val_auc: 0.8894
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d50da908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d50e4ef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d50ecb00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d50ecc50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d50ecef0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d50ff2e8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d50ff588>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d50ff898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e820f208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e92b60b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d4041908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49ea0891d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d51350b8>]
          

Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_18 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_114 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_114 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_115 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_115 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_38 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_116 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_116 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256886/256886 - 128s - loss: 0.0413 - tp: 609.0000 - fp: 333.0000 - tn: 253445.0000 - fn: 2499.0000 - accuracy: 0.9890 - precision: 0.6465 - recall: 0.1959 - auc: 0.9105 - val_loss: 0.0276 - val_tp: 1013.0000 - val_fp: 331.0000 - val_tn: 234688.0000 - val_fn: 1826.0000 - val_accuracy: 0.9909 - val_precision: 0.7537 - val_recall: 0.3568 - val_auc: 0.9660
256886/256886 - 128s - loss: 0.0413 - tp: 609.0000 - fp: 333.0000 - tn: 253445.0000 - fn: 2499.0000 - accuracy: 0.9890 - precision: 0.6465 - recall: 0.1959 - auc: 0.9105 - val_loss: 0.0276 - val_tp: 1013.0000 - val_fp: 331.0000 - val_tn: 234688.0000 - val_fn: 1826.0000 - val_accuracy: 0.9909 - val_precision: 0.7537 - val_recall: 0.3568 - val_auc: 0.9660
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256886/256886 - 126s - loss: 0.0241 - tp: 1598.0000 - fp: 448.0000 - tn: 253330.0000 - fn: 1510.0000 - accuracy: 0.9924 - precision: 0.7810 - recall: 0.5142 - auc: 0.9702 - val_loss: 0.0241 - val_tp: 1419.0000 - val_fp: 194.0000 - val_tn: 234825.0000 - val_fn: 1420.0000 - val_accuracy: 0.9932 - val_precision: 0.8797 - val_recall: 0.4998 - val_auc: 0.9424
256886/256886 - 126s - loss: 0.0241 - tp: 1598.0000 - fp: 448.0000 - tn: 253330.0000 - fn: 1510.0000 - accuracy: 0.9924 - precision: 0.7810 - recall: 0.5142 - auc: 0.9702 - val_loss: 0.0241 - val_tp: 1419.0000 - val_fp: 194.0000 - val_tn: 234825.0000 - val_fn: 1420.0000 - val_accuracy: 0.9932 - val_precision: 0.8797 - val_recall: 0.4998 - val_auc: 0.9424
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ea0e7080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ead4eb38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ead4edd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8d1c5c0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8d1c748>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ead09240>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ead09b38>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ead09f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d51350b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d51524e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d5152518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8118c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e9b6a0f0>]
          

Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_19 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_117 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_117 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_118 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_118 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_39 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_119 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_119 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256886/256886 - 128s - loss: 0.0438 - tp: 552.0000 - fp: 379.0000 - tn: 253383.0000 - fn: 2572.0000 - accuracy: 0.9885 - precision: 0.5929 - recall: 0.1767 - auc: 0.8960 - val_loss: 0.0319 - val_tp: 686.0000 - val_fp: 193.0000 - val_tn: 234826.0000 - val_fn: 2153.0000 - val_accuracy: 0.9901 - val_precision: 0.7804 - val_recall: 0.2416 - val_auc: 0.9445
256886/256886 - 128s - loss: 0.0438 - tp: 552.0000 - fp: 379.0000 - tn: 253383.0000 - fn: 2572.0000 - accuracy: 0.9885 - precision: 0.5929 - recall: 0.1767 - auc: 0.8960 - val_loss: 0.0319 - val_tp: 686.0000 - val_fp: 193.0000 - val_tn: 234826.0000 - val_fn: 2153.0000 - val_accuracy: 0.9901 - val_precision: 0.7804 - val_recall: 0.2416 - val_auc: 0.9445
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256886/256886 - 125s - loss: 0.0253 - tp: 1542.0000 - fp: 418.0000 - tn: 253344.0000 - fn: 1582.0000 - accuracy: 0.9922 - precision: 0.7867 - recall: 0.4936 - auc: 0.9674 - val_loss: 0.0222 - val_tp: 1982.0000 - val_fp: 747.0000 - val_tn: 234272.0000 - val_fn: 857.0000 - val_accuracy: 0.9933 - val_precision: 0.7263 - val_recall: 0.6981 - val_auc: 0.9858
256886/256886 - 125s - loss: 0.0253 - tp: 1542.0000 - fp: 418.0000 - tn: 253344.0000 - fn: 1582.0000 - accuracy: 0.9922 - precision: 0.7867 - recall: 0.4936 - auc: 0.9674 - val_loss: 0.0222 - val_tp: 1982.0000 - val_fp: 747.0000 - val_tn: 234272.0000 - val_fn: 857.0000 - val_accuracy: 0.9933 - val_precision: 0.7263 - val_recall: 0.6981 - val_auc: 0.9858
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d5152518>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e806c630>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e91c0b00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e91c0c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e91c0208>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e91c0ac8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e91c0048>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e82b5048>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e9b6a0f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d51524a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e1d4d0f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d6d4fc18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e82a01d0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c3f0c358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c3f0c5f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3f0c898>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3f0cb38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c3f0cdd8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3f211d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c3f21470>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3f21780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8298f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e91bf128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e91bfeb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c3f0c048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3f0c0b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ea28e780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ea28e9b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ea28ec50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49ea28eef0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ea22a1d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ea22a588>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ea22a828>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea22ab38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3f0c2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e91c02e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e91c0ac8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49ea28e4a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ea28e630>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8e2c358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8e2c5f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8e2c898>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8e2cb38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8e2cdd8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8e051d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8e05470>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8e05780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49ea28e6d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ea20d6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49ea20d6d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8e2c048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8e2c0b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e84b7208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e84b74a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e84b7748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e84b79e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7c88>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b7f60>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e848b320>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e848b630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8e2c2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8480f60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8480f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8480f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8e2f2e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e848b828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e848b550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e848b128>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e848b080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7fd0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b7940>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e84b7438>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e84b7e10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e84b7198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8e2c2e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8480f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8480f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8e2f2e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e84b7b38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e84b74e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e84b7828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e84b7e80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b79e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e848bf60>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e848b358>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e848b6d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e848b8d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e849f0f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e849f320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e849f198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e849f358>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e848b358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e848b710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e848b160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e848b908>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7278>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b7518>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e84b72e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e84b7668>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e84b7438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e860e1d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8485390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e84852e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8485198>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e84b7a90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e84b7f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e84b7ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e84b77b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7898>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e848b4e0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e848b278>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e848b898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e848b588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e84938d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8493748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8493828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e84930f0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8302b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e848b5f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e848b710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e848b240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7470>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b7710>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e84b7ac8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e84b7400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e84b7550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e82d9208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8302ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8302c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8302a58>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e82e3a20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e84b7908>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e84b7b00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e84b7c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7320>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b77b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e848b550>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e848b3c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8302ac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8e77b70>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9158358>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9158668>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e82d9048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e848b7f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e848b2b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e848b198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e848b2e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e84b7ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e84b7d68>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e84b70b8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e82e3240>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e82e3da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8e6b668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e86290f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e86290b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8629400>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e90dc8d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e90dcbe0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e90dce80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e90ee160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e90ee400>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e90ee7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e90eea58>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e90eed68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8e77f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9115a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9115ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9115ac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e90dc860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e90aec88>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e90aef98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e90bb278>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e90bb518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e90bb7b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e90bbb70>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e90bbe10>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9047160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e90dc828>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e84b74a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e84b7978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e84b7cf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e90aec18>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e90119b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9011be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9011e80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e9017160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e9017400>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e90177b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9017a58>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9017d68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e90aebe0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9047be0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9047d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e90116d8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e9011860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f81780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f81a90>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f81d30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f81fd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f902b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f90668>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f90908>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f90c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e9011908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e90338d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9033a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9033978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8f81710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f81c88>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f81898>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f818d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f9e860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f6d3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f6d860>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f6db00>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f6de10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f816d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e9011908>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e9033a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e9033978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8f81f60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f6da90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f6d940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f6d470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f6d588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f9e828>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f81860>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f81e48>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f782b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f81cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8f6de48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8f6ddd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8f6deb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8f6dd68>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f78a58>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f81a20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f81e80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f818d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f9e6d8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f6dc50>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f6d3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f6d8d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f6da58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8f78a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8f78b00>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8f788d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8f78080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f32f28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f6d9b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f6d780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f6d6a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f9e780>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f9eb00>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f819e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f81b38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f78898>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8d819b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8d81b70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8d81f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8f32e10>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8f32630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8f8b518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e8f81518>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e8f81860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49e8f9e7b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49e8f6d7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8f6d748>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f6d630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f32c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8d874e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8d4ddd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e8d4d9e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8d4df28>]
          

Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_60 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_120 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_120 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_121 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_121 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_40 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_122 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_122 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0417 - tp: 629.0000 - fp: 364.0000 - tn: 253395.0000 - fn: 2497.0000 - accuracy: 0.9889 - precision: 0.6334 - recall: 0.2012 - auc: 0.9058 - val_loss: 0.0286 - val_tp: 1040.0000 - val_fp: 484.0000 - val_tn: 234535.0000 - val_fn: 1799.0000 - val_accuracy: 0.9904 - val_precision: 0.6824 - val_recall: 0.3663 - val_auc: 0.9710
256885/256885 - 108s - loss: 0.0417 - tp: 629.0000 - fp: 364.0000 - tn: 253395.0000 - fn: 2497.0000 - accuracy: 0.9889 - precision: 0.6334 - recall: 0.2012 - auc: 0.9058 - val_loss: 0.0286 - val_tp: 1040.0000 - val_fp: 484.0000 - val_tn: 234535.0000 - val_fn: 1799.0000 - val_accuracy: 0.9904 - val_precision: 0.6824 - val_recall: 0.3663 - val_auc: 0.9710
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0261 - tp: 1453.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 1673.0000 - accuracy: 0.9917 - precision: 0.7584 - recall: 0.4648 - auc: 0.9649 - val_loss: 0.0234 - val_tp: 1329.0000 - val_fp: 182.0000 - val_tn: 234837.0000 - val_fn: 1510.0000 - val_accuracy: 0.9929 - val_precision: 0.8795 - val_recall: 0.4681 - val_auc: 0.9564
256885/256885 - 103s - loss: 0.0261 - tp: 1453.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 1673.0000 - accuracy: 0.9917 - precision: 0.7584 - recall: 0.4648 - auc: 0.9649 - val_loss: 0.0234 - val_tp: 1329.0000 - val_fp: 182.0000 - val_tn: 234837.0000 - val_fn: 1510.0000 - val_accuracy: 0.9929 - val_precision: 0.8795 - val_recall: 0.4681 - val_auc: 0.9564
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e1d81208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e1d814e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e1d81198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49ea2d7cf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d41412e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d41410b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9d8a780>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e8f81fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8f78a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e88566d8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e809f278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4a1c2c6cf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d697e5c0>]
          

Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_61 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_123 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_123 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_124 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_124 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_41 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_125 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_125 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0441 - tp: 538.0000 - fp: 460.0000 - tn: 253298.0000 - fn: 2589.0000 - accuracy: 0.9881 - precision: 0.5391 - recall: 0.1720 - auc: 0.8976 - val_loss: 0.0441 - val_tp: 339.0000 - val_fp: 70.0000 - val_tn: 234949.0000 - val_fn: 2500.0000 - val_accuracy: 0.9892 - val_precision: 0.8289 - val_recall: 0.1194 - val_auc: 0.8693
256885/256885 - 108s - loss: 0.0441 - tp: 538.0000 - fp: 460.0000 - tn: 253298.0000 - fn: 2589.0000 - accuracy: 0.9881 - precision: 0.5391 - recall: 0.1720 - auc: 0.8976 - val_loss: 0.0441 - val_tp: 339.0000 - val_fp: 70.0000 - val_tn: 234949.0000 - val_fn: 2500.0000 - val_accuracy: 0.9892 - val_precision: 0.8289 - val_recall: 0.1194 - val_auc: 0.8693
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0259 - tp: 1450.0000 - fp: 450.0000 - tn: 253308.0000 - fn: 1677.0000 - accuracy: 0.9917 - precision: 0.7632 - recall: 0.4637 - auc: 0.9675 - val_loss: 0.0203 - val_tp: 1891.0000 - val_fp: 561.0000 - val_tn: 234458.0000 - val_fn: 948.0000 - val_accuracy: 0.9937 - val_precision: 0.7712 - val_recall: 0.6661 - val_auc: 0.9854
256885/256885 - 103s - loss: 0.0259 - tp: 1450.0000 - fp: 450.0000 - tn: 253308.0000 - fn: 1677.0000 - accuracy: 0.9917 - precision: 0.7632 - recall: 0.4637 - auc: 0.9675 - val_loss: 0.0203 - val_tp: 1891.0000 - val_fp: 561.0000 - val_tn: 234458.0000 - val_fn: 948.0000 - val_accuracy: 0.9937 - val_precision: 0.7712 - val_recall: 0.6661 - val_auc: 0.9854
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d4cad470>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9f6d240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e9f7ac18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3656be0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c3656b38>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c36560b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c36567f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3647eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a1c2c6cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d697e6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e1d813c8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49e1d81e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8d4df28>]
          

Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_62 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_126 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_126 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_127 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_127 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_42 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_128 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_128 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 107s - loss: 0.0427 - tp: 555.0000 - fp: 407.0000 - tn: 253362.0000 - fn: 2561.0000 - accuracy: 0.9884 - precision: 0.5769 - recall: 0.1781 - auc: 0.9023 - val_loss: 0.0386 - val_tp: 506.0000 - val_fp: 127.0000 - val_tn: 234892.0000 - val_fn: 2333.0000 - val_accuracy: 0.9897 - val_precision: 0.7994 - val_recall: 0.1782 - val_auc: 0.9015
256885/256885 - 107s - loss: 0.0427 - tp: 555.0000 - fp: 407.0000 - tn: 253362.0000 - fn: 2561.0000 - accuracy: 0.9884 - precision: 0.5769 - recall: 0.1781 - auc: 0.9023 - val_loss: 0.0386 - val_tp: 506.0000 - val_fp: 127.0000 - val_tn: 234892.0000 - val_fn: 2333.0000 - val_accuracy: 0.9897 - val_precision: 0.7994 - val_recall: 0.1782 - val_auc: 0.9015
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0259 - tp: 1479.0000 - fp: 425.0000 - tn: 253344.0000 - fn: 1637.0000 - accuracy: 0.9920 - precision: 0.7768 - recall: 0.4746 - auc: 0.9637 - val_loss: 0.0203 - val_tp: 1700.0000 - val_fp: 410.0000 - val_tn: 234609.0000 - val_fn: 1139.0000 - val_accuracy: 0.9935 - val_precision: 0.8057 - val_recall: 0.5988 - val_auc: 0.9816
256885/256885 - 103s - loss: 0.0259 - tp: 1479.0000 - fp: 425.0000 - tn: 253344.0000 - fn: 1637.0000 - accuracy: 0.9920 - precision: 0.7768 - recall: 0.4746 - auc: 0.9637 - val_loss: 0.0203 - val_tp: 1700.0000 - val_fp: 410.0000 - val_tn: 234609.0000 - val_fn: 1139.0000 - val_accuracy: 0.9935 - val_precision: 0.8057 - val_recall: 0.5988 - val_auc: 0.9816
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d4cad3c8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c4fafb00>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c4fafeb8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c4fb76d8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c4fb7978>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c4fb7d30>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c4fb7fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c4f4c320>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb911208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e1d812b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c3661f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c365e550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d697e6a0>]
          

Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_63 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_129 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_129 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_130 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_130 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_43 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_131 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_131 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 107s - loss: 0.0441 - tp: 560.0000 - fp: 462.0000 - tn: 253330.0000 - fn: 2533.0000 - accuracy: 0.9883 - precision: 0.5479 - recall: 0.1811 - auc: 0.8902 - val_loss: 0.0403 - val_tp: 469.0000 - val_fp: 116.0000 - val_tn: 234903.0000 - val_fn: 2370.0000 - val_accuracy: 0.9895 - val_precision: 0.8017 - val_recall: 0.1652 - val_auc: 0.8905
256885/256885 - 107s - loss: 0.0441 - tp: 560.0000 - fp: 462.0000 - tn: 253330.0000 - fn: 2533.0000 - accuracy: 0.9883 - precision: 0.5479 - recall: 0.1811 - auc: 0.8902 - val_loss: 0.0403 - val_tp: 469.0000 - val_fp: 116.0000 - val_tn: 234903.0000 - val_fn: 2370.0000 - val_accuracy: 0.9895 - val_precision: 0.8017 - val_recall: 0.1652 - val_auc: 0.8905
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0257 - tp: 1463.0000 - fp: 408.0000 - tn: 253384.0000 - fn: 1630.0000 - accuracy: 0.9921 - precision: 0.7819 - recall: 0.4730 - auc: 0.9659 - val_loss: 0.0236 - val_tp: 2014.0000 - val_fp: 887.0000 - val_tn: 234132.0000 - val_fn: 825.0000 - val_accuracy: 0.9928 - val_precision: 0.6942 - val_recall: 0.7094 - val_auc: 0.9868
256885/256885 - 103s - loss: 0.0257 - tp: 1463.0000 - fp: 408.0000 - tn: 253384.0000 - fn: 1630.0000 - accuracy: 0.9921 - precision: 0.7819 - recall: 0.4730 - auc: 0.9659 - val_loss: 0.0236 - val_tp: 2014.0000 - val_fp: 887.0000 - val_tn: 234132.0000 - val_fn: 825.0000 - val_accuracy: 0.9928 - val_precision: 0.6942 - val_recall: 0.7094 - val_auc: 0.9868
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c4768908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c4770c88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c46fa390>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c46fab70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c46fae10>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c470d208>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c470d4a8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c470d7b8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c365e550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d697e6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c4f92f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4f92f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8d4df28>]
          

Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_64 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_132 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_132 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_133 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_133 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_44 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_134 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_134 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 108s - loss: 0.0430 - tp: 600.0000 - fp: 391.0000 - tn: 253348.0000 - fn: 2546.0000 - accuracy: 0.9886 - precision: 0.6054 - recall: 0.1907 - auc: 0.9024 - val_loss: 0.0292 - val_tp: 1218.0000 - val_fp: 727.0000 - val_tn: 234292.0000 - val_fn: 1621.0000 - val_accuracy: 0.9901 - val_precision: 0.6262 - val_recall: 0.4290 - val_auc: 0.9714
256885/256885 - 108s - loss: 0.0430 - tp: 600.0000 - fp: 391.0000 - tn: 253348.0000 - fn: 2546.0000 - accuracy: 0.9886 - precision: 0.6054 - recall: 0.1907 - auc: 0.9024 - val_loss: 0.0292 - val_tp: 1218.0000 - val_fp: 727.0000 - val_tn: 234292.0000 - val_fn: 1621.0000 - val_accuracy: 0.9901 - val_precision: 0.6262 - val_recall: 0.4290 - val_auc: 0.9714
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 104s - loss: 0.0256 - tp: 1550.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 1596.0000 - accuracy: 0.9922 - precision: 0.7896 - recall: 0.4927 - auc: 0.9657 - val_loss: 0.0219 - val_tp: 1891.0000 - val_fp: 615.0000 - val_tn: 234404.0000 - val_fn: 948.0000 - val_accuracy: 0.9934 - val_precision: 0.7546 - val_recall: 0.6661 - val_auc: 0.9873
256885/256885 - 104s - loss: 0.0256 - tp: 1550.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 1596.0000 - accuracy: 0.9922 - precision: 0.7896 - recall: 0.4927 - auc: 0.9657 - val_loss: 0.0219 - val_tp: 1891.0000 - val_fp: 615.0000 - val_tn: 234404.0000 - val_fn: 948.0000 - val_accuracy: 0.9934 - val_precision: 0.7546 - val_recall: 0.6661 - val_auc: 0.9873
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49eb37d240>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a04410898>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a04410d30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49e99b1550>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ea8ce3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ea8ceb70>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e991c3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d6e4c550>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c4f92ef0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c4f92b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a043f38d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb989358>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eb37d128>]
          

Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_65 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_135 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_135 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_136 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_136 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_45 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_137 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_137 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 107s - loss: 0.0431 - tp: 572.0000 - fp: 414.0000 - tn: 253364.0000 - fn: 2535.0000 - accuracy: 0.9885 - precision: 0.5801 - recall: 0.1841 - auc: 0.8972 - val_loss: 0.0389 - val_tp: 1478.0000 - val_fp: 1123.0000 - val_tn: 233896.0000 - val_fn: 1361.0000 - val_accuracy: 0.9896 - val_precision: 0.5682 - val_recall: 0.5206 - val_auc: 0.9769
256885/256885 - 107s - loss: 0.0431 - tp: 572.0000 - fp: 414.0000 - tn: 253364.0000 - fn: 2535.0000 - accuracy: 0.9885 - precision: 0.5801 - recall: 0.1841 - auc: 0.8972 - val_loss: 0.0389 - val_tp: 1478.0000 - val_fp: 1123.0000 - val_tn: 233896.0000 - val_fn: 1361.0000 - val_accuracy: 0.9896 - val_precision: 0.5682 - val_recall: 0.5206 - val_auc: 0.9769
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0259 - tp: 1453.0000 - fp: 476.0000 - tn: 253302.0000 - fn: 1654.0000 - accuracy: 0.9917 - precision: 0.7532 - recall: 0.4677 - auc: 0.9666 - val_loss: 0.0214 - val_tp: 1441.0000 - val_fp: 230.0000 - val_tn: 234789.0000 - val_fn: 1398.0000 - val_accuracy: 0.9932 - val_precision: 0.8624 - val_recall: 0.5076 - val_auc: 0.9701
256885/256885 - 103s - loss: 0.0259 - tp: 1453.0000 - fp: 476.0000 - tn: 253302.0000 - fn: 1654.0000 - accuracy: 0.9917 - precision: 0.7532 - recall: 0.4677 - auc: 0.9666 - val_loss: 0.0214 - val_tp: 1441.0000 - val_fp: 230.0000 - val_tn: 234789.0000 - val_fn: 1398.0000 - val_accuracy: 0.9932 - val_precision: 0.8624 - val_recall: 0.5076 - val_auc: 0.9701
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0212 - tp: 1871.0000 - fp: 412.0000 - tn: 253366.0000 - fn: 1236.0000 - accuracy: 0.9936 - precision: 0.8195 - recall: 0.6022 - auc: 0.9697 - val_loss: 0.0255 - val_tp: 1349.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 1490.0000 - val_accuracy: 0.9931 - val_precision: 0.9029 - val_recall: 0.4752 - val_auc: 0.9339
256885/256885 - 103s - loss: 0.0212 - tp: 1871.0000 - fp: 412.0000 - tn: 253366.0000 - fn: 1236.0000 - accuracy: 0.9936 - precision: 0.8195 - recall: 0.6022 - auc: 0.9697 - val_loss: 0.0255 - val_tp: 1349.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 1490.0000 - val_accuracy: 0.9931 - val_precision: 0.9029 - val_recall: 0.4752 - val_auc: 0.9339
Epoch 4/50
Epoch 4/50

Epoch 00004: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0200 - tp: 1970.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 1137.0000 - accuracy: 0.9941 - precision: 0.8394 - recall: 0.6341 - auc: 0.9722 - val_loss: 0.0192 - val_tp: 1757.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1082.0000 - val_accuracy: 0.9943 - val_precision: 0.8609 - val_recall: 0.6189 - val_auc: 0.9632
256885/256885 - 103s - loss: 0.0200 - tp: 1970.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 1137.0000 - accuracy: 0.9941 - precision: 0.8394 - recall: 0.6341 - auc: 0.9722 - val_loss: 0.0192 - val_tp: 1757.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1082.0000 - val_accuracy: 0.9943 - val_precision: 0.8609 - val_recall: 0.6189 - val_auc: 0.9632
Epoch 00004: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 7.1min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d76e9c50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d6d27908>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d76dcb38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d73ac208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d73ac4a8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d73ac860>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d73acb00>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d73ace10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4a043f38d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49eb37da58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49eb37def0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49eb37d400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d7428080>]
          

Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_66 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_138 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_138 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_139 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_139 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_46 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_140 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_140 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 106s - loss: 0.0425 - tp: 585.0000 - fp: 388.0000 - tn: 253406.0000 - fn: 2506.0000 - accuracy: 0.9887 - precision: 0.6012 - recall: 0.1893 - auc: 0.9003 - val_loss: 0.0335 - val_tp: 1517.0000 - val_fp: 1346.0000 - val_tn: 233673.0000 - val_fn: 1322.0000 - val_accuracy: 0.9888 - val_precision: 0.5299 - val_recall: 0.5343 - val_auc: 0.9743
256885/256885 - 106s - loss: 0.0425 - tp: 585.0000 - fp: 388.0000 - tn: 253406.0000 - fn: 2506.0000 - accuracy: 0.9887 - precision: 0.6012 - recall: 0.1893 - auc: 0.9003 - val_loss: 0.0335 - val_tp: 1517.0000 - val_fp: 1346.0000 - val_tn: 233673.0000 - val_fn: 1322.0000 - val_accuracy: 0.9888 - val_precision: 0.5299 - val_recall: 0.5343 - val_auc: 0.9743
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73054
256885/256885 - 103s - loss: 0.0256 - tp: 1471.0000 - fp: 439.0000 - tn: 253355.0000 - fn: 1620.0000 - accuracy: 0.9920 - precision: 0.7702 - recall: 0.4759 - auc: 0.9640 - val_loss: 0.0226 - val_tp: 1884.0000 - val_fp: 607.0000 - val_tn: 234412.0000 - val_fn: 955.0000 - val_accuracy: 0.9934 - val_precision: 0.7563 - val_recall: 0.6636 - val_auc: 0.9871
256885/256885 - 103s - loss: 0.0256 - tp: 1471.0000 - fp: 439.0000 - tn: 253355.0000 - fn: 1620.0000 - accuracy: 0.9920 - precision: 0.7702 - recall: 0.4759 - auc: 0.9640 - val_loss: 0.0226 - val_tp: 1884.0000 - val_fp: 607.0000 - val_tn: 234412.0000 - val_fn: 955.0000 - val_accuracy: 0.9934 - val_precision: 0.7563 - val_recall: 0.6636 - val_auc: 0.9871
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c4072898>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c3ffcda0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c4006358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c4006b38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c4006dd8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c40191d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c4019470>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c4019780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eb37def0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e857e860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d7428940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d6d35198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c4f92ef0>]
          

Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_67 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_141 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_141 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_142 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_142 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_47 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_143 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_143 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73054
256885/256885 - 106s - loss: 0.0434 - tp: 579.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 2532.0000 - accuracy: 0.9884 - precision: 0.5682 - recall: 0.1861 - auc: 0.8956 - val_loss: 0.0313 - val_tp: 781.0000 - val_fp: 252.0000 - val_tn: 234767.0000 - val_fn: 2058.0000 - val_accuracy: 0.9903 - val_precision: 0.7561 - val_recall: 0.2751 - val_auc: 0.9469
256885/256885 - 106s - loss: 0.0434 - tp: 579.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 2532.0000 - accuracy: 0.9884 - precision: 0.5682 - recall: 0.1861 - auc: 0.8956 - val_loss: 0.0313 - val_tp: 781.0000 - val_fp: 252.0000 - val_tn: 234767.0000 - val_fn: 2058.0000 - val_accuracy: 0.9903 - val_precision: 0.7561 - val_recall: 0.2751 - val_auc: 0.9469
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.73054 to 0.73124, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 103s - loss: 0.0259 - tp: 1458.0000 - fp: 445.0000 - tn: 253329.0000 - fn: 1653.0000 - accuracy: 0.9918 - precision: 0.7662 - recall: 0.4687 - auc: 0.9667 - val_loss: 0.0299 - val_tp: 2076.0000 - val_fp: 1024.0000 - val_tn: 233995.0000 - val_fn: 763.0000 - val_accuracy: 0.9925 - val_precision: 0.6697 - val_recall: 0.7312 - val_auc: 0.9882
256885/256885 - 103s - loss: 0.0259 - tp: 1458.0000 - fp: 445.0000 - tn: 253329.0000 - fn: 1653.0000 - accuracy: 0.9918 - precision: 0.7662 - recall: 0.4687 - auc: 0.9667 - val_loss: 0.0299 - val_tp: 2076.0000 - val_fp: 1024.0000 - val_tn: 233995.0000 - val_fn: 763.0000 - val_accuracy: 0.9925 - val_precision: 0.6697 - val_recall: 0.7312 - val_auc: 0.9882
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d73d5d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496b87a860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3e04ac8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3e04550>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c3e04780>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3e04208>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c3e04a58>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3e4f908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c4f92ef0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c406a470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d6d351d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f497812ab00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496b85fdd8>]
          

Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_68 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_144 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_144 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_145 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_145 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_48 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_146 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_146 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 107s - loss: 0.0420 - tp: 621.0000 - fp: 420.0000 - tn: 253358.0000 - fn: 2487.0000 - accuracy: 0.9887 - precision: 0.5965 - recall: 0.1998 - auc: 0.9020 - val_loss: 0.0298 - val_tp: 826.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 2013.0000 - val_accuracy: 0.9903 - val_precision: 0.7448 - val_recall: 0.2909 - val_auc: 0.9595
256886/256886 - 107s - loss: 0.0420 - tp: 621.0000 - fp: 420.0000 - tn: 253358.0000 - fn: 2487.0000 - accuracy: 0.9887 - precision: 0.5965 - recall: 0.1998 - auc: 0.9020 - val_loss: 0.0298 - val_tp: 826.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 2013.0000 - val_accuracy: 0.9903 - val_precision: 0.7448 - val_recall: 0.2909 - val_auc: 0.9595
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 104s - loss: 0.0260 - tp: 1468.0000 - fp: 437.0000 - tn: 253341.0000 - fn: 1640.0000 - accuracy: 0.9919 - precision: 0.7706 - recall: 0.4723 - auc: 0.9689 - val_loss: 0.0235 - val_tp: 1320.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 1519.0000 - val_accuracy: 0.9928 - val_precision: 0.8765 - val_recall: 0.4650 - val_auc: 0.9574
256886/256886 - 104s - loss: 0.0260 - tp: 1468.0000 - fp: 437.0000 - tn: 253341.0000 - fn: 1640.0000 - accuracy: 0.9919 - precision: 0.7706 - recall: 0.4723 - auc: 0.9689 - val_loss: 0.0235 - val_tp: 1320.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 1519.0000 - val_accuracy: 0.9928 - val_precision: 0.8765 - val_recall: 0.4650 - val_auc: 0.9574
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d408a860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ea6e6d68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49ea6e6780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49ea6e6e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49ea6e6080>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3f0cb00>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d719f7f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea28e518>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3e49f28>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c3e43e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496b85fdd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d792a828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4a04410630>]
          

Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_69 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_147 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_147 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_148 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_148 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_49 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_149 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_149 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 107s - loss: 0.0429 - tp: 567.0000 - fp: 397.0000 - tn: 253365.0000 - fn: 2557.0000 - accuracy: 0.9885 - precision: 0.5882 - recall: 0.1815 - auc: 0.9024 - val_loss: 0.0288 - val_tp: 832.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 2007.0000 - val_accuracy: 0.9904 - val_precision: 0.7455 - val_recall: 0.2931 - val_auc: 0.9688
256886/256886 - 107s - loss: 0.0429 - tp: 567.0000 - fp: 397.0000 - tn: 253365.0000 - fn: 2557.0000 - accuracy: 0.9885 - precision: 0.5882 - recall: 0.1815 - auc: 0.9024 - val_loss: 0.0288 - val_tp: 832.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 2007.0000 - val_accuracy: 0.9904 - val_precision: 0.7455 - val_recall: 0.2931 - val_auc: 0.9688
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 103s - loss: 0.0261 - tp: 1459.0000 - fp: 459.0000 - tn: 253303.0000 - fn: 1665.0000 - accuracy: 0.9917 - precision: 0.7607 - recall: 0.4670 - auc: 0.9660 - val_loss: 0.0236 - val_tp: 1360.0000 - val_fp: 228.0000 - val_tn: 234791.0000 - val_fn: 1479.0000 - val_accuracy: 0.9928 - val_precision: 0.8564 - val_recall: 0.4790 - val_auc: 0.9552
256886/256886 - 103s - loss: 0.0261 - tp: 1459.0000 - fp: 459.0000 - tn: 253303.0000 - fn: 1665.0000 - accuracy: 0.9917 - precision: 0.7607 - recall: 0.4670 - auc: 0.9660 - val_loss: 0.0236 - val_tp: 1360.0000 - val_fp: 228.0000 - val_tn: 234791.0000 - val_fn: 1479.0000 - val_accuracy: 0.9928 - val_precision: 0.8564 - val_recall: 0.4790 - val_auc: 0.9552
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d7644128>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d4179f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d416ab70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d416acc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d416af60>, <tensorflow.python.keras.metrics.Precision object at 0x7f49ea8af358>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ea8af5f8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea8af908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d792a828>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496b85fdd8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d408a9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d408a710>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d417a5f8>]
          

Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_70 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_150 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_150 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_151 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_151 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_50 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_152 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_152 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 132s - loss: 0.0423 - tp: 617.0000 - fp: 413.0000 - tn: 253346.0000 - fn: 2509.0000 - accuracy: 0.9886 - precision: 0.5990 - recall: 0.1974 - auc: 0.9037 - val_loss: 0.0285 - val_tp: 1139.0000 - val_fp: 538.0000 - val_tn: 234481.0000 - val_fn: 1700.0000 - val_accuracy: 0.9906 - val_precision: 0.6792 - val_recall: 0.4012 - val_auc: 0.9688
256885/256885 - 132s - loss: 0.0423 - tp: 617.0000 - fp: 413.0000 - tn: 253346.0000 - fn: 2509.0000 - accuracy: 0.9886 - precision: 0.5990 - recall: 0.1974 - auc: 0.9037 - val_loss: 0.0285 - val_tp: 1139.0000 - val_fp: 538.0000 - val_tn: 234481.0000 - val_fn: 1700.0000 - val_accuracy: 0.9906 - val_precision: 0.6792 - val_recall: 0.4012 - val_auc: 0.9688
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0266 - tp: 1504.0000 - fp: 450.0000 - tn: 253309.0000 - fn: 1622.0000 - accuracy: 0.9919 - precision: 0.7697 - recall: 0.4811 - auc: 0.9630 - val_loss: 0.0214 - val_tp: 1819.0000 - val_fp: 574.0000 - val_tn: 234445.0000 - val_fn: 1020.0000 - val_accuracy: 0.9933 - val_precision: 0.7601 - val_recall: 0.6407 - val_auc: 0.9837
256885/256885 - 129s - loss: 0.0266 - tp: 1504.0000 - fp: 450.0000 - tn: 253309.0000 - fn: 1622.0000 - accuracy: 0.9919 - precision: 0.7697 - recall: 0.4811 - auc: 0.9630 - val_loss: 0.0214 - val_tp: 1819.0000 - val_fp: 574.0000 - val_tn: 234445.0000 - val_fn: 1020.0000 - val_accuracy: 0.9933 - val_precision: 0.7601 - val_recall: 0.6407 - val_auc: 0.9837
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c48409b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c48936a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c484ba58>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c4850198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c4850438>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c48507f0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c4850a90>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c4850da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d408a9b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d417a5f8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d417a588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d7626dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3e43e10>]
          

Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_71 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_153 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_153 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_154 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_154 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_51 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_155 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_155 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 133s - loss: 0.0424 - tp: 590.0000 - fp: 411.0000 - tn: 253347.0000 - fn: 2537.0000 - accuracy: 0.9885 - precision: 0.5894 - recall: 0.1887 - auc: 0.9008 - val_loss: 0.0290 - val_tp: 826.0000 - val_fp: 252.0000 - val_tn: 234767.0000 - val_fn: 2013.0000 - val_accuracy: 0.9905 - val_precision: 0.7662 - val_recall: 0.2909 - val_auc: 0.9618
256885/256885 - 133s - loss: 0.0424 - tp: 590.0000 - fp: 411.0000 - tn: 253347.0000 - fn: 2537.0000 - accuracy: 0.9885 - precision: 0.5894 - recall: 0.1887 - auc: 0.9008 - val_loss: 0.0290 - val_tp: 826.0000 - val_fp: 252.0000 - val_tn: 234767.0000 - val_fn: 2013.0000 - val_accuracy: 0.9905 - val_precision: 0.7662 - val_recall: 0.2909 - val_auc: 0.9618
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0259 - tp: 1507.0000 - fp: 458.0000 - tn: 253300.0000 - fn: 1620.0000 - accuracy: 0.9919 - precision: 0.7669 - recall: 0.4819 - auc: 0.9648 - val_loss: 0.0270 - val_tp: 1183.0000 - val_fp: 147.0000 - val_tn: 234872.0000 - val_fn: 1656.0000 - val_accuracy: 0.9924 - val_precision: 0.8895 - val_recall: 0.4167 - val_auc: 0.9345
256885/256885 - 129s - loss: 0.0259 - tp: 1507.0000 - fp: 458.0000 - tn: 253300.0000 - fn: 1620.0000 - accuracy: 0.9919 - precision: 0.7669 - recall: 0.4819 - auc: 0.9648 - val_loss: 0.0270 - val_tp: 1183.0000 - val_fp: 147.0000 - val_tn: 234872.0000 - val_fn: 1656.0000 - val_accuracy: 0.9924 - val_precision: 0.8895 - val_recall: 0.4167 - val_auc: 0.9345
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496b5a9358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496b51cdd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496b51cf98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496b546eb8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b4dcef0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b4dc630>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b4dcbe0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b4dc0f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3e43e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d417a550>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d417a588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4971f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496b5bfe80>]
          

Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_72 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_156 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_156 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_157 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_157 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_52 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_158 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_158 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 134s - loss: 0.0421 - tp: 604.0000 - fp: 392.0000 - tn: 253377.0000 - fn: 2512.0000 - accuracy: 0.9887 - precision: 0.6064 - recall: 0.1938 - auc: 0.9040 - val_loss: 0.0293 - val_tp: 1108.0000 - val_fp: 485.0000 - val_tn: 234534.0000 - val_fn: 1731.0000 - val_accuracy: 0.9907 - val_precision: 0.6955 - val_recall: 0.3903 - val_auc: 0.9735
256885/256885 - 134s - loss: 0.0421 - tp: 604.0000 - fp: 392.0000 - tn: 253377.0000 - fn: 2512.0000 - accuracy: 0.9887 - precision: 0.6064 - recall: 0.1938 - auc: 0.9040 - val_loss: 0.0293 - val_tp: 1108.0000 - val_fp: 485.0000 - val_tn: 234534.0000 - val_fn: 1731.0000 - val_accuracy: 0.9907 - val_precision: 0.6955 - val_recall: 0.3903 - val_auc: 0.9735
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0261 - tp: 1498.0000 - fp: 483.0000 - tn: 253286.0000 - fn: 1618.0000 - accuracy: 0.9918 - precision: 0.7562 - recall: 0.4807 - auc: 0.9644 - val_loss: 0.0262 - val_tp: 1140.0000 - val_fp: 137.0000 - val_tn: 234882.0000 - val_fn: 1699.0000 - val_accuracy: 0.9923 - val_precision: 0.8927 - val_recall: 0.4015 - val_auc: 0.9452
256885/256885 - 129s - loss: 0.0261 - tp: 1498.0000 - fp: 483.0000 - tn: 253286.0000 - fn: 1618.0000 - accuracy: 0.9918 - precision: 0.7562 - recall: 0.4807 - auc: 0.9644 - val_loss: 0.0262 - val_tp: 1140.0000 - val_fp: 137.0000 - val_tn: 234882.0000 - val_fn: 1699.0000 - val_accuracy: 0.9923 - val_precision: 0.8927 - val_recall: 0.4015 - val_auc: 0.9452
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49ea7fd438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49ea3d2cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d7059b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d7059ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d7059a90>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c35d88d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c35d81d0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9228208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496b516f28>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ead5ba58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496b2b3668>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c3456358>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49eaa0b6a0>]
          

Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_73 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_159 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_159 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_160 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_160 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_53 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_161 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_161 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 133s - loss: 0.0427 - tp: 566.0000 - fp: 416.0000 - tn: 253376.0000 - fn: 2527.0000 - accuracy: 0.9885 - precision: 0.5764 - recall: 0.1830 - auc: 0.9034 - val_loss: 0.0290 - val_tp: 948.0000 - val_fp: 379.0000 - val_tn: 234640.0000 - val_fn: 1891.0000 - val_accuracy: 0.9905 - val_precision: 0.7144 - val_recall: 0.3339 - val_auc: 0.9621
256885/256885 - 133s - loss: 0.0427 - tp: 566.0000 - fp: 416.0000 - tn: 253376.0000 - fn: 2527.0000 - accuracy: 0.9885 - precision: 0.5764 - recall: 0.1830 - auc: 0.9034 - val_loss: 0.0290 - val_tp: 948.0000 - val_fp: 379.0000 - val_tn: 234640.0000 - val_fn: 1891.0000 - val_accuracy: 0.9905 - val_precision: 0.7144 - val_recall: 0.3339 - val_auc: 0.9621
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 128s - loss: 0.0253 - tp: 1517.0000 - fp: 459.0000 - tn: 253333.0000 - fn: 1576.0000 - accuracy: 0.9921 - precision: 0.7677 - recall: 0.4905 - auc: 0.9661 - val_loss: 0.0210 - val_tp: 1856.0000 - val_fp: 649.0000 - val_tn: 234370.0000 - val_fn: 983.0000 - val_accuracy: 0.9931 - val_precision: 0.7409 - val_recall: 0.6538 - val_auc: 0.9854
256885/256885 - 128s - loss: 0.0253 - tp: 1517.0000 - fp: 459.0000 - tn: 253333.0000 - fn: 1576.0000 - accuracy: 0.9921 - precision: 0.7677 - recall: 0.4905 - auc: 0.9661 - val_loss: 0.0210 - val_tp: 1856.0000 - val_fp: 649.0000 - val_tn: 234370.0000 - val_fn: 983.0000 - val_accuracy: 0.9931 - val_precision: 0.7409 - val_recall: 0.6538 - val_auc: 0.9854
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c47eee48>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d6b84940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d715de48>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d7183518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d71837b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d7183b70>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d7183e10>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c4d74160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49eaa0b6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49ea798320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8485390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49ea7fd588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49ead5b400>]
          

Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_74 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_162 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_162 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_163 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_163 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_54 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_164 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_164 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 133s - loss: 0.0437 - tp: 603.0000 - fp: 444.0000 - tn: 253295.0000 - fn: 2543.0000 - accuracy: 0.9884 - precision: 0.5759 - recall: 0.1917 - auc: 0.8967 - val_loss: 0.0324 - val_tp: 1440.0000 - val_fp: 1130.0000 - val_tn: 233889.0000 - val_fn: 1399.0000 - val_accuracy: 0.9894 - val_precision: 0.5603 - val_recall: 0.5072 - val_auc: 0.9762
256885/256885 - 133s - loss: 0.0437 - tp: 603.0000 - fp: 444.0000 - tn: 253295.0000 - fn: 2543.0000 - accuracy: 0.9884 - precision: 0.5759 - recall: 0.1917 - auc: 0.8967 - val_loss: 0.0324 - val_tp: 1440.0000 - val_fp: 1130.0000 - val_tn: 233889.0000 - val_fn: 1399.0000 - val_accuracy: 0.9894 - val_precision: 0.5603 - val_recall: 0.5072 - val_auc: 0.9762
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 128s - loss: 0.0262 - tp: 1510.0000 - fp: 457.0000 - tn: 253282.0000 - fn: 1636.0000 - accuracy: 0.9919 - precision: 0.7677 - recall: 0.4800 - auc: 0.9639 - val_loss: 0.0249 - val_tp: 1349.0000 - val_fp: 246.0000 - val_tn: 234773.0000 - val_fn: 1490.0000 - val_accuracy: 0.9927 - val_precision: 0.8458 - val_recall: 0.4752 - val_auc: 0.9442
256885/256885 - 128s - loss: 0.0262 - tp: 1510.0000 - fp: 457.0000 - tn: 253282.0000 - fn: 1636.0000 - accuracy: 0.9919 - precision: 0.7677 - recall: 0.4800 - auc: 0.9639 - val_loss: 0.0249 - val_tp: 1349.0000 - val_fp: 246.0000 - val_tn: 234773.0000 - val_fn: 1490.0000 - val_accuracy: 0.9927 - val_precision: 0.8458 - val_recall: 0.4752 - val_auc: 0.9442
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.73124
256885/256885 - 128s - loss: 0.0215 - tp: 1908.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1238.0000 - accuracy: 0.9936 - precision: 0.8217 - recall: 0.6065 - auc: 0.9689 - val_loss: 0.0190 - val_tp: 1828.0000 - val_fp: 404.0000 - val_tn: 234615.0000 - val_fn: 1011.0000 - val_accuracy: 0.9941 - val_precision: 0.8190 - val_recall: 0.6439 - val_auc: 0.9850
256885/256885 - 128s - loss: 0.0215 - tp: 1908.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1238.0000 - accuracy: 0.9936 - precision: 0.8217 - recall: 0.6065 - auc: 0.9689 - val_loss: 0.0190 - val_tp: 1828.0000 - val_fp: 404.0000 - val_tn: 234615.0000 - val_fn: 1011.0000 - val_accuracy: 0.9941 - val_precision: 0.8190 - val_recall: 0.6439 - val_auc: 0.9850
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c3b4d908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c38f8518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c437e4a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c437ea90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c437e940>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c437e0b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c437e7f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3c7d128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49ead5ba58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8485550>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8485390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c38fea20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496b2b3550>]
          

Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_75 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_165 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_165 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_166 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_166 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_55 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_167 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_167 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 133s - loss: 0.0426 - tp: 589.0000 - fp: 430.0000 - tn: 253348.0000 - fn: 2518.0000 - accuracy: 0.9885 - precision: 0.5780 - recall: 0.1896 - auc: 0.8980 - val_loss: 0.0299 - val_tp: 1287.0000 - val_fp: 734.0000 - val_tn: 234285.0000 - val_fn: 1552.0000 - val_accuracy: 0.9904 - val_precision: 0.6368 - val_recall: 0.4533 - val_auc: 0.9749
256885/256885 - 133s - loss: 0.0426 - tp: 589.0000 - fp: 430.0000 - tn: 253348.0000 - fn: 2518.0000 - accuracy: 0.9885 - precision: 0.5780 - recall: 0.1896 - auc: 0.8980 - val_loss: 0.0299 - val_tp: 1287.0000 - val_fp: 734.0000 - val_tn: 234285.0000 - val_fn: 1552.0000 - val_accuracy: 0.9904 - val_precision: 0.6368 - val_recall: 0.4533 - val_auc: 0.9749
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0261 - tp: 1465.0000 - fp: 459.0000 - tn: 253319.0000 - fn: 1642.0000 - accuracy: 0.9918 - precision: 0.7614 - recall: 0.4715 - auc: 0.9645 - val_loss: 0.0208 - val_tp: 1765.0000 - val_fp: 528.0000 - val_tn: 234491.0000 - val_fn: 1074.0000 - val_accuracy: 0.9933 - val_precision: 0.7697 - val_recall: 0.6217 - val_auc: 0.9795
256885/256885 - 129s - loss: 0.0261 - tp: 1465.0000 - fp: 459.0000 - tn: 253319.0000 - fn: 1642.0000 - accuracy: 0.9918 - precision: 0.7614 - recall: 0.4715 - auc: 0.9645 - val_loss: 0.0208 - val_tp: 1765.0000 - val_fp: 528.0000 - val_tn: 234491.0000 - val_fn: 1074.0000 - val_accuracy: 0.9933 - val_precision: 0.7697 - val_recall: 0.6217 - val_auc: 0.9795
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c3747c50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c37785f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3755400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3755b38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c3755978>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3755ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c37556d8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3b69f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c38fea20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c3c3e668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496b2b3550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c37e3a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d4b17cf8>]
          

Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_76 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_168 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_168 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_169 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_56 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_170 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_170 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 134s - loss: 0.0432 - tp: 578.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 2513.0000 - accuracy: 0.9886 - precision: 0.5868 - recall: 0.1870 - auc: 0.8910 - val_loss: 0.0292 - val_tp: 1197.0000 - val_fp: 617.0000 - val_tn: 234402.0000 - val_fn: 1642.0000 - val_accuracy: 0.9905 - val_precision: 0.6599 - val_recall: 0.4216 - val_auc: 0.9726
256885/256885 - 134s - loss: 0.0432 - tp: 578.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 2513.0000 - accuracy: 0.9886 - precision: 0.5868 - recall: 0.1870 - auc: 0.8910 - val_loss: 0.0292 - val_tp: 1197.0000 - val_fp: 617.0000 - val_tn: 234402.0000 - val_fn: 1642.0000 - val_accuracy: 0.9905 - val_precision: 0.6599 - val_recall: 0.4216 - val_auc: 0.9726
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0255 - tp: 1519.0000 - fp: 441.0000 - tn: 253353.0000 - fn: 1572.0000 - accuracy: 0.9922 - precision: 0.7750 - recall: 0.4914 - auc: 0.9645 - val_loss: 0.0210 - val_tp: 1762.0000 - val_fp: 462.0000 - val_tn: 234557.0000 - val_fn: 1077.0000 - val_accuracy: 0.9935 - val_precision: 0.7923 - val_recall: 0.6206 - val_auc: 0.9867
256885/256885 - 129s - loss: 0.0255 - tp: 1519.0000 - fp: 441.0000 - tn: 253353.0000 - fn: 1572.0000 - accuracy: 0.9922 - precision: 0.7750 - recall: 0.4914 - auc: 0.9645 - val_loss: 0.0210 - val_tp: 1762.0000 - val_fp: 462.0000 - val_tn: 234557.0000 - val_fn: 1077.0000 - val_accuracy: 0.9935 - val_precision: 0.7923 - val_recall: 0.6206 - val_auc: 0.9867
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c33d0438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8546438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c48d5828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c48d5be0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c48d59b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c48d50f0>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c3c3b4e0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3c3be10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c374dfd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c3747908>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e8485390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c33a5b38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c48cd358>]
          

Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_77 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_171 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_171 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_172 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_172 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_57 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_173 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_173 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 133s - loss: 0.0434 - tp: 510.0000 - fp: 371.0000 - tn: 253403.0000 - fn: 2601.0000 - accuracy: 0.9884 - precision: 0.5789 - recall: 0.1639 - auc: 0.8952 - val_loss: 0.0296 - val_tp: 1058.0000 - val_fp: 559.0000 - val_tn: 234460.0000 - val_fn: 1781.0000 - val_accuracy: 0.9902 - val_precision: 0.6543 - val_recall: 0.3727 - val_auc: 0.9705
256885/256885 - 133s - loss: 0.0434 - tp: 510.0000 - fp: 371.0000 - tn: 253403.0000 - fn: 2601.0000 - accuracy: 0.9884 - precision: 0.5789 - recall: 0.1639 - auc: 0.8952 - val_loss: 0.0296 - val_tp: 1058.0000 - val_fp: 559.0000 - val_tn: 234460.0000 - val_fn: 1781.0000 - val_accuracy: 0.9902 - val_precision: 0.6543 - val_recall: 0.3727 - val_auc: 0.9705
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0265 - tp: 1408.0000 - fp: 454.0000 - tn: 253320.0000 - fn: 1703.0000 - accuracy: 0.9916 - precision: 0.7562 - recall: 0.4526 - auc: 0.9662 - val_loss: 0.0284 - val_tp: 1163.0000 - val_fp: 152.0000 - val_tn: 234867.0000 - val_fn: 1676.0000 - val_accuracy: 0.9923 - val_precision: 0.8844 - val_recall: 0.4097 - val_auc: 0.9274
256885/256885 - 129s - loss: 0.0265 - tp: 1408.0000 - fp: 454.0000 - tn: 253320.0000 - fn: 1703.0000 - accuracy: 0.9916 - precision: 0.7562 - recall: 0.4526 - auc: 0.9662 - val_loss: 0.0284 - val_tp: 1163.0000 - val_fp: 152.0000 - val_tn: 234867.0000 - val_fn: 1676.0000 - val_accuracy: 0.9923 - val_precision: 0.8844 - val_recall: 0.4097 - val_auc: 0.9274
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c34b6b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e9d7ccf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49783ffc18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49783f62e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49783f6588>, <tensorflow.python.keras.metrics.Precision object at 0x7f49783f6940>, <tensorflow.python.keras.metrics.Recall object at 0x7f49783f6be0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49783f6ef0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49e8485390>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c33a5e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c33d0cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c33d0ef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3adda20>]
          

Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_78 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_174 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_174 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_175 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_175 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_58 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_176 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_176 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 133s - loss: 0.0423 - tp: 539.0000 - fp: 364.0000 - tn: 253414.0000 - fn: 2569.0000 - accuracy: 0.9886 - precision: 0.5969 - recall: 0.1734 - auc: 0.9087 - val_loss: 0.0289 - val_tp: 1004.0000 - val_fp: 446.0000 - val_tn: 234573.0000 - val_fn: 1835.0000 - val_accuracy: 0.9904 - val_precision: 0.6924 - val_recall: 0.3536 - val_auc: 0.9689
256886/256886 - 133s - loss: 0.0423 - tp: 539.0000 - fp: 364.0000 - tn: 253414.0000 - fn: 2569.0000 - accuracy: 0.9886 - precision: 0.5969 - recall: 0.1734 - auc: 0.9087 - val_loss: 0.0289 - val_tp: 1004.0000 - val_fp: 446.0000 - val_tn: 234573.0000 - val_fn: 1835.0000 - val_accuracy: 0.9904 - val_precision: 0.6924 - val_recall: 0.3536 - val_auc: 0.9689
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 131s - loss: 0.0269 - tp: 1425.0000 - fp: 493.0000 - tn: 253285.0000 - fn: 1683.0000 - accuracy: 0.9915 - precision: 0.7430 - recall: 0.4585 - auc: 0.9634 - val_loss: 0.0249 - val_tp: 1308.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 1531.0000 - val_accuracy: 0.9927 - val_precision: 0.8657 - val_recall: 0.4607 - val_auc: 0.9500
256886/256886 - 131s - loss: 0.0269 - tp: 1425.0000 - fp: 493.0000 - tn: 253285.0000 - fn: 1683.0000 - accuracy: 0.9915 - precision: 0.7430 - recall: 0.4585 - auc: 0.9634 - val_loss: 0.0249 - val_tp: 1308.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 1531.0000 - val_accuracy: 0.9927 - val_precision: 0.8657 - val_recall: 0.4607 - val_auc: 0.9500
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 30s
256886/256886 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496b8f06d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e86dc080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496b656278>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496b9d9cf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b9d98d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b9d9a20>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b9d9e80>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b9d9390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c33d0cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c3480668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c33d04a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496b672d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e83fb748>]
          

Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_79 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_177 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_177 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_178 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_178 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_59 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_179 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_179 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 133s - loss: 0.0423 - tp: 580.0000 - fp: 397.0000 - tn: 253365.0000 - fn: 2544.0000 - accuracy: 0.9886 - precision: 0.5937 - recall: 0.1857 - auc: 0.9045 - val_loss: 0.0336 - val_tp: 469.0000 - val_fp: 102.0000 - val_tn: 234917.0000 - val_fn: 2370.0000 - val_accuracy: 0.9896 - val_precision: 0.8214 - val_recall: 0.1652 - val_auc: 0.9412
256886/256886 - 133s - loss: 0.0423 - tp: 580.0000 - fp: 397.0000 - tn: 253365.0000 - fn: 2544.0000 - accuracy: 0.9886 - precision: 0.5937 - recall: 0.1857 - auc: 0.9045 - val_loss: 0.0336 - val_tp: 469.0000 - val_fp: 102.0000 - val_tn: 234917.0000 - val_fn: 2370.0000 - val_accuracy: 0.9896 - val_precision: 0.8214 - val_recall: 0.1652 - val_auc: 0.9412
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 129s - loss: 0.0262 - tp: 1509.0000 - fp: 475.0000 - tn: 253287.0000 - fn: 1615.0000 - accuracy: 0.9919 - precision: 0.7606 - recall: 0.4830 - auc: 0.9656 - val_loss: 0.0212 - val_tp: 1464.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1375.0000 - val_accuracy: 0.9931 - val_precision: 0.8497 - val_recall: 0.5157 - val_auc: 0.9789
256886/256886 - 129s - loss: 0.0262 - tp: 1509.0000 - fp: 475.0000 - tn: 253287.0000 - fn: 1615.0000 - accuracy: 0.9919 - precision: 0.7606 - recall: 0.4830 - auc: 0.9656 - val_loss: 0.0212 - val_tp: 1464.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1375.0000 - val_accuracy: 0.9931 - val_precision: 0.8497 - val_recall: 0.5157 - val_auc: 0.9789
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 30s
256886/256886 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bc1f6d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c370bfd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3bc13c8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bfa0588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b09b710>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b09b5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b09bc18>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b09b358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496b672358>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c413d438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49e83fb748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4475be0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496b1759b0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c48cd358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496b09b6a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496b09beb8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496b09b710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b09bbe0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b09be10>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b8f0c88>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c3bc1278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bc1fcf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bc3fda0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c4452780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4452080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c4452898>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bc3f208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bc19f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bc1feb8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3bc1c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b09b978>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b09b8d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b09b080>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b09bdd8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3bce048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a9c9828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496bc3fef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496bc3f5f8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496bc3f198>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a958b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a958f60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a969240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a9694e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a969780>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a969b38>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a969dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a978128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bc3ff98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a99c470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a99c5f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a99c518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a958d68>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a927908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a927d68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a927f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a9372e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a937588>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a937940>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a937be0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a937ef0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a958b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496b09ba58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496b09b1d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496b09b2e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a927b70>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bfb3160>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bfb3400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bfb36a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bfb3940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496bfb3be0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496bfb3f98>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a89e278>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a89e588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a927978>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a884a90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a884eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a884e80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a884f60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a86e9b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a86ecc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a86ef60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a800240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a8004e0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a800898>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a800b38>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a800e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bfb30f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a8af1d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a8af208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a86ea58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a86ea20>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a86ebe0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a86ee10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a810198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a8108d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496bc2e128>, <tensorflow.python.keras.metrics.Precision object at 0x7f496bc2e4e0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496bc2e780>, <tensorflow.python.keras.metrics.AUC object at 0x7f496bc2ea90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a86e7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bfb30f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a8af208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a86ef98>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a86efd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bc2eb70>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bc2e710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bc2e5c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bc2e048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496bc2e278>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a810c50>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a810b00>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a86e908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a86ec88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bc2edd8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496bc2ea90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496bc2ef60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496bc2eef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a86e978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a86ec50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a8102e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a8100f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496bc2e048>, <tensorflow.python.keras.metrics.Precision object at 0x7f496bc2e710>, <tensorflow.python.keras.metrics.Recall object at 0x7f496bc2e4e0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496bc2e4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bc2e780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a7a4e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a7a4f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a807780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a807860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bc2e978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bc2ea20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bc2e048>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bc2e5f8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496bc2ecf8>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a8108d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a810c50>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a86ee10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a86ed68>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a76fb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a76fdd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c443c518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c443c438>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d6d6b438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a86eb00>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a86ea20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a810358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a8102e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f496bc2e080>, <tensorflow.python.keras.metrics.Recall object at 0x7f496bc2e860>, <tensorflow.python.keras.metrics.AUC object at 0x7f496bc2e160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c443c2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a6ca0b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a73bba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a73bfd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a73b8d0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bc2e400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bc2e978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bc2e470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bc2e518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a810128>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a810080>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d6d6b470>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a86ee10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d6d6b588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a687e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a6ca0f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a6ca390>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a6ca3c8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a86edd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a86ea58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a810c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a810ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a8100b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f496bc2ebe0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496bc2eb70>, <tensorflow.python.keras.metrics.AUC object at 0x7f496bc2e2e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bc2e940>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a652ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a687e48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a687f98>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a687c50>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a5f1198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a5f1438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a5f16d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a5f1978>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a5f1c18>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a5f1fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a5fe2b0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a5fe5c0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a86ee10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a5e3b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a5e3ac8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a5e3f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a5e3fd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a5b5e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a5bf1d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a5bf470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a5bf710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a5bf9b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a5bfd68>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a5bffd0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a549358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a5f1128>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bc2e0f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496bc2e978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496bc2e438>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a5b5f60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a51a390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a51a7b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a51aa58>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a51acf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a51af98>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a527390>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a527630>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a527940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a5b5d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a558080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a549f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a51a518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a51a4e0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a481c88>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a481f60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a88e2e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a88e588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a88e828>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a88ebe0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a88ee80>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a49b1d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a51a2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a53a550>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a53a860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a53a5f8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a481dd8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a481e48>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a49b6a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a49b278>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a49b390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a46e3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a46e780>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a46ea58>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a46ed68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a481ba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a51a2e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a53a860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a53a5f8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a481f60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a46ec50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a46e4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a46e400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a46ec18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a49b048>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a49b5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a49bba8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a432f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a481cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a481e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a51a400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a46ed68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a46eda0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496a499278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496a49be10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496a49b4e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496a49bbe0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496a49b198>, <tensorflow.python.keras.metrics.Precision object at 0x7f496a46e4e0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a46e860>, <tensorflow.python.keras.metrics.AUC object at 0x7f496a46e4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a46ea90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a499b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a4999b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a499a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496a499c88>]
          

Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_60 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_180 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_180 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_181 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_60 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_182 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_182 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 112s - loss: 0.0418 - tp: 675.0000 - fp: 362.0000 - tn: 253397.0000 - fn: 2451.0000 - accuracy: 0.9890 - precision: 0.6509 - recall: 0.2159 - auc: 0.9012 - val_loss: 0.0283 - val_tp: 902.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 1937.0000 - val_accuracy: 0.9908 - val_precision: 0.7871 - val_recall: 0.3177 - val_auc: 0.9643
256885/256885 - 112s - loss: 0.0418 - tp: 675.0000 - fp: 362.0000 - tn: 253397.0000 - fn: 2451.0000 - accuracy: 0.9890 - precision: 0.6509 - recall: 0.2159 - auc: 0.9012 - val_loss: 0.0283 - val_tp: 902.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 1937.0000 - val_accuracy: 0.9908 - val_precision: 0.7871 - val_recall: 0.3177 - val_auc: 0.9643
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 109s - loss: 0.0246 - tp: 1587.0000 - fp: 437.0000 - tn: 253322.0000 - fn: 1539.0000 - accuracy: 0.9923 - precision: 0.7841 - recall: 0.5077 - auc: 0.9690 - val_loss: 0.0258 - val_tp: 1300.0000 - val_fp: 159.0000 - val_tn: 234860.0000 - val_fn: 1539.0000 - val_accuracy: 0.9929 - val_precision: 0.8910 - val_recall: 0.4579 - val_auc: 0.9359
256885/256885 - 109s - loss: 0.0246 - tp: 1587.0000 - fp: 437.0000 - tn: 253322.0000 - fn: 1539.0000 - accuracy: 0.9923 - precision: 0.7841 - recall: 0.5077 - auc: 0.9690 - val_loss: 0.0258 - val_tp: 1300.0000 - val_fp: 159.0000 - val_tn: 234860.0000 - val_fn: 1539.0000 - val_accuracy: 0.9929 - val_precision: 0.8910 - val_recall: 0.4579 - val_auc: 0.9359
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e8629630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4a7c154710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4a7c1548d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d6ab1b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c35b06a0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c35b0860>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c35b0c88>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9115cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a499b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a499c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a499a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a499940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e82a92e8>]
          

Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_61 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_183 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_183 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_184 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_184 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_61 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_185 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_185 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 112s - loss: 0.0423 - tp: 625.0000 - fp: 427.0000 - tn: 253331.0000 - fn: 2502.0000 - accuracy: 0.9886 - precision: 0.5941 - recall: 0.1999 - auc: 0.9048 - val_loss: 0.0285 - val_tp: 1121.0000 - val_fp: 499.0000 - val_tn: 234520.0000 - val_fn: 1718.0000 - val_accuracy: 0.9907 - val_precision: 0.6920 - val_recall: 0.3949 - val_auc: 0.9701
256885/256885 - 112s - loss: 0.0423 - tp: 625.0000 - fp: 427.0000 - tn: 253331.0000 - fn: 2502.0000 - accuracy: 0.9886 - precision: 0.5941 - recall: 0.1999 - auc: 0.9048 - val_loss: 0.0285 - val_tp: 1121.0000 - val_fp: 499.0000 - val_tn: 234520.0000 - val_fn: 1718.0000 - val_accuracy: 0.9907 - val_precision: 0.6920 - val_recall: 0.3949 - val_auc: 0.9701
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 109s - loss: 0.0254 - tp: 1511.0000 - fp: 421.0000 - tn: 253337.0000 - fn: 1616.0000 - accuracy: 0.9921 - precision: 0.7821 - recall: 0.4832 - auc: 0.9694 - val_loss: 0.0220 - val_tp: 1466.0000 - val_fp: 217.0000 - val_tn: 234802.0000 - val_fn: 1373.0000 - val_accuracy: 0.9933 - val_precision: 0.8711 - val_recall: 0.5164 - val_auc: 0.9622
256885/256885 - 109s - loss: 0.0254 - tp: 1511.0000 - fp: 421.0000 - tn: 253337.0000 - fn: 1616.0000 - accuracy: 0.9921 - precision: 0.7821 - recall: 0.4832 - auc: 0.9694 - val_loss: 0.0220 - val_tp: 1466.0000 - val_fp: 217.0000 - val_tn: 234802.0000 - val_fn: 1373.0000 - val_accuracy: 0.9933 - val_precision: 0.8711 - val_recall: 0.5164 - val_auc: 0.9622
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c3b3d278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49c3b3d898>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3b3d630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49784cf9b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c4fd1518>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c4fd1320>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c4fd1668>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a04437da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c4ced0f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496b7f5438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c4b7e978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c3b45320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c41dab38>]
          

Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_62 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_186 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_186 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_187 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_187 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_62 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_188 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_188 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 111s - loss: 0.0420 - tp: 602.0000 - fp: 429.0000 - tn: 253340.0000 - fn: 2514.0000 - accuracy: 0.9885 - precision: 0.5839 - recall: 0.1932 - auc: 0.9078 - val_loss: 0.0287 - val_tp: 762.0000 - val_fp: 190.0000 - val_tn: 234829.0000 - val_fn: 2077.0000 - val_accuracy: 0.9905 - val_precision: 0.8004 - val_recall: 0.2684 - val_auc: 0.9650
256885/256885 - 111s - loss: 0.0420 - tp: 602.0000 - fp: 429.0000 - tn: 253340.0000 - fn: 2514.0000 - accuracy: 0.9885 - precision: 0.5839 - recall: 0.1932 - auc: 0.9078 - val_loss: 0.0287 - val_tp: 762.0000 - val_fp: 190.0000 - val_tn: 234829.0000 - val_fn: 2077.0000 - val_accuracy: 0.9905 - val_precision: 0.8004 - val_recall: 0.2684 - val_auc: 0.9650
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 107s - loss: 0.0247 - tp: 1568.0000 - fp: 450.0000 - tn: 253319.0000 - fn: 1548.0000 - accuracy: 0.9922 - precision: 0.7770 - recall: 0.5032 - auc: 0.9698 - val_loss: 0.0208 - val_tp: 1770.0000 - val_fp: 399.0000 - val_tn: 234620.0000 - val_fn: 1069.0000 - val_accuracy: 0.9938 - val_precision: 0.8160 - val_recall: 0.6235 - val_auc: 0.9878
256885/256885 - 107s - loss: 0.0247 - tp: 1568.0000 - fp: 450.0000 - tn: 253319.0000 - fn: 1548.0000 - accuracy: 0.9922 - precision: 0.7770 - recall: 0.5032 - auc: 0.9698 - val_loss: 0.0208 - val_tp: 1770.0000 - val_fp: 399.0000 - val_tn: 234620.0000 - val_fn: 1069.0000 - val_accuracy: 0.9938 - val_precision: 0.8160 - val_recall: 0.6235 - val_auc: 0.9878
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4965d03780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4965fa4fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4965cf1ef0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4965d68d30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4965c895c0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4965c89b38>, <tensorflow.python.keras.metrics.Recall object at 0x7f4965c89dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7f4965c96128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c4b7e978>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c4945828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c3b3d550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c3b3d080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3b3d438>]
          

Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_63 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_189 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_189 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_190 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_190 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_63 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_191 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_191 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 111s - loss: 0.0418 - tp: 625.0000 - fp: 349.0000 - tn: 253443.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6417 - recall: 0.2021 - auc: 0.9027 - val_loss: 0.0338 - val_tp: 1574.0000 - val_fp: 1384.0000 - val_tn: 233635.0000 - val_fn: 1265.0000 - val_accuracy: 0.9889 - val_precision: 0.5321 - val_recall: 0.5544 - val_auc: 0.9753
256885/256885 - 111s - loss: 0.0418 - tp: 625.0000 - fp: 349.0000 - tn: 253443.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6417 - recall: 0.2021 - auc: 0.9027 - val_loss: 0.0338 - val_tp: 1574.0000 - val_fp: 1384.0000 - val_tn: 233635.0000 - val_fn: 1265.0000 - val_accuracy: 0.9889 - val_precision: 0.5321 - val_recall: 0.5544 - val_auc: 0.9753
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 107s - loss: 0.0253 - tp: 1477.0000 - fp: 442.0000 - tn: 253350.0000 - fn: 1616.0000 - accuracy: 0.9920 - precision: 0.7697 - recall: 0.4775 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1503.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1336.0000 - val_accuracy: 0.9932 - val_precision: 0.8434 - val_recall: 0.5294 - val_auc: 0.9648
256885/256885 - 107s - loss: 0.0253 - tp: 1477.0000 - fp: 442.0000 - tn: 253350.0000 - fn: 1616.0000 - accuracy: 0.9920 - precision: 0.7697 - recall: 0.4775 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1503.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1336.0000 - val_accuracy: 0.9932 - val_precision: 0.8434 - val_recall: 0.5294 - val_auc: 0.9648
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.73124
256885/256885 - 108s - loss: 0.0207 - tp: 1885.0000 - fp: 383.0000 - tn: 253409.0000 - fn: 1208.0000 - accuracy: 0.9938 - precision: 0.8311 - recall: 0.6094 - auc: 0.9700 - val_loss: 0.0185 - val_tp: 1842.0000 - val_fp: 363.0000 - val_tn: 234656.0000 - val_fn: 997.0000 - val_accuracy: 0.9943 - val_precision: 0.8354 - val_recall: 0.6488 - val_auc: 0.9817
256885/256885 - 108s - loss: 0.0207 - tp: 1885.0000 - fp: 383.0000 - tn: 253409.0000 - fn: 1208.0000 - accuracy: 0.9938 - precision: 0.8311 - recall: 0.6094 - auc: 0.9700 - val_loss: 0.0185 - val_tp: 1842.0000 - val_fp: 363.0000 - val_tn: 234656.0000 - val_fn: 997.0000 - val_accuracy: 0.9943 - val_precision: 0.8354 - val_recall: 0.6488 - val_auc: 0.9817
Epoch 00003: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 5.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4966e4cfd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4968ef2eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4966e55320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4966e55fd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4966e55a20>, <tensorflow.python.keras.metrics.Precision object at 0x7f4966e550b8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4966e552b0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4965cf9dd8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3b3d550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4965fa8278>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c3b3d438>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49699379e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4968ee93c8>]
          

Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_64 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_192 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_192 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_193 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_193 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_64 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_194 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_194 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 113s - loss: 0.0415 - tp: 649.0000 - fp: 387.0000 - tn: 253352.0000 - fn: 2497.0000 - accuracy: 0.9888 - precision: 0.6264 - recall: 0.2063 - auc: 0.9119 - val_loss: 0.0352 - val_tp: 610.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 2229.0000 - val_accuracy: 0.9900 - val_precision: 0.8079 - val_recall: 0.2149 - val_auc: 0.9189
256885/256885 - 113s - loss: 0.0415 - tp: 649.0000 - fp: 387.0000 - tn: 253352.0000 - fn: 2497.0000 - accuracy: 0.9888 - precision: 0.6264 - recall: 0.2063 - auc: 0.9119 - val_loss: 0.0352 - val_tp: 610.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 2229.0000 - val_accuracy: 0.9900 - val_precision: 0.8079 - val_recall: 0.2149 - val_auc: 0.9189
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 109s - loss: 0.0253 - tp: 1565.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 1581.0000 - accuracy: 0.9921 - precision: 0.7802 - recall: 0.4975 - auc: 0.9690 - val_loss: 0.0203 - val_tp: 1665.0000 - val_fp: 290.0000 - val_tn: 234729.0000 - val_fn: 1174.0000 - val_accuracy: 0.9938 - val_precision: 0.8517 - val_recall: 0.5865 - val_auc: 0.9824
256885/256885 - 109s - loss: 0.0253 - tp: 1565.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 1581.0000 - accuracy: 0.9921 - precision: 0.7802 - recall: 0.4975 - auc: 0.9690 - val_loss: 0.0203 - val_tp: 1665.0000 - val_fp: 290.0000 - val_tn: 234729.0000 - val_fn: 1174.0000 - val_accuracy: 0.9938 - val_precision: 0.8517 - val_recall: 0.5865 - val_auc: 0.9824
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49e90ebf28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e8485780>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d4ee2e10>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3597438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c35973c8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3597a20>, <tensorflow.python.keras.metrics.Recall object at 0x7f496a46eeb8>, <tensorflow.python.keras.metrics.AUC object at 0x7f4a4011b710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496a481fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496a481da0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496a884f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496a884e80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e8e2f4e0>]
          

Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_65 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_195 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_195 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_196 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_196 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_65 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_197 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_197 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 112s - loss: 0.0413 - tp: 612.0000 - fp: 363.0000 - tn: 253415.0000 - fn: 2495.0000 - accuracy: 0.9889 - precision: 0.6277 - recall: 0.1970 - auc: 0.9115 - val_loss: 0.0285 - val_tp: 983.0000 - val_fp: 353.0000 - val_tn: 234666.0000 - val_fn: 1856.0000 - val_accuracy: 0.9907 - val_precision: 0.7358 - val_recall: 0.3462 - val_auc: 0.9611
256885/256885 - 112s - loss: 0.0413 - tp: 612.0000 - fp: 363.0000 - tn: 253415.0000 - fn: 2495.0000 - accuracy: 0.9889 - precision: 0.6277 - recall: 0.1970 - auc: 0.9115 - val_loss: 0.0285 - val_tp: 983.0000 - val_fp: 353.0000 - val_tn: 234666.0000 - val_fn: 1856.0000 - val_accuracy: 0.9907 - val_precision: 0.7358 - val_recall: 0.3462 - val_auc: 0.9611
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 109s - loss: 0.0251 - tp: 1529.0000 - fp: 439.0000 - tn: 253339.0000 - fn: 1578.0000 - accuracy: 0.9921 - precision: 0.7769 - recall: 0.4921 - auc: 0.9663 - val_loss: 0.0243 - val_tp: 1338.0000 - val_fp: 177.0000 - val_tn: 234842.0000 - val_fn: 1501.0000 - val_accuracy: 0.9929 - val_precision: 0.8832 - val_recall: 0.4713 - val_auc: 0.9453
256885/256885 - 109s - loss: 0.0251 - tp: 1529.0000 - fp: 439.0000 - tn: 253339.0000 - fn: 1578.0000 - accuracy: 0.9921 - precision: 0.7769 - recall: 0.4921 - auc: 0.9663 - val_loss: 0.0243 - val_tp: 1338.0000 - val_fp: 177.0000 - val_tn: 234842.0000 - val_fn: 1501.0000 - val_accuracy: 0.9929 - val_precision: 0.8832 - val_recall: 0.4713 - val_auc: 0.9453
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49d773e1d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d773e940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d6d84c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d6b5f320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d6b5f2b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4969f84e10>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d71bc908>, <tensorflow.python.keras.metrics.AUC object at 0x7f4968f98390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49783d0fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bba6a90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49c48d4da0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496b552320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4966dd8be0>]
          

Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_66 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_198 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_198 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_199 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_199 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_66 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_200 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_200 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 112s - loss: 0.0425 - tp: 533.0000 - fp: 421.0000 - tn: 253373.0000 - fn: 2558.0000 - accuracy: 0.9884 - precision: 0.5587 - recall: 0.1724 - auc: 0.9067 - val_loss: 0.0293 - val_tp: 802.0000 - val_fp: 241.0000 - val_tn: 234778.0000 - val_fn: 2037.0000 - val_accuracy: 0.9904 - val_precision: 0.7689 - val_recall: 0.2825 - val_auc: 0.9644
256885/256885 - 112s - loss: 0.0425 - tp: 533.0000 - fp: 421.0000 - tn: 253373.0000 - fn: 2558.0000 - accuracy: 0.9884 - precision: 0.5587 - recall: 0.1724 - auc: 0.9067 - val_loss: 0.0293 - val_tp: 802.0000 - val_fp: 241.0000 - val_tn: 234778.0000 - val_fn: 2037.0000 - val_accuracy: 0.9904 - val_precision: 0.7689 - val_recall: 0.2825 - val_auc: 0.9644
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 109s - loss: 0.0250 - tp: 1495.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1596.0000 - accuracy: 0.9922 - precision: 0.7844 - recall: 0.4837 - auc: 0.9665 - val_loss: 0.0201 - val_tp: 1705.0000 - val_fp: 413.0000 - val_tn: 234606.0000 - val_fn: 1134.0000 - val_accuracy: 0.9935 - val_precision: 0.8050 - val_recall: 0.6006 - val_auc: 0.9786
256885/256885 - 109s - loss: 0.0250 - tp: 1495.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1596.0000 - accuracy: 0.9922 - precision: 0.7844 - recall: 0.4837 - auc: 0.9665 - val_loss: 0.0201 - val_tp: 1705.0000 - val_fp: 413.0000 - val_tn: 234606.0000 - val_fn: 1134.0000 - val_accuracy: 0.9935 - val_precision: 0.8050 - val_recall: 0.6006 - val_auc: 0.9786
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496b175f60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496b783cc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496b7a6198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496b7a6940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496b7a6be0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496b7a6f98>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c416f278>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c416f588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c48d4da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c490a400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d773e5f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d773e8d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3cf6be0>]
          

Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_67 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_201 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_201 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_202 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_202 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_67 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_203 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_203 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 111s - loss: 0.0414 - tp: 569.0000 - fp: 379.0000 - tn: 253395.0000 - fn: 2542.0000 - accuracy: 0.9886 - precision: 0.6002 - recall: 0.1829 - auc: 0.9108 - val_loss: 0.0322 - val_tp: 829.0000 - val_fp: 292.0000 - val_tn: 234727.0000 - val_fn: 2010.0000 - val_accuracy: 0.9903 - val_precision: 0.7395 - val_recall: 0.2920 - val_auc: 0.9350
256885/256885 - 111s - loss: 0.0414 - tp: 569.0000 - fp: 379.0000 - tn: 253395.0000 - fn: 2542.0000 - accuracy: 0.9886 - precision: 0.6002 - recall: 0.1829 - auc: 0.9108 - val_loss: 0.0322 - val_tp: 829.0000 - val_fp: 292.0000 - val_tn: 234727.0000 - val_fn: 2010.0000 - val_accuracy: 0.9903 - val_precision: 0.7395 - val_recall: 0.2920 - val_auc: 0.9350
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 108s - loss: 0.0253 - tp: 1531.0000 - fp: 438.0000 - tn: 253336.0000 - fn: 1580.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4921 - auc: 0.9677 - val_loss: 0.0211 - val_tp: 1551.0000 - val_fp: 291.0000 - val_tn: 234728.0000 - val_fn: 1288.0000 - val_accuracy: 0.9934 - val_precision: 0.8420 - val_recall: 0.5463 - val_auc: 0.9696
256885/256885 - 108s - loss: 0.0253 - tp: 1531.0000 - fp: 438.0000 - tn: 253336.0000 - fn: 1580.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4921 - auc: 0.9677 - val_loss: 0.0211 - val_tp: 1551.0000 - val_fp: 291.0000 - val_tn: 234728.0000 - val_fn: 1288.0000 - val_accuracy: 0.9934 - val_precision: 0.8420 - val_recall: 0.5463 - val_auc: 0.9696
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49699dfeb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496b19fb70>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496b1beda0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496aeac1d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496aeac550>, <tensorflow.python.keras.metrics.Precision object at 0x7f496aeac8d0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496aeac278>, <tensorflow.python.keras.metrics.AUC object at 0x7f496aeac2e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d773e630>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d773ec18>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49d773e8d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4969be2ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4969be23c8>]
          

Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_68 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_204 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_204 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_205 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_205 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_68 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_206 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_206 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 111s - loss: 0.0416 - tp: 623.0000 - fp: 397.0000 - tn: 253381.0000 - fn: 2485.0000 - accuracy: 0.9888 - precision: 0.6108 - recall: 0.2005 - auc: 0.9038 - val_loss: 0.0280 - val_tp: 1034.0000 - val_fp: 395.0000 - val_tn: 234624.0000 - val_fn: 1805.0000 - val_accuracy: 0.9908 - val_precision: 0.7236 - val_recall: 0.3642 - val_auc: 0.9700
256886/256886 - 111s - loss: 0.0416 - tp: 623.0000 - fp: 397.0000 - tn: 253381.0000 - fn: 2485.0000 - accuracy: 0.9888 - precision: 0.6108 - recall: 0.2005 - auc: 0.9038 - val_loss: 0.0280 - val_tp: 1034.0000 - val_fp: 395.0000 - val_tn: 234624.0000 - val_fn: 1805.0000 - val_accuracy: 0.9908 - val_precision: 0.7236 - val_recall: 0.3642 - val_auc: 0.9700
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 108s - loss: 0.0245 - tp: 1559.0000 - fp: 439.0000 - tn: 253339.0000 - fn: 1549.0000 - accuracy: 0.9923 - precision: 0.7803 - recall: 0.5016 - auc: 0.9683 - val_loss: 0.0203 - val_tp: 1512.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 1327.0000 - val_accuracy: 0.9936 - val_precision: 0.8816 - val_recall: 0.5326 - val_auc: 0.9724
256886/256886 - 108s - loss: 0.0245 - tp: 1559.0000 - fp: 439.0000 - tn: 253339.0000 - fn: 1549.0000 - accuracy: 0.9923 - precision: 0.7803 - recall: 0.5016 - auc: 0.9683 - val_loss: 0.0203 - val_tp: 1512.0000 - val_fp: 203.0000 - val_tn: 234816.0000 - val_fn: 1327.0000 - val_accuracy: 0.9936 - val_precision: 0.8816 - val_recall: 0.5326 - val_auc: 0.9724
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4966238358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4969d09c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d5900fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d5900668>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d59005f8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d5900828>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d59002b0>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d58dc710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969be2c18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c4321f28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49699df860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49699dfe10>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c3cf6be0>]
          

Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_69 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_207 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_207 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_208 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_208 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_69 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_209 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_209 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 111s - loss: 0.0425 - tp: 585.0000 - fp: 420.0000 - tn: 253342.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5821 - recall: 0.1873 - auc: 0.9041 - val_loss: 0.0318 - val_tp: 817.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2022.0000 - val_accuracy: 0.9905 - val_precision: 0.7700 - val_recall: 0.2878 - val_auc: 0.9368
256886/256886 - 111s - loss: 0.0425 - tp: 585.0000 - fp: 420.0000 - tn: 253342.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5821 - recall: 0.1873 - auc: 0.9041 - val_loss: 0.0318 - val_tp: 817.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2022.0000 - val_accuracy: 0.9905 - val_precision: 0.7700 - val_recall: 0.2878 - val_auc: 0.9368
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 108s - loss: 0.0248 - tp: 1568.0000 - fp: 436.0000 - tn: 253326.0000 - fn: 1556.0000 - accuracy: 0.9922 - precision: 0.7824 - recall: 0.5019 - auc: 0.9683 - val_loss: 0.0212 - val_tp: 1516.0000 - val_fp: 239.0000 - val_tn: 234780.0000 - val_fn: 1323.0000 - val_accuracy: 0.9934 - val_precision: 0.8638 - val_recall: 0.5340 - val_auc: 0.9638
256886/256886 - 108s - loss: 0.0248 - tp: 1568.0000 - fp: 436.0000 - tn: 253326.0000 - fn: 1556.0000 - accuracy: 0.9922 - precision: 0.7824 - recall: 0.5019 - auc: 0.9683 - val_loss: 0.0212 - val_tp: 1516.0000 - val_fp: 239.0000 - val_tn: 234780.0000 - val_fn: 1323.0000 - val_accuracy: 0.9934 - val_precision: 0.8638 - val_recall: 0.5340 - val_auc: 0.9638
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4965c00ac8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4965c00da0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4965c00b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d57c4f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49637de860>, <tensorflow.python.keras.metrics.Precision object at 0x7f4965c20f60>, <tensorflow.python.keras.metrics.Recall object at 0x7f4965c20a90>, <tensorflow.python.keras.metrics.AUC object at 0x7f4965c20630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3cf6be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4969be23c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4969be2c18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4963a1c3c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d534d400>]
          

Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_70 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_210 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_210 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_211 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_211 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_70 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_212 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_212 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0408 - tp: 636.0000 - fp: 333.0000 - tn: 253426.0000 - fn: 2490.0000 - accuracy: 0.9890 - precision: 0.6563 - recall: 0.2035 - auc: 0.9123 - val_loss: 0.0280 - val_tp: 1221.0000 - val_fp: 569.0000 - val_tn: 234450.0000 - val_fn: 1618.0000 - val_accuracy: 0.9908 - val_precision: 0.6821 - val_recall: 0.4301 - val_auc: 0.9690
256885/256885 - 129s - loss: 0.0408 - tp: 636.0000 - fp: 333.0000 - tn: 253426.0000 - fn: 2490.0000 - accuracy: 0.9890 - precision: 0.6563 - recall: 0.2035 - auc: 0.9123 - val_loss: 0.0280 - val_tp: 1221.0000 - val_fp: 569.0000 - val_tn: 234450.0000 - val_fn: 1618.0000 - val_accuracy: 0.9908 - val_precision: 0.6821 - val_recall: 0.4301 - val_auc: 0.9690
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0245 - tp: 1592.0000 - fp: 458.0000 - tn: 253301.0000 - fn: 1534.0000 - accuracy: 0.9922 - precision: 0.7766 - recall: 0.5093 - auc: 0.9688 - val_loss: 0.0197 - val_tp: 1802.0000 - val_fp: 472.0000 - val_tn: 234547.0000 - val_fn: 1037.0000 - val_accuracy: 0.9937 - val_precision: 0.7924 - val_recall: 0.6347 - val_auc: 0.9750
256885/256885 - 126s - loss: 0.0245 - tp: 1592.0000 - fp: 458.0000 - tn: 253301.0000 - fn: 1534.0000 - accuracy: 0.9922 - precision: 0.7766 - recall: 0.5093 - auc: 0.9688 - val_loss: 0.0197 - val_tp: 1802.0000 - val_fp: 472.0000 - val_tn: 234547.0000 - val_fn: 1037.0000 - val_accuracy: 0.9937 - val_precision: 0.7924 - val_recall: 0.6347 - val_auc: 0.9750
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c33802b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49e856e860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49e856ec50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c48d4588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c48d4780>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c48d4080>, <tensorflow.python.keras.metrics.Recall object at 0x7f49c48d42e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49c48d4710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969be2c18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4963a1c3c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4965c00ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4965c00c18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49e86dc9e8>]
          

Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_71 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_213 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_213 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_214 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_214 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_71 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_215 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_215 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0423 - tp: 626.0000 - fp: 422.0000 - tn: 253336.0000 - fn: 2501.0000 - accuracy: 0.9886 - precision: 0.5973 - recall: 0.2002 - auc: 0.9036 - val_loss: 0.0300 - val_tp: 724.0000 - val_fp: 202.0000 - val_tn: 234817.0000 - val_fn: 2115.0000 - val_accuracy: 0.9903 - val_precision: 0.7819 - val_recall: 0.2550 - val_auc: 0.9598
256885/256885 - 129s - loss: 0.0423 - tp: 626.0000 - fp: 422.0000 - tn: 253336.0000 - fn: 2501.0000 - accuracy: 0.9886 - precision: 0.5973 - recall: 0.2002 - auc: 0.9036 - val_loss: 0.0300 - val_tp: 724.0000 - val_fp: 202.0000 - val_tn: 234817.0000 - val_fn: 2115.0000 - val_accuracy: 0.9903 - val_precision: 0.7819 - val_recall: 0.2550 - val_auc: 0.9598
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0249 - tp: 1559.0000 - fp: 434.0000 - tn: 253324.0000 - fn: 1568.0000 - accuracy: 0.9922 - precision: 0.7822 - recall: 0.4986 - auc: 0.9678 - val_loss: 0.0209 - val_tp: 1413.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 1426.0000 - val_accuracy: 0.9932 - val_precision: 0.8809 - val_recall: 0.4977 - val_auc: 0.9758
256885/256885 - 126s - loss: 0.0249 - tp: 1559.0000 - fp: 434.0000 - tn: 253324.0000 - fn: 1568.0000 - accuracy: 0.9922 - precision: 0.7822 - recall: 0.4986 - auc: 0.9678 - val_loss: 0.0209 - val_tp: 1413.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 1426.0000 - val_accuracy: 0.9932 - val_precision: 0.8809 - val_recall: 0.4977 - val_auc: 0.9758
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49c48cf908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496aba55f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49d4b56940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d4b566a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d4b56320>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d4b56978>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d4b56128>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d4b56400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4965c00c18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49c3e43940>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4965bf28d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4930cf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49c4930198>]
          

Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_72 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_216 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_216 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_217 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_217 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_72 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_218 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_218 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0414 - tp: 613.0000 - fp: 364.0000 - tn: 253405.0000 - fn: 2503.0000 - accuracy: 0.9888 - precision: 0.6274 - recall: 0.1967 - auc: 0.9095 - val_loss: 0.0300 - val_tp: 724.0000 - val_fp: 181.0000 - val_tn: 234838.0000 - val_fn: 2115.0000 - val_accuracy: 0.9903 - val_precision: 0.8000 - val_recall: 0.2550 - val_auc: 0.9515
256885/256885 - 129s - loss: 0.0414 - tp: 613.0000 - fp: 364.0000 - tn: 253405.0000 - fn: 2503.0000 - accuracy: 0.9888 - precision: 0.6274 - recall: 0.1967 - auc: 0.9095 - val_loss: 0.0300 - val_tp: 724.0000 - val_fp: 181.0000 - val_tn: 234838.0000 - val_fn: 2115.0000 - val_accuracy: 0.9903 - val_precision: 0.8000 - val_recall: 0.2550 - val_auc: 0.9515
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0241 - tp: 1617.0000 - fp: 441.0000 - tn: 253328.0000 - fn: 1499.0000 - accuracy: 0.9924 - precision: 0.7857 - recall: 0.5189 - auc: 0.9695 - val_loss: 0.0248 - val_tp: 1400.0000 - val_fp: 197.0000 - val_tn: 234822.0000 - val_fn: 1439.0000 - val_accuracy: 0.9931 - val_precision: 0.8766 - val_recall: 0.4931 - val_auc: 0.9394
256885/256885 - 126s - loss: 0.0241 - tp: 1617.0000 - fp: 441.0000 - tn: 253328.0000 - fn: 1499.0000 - accuracy: 0.9924 - precision: 0.7857 - recall: 0.5189 - auc: 0.9695 - val_loss: 0.0248 - val_tp: 1400.0000 - val_fp: 197.0000 - val_tn: 234822.0000 - val_fn: 1439.0000 - val_accuracy: 0.9931 - val_precision: 0.8766 - val_recall: 0.4931 - val_auc: 0.9394
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4966b781d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496be0d438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496be0dcc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4969c74cc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4969c449e8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d6de1da0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496b1e8f98>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b1e8828>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c4930cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496abac668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4a4038a1d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49d788a208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4965c00ba8>]
          

Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_73 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_219 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_219 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_220 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_220 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_73 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_221 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_221 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0411 - tp: 666.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 2427.0000 - accuracy: 0.9890 - precision: 0.6230 - recall: 0.2153 - auc: 0.9081 - val_loss: 0.0328 - val_tp: 1724.0000 - val_fp: 1518.0000 - val_tn: 233501.0000 - val_fn: 1115.0000 - val_accuracy: 0.9889 - val_precision: 0.5318 - val_recall: 0.6073 - val_auc: 0.9787
256885/256885 - 129s - loss: 0.0411 - tp: 666.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 2427.0000 - accuracy: 0.9890 - precision: 0.6230 - recall: 0.2153 - auc: 0.9081 - val_loss: 0.0328 - val_tp: 1724.0000 - val_fp: 1518.0000 - val_tn: 233501.0000 - val_fn: 1115.0000 - val_accuracy: 0.9889 - val_precision: 0.5318 - val_recall: 0.6073 - val_auc: 0.9787
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0240 - tp: 1649.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 1444.0000 - accuracy: 0.9928 - precision: 0.8036 - recall: 0.5331 - auc: 0.9676 - val_loss: 0.0212 - val_tp: 1533.0000 - val_fp: 223.0000 - val_tn: 234796.0000 - val_fn: 1306.0000 - val_accuracy: 0.9936 - val_precision: 0.8730 - val_recall: 0.5400 - val_auc: 0.9601
256885/256885 - 126s - loss: 0.0240 - tp: 1649.0000 - fp: 403.0000 - tn: 253389.0000 - fn: 1444.0000 - accuracy: 0.9928 - precision: 0.8036 - recall: 0.5331 - auc: 0.9676 - val_loss: 0.0212 - val_tp: 1533.0000 - val_fp: 223.0000 - val_tn: 234796.0000 - val_fn: 1306.0000 - val_accuracy: 0.9936 - val_precision: 0.8730 - val_recall: 0.5400 - val_auc: 0.9601
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0198 - tp: 1969.0000 - fp: 377.0000 - tn: 253415.0000 - fn: 1124.0000 - accuracy: 0.9942 - precision: 0.8393 - recall: 0.6366 - auc: 0.9720 - val_loss: 0.0187 - val_tp: 1652.0000 - val_fp: 171.0000 - val_tn: 234848.0000 - val_fn: 1187.0000 - val_accuracy: 0.9943 - val_precision: 0.9062 - val_recall: 0.5819 - val_auc: 0.9705
256885/256885 - 126s - loss: 0.0198 - tp: 1969.0000 - fp: 377.0000 - tn: 253415.0000 - fn: 1124.0000 - accuracy: 0.9942 - precision: 0.8393 - recall: 0.6366 - auc: 0.9720 - val_loss: 0.0187 - val_tp: 1652.0000 - val_fp: 171.0000 - val_tn: 234848.0000 - val_fn: 1187.0000 - val_accuracy: 0.9943 - val_precision: 0.9062 - val_recall: 0.5819 - val_auc: 0.9705
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49667d4fd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49667e0080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4968ebd588>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4968ebdcf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4968ebd9b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4968ebd198>, <tensorflow.python.keras.metrics.Recall object at 0x7f4968ebd8d0>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b1c1908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49d788a208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49e8563f98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4965c00ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49c4930160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49667cf198>]
          

Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_74 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_222 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_222 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_223 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_223 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_74 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_224 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_224 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0411 - tp: 721.0000 - fp: 426.0000 - tn: 253313.0000 - fn: 2425.0000 - accuracy: 0.9889 - precision: 0.6286 - recall: 0.2292 - auc: 0.9129 - val_loss: 0.0290 - val_tp: 856.0000 - val_fp: 211.0000 - val_tn: 234808.0000 - val_fn: 1983.0000 - val_accuracy: 0.9908 - val_precision: 0.8022 - val_recall: 0.3015 - val_auc: 0.9567
256885/256885 - 129s - loss: 0.0411 - tp: 721.0000 - fp: 426.0000 - tn: 253313.0000 - fn: 2425.0000 - accuracy: 0.9889 - precision: 0.6286 - recall: 0.2292 - auc: 0.9129 - val_loss: 0.0290 - val_tp: 856.0000 - val_fp: 211.0000 - val_tn: 234808.0000 - val_fn: 1983.0000 - val_accuracy: 0.9908 - val_precision: 0.8022 - val_recall: 0.3015 - val_auc: 0.9567
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 127s - loss: 0.0241 - tp: 1680.0000 - fp: 451.0000 - tn: 253288.0000 - fn: 1466.0000 - accuracy: 0.9925 - precision: 0.7884 - recall: 0.5340 - auc: 0.9696 - val_loss: 0.0199 - val_tp: 1749.0000 - val_fp: 345.0000 - val_tn: 234674.0000 - val_fn: 1090.0000 - val_accuracy: 0.9940 - val_precision: 0.8352 - val_recall: 0.6161 - val_auc: 0.9848
256885/256885 - 127s - loss: 0.0241 - tp: 1680.0000 - fp: 451.0000 - tn: 253288.0000 - fn: 1466.0000 - accuracy: 0.9925 - precision: 0.7884 - recall: 0.5340 - auc: 0.9696 - val_loss: 0.0199 - val_tp: 1749.0000 - val_fp: 345.0000 - val_tn: 234674.0000 - val_fn: 1090.0000 - val_accuracy: 0.9940 - val_precision: 0.8352 - val_recall: 0.6161 - val_auc: 0.9848
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49688aecf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4968681240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4968681048>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496426a128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4968c38da0>, <tensorflow.python.keras.metrics.Precision object at 0x7f4968bcbdd8>, <tensorflow.python.keras.metrics.Recall object at 0x7f4968610668>, <tensorflow.python.keras.metrics.AUC object at 0x7f4968610278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49667cf198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496428bb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496869ef60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496864ffd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496868d320>]
          

Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_75 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_225 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_225 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_226 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_226 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_75 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_227 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_227 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 131s - loss: 0.0413 - tp: 654.0000 - fp: 400.0000 - tn: 253378.0000 - fn: 2453.0000 - accuracy: 0.9889 - precision: 0.6205 - recall: 0.2105 - auc: 0.9063 - val_loss: 0.0311 - val_tp: 885.0000 - val_fp: 282.0000 - val_tn: 234737.0000 - val_fn: 1954.0000 - val_accuracy: 0.9906 - val_precision: 0.7584 - val_recall: 0.3117 - val_auc: 0.9368
256885/256885 - 131s - loss: 0.0413 - tp: 654.0000 - fp: 400.0000 - tn: 253378.0000 - fn: 2453.0000 - accuracy: 0.9889 - precision: 0.6205 - recall: 0.2105 - auc: 0.9063 - val_loss: 0.0311 - val_tp: 885.0000 - val_fp: 282.0000 - val_tn: 234737.0000 - val_fn: 1954.0000 - val_accuracy: 0.9906 - val_precision: 0.7584 - val_recall: 0.3117 - val_auc: 0.9368
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0243 - tp: 1593.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1514.0000 - accuracy: 0.9924 - precision: 0.7890 - recall: 0.5127 - auc: 0.9676 - val_loss: 0.0196 - val_tp: 1685.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1154.0000 - val_accuracy: 0.9940 - val_precision: 0.8579 - val_recall: 0.5935 - val_auc: 0.9823
256885/256885 - 126s - loss: 0.0243 - tp: 1593.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1514.0000 - accuracy: 0.9924 - precision: 0.7890 - recall: 0.5127 - auc: 0.9676 - val_loss: 0.0196 - val_tp: 1685.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1154.0000 - val_accuracy: 0.9940 - val_precision: 0.8579 - val_recall: 0.5935 - val_auc: 0.9823
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bdec2e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496bdec278>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496bdece80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496bde2588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49780b7048>, <tensorflow.python.keras.metrics.Precision object at 0x7f49780b7320>, <tensorflow.python.keras.metrics.Recall object at 0x7f49ea826470>, <tensorflow.python.keras.metrics.AUC object at 0x7f49ea826cc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969a7ee48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496868d320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4969c07208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496bdec898>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496bdec6a0>]
          

Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_76 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_228 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_228 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_229 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_229 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_76 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_230 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_230 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0404 - tp: 663.0000 - fp: 366.0000 - tn: 253428.0000 - fn: 2428.0000 - accuracy: 0.9891 - precision: 0.6443 - recall: 0.2145 - auc: 0.9109 - val_loss: 0.0338 - val_tp: 1679.0000 - val_fp: 1336.0000 - val_tn: 233683.0000 - val_fn: 1160.0000 - val_accuracy: 0.9895 - val_precision: 0.5569 - val_recall: 0.5914 - val_auc: 0.9809
256885/256885 - 129s - loss: 0.0404 - tp: 663.0000 - fp: 366.0000 - tn: 253428.0000 - fn: 2428.0000 - accuracy: 0.9891 - precision: 0.6443 - recall: 0.2145 - auc: 0.9109 - val_loss: 0.0338 - val_tp: 1679.0000 - val_fp: 1336.0000 - val_tn: 233683.0000 - val_fn: 1160.0000 - val_accuracy: 0.9895 - val_precision: 0.5569 - val_recall: 0.5914 - val_auc: 0.9809
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0234 - tp: 1664.0000 - fp: 428.0000 - tn: 253366.0000 - fn: 1427.0000 - accuracy: 0.9928 - precision: 0.7954 - recall: 0.5383 - auc: 0.9680 - val_loss: 0.0193 - val_tp: 1845.0000 - val_fp: 434.0000 - val_tn: 234585.0000 - val_fn: 994.0000 - val_accuracy: 0.9940 - val_precision: 0.8096 - val_recall: 0.6499 - val_auc: 0.9828
256885/256885 - 126s - loss: 0.0234 - tp: 1664.0000 - fp: 428.0000 - tn: 253366.0000 - fn: 1427.0000 - accuracy: 0.9928 - precision: 0.7954 - recall: 0.5383 - auc: 0.9680 - val_loss: 0.0193 - val_tp: 1845.0000 - val_fp: 434.0000 - val_tn: 234585.0000 - val_fn: 994.0000 - val_accuracy: 0.9940 - val_precision: 0.8096 - val_recall: 0.6499 - val_auc: 0.9828
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4968eb2978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49d6df80f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49c3bbe5c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49c3bbe278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49c3bbe978>, <tensorflow.python.keras.metrics.Precision object at 0x7f49c3bbec50>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e9dd82e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49e9dd8588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bdec5f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bdec4e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496bdec518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496bdec588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496864ffd0>]
          

Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_77 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_231 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_231 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_232 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_232 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_77 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_233 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_233 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256885/256885 - 129s - loss: 0.0409 - tp: 671.0000 - fp: 423.0000 - tn: 253351.0000 - fn: 2440.0000 - accuracy: 0.9889 - precision: 0.6133 - recall: 0.2157 - auc: 0.9116 - val_loss: 0.0294 - val_tp: 1191.0000 - val_fp: 472.0000 - val_tn: 234547.0000 - val_fn: 1648.0000 - val_accuracy: 0.9911 - val_precision: 0.7162 - val_recall: 0.4195 - val_auc: 0.9775
256885/256885 - 129s - loss: 0.0409 - tp: 671.0000 - fp: 423.0000 - tn: 253351.0000 - fn: 2440.0000 - accuracy: 0.9889 - precision: 0.6133 - recall: 0.2157 - auc: 0.9116 - val_loss: 0.0294 - val_tp: 1191.0000 - val_fp: 472.0000 - val_tn: 234547.0000 - val_fn: 1648.0000 - val_accuracy: 0.9911 - val_precision: 0.7162 - val_recall: 0.4195 - val_auc: 0.9775
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256885/256885 - 126s - loss: 0.0247 - tp: 1593.0000 - fp: 429.0000 - tn: 253345.0000 - fn: 1518.0000 - accuracy: 0.9924 - precision: 0.7878 - recall: 0.5121 - auc: 0.9692 - val_loss: 0.0195 - val_tp: 1808.0000 - val_fp: 397.0000 - val_tn: 234622.0000 - val_fn: 1031.0000 - val_accuracy: 0.9940 - val_precision: 0.8200 - val_recall: 0.6368 - val_auc: 0.9755
256885/256885 - 126s - loss: 0.0247 - tp: 1593.0000 - fp: 429.0000 - tn: 253345.0000 - fn: 1518.0000 - accuracy: 0.9924 - precision: 0.7878 - recall: 0.5121 - auc: 0.9692 - val_loss: 0.0195 - val_tp: 1808.0000 - val_fp: 397.0000 - val_tn: 234622.0000 - val_fn: 1031.0000 - val_accuracy: 0.9940 - val_precision: 0.8200 - val_recall: 0.6368 - val_auc: 0.9755
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4963818588>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4965f3ef60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4966080080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49660809b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4966080c88>, <tensorflow.python.keras.metrics.Precision object at 0x7f4966080588>, <tensorflow.python.keras.metrics.Recall object at 0x7f49660803c8>, <tensorflow.python.keras.metrics.AUC object at 0x7f4968036898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496bdec4e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496bdec6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496bdec588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4965f51940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49d75bdeb8>]
          

Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_78 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_234 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_234 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_235 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_235 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_78 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_236 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_236 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 129s - loss: 0.0409 - tp: 653.0000 - fp: 342.0000 - tn: 253436.0000 - fn: 2455.0000 - accuracy: 0.9891 - precision: 0.6563 - recall: 0.2101 - auc: 0.9072 - val_loss: 0.0288 - val_tp: 1117.0000 - val_fp: 452.0000 - val_tn: 234567.0000 - val_fn: 1722.0000 - val_accuracy: 0.9909 - val_precision: 0.7119 - val_recall: 0.3934 - val_auc: 0.9517
256886/256886 - 129s - loss: 0.0409 - tp: 653.0000 - fp: 342.0000 - tn: 253436.0000 - fn: 2455.0000 - accuracy: 0.9891 - precision: 0.6563 - recall: 0.2101 - auc: 0.9072 - val_loss: 0.0288 - val_tp: 1117.0000 - val_fp: 452.0000 - val_tn: 234567.0000 - val_fn: 1722.0000 - val_accuracy: 0.9909 - val_precision: 0.7119 - val_recall: 0.3934 - val_auc: 0.9517
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 126s - loss: 0.0242 - tp: 1620.0000 - fp: 422.0000 - tn: 253356.0000 - fn: 1488.0000 - accuracy: 0.9926 - precision: 0.7933 - recall: 0.5212 - auc: 0.9684 - val_loss: 0.0203 - val_tp: 1492.0000 - val_fp: 192.0000 - val_tn: 234827.0000 - val_fn: 1347.0000 - val_accuracy: 0.9935 - val_precision: 0.8860 - val_recall: 0.5255 - val_auc: 0.9734
256886/256886 - 126s - loss: 0.0242 - tp: 1620.0000 - fp: 422.0000 - tn: 253356.0000 - fn: 1488.0000 - accuracy: 0.9926 - precision: 0.7933 - recall: 0.5212 - auc: 0.9684 - val_loss: 0.0203 - val_tp: 1492.0000 - val_fp: 192.0000 - val_tn: 234827.0000 - val_fn: 1347.0000 - val_accuracy: 0.9935 - val_precision: 0.8860 - val_recall: 0.5255 - val_auc: 0.9734
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49687feda0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49687fe438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49687fefd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49d4a9a588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49d4a9a470>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d4a9a160>, <tensorflow.python.keras.metrics.Recall object at 0x7f49d4a9a048>, <tensorflow.python.keras.metrics.AUC object at 0x7f496b0d0f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4965f56400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49d7419e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4969d14e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4969d251d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49661f54e0>]
          

Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_79 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_237 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_237 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_238 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_238 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_79 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_239 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_239 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
256886/256886 - 128s - loss: 0.0416 - tp: 581.0000 - fp: 391.0000 - tn: 253371.0000 - fn: 2543.0000 - accuracy: 0.9886 - precision: 0.5977 - recall: 0.1860 - auc: 0.9090 - val_loss: 0.0320 - val_tp: 683.0000 - val_fp: 179.0000 - val_tn: 234840.0000 - val_fn: 2156.0000 - val_accuracy: 0.9902 - val_precision: 0.7923 - val_recall: 0.2406 - val_auc: 0.9431
256886/256886 - 128s - loss: 0.0416 - tp: 581.0000 - fp: 391.0000 - tn: 253371.0000 - fn: 2543.0000 - accuracy: 0.9886 - precision: 0.5977 - recall: 0.1860 - auc: 0.9090 - val_loss: 0.0320 - val_tp: 683.0000 - val_fp: 179.0000 - val_tn: 234840.0000 - val_fn: 2156.0000 - val_accuracy: 0.9902 - val_precision: 0.7923 - val_recall: 0.2406 - val_auc: 0.9431
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
256886/256886 - 127s - loss: 0.0247 - tp: 1593.0000 - fp: 429.0000 - tn: 253333.0000 - fn: 1531.0000 - accuracy: 0.9924 - precision: 0.7878 - recall: 0.5099 - auc: 0.9681 - val_loss: 0.0197 - val_tp: 1867.0000 - val_fp: 508.0000 - val_tn: 234511.0000 - val_fn: 972.0000 - val_accuracy: 0.9938 - val_precision: 0.7861 - val_recall: 0.6576 - val_auc: 0.9827
256886/256886 - 127s - loss: 0.0247 - tp: 1593.0000 - fp: 429.0000 - tn: 253333.0000 - fn: 1531.0000 - accuracy: 0.9924 - precision: 0.7878 - recall: 0.5099 - auc: 0.9681 - val_loss: 0.0197 - val_tp: 1867.0000 - val_fp: 508.0000 - val_tn: 234511.0000 - val_fn: 972.0000 - val_accuracy: 0.9938 - val_precision: 0.7861 - val_recall: 0.6576 - val_auc: 0.9827
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4968703860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496870ccf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496870cdd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496870cf28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496871e208>, <tensorflow.python.keras.metrics.Precision object at 0x7f496871e5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496871e860>, <tensorflow.python.keras.metrics.AUC object at 0x7f496871eb70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969d14e80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49687f8e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49687febe0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49687fe390>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4968796390>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496878d908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496878d3c8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49688fdb70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49688fd710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49688fdb38>, <tensorflow.python.keras.metrics.Precision object at 0x7f49688fdeb8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49688fd240>, <tensorflow.python.keras.metrics.AUC object at 0x7f49677c1160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49687b12e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4969d251d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496872f748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496872f710>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496872f860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967786b38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967786e48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4968b04128>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4968b043c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4968b04668>, <tensorflow.python.keras.metrics.Precision object at 0x7f4968b04a20>, <tensorflow.python.keras.metrics.Recall object at 0x7f4968b04cc0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4968b04fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496872f5f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49677c1c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49677c1e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49677c1d30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967786ac8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967786c18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496779fba8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496779f390>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496779f198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49677727b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967772c18>, <tensorflow.python.keras.metrics.Recall object at 0x7f4967772eb8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496777d208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4967786a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496872f5f8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49677c1e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49677c1d30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967786e80>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967772b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967772978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496779f1d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496779f160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779f0b8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967786f98>, <tensorflow.python.keras.metrics.Recall object at 0x7f496777d668>, <tensorflow.python.keras.metrics.AUC object at 0x7f496777d278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4967786c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967772eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967772e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967772f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967772e10>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496777d160>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496777d6d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496777d358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4967786cf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779f320>, <tensorflow.python.keras.metrics.Precision object at 0x7f496779fb38>, <tensorflow.python.keras.metrics.Recall object at 0x7f496779f940>, <tensorflow.python.keras.metrics.AUC object at 0x7f4967772898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49677729e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496773c9b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496773cb70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496773cf28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496777d278>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496777a4a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967772940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49677728d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496779fcc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779fb00>, <tensorflow.python.keras.metrics.Precision object at 0x7f496779fbe0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496777dcf8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496777d2e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496777db38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967685d68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967685f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496777a160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496777a080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4969bf0550>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496777dcf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496777d3c8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4967786c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779fb00>, <tensorflow.python.keras.metrics.Precision object at 0x7f496779f470>, <tensorflow.python.keras.metrics.Recall object at 0x7f496779f978>, <tensorflow.python.keras.metrics.AUC object at 0x7f4967772860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496777a048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967658710>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496777a2e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4969bf08d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4969bf0668>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4969bf0400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967772be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4967772908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f496779fa58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779f390>, <tensorflow.python.keras.metrics.Precision object at 0x7f496779fcf8>, <tensorflow.python.keras.metrics.Recall object at 0x7f496777df28>, <tensorflow.python.keras.metrics.AUC object at 0x7f496777d4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969bf06a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967623860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967658518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967658780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967658898>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.5s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4969bf0400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496777d0f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496777dc50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49677868d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496779fcc0>, <tensorflow.python.keras.metrics.Precision object at 0x7f496779f198>, <tensorflow.python.keras.metrics.Recall object at 0x7f496779f208>, <tensorflow.python.keras.metrics.AUC object at 0x7f4967772cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4969bf02e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49675eca58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967623710>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967623978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967623940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967504ba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967504eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4967512198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4967512438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49675126d8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967512a90>, <tensorflow.python.keras.metrics.Recall object at 0x7f4967512d30>, <tensorflow.python.keras.metrics.AUC object at 0x7f4967512f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49676237b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49675bacf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49675badd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49675bada0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967504b38>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49674d3f60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49675412b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4967541550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49675417f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4967541a90>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967541e48>, <tensorflow.python.keras.metrics.Recall object at 0x7f49674e9128>, <tensorflow.python.keras.metrics.AUC object at 0x7f49674e9438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4967504b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496779f358>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496779f470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496779f0b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49674d3ef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f49674bbba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49674bbeb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4969d86198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4969d86438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4969d866d8>, <tensorflow.python.keras.metrics.Precision object at 0x7f4969d86a90>, <tensorflow.python.keras.metrics.Recall object at 0x7f4969d86d30>, <tensorflow.python.keras.metrics.AUC object at 0x7f4969d86f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49674d3eb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967504c18>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49674f7128>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49674f70f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49674bbb38>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967426b38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967426d68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f4967426f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49674342e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f4967434588>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967434940>, <tensorflow.python.keras.metrics.Recall object at 0x7f4967434be0>, <tensorflow.python.keras.metrics.AUC object at 0x7f4967434ef0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49674bbb00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967453ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967453be0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967426898>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49674269e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4967426ac8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f4967426be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49673c1160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49673c1198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f496738f358>, <tensorflow.python.keras.metrics.Precision object at 0x7f496738fb38>, <tensorflow.python.keras.metrics.Recall object at 0x7f496738fdd8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496743b128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4967426a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49674bbb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967453be0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967426d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967426f60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496738fc18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496738f860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496738f710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49673c11d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49673c1860>, <tensorflow.python.keras.metrics.Precision object at 0x7f4967426898>, <tensorflow.python.keras.metrics.Recall object at 0x7f496743b5f8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496743b208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f4967426b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496738fe10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496738fef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496738fb38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496738feb8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496743b048>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496743bda0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496743b320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4967426b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49673c1c18>, <tensorflow.python.keras.metrics.Precision object at 0x7f49673c1be0>, <tensorflow.python.keras.metrics.Recall object at 0x7f496738f828>, <tensorflow.python.keras.metrics.AUC object at 0x7f496738fb70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496738f7b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f496735ef28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f496735e9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f496735ea90>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496735ee10>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496738f780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496738f748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49673c1b38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49673c1278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49673c1208>, <tensorflow.python.keras.metrics.Precision object at 0x7f49674269e8>, <tensorflow.python.keras.metrics.Recall object at 0x7f496743b3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7f496743bb70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496743b080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49673258d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967325c50>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967325cc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f496742d080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496743b3c8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f496743b518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f496743b4e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4967426b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49673c1898>, <tensorflow.python.keras.metrics.Precision object at 0x7f49673c1ba8>, <tensorflow.python.keras.metrics.Recall object at 0x7f496738f780>, <tensorflow.python.keras.metrics.AUC object at 0x7f496738f908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496738f668>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49673677b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4967430438>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4967430358>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f4967430400>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f4964083908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49640839b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49640832e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f4964083e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49662e5cc0>, <tensorflow.python.keras.metrics.Precision object at 0x7f49662e5860>, <tensorflow.python.keras.metrics.Recall object at 0x7f49662e59e8>, <tensorflow.python.keras.metrics.AUC object at 0x7f49688aee48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f496743ba90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f4967243ac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f4964083438>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f4964083278>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49640833c8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.5s


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f496bfb30b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f49688ae4a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f49662e5780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f49662e5898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f49662e5dd8>, <tensorflow.python.keras.metrics.Precision object at 0x7f49d408a6d8>, <tensorflow.python.keras.metrics.Recall object at 0x7f49e8e77f60>, <tensorflow.python.keras.metrics.AUC object at 0x7f49d4138358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f49c3480b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f49688aea20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f49688aeb38>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f49688ae978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f49688aee48>]
          

Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_120 (LSTM)              (None, 50)                12600     
_________________________________________________________________
dense_240 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_240 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_241 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 285428 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73124
285428/285428 - 116s - loss: 0.0418 - tp: 715.0000 - fp: 460.0000 - tn: 281507.0000 - fn: 2746.0000 - accuracy: 0.9888 - precision: 0.6085 - recall: 0.2066 - auc: 0.9050 - val_loss: 0.0282 - val_tp: 977.0000 - val_fp: 360.0000 - val_tn: 234659.0000 - val_fn: 1862.0000 - val_accuracy: 0.9907 - val_precision: 0.7307 - val_recall: 0.3441 - val_auc: 0.9688
285428/285428 - 116s - loss: 0.0418 - tp: 715.0000 - fp: 460.0000 - tn: 281507.0000 - fn: 2746.0000 - accuracy: 0.9888 - precision: 0.6085 - recall: 0.2066 - auc: 0.9050 - val_loss: 0.0282 - val_tp: 977.0000 - val_fp: 360.0000 - val_tn: 234659.0000 - val_fn: 1862.0000 - val_accuracy: 0.9907 - val_precision: 0.7307 - val_recall: 0.3441 - val_auc: 0.9688
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73124
285428/285428 - 113s - loss: 0.0252 - tp: 1708.0000 - fp: 519.0000 - tn: 281448.0000 - fn: 1753.0000 - accuracy: 0.9920 - precision: 0.7670 - recall: 0.4935 - auc: 0.9690 - val_loss: 0.0212 - val_tp: 1938.0000 - val_fp: 704.0000 - val_tn: 234315.0000 - val_fn: 901.0000 - val_accuracy: 0.9933 - val_precision: 0.7335 - val_recall: 0.6826 - val_auc: 0.9856
285428/285428 - 113s - loss: 0.0252 - tp: 1708.0000 - fp: 519.0000 - tn: 281448.0000 - fn: 1753.0000 - accuracy: 0.9920 - precision: 0.7670 - recall: 0.4935 - auc: 0.9690 - val_loss: 0.0212 - val_tp: 1938.0000 - val_fp: 704.0000 - val_tn: 234315.0000 - val_fn: 901.0000 - val_accuracy: 0.9933 - val_precision: 0.7335 - val_recall: 0.6826 - val_auc: 0.9856
Epoch 00002: early stopping


_ _ _ _ _ _ _ _ _ _  RNN TRAINING RESULTS _ _ _ _ _ _ _ _ _ _ 



          BEST ESTIMATOR:          <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f49688ae9e8> 
          BEST SCORE:              0.6079742135467515
          BEST PARAMS:             {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}
          BEST INDEX IN CV SEARCH: 8
          SCORER FUNCTIONS:        {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}
          

          HISTORY OBJ:             GridSearchCV(cv=10, error_score=nan,
             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4b000e1eb8>,
             iid='deprecated', n_jobs=1,
             param_grid={'dropout': [True], 'dropout_rate': [0.2],
                         'epochs': [50], 'hidden_layer_activation': ['sigmoid'],
                         'hidden_layers': [2],
                         'hidden_layers_neurons': [100, 200],
                         'loss': ['binary_crossentropy'],
                         'modelType': ['LSTM', 'GRU'], 'optimizer': ['adam'],
                         'output_layer_activation': ['sigmoid'],
                         'rnn_hidden_layers': [0, 1],
                         'rnn_hidden_layers_neurons': [50, 100],
                         'rnn_layer_activation': ['sigmoid']},
             pre_dispatch='1*n_jobs', refit='recall', return_train_score=True,
             scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1',
                      'average_precision'],
             verbose=2)        
        


cv_results_dict: 
    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_dropout param_dropout_rate param_epochs param_hidden_layer_activation param_hidden_layers param_hidden_layers_neurons           param_loss param_modelType param_optimizer param_output_layer_activation param_rnn_hidden_layers param_rnn_hidden_layers_neurons param_rnn_layer_activation                                                                                                                                                                                                                                                                                                                                                    params  split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  split5_test_accuracy  split6_test_accuracy  split7_test_accuracy  split8_test_accuracy  split9_test_accuracy  mean_test_accuracy  std_test_accuracy  rank_test_accuracy  split0_train_accuracy  split1_train_accuracy  split2_train_accuracy  split3_train_accuracy  split4_train_accuracy  split5_train_accuracy  split6_train_accuracy  split7_train_accuracy  split8_train_accuracy  split9_train_accuracy  mean_train_accuracy  std_train_accuracy  split0_test_precision  split1_test_precision  split2_test_precision  split3_test_precision  split4_test_precision  split5_test_precision  split6_test_precision  split7_test_precision  split8_test_precision  split9_test_precision  mean_test_precision  std_test_precision  rank_test_precision  split0_train_precision  split1_train_precision  split2_train_precision  split3_train_precision  split4_train_precision  split5_train_precision  split6_train_precision  split7_train_precision  split8_train_precision  split9_train_precision  mean_train_precision  std_train_precision  split0_test_recall  split1_test_recall  split2_test_recall  split3_test_recall  split4_test_recall  split5_test_recall  split6_test_recall  split7_test_recall  split8_test_recall  split9_test_recall  mean_test_recall  std_test_recall  rank_test_recall  split0_train_recall  split1_train_recall  split2_train_recall  split3_train_recall  split4_train_recall  split5_train_recall  split6_train_recall  split7_train_recall  split8_train_recall  split9_train_recall  mean_train_recall  std_train_recall  split0_test_roc_auc  split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  split4_test_roc_auc  split5_test_roc_auc  split6_test_roc_auc  split7_test_roc_auc  split8_test_roc_auc  split9_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  rank_test_roc_auc  split0_train_roc_auc  split1_train_roc_auc  split2_train_roc_auc  split3_train_roc_auc  split4_train_roc_auc  split5_train_roc_auc  split6_train_roc_auc  split7_train_roc_auc  split8_train_roc_auc  split9_train_roc_auc  mean_train_roc_auc  std_train_roc_auc  split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  split5_test_f1  split6_test_f1  split7_test_f1  split8_test_f1  split9_test_f1  mean_test_f1  std_test_f1  rank_test_f1  split0_train_f1  split1_train_f1  split2_train_f1  split3_train_f1  split4_train_f1  split5_train_f1  split6_train_f1  split7_train_f1  split8_train_f1  split9_train_f1  mean_train_f1  std_train_f1  split0_test_average_precision  split1_test_average_precision  split2_test_average_precision  split3_test_average_precision  split4_test_average_precision  split5_test_average_precision  split6_test_average_precision  split7_test_average_precision  split8_test_average_precision  split9_test_average_precision  mean_test_average_precision  std_test_average_precision  rank_test_average_precision  split0_train_average_precision  split1_train_average_precision  split2_train_average_precision  split3_train_average_precision  split4_train_average_precision  split5_train_average_precision  split6_train_average_precision  split7_train_average_precision  split8_train_average_precision  split9_train_average_precision  mean_train_average_precision  std_train_average_precision
0   210.640618     0.549548      5.019846         0.092189        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.993589              0.994254              0.994079              0.992292              0.993974              0.993238              0.992643              0.994009              0.992467              0.993939              0.993448            0.000699           5                   0.993620               0.993351               0.993892               0.993635               0.992826               0.993363               0.993807               0.993892               0.992608               0.993406               0.993440             0.000412            0.771429               0.876106               0.854839               0.768116               0.923077               0.803774               0.805344               0.848249               0.925926               0.872727               0.844959             0.053930            4                    0.780884                0.863287                0.843016                0.824000                0.898471                0.784266                0.844353                0.845121                0.874303                0.841778                0.839948              0.034716             0.644776            0.592814            0.614493            0.576087            0.495238            0.601695            0.570270            0.622857            0.424929            0.569733            0.571289          0.062085         5                 0.661228             0.539175             0.610077             0.599418             0.466942             0.622465             0.594953             0.606879             0.454311             0.563700             0.571915           0.063630          0.991310             0.989663             0.990939             0.988491             0.988837             0.989913             0.991191             0.988950             0.989218             0.987628             0.989614           0.001167          2                  0.988826              0.989459              0.989569              0.989229              0.990507              0.989075              0.989811              0.989608              0.988737              0.990238              0.989506            0.000544           0.702439        0.707143        0.715008        0.658385        0.644628        0.688207        0.667722        0.718287        0.582524        0.689408        0.677375      0.039229     6             0.716092         0.663780         0.707876         0.693992         0.614516         0.694061         0.698045         0.706455         0.597925         0.675230         0.676797       0.038349      0.755752                       0.780741                       0.760060                       0.720667                       0.761132                       0.761124                       0.749167                       0.771653                       0.765077                       0.775804                       0.760118                     0.015894                    7                            0.755320                        0.760011                        0.771496                        0.757727                        0.770421                        0.746000                        0.771490                        0.774891                        0.743761                        0.755512                        0.760663                      0.010474                   
1   262.167423     0.462230      6.715717         0.021616        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.992923              0.994254              0.993764              0.992888              0.993554              0.993799              0.992362              0.993589              0.992958              0.994534              0.993462            0.000640           4                   0.992942               0.993581               0.993705               0.994106               0.993316               0.993986               0.993374               0.993573               0.992884               0.993857               0.993533             0.000389            0.888889               0.777778               0.830040               0.781570               0.714754               0.861224               0.836283               0.846473               0.936782               0.881857               0.835565             0.060737            6                    0.893349                0.763364                0.830031                0.825567                0.741794                0.844965                0.878062                0.855058                0.881406                0.852646                0.836624              0.047045             0.453731            0.712575            0.608696            0.622283            0.692063            0.596045            0.510811            0.582857            0.461756            0.620178            0.586100          0.083046         4                 0.476967             0.685002             0.604942             0.647268             0.696758             0.615706             0.521838             0.565092             0.475869             0.598271             0.588771           0.074638          0.991076             0.989175             0.990936             0.987469             0.986656             0.990116             0.991160             0.988724             0.990282             0.983824             0.988942           0.002243          7                  0.989158              0.989193              0.990039              0.990044              0.989022              0.989048              0.989318              0.989806              0.989613              0.989063              0.989430            0.000389           0.600791        0.743750        0.702341        0.692890        0.703226        0.704508        0.634228        0.690355        0.618596        0.728223        0.681891      0.045173     4             0.621898         0.722063         0.699833         0.725625         0.718571         0.712344         0.654627         0.680472         0.618053         0.703160         0.685665       0.038537      0.770484                       0.779787                       0.755588                       0.737713                       0.750481                       0.790400                       0.743091                       0.763605                       0.777464                       0.791371                       0.765998                     0.018057                    4                            0.764261                        0.761732                        0.764753                        0.779044                        0.757019                        0.772393                        0.766528                        0.766789                        0.761676                        0.771521                        0.766571                      0.006011                   
2   0.439763       0.009750      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 9                  NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  9                   NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               9                NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                9                 NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           9            NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          9                           NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
3   0.445297       0.010058      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 10                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  10                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               10               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                10                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           10           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          10                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
4   221.442589     0.314151      4.734727         0.169836        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.993729              0.993308              0.993343              0.991311              0.994219              0.993308              0.992608              0.994079              0.993729              0.995025              0.993466            0.000946           3                   0.993709               0.992779               0.993542               0.992709               0.993643               0.993355               0.993604               0.994137               0.993316               0.994161               0.993496             0.000460            0.836207               0.696970               0.885572               0.803030               0.831858               0.846809               0.847162               0.802676               0.822222               0.901235               0.827374             0.052862            7                    0.838869                0.692611                0.894423                0.865707                0.843395                0.819927                0.887580                0.822678                0.764952                0.861210                0.829135              0.057643             0.579104            0.757485            0.515942            0.432065            0.596825            0.562147            0.524324            0.685714            0.628895            0.649852            0.593235          0.088253         2                 0.597889             0.731372             0.530167             0.466861             0.590591             0.577406             0.536396             0.657666             0.646075             0.619718             0.595414           0.070808          0.991442             0.988335             0.989411             0.988990             0.986420             0.989800             0.990937             0.987534             0.987982             0.986123             0.988697           0.001678          8                  0.988876              0.989728              0.989643              0.988061              0.989087              0.988325              0.989903              0.989128              0.988326              0.989451              0.989053            0.000614           0.684303        0.725968        0.652015        0.561837        0.695009        0.675722        0.647746        0.739599        0.712681        0.755172        0.685005      0.053086     3             0.698170         0.711464         0.665726         0.606595         0.694709         0.677620         0.668683         0.730975         0.700506         0.720774         0.687522       0.033731      0.764782                       0.777893                       0.769523                       0.694516                       0.753055                       0.759889                       0.748646                       0.774424                       0.762777                       0.804841                       0.761035                     0.026674                    6                            0.759662                        0.762832                        0.778079                        0.731771                        0.763200                        0.739453                        0.772642                        0.778508                        0.740330                        0.781100                        0.760758                      0.017009                   
5   255.984431     0.965083      5.859765         0.209262        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993133              0.994464              0.993904              0.992503              0.994605              0.993869              0.992257              0.991837              0.993133              0.994359              0.993406            0.000931           6                   0.993254               0.993779               0.994021               0.993795               0.994071               0.994336               0.993429               0.991961               0.993336               0.993565               0.993555             0.000624            0.906433               0.814286               0.873362               0.763699               0.820717               0.823105               0.856459               0.903448               0.938547               0.778481               0.847854             0.054629            3                    0.898683                0.807894                0.881274                0.809583                0.834639                0.826999                0.889939                0.922456                0.893461                0.752143                0.851707              0.050794             0.462687            0.682635            0.579710            0.605978            0.653968            0.644068            0.483784            0.374286            0.475921            0.729970            0.569301          0.108767         6                 0.502239             0.641509             0.586008             0.633689             0.643357             0.672353             0.517955             0.367085             0.509974             0.702305             0.577647           0.097098          0.991805             0.987132             0.990967             0.989198             0.987459             0.991548             0.990273             0.987702             0.990249             0.986953             0.989329           0.001792          4                  0.989388              0.989037              0.989937              0.989142              0.989822              0.990179              0.988792              0.989485              0.989949              0.989827              0.989556            0.000435           0.612648        0.742671        0.696864        0.675758        0.727915        0.722662        0.618307        0.529293        0.631579        0.753446        0.671114      0.068081     7             0.644367         0.715152         0.703932         0.710918         0.726620         0.741701         0.654806         0.525178         0.649324         0.726370         0.679837       0.061408      0.773873                       0.777427                       0.771963                       0.723739                       0.766711                       0.798140                       0.743065                       0.756947                       0.796339                       0.792319                       0.770052                     0.022593                    3                            0.771509                        0.763089                        0.783997                        0.762227                        0.778664                        0.783350                        0.769304                        0.760947                        0.769405                        0.772228                        0.771472                      0.007910                   
6   0.441034       0.001579      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 11                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  11                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               11               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                11                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           11           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          11                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
7   0.443932       0.009738      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 12                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  12                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               12               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                12                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           12           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          12                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
8   234.329963     61.735997     5.050816         0.025268        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.992993              0.994780              0.993764              0.992327              0.993939              0.993939              0.992397              0.993238              0.992712              0.993623              0.993371            0.000740           7                   0.992806               0.993853               0.993807               0.993211               0.993760               0.994562               0.993834               0.992880               0.992810               0.992763               0.993429             0.000587            0.909091               0.813559               0.838057               0.698667               0.761029               0.878661               0.745981               0.708223               0.934132               0.897436               0.818484             0.081803            8                    0.892025                0.797921                0.836348                0.720641                0.788411                0.883408                0.788366                0.696385                0.886099                0.869667                0.815927              0.066170             0.447761            0.718563            0.600000            0.711957            0.657143            0.593220            0.627027            0.762857            0.441926            0.519288            0.607974          0.105451         1                 0.465131             0.662936             0.608472             0.712253             0.670375             0.634052             0.666451             0.730633             0.465573             0.476312             0.609219           0.097435          0.991393             0.989378             0.990901             0.989012             0.986651             0.991152             0.990614             0.987609             0.989759             0.987242             0.989371           0.001627          3                  0.989569              0.990106              0.989501              0.989175              0.989821              0.990634              0.989490              0.989248              0.989215              0.989874              0.989663            0.000434           0.600000        0.763116        0.699324        0.705249        0.705281        0.708263        0.681351        0.734525        0.600000        0.657895        0.685500      0.050317     2             0.611438         0.724192         0.704440         0.716423         0.724618         0.738242         0.722300         0.713098         0.610420         0.615512         0.688068       0.050194      0.768932                       0.787905                       0.754660                       0.732016                       0.755585                       0.801004                       0.739865                       0.760988                       0.780381                       0.768176                       0.764951                     0.020036                    5                            0.759747                        0.772183                        0.766868                        0.766245                        0.766500                        0.801161                        0.764723                        0.764902                        0.756451                        0.749403                        0.766818                      0.012952                   
9   278.483883     38.153983     6.781726         0.030712        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993554              0.993168              0.991662              0.992292              0.994570              0.993063              0.992468              0.992082              0.992677              0.994009              0.992954            0.000856           8                   0.993585               0.992284               0.992230               0.993534               0.994293               0.993604               0.993892               0.992296               0.992724               0.993195               0.993164             0.000700            0.782772               0.921212               0.859060               0.725610               0.810078               0.793233               0.773852               0.864706               0.928571               0.902913               0.836201             0.065609            5                    0.788672                0.901754                0.908163                0.768567                0.847682                0.797803                0.821368                0.900850                0.878436                0.867914                0.848121              0.048666             0.623881            0.455090            0.371014            0.646739            0.663492            0.596045            0.591892            0.420000            0.441926            0.551929            0.536201          0.099647         8                 0.645873             0.410937             0.399872             0.662464             0.650985             0.631155             0.629246             0.408872             0.462677             0.519526             0.542161           0.107069          0.991063             0.989715             0.989465             0.989439             0.988000             0.989846             0.990572             0.986741             0.988281             0.986364             0.988949           0.001480          6                  0.988433              0.989347              0.987802              0.989954              0.990708              0.988825              0.989412              0.988635              0.988483              0.989063              0.989066            0.000791           0.694352        0.609218        0.518219        0.683908        0.729494        0.680645        0.670750        0.565385        0.598848        0.685083        0.643590      0.063586     8             0.710165         0.564587         0.555258         0.711582         0.736426         0.704762         0.712585         0.562459         0.606112         0.649980         0.651392       0.069021      0.764345                       0.776141                       0.728874                       0.721084                       0.782704                       0.764044                       0.740232                       0.741912                       0.764736                       0.769699                       0.755377                     0.019787                    8                            0.752712                        0.756202                        0.746490                        0.760508                        0.792396                        0.751066                        0.766024                        0.749554                        0.746642                        0.750560                        0.757215                      0.013096                   
10  0.448943       0.015157      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 13                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  13                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               13               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                13                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           13           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          13                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
11  0.443834       0.010256      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 14                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  14                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               14               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                14                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           14           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          14                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
12  234.847996     31.776178     4.712548         0.025436        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.992818              0.994289              0.994184              0.993343              0.994710              0.992608              0.992678              0.993799              0.993729              0.994254              0.993641            0.000709           2                   0.992798               0.993238               0.994067               0.994601               0.993908               0.992974               0.993822               0.993550               0.993651               0.993507               0.993612             0.000504            0.911392               0.890411               0.853755               0.822464               0.869369               0.903955               0.799257               0.858921               0.943878               0.917874               0.877128             0.042633            1                    0.906888                0.881868                0.844291                0.861747                0.870258                0.895985                0.835714                0.866801                0.887257                0.879167                0.872998              0.020937             0.429851            0.583832            0.626087            0.616848            0.612698            0.451977            0.581081            0.591429            0.524079            0.563798            0.558168          0.065004         7                 0.454894             0.513272             0.626444             0.656967             0.590591             0.474091             0.605629             0.552234             0.544402             0.540333             0.555886           0.061618          0.991738             0.987496             0.990785             0.990344             0.986718             0.991400             0.990684             0.988543             0.991500             0.987143             0.989635           0.001856          1                  0.990043              0.989286              0.990409              0.990630              0.989412              0.989803              0.989524              0.990629              0.989798              0.990280              0.989981            0.000469           0.584178        0.705244        0.722408        0.704969        0.718808        0.602637        0.672926        0.700508        0.673953        0.698529        0.678416      0.045340     5             0.605880         0.648878         0.719234         0.745551         0.703655         0.620080         0.702307         0.674651         0.674776         0.669310         0.676432       0.041218      0.780945                       0.777573                       0.763901                       0.760918                       0.757013                       0.782692                       0.742874                       0.759334                       0.802667                       0.792432                       0.772035                     0.017335                    2                            0.774391                        0.763735                        0.776064                        0.798385                        0.771598                        0.768279                        0.768042                        0.767058                        0.776438                        0.770300                        0.773429                      0.009182                   
13  272.638809     37.295566     5.861480         0.016434        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993974              0.994219              0.993238              0.993413              0.994464              0.993694              0.993273              0.994044              0.993588              0.994885              0.993879            0.000512           1                   0.993919               0.993168               0.993219               0.994499               0.994040               0.994165               0.994410               0.994114               0.993592               0.993927               0.993905             0.000430            0.817121               0.900474               0.883838               0.898230               0.831224               0.895455               0.800676               0.826087               0.952128               0.847273               0.865250             0.045426            2                    0.821282                0.896532                0.896651                0.919580                0.855570                0.872567                0.841801                0.837769                0.894283                0.807632                0.864367              0.035294             0.626866            0.568862            0.507246            0.551630            0.625397            0.556497            0.640541            0.651429            0.507082            0.691395            0.592694          0.059928         3                 0.639475             0.496003             0.498395             0.595215             0.617610             0.606051             0.659334             0.637416             0.533462             0.657170             0.594013           0.059434          0.991848             0.989433             0.990047             0.988841             0.986911             0.989568             0.990894             0.987465             0.989534             0.987447             0.989199           0.001495          5                  0.989816              0.989845              0.989320              0.990437              0.989947              0.989627              0.990014              0.989490              0.989407              0.990120              0.989802            0.000330           0.709459        0.697248        0.644567        0.683502        0.713768        0.686411        0.711712        0.728435        0.661738        0.761438        0.699828      0.031623     1             0.719065         0.638666         0.640677         0.722669         0.717371         0.715290         0.739478         0.723987         0.668279         0.724673         0.701015       0.035260      0.785724                       0.787120                       0.765941                       0.783758                       0.765842                       0.797013                       0.760470                       0.777048                       0.801683                       0.800273                       0.782487                     0.014123                    1                            0.775561                        0.771717                        0.772027                        0.813467                        0.779786                        0.781268                        0.785367                        0.782944                        0.777295                        0.777666                        0.781710                      0.011378                   
14  0.446615       0.014767      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 15                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  15                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               15               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                15                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           15           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          15                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
15  0.442234       0.004806      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 16                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  16                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               16               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                16                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           16           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          16                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
Total time: 24323.10  seconds or 405.38 minutes. Saving model to: customer_batches_rnn_best_model.h5
Saving best estimator at rnn_model.h5 and weights at rnn_model_weights.h5
<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4a4018ef60>
{'scoring': ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], 'estimator': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f4b000e1eb8>, 'n_jobs': 1, 'iid': 'deprecated', 'refit': 'recall', 'cv': 10, 'verbose': 2, 'pre_dispatch': '1*n_jobs', 'error_score': nan, 'return_train_score': True, 'param_grid': {'rnn_hidden_layers': [0, 1], 'rnn_hidden_layers_neurons': [50, 100], 'hidden_layers': [2], 'hidden_layers_neurons': [100, 200], 'loss': ['binary_crossentropy'], 'optimizer': ['adam'], 'modelType': ['LSTM', 'GRU'], 'epochs': [50], 'output_layer_activation': ['sigmoid'], 'rnn_layer_activation': ['sigmoid'], 'hidden_layer_activation': ['sigmoid'], 'dropout': [True], 'dropout_rate': [0.2]}, 'multimetric_': True, 'best_index_': 8, 'best_score_': 0.6079742135467515, 'best_params_': {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, 'best_estimator_': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f49688ae9e8>, 'refit_time_': 234.40723180770874, 'scorer_': {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}, 'cv_results_': {'mean_fit_time': array([210.64061801, 262.16742308,   0.43976305,   0.44529738,
       221.44258885, 255.98443065,   0.44103367,   0.44393208,
       234.32996323, 278.48388319,   0.4489429 ,   0.44383445,
       234.84799612, 272.63880863,   0.44661508,   0.44223435]), 'std_fit_time': array([5.49548180e-01, 4.62229929e-01, 9.75040067e-03, 1.00579553e-02,
       3.14150866e-01, 9.65082892e-01, 1.57862962e-03, 9.73779335e-03,
       6.17359971e+01, 3.81539832e+01, 1.51566404e-02, 1.02564330e-02,
       3.17761781e+01, 3.72955661e+01, 1.47666652e-02, 4.80633511e-03]), 'mean_score_time': array([5.0198458 , 6.71571734, 0.        , 0.        , 4.73472736,
       5.85976541, 0.        , 0.        , 5.05081611, 6.78172629,
       0.        , 0.        , 4.71254849, 5.86147966, 0.        ,
       0.        ]), 'std_score_time': array([0.09218868, 0.02161563, 0.        , 0.        , 0.16983561,
       0.20926162, 0.        , 0.        , 0.02526843, 0.03071224,
       0.        , 0.        , 0.02543629, 0.0164337 , 0.        ,
       0.        ]), 'param_dropout': masked_array(data=[True, True, True, True, True, True, True, True, True,
                   True, True, True, True, True, True, True],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_dropout_rate': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
                   0.2, 0.2, 0.2, 0.2, 0.2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_epochs': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
                   50, 50],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers_neurons': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 200, 200, 200,
                   200, 200, 200, 200, 200],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_loss': masked_array(data=['binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_modelType': masked_array(data=['LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU', 'GRU',
                   'GRU', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU',
                   'GRU', 'GRU'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_optimizer': masked_array(data=['adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_output_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers': masked_array(data=[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers_neurons': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,
                   50, 100, 50, 100],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}], 'split0_test_accuracy': array([0.99358862, 0.99292296,        nan,        nan, 0.99372876,
       0.99313317,        nan,        nan, 0.99299303, 0.99355359,
              nan,        nan, 0.99281785, 0.993974  ,        nan,
              nan]), 'split1_test_accuracy': array([0.99425428, 0.99425428,        nan,        nan, 0.99330834,
       0.99446449,        nan,        nan, 0.99477981, 0.9931682 ,
              nan,        nan, 0.99428932, 0.99421925,        nan,
              nan]), 'split2_test_accuracy': array([0.99407911, 0.99376379,        nan,        nan, 0.99334338,
       0.99390393,        nan,        nan, 0.99376379, 0.9916617 ,
              nan,        nan, 0.99418421, 0.99323827,        nan,
              nan]), 'split3_test_accuracy': array([0.99229233, 0.99288792,        nan,        nan, 0.99131135,
       0.99250254,        nan,        nan, 0.99232737, 0.99229233,
              nan,        nan, 0.99334338, 0.99341345,        nan,
              nan]), 'split4_test_accuracy': array([0.993974  , 0.99355359,        nan,        nan, 0.99421925,
       0.99460463,        nan,        nan, 0.99393897, 0.9945696 ,
              nan,        nan, 0.99470974, 0.99446449,        nan,
              nan]), 'split5_test_accuracy': array([0.99323827, 0.99379883,        nan,        nan, 0.99330834,
       0.9938689 ,        nan,        nan, 0.99393897, 0.9930631 ,
              nan,        nan, 0.99260764, 0.99369373,        nan,
              nan]), 'split6_test_accuracy': array([0.99264268, 0.9923624 ,        nan,        nan, 0.99260764,
       0.9922573 ,        nan,        nan, 0.99239744, 0.99246751,
              nan,        nan, 0.99267771, 0.99327331,        nan,
              nan]), 'split7_test_accuracy': array([0.99400904, 0.99358862,        nan,        nan, 0.99407911,
       0.99183688,        nan,        nan, 0.99323827, 0.99208212,
              nan,        nan, 0.99379883, 0.99404407,        nan,
              nan]), 'split8_test_accuracy': array([0.99246724, 0.99295775,        nan,        nan, 0.99372854,
       0.99313293,        nan,        nan, 0.99271249, 0.99267746,
              nan,        nan, 0.99372854, 0.9935884 ,        nan,
              nan]), 'split9_test_accuracy': array([0.99393876, 0.99453437,        nan,        nan, 0.99502488,
       0.99435919,        nan,        nan, 0.99362343, 0.99400883,
              nan,        nan, 0.99425408, 0.99488473,        nan,
              nan]), 'mean_test_accuracy': array([0.99344843, 0.99346245,        nan,        nan, 0.99346596,
       0.9934064 ,        nan,        nan, 0.99337136, 0.99295444,
              nan,        nan, 0.99364113, 0.99387937,        nan,
              nan]), 'std_test_accuracy': array([0.00069932, 0.00063954,        nan,        nan, 0.00094633,
       0.00093139,        nan,        nan, 0.0007402 , 0.00085564,
              nan,        nan, 0.00070908, 0.00051179,        nan,
              nan]), 'rank_test_accuracy': array([ 5,  4,  9, 10,  3,  6, 11, 12,  7,  8, 13, 14,  2,  1, 15, 16],
      dtype=int32), 'split0_train_accuracy': array([0.99361971, 0.99294237,        nan,        nan, 0.99370925,
       0.99325379,        nan,        nan, 0.99280612, 0.99358468,
              nan,        nan, 0.99279833, 0.99391946,        nan,
              nan]), 'split1_train_accuracy': array([0.99335111, 0.99358079,        nan,        nan, 0.99277887,
       0.99377932,        nan,        nan, 0.99385328, 0.99228449,
              nan,        nan, 0.99323822, 0.99316815,        nan,
              nan]), 'split2_train_accuracy': array([0.99389221, 0.99370535,        nan,        nan, 0.99354186,
       0.99402067,        nan,        nan, 0.99380657, 0.99222999,
              nan,        nan, 0.99406738, 0.99321876,        nan,
              nan]), 'split3_train_accuracy': array([0.99363528, 0.99410631,        nan,        nan, 0.9927088 ,
       0.99379489,        nan,        nan, 0.99321097, 0.99353407,
              nan,        nan, 0.9946007 , 0.99449948,        nan,
              nan]), 'split4_train_accuracy': array([0.99282558, 0.99331608,        nan,        nan, 0.99364307,
       0.99407128,        nan,        nan, 0.99375985, 0.99429317,
              nan,        nan, 0.99390778, 0.99404013,        nan,
              nan]), 'split5_train_accuracy': array([0.99336279, 0.99398564,        nan,        nan, 0.993355  ,
       0.99433599,        nan,        nan, 0.99456177, 0.99360414,
              nan,        nan, 0.99297351, 0.9941647 ,        nan,
              nan]), 'split6_train_accuracy': array([0.99380657, 0.99337447,        nan,        nan, 0.99360414,
       0.99342897,        nan,        nan, 0.99383382, 0.99389221,
              nan,        nan, 0.99382214, 0.99440995,        nan,
              nan]), 'split7_train_accuracy': array([0.99389221, 0.993573  ,        nan,        nan, 0.99413745,
       0.99196138,        nan,        nan, 0.99288008, 0.99229616,
              nan,        nan, 0.99354964, 0.9941141 ,        nan,
              nan]), 'split8_train_accuracy': array([0.99260762, 0.992884  ,        nan,        nan, 0.9933161 ,
       0.99333557,        nan,        nan, 0.99281004, 0.9927244 ,
              nan,        nan, 0.99365088, 0.99359249,        nan,
              nan]), 'split9_train_accuracy': array([0.99340564, 0.9938572 ,        nan,        nan, 0.99416083,
       0.99356524,        nan,        nan, 0.99276333, 0.99319543,
              nan,        nan, 0.99350685, 0.99392727,        nan,
              nan]), 'mean_train_accuracy': array([0.99343987, 0.99353252,        nan,        nan, 0.99349554,
       0.99355471,        nan,        nan, 0.99342858, 0.99316387,
              nan,        nan, 0.99361154, 0.99390545,        nan,
              nan]), 'std_train_accuracy': array([0.00041221, 0.00038916,        nan,        nan, 0.0004605 ,
       0.00062415,        nan,        nan, 0.0005867 , 0.00070045,
              nan,        nan, 0.00050423, 0.00043012,        nan,
              nan]), 'split0_test_precision': array([0.77142857, 0.88888889,        nan,        nan, 0.8362069 ,
       0.90643275,        nan,        nan, 0.90909091, 0.78277154,
              nan,        nan, 0.91139241, 0.81712062,        nan,
              nan]), 'split1_test_precision': array([0.87610619, 0.77777778,        nan,        nan, 0.6969697 ,
       0.81428571,        nan,        nan, 0.81355932, 0.92121212,
              nan,        nan, 0.89041096, 0.90047393,        nan,
              nan]), 'split2_test_precision': array([0.85483871, 0.83003953,        nan,        nan, 0.88557214,
       0.87336245,        nan,        nan, 0.83805668, 0.8590604 ,
              nan,        nan, 0.85375494, 0.88383838,        nan,
              nan]), 'split3_test_precision': array([0.76811594, 0.78156997,        nan,        nan, 0.8030303 ,
       0.76369863,        nan,        nan, 0.69866667, 0.72560976,
              nan,        nan, 0.82246377, 0.89823009,        nan,
              nan]), 'split4_test_precision': array([0.92307692, 0.7147541 ,        nan,        nan, 0.83185841,
       0.82071713,        nan,        nan, 0.76102941, 0.81007752,
              nan,        nan, 0.86936937, 0.83122363,        nan,
              nan]), 'split5_test_precision': array([0.80377358, 0.86122449,        nan,        nan, 0.84680851,
       0.82310469,        nan,        nan, 0.87866109, 0.79323308,
              nan,        nan, 0.9039548 , 0.89545455,        nan,
              nan]), 'split6_test_precision': array([0.80534351, 0.83628319,        nan,        nan, 0.84716157,
       0.85645933,        nan,        nan, 0.74598071, 0.77385159,
              nan,        nan, 0.79925651, 0.80067568,        nan,
              nan]), 'split7_test_precision': array([0.84824903, 0.84647303,        nan,        nan, 0.80267559,
       0.90344828,        nan,        nan, 0.70822281, 0.86470588,
              nan,        nan, 0.85892116, 0.82608696,        nan,
              nan]), 'split8_test_precision': array([0.92592593, 0.93678161,        nan,        nan, 0.82222222,
       0.93854749,        nan,        nan, 0.93413174, 0.92857143,
              nan,        nan, 0.94387755, 0.95212766,        nan,
              nan]), 'split9_test_precision': array([0.87272727, 0.88185654,        nan,        nan, 0.90123457,
       0.77848101,        nan,        nan, 0.8974359 , 0.90291262,
              nan,        nan, 0.9178744 , 0.84727273,        nan,
              nan]), 'mean_test_precision': array([0.84495857, 0.83556491,        nan,        nan, 0.82737399,
       0.84785375,        nan,        nan, 0.81848352, 0.83620059,
              nan,        nan, 0.87712759, 0.86525042,        nan,
              nan]), 'std_test_precision': array([0.05393043, 0.06073688,        nan,        nan, 0.05286231,
       0.05462851,        nan,        nan, 0.08180313, 0.06560942,
              nan,        nan, 0.0426334 , 0.04542574,        nan,
              nan]), 'rank_test_precision': array([ 4,  6,  9, 10,  7,  3, 11, 12,  8,  5, 13, 14,  1,  2, 15, 16],
      dtype=int32), 'split0_train_precision': array([0.78088402, 0.89334931,        nan,        nan, 0.83886894,
       0.89868346,        nan,        nan, 0.89202454, 0.78867188,
              nan,        nan, 0.90688776, 0.82128184,        nan,
              nan]), 'split1_train_precision': array([0.86328725, 0.76336422,        nan,        nan, 0.69261054,
       0.80789368,        nan,        nan, 0.79792148, 0.90175439,
              nan,        nan, 0.88186813, 0.89653179,        nan,
              nan]), 'split2_train_precision': array([0.84301552, 0.83003082,        nan,        nan, 0.89442339,
       0.88127413,        nan,        nan, 0.8363476 , 0.90816327,
              nan,        nan, 0.84429066, 0.89665127,        nan,
              nan]), 'split3_train_precision': array([0.824     , 0.82556701,        nan,        nan, 0.86570743,
       0.80958282,        nan,        nan, 0.72064115, 0.76856714,
              nan,        nan, 0.86174724, 0.91958042,        nan,
              nan]), 'split4_train_precision': array([0.89847095, 0.74179357,        nan,        nan, 0.84339537,
       0.83463918,        nan,        nan, 0.78841121, 0.84768212,
              nan,        nan, 0.87025761, 0.85557023,        nan,
              nan]), 'split5_train_precision': array([0.78426602, 0.84496466,        nan,        nan, 0.81992687,
       0.82699921,        nan,        nan, 0.88340807, 0.79780309,
              nan,        nan, 0.8959854 , 0.87256719,        nan,
              nan]), 'split6_train_precision': array([0.84435262, 0.87806206,        nan,        nan, 0.8875803 ,
       0.88993885,        nan,        nan, 0.78836586, 0.82136824,
              nan,        nan, 0.83571429, 0.84180091,        nan,
              nan]), 'split7_train_precision': array([0.84512086, 0.85505837,        nan,        nan, 0.82267793,
       0.92245557,        nan,        nan, 0.6963848 , 0.90084986,
              nan,        nan, 0.86680121, 0.83776933,        nan,
              nan]), 'split8_train_precision': array([0.87430341, 0.88140644,        nan,        nan, 0.76495238,
       0.8934611 ,        nan,        nan, 0.8860992 , 0.87843616,
              nan,        nan, 0.88725747, 0.89428263,        nan,
              nan]), 'split9_train_precision': array([0.8417782 , 0.85264599,        nan,        nan, 0.86120996,
       0.75214261,        nan,        nan, 0.86966686, 0.86791444,
              nan,        nan, 0.87916667, 0.80763179,        nan,
              nan]), 'mean_train_precision': array([0.83994788, 0.83662424,        nan,        nan, 0.82913531,
       0.85170706,        nan,        nan, 0.81592708, 0.84812106,
              nan,        nan, 0.87299764, 0.86436674,        nan,
              nan]), 'std_train_precision': array([0.03471634, 0.04704463,        nan,        nan, 0.05764347,
       0.05079405,        nan,        nan, 0.06616971, 0.04866574,
              nan,        nan, 0.02093723, 0.03529422,        nan,
              nan]), 'split0_test_recall': array([0.64477612, 0.45373134,        nan,        nan, 0.57910448,
       0.46268657,        nan,        nan, 0.44776119, 0.6238806 ,
              nan,        nan, 0.42985075, 0.62686567,        nan,
              nan]), 'split1_test_recall': array([0.59281437, 0.71257485,        nan,        nan, 0.75748503,
       0.68263473,        nan,        nan, 0.71856287, 0.45508982,
              nan,        nan, 0.58383234, 0.56886228,        nan,
              nan]), 'split2_test_recall': array([0.61449275, 0.60869565,        nan,        nan, 0.51594203,
       0.57971014,        nan,        nan, 0.6       , 0.37101449,
              nan,        nan, 0.62608696, 0.50724638,        nan,
              nan]), 'split3_test_recall': array([0.57608696, 0.62228261,        nan,        nan, 0.43206522,
       0.60597826,        nan,        nan, 0.71195652, 0.64673913,
              nan,        nan, 0.61684783, 0.55163043,        nan,
              nan]), 'split4_test_recall': array([0.4952381 , 0.69206349,        nan,        nan, 0.5968254 ,
       0.65396825,        nan,        nan, 0.65714286, 0.66349206,
              nan,        nan, 0.61269841, 0.62539683,        nan,
              nan]), 'split5_test_recall': array([0.60169492, 0.5960452 ,        nan,        nan, 0.56214689,
       0.6440678 ,        nan,        nan, 0.59322034, 0.5960452 ,
              nan,        nan, 0.4519774 , 0.55649718,        nan,
              nan]), 'split6_test_recall': array([0.57027027, 0.51081081,        nan,        nan, 0.52432432,
       0.48378378,        nan,        nan, 0.62702703, 0.59189189,
              nan,        nan, 0.58108108, 0.64054054,        nan,
              nan]), 'split7_test_recall': array([0.62285714, 0.58285714,        nan,        nan, 0.68571429,
       0.37428571,        nan,        nan, 0.76285714, 0.42      ,
              nan,        nan, 0.59142857, 0.65142857,        nan,
              nan]), 'split8_test_recall': array([0.42492918, 0.46175637,        nan,        nan, 0.62889518,
       0.47592068,        nan,        nan, 0.44192635, 0.44192635,
              nan,        nan, 0.52407932, 0.50708215,        nan,
              nan]), 'split9_test_recall': array([0.56973294, 0.62017804,        nan,        nan, 0.64985163,
       0.72997033,        nan,        nan, 0.51928783, 0.55192878,
              nan,        nan, 0.56379822, 0.69139466,        nan,
              nan]), 'mean_test_recall': array([0.57128927, 0.58609955,        nan,        nan, 0.59323545,
       0.56930063,        nan,        nan, 0.60797421, 0.53620083,
              nan,        nan, 0.55816809, 0.59269447,        nan,
              nan]), 'std_test_recall': array([0.062085  , 0.0830457 ,        nan,        nan, 0.08825259,
       0.10876674,        nan,        nan, 0.10545051, 0.09964716,
              nan,        nan, 0.06500408, 0.05992754,        nan,
              nan]), 'rank_test_recall': array([ 5,  4,  9, 10,  2,  6, 11, 12,  1,  8, 13, 14,  7,  3, 15, 16],
      dtype=int32), 'split0_train_recall': array([0.66122841, 0.47696737,        nan,        nan, 0.59788868,
       0.50223928,        nan,        nan, 0.46513116, 0.64587332,
              nan,        nan, 0.45489443, 0.63947537,        nan,
              nan]), 'split1_train_recall': array([0.53917493, 0.6850016 ,        nan,        nan, 0.73137192,
       0.64150943,        nan,        nan, 0.66293572, 0.410937  ,
              nan,        nan, 0.51327151, 0.49600256,        nan,
              nan]), 'split2_train_recall': array([0.61007702, 0.60494223,        nan,        nan, 0.53016688,
       0.5860077 ,        nan,        nan, 0.6084724 , 0.39987163,
              nan,        nan, 0.62644416, 0.49839538,        nan,
              nan]), 'split3_train_recall': array([0.59941804, 0.64726802,        nan,        nan, 0.46686065,
       0.63368898,        nan,        nan, 0.71225348, 0.66246363,
              nan,        nan, 0.65696735, 0.595215  ,        nan,
              nan]), 'split4_train_recall': array([0.46694215, 0.69675779,        nan,        nan, 0.59059123,
       0.64335664,        nan,        nan, 0.67037508, 0.65098538,
              nan,        nan, 0.59059123, 0.61760966,        nan,
              nan]), 'split5_train_recall': array([0.6224654 , 0.61570647,        nan,        nan, 0.57740586,
       0.67235275,        nan,        nan, 0.63405214, 0.63115546,
              nan,        nan, 0.47409076, 0.60605085,        nan,
              nan]), 'split6_train_recall': array([0.59495309, 0.52183759,        nan,        nan, 0.53639599,
       0.51795535,        nan,        nan, 0.66645099, 0.6292462 ,
              nan,        nan, 0.60562925, 0.65933355,        nan,
              nan]), 'split7_train_recall': array([0.60687882, 0.56509161,        nan,        nan, 0.65766635,
       0.36708454,        nan,        nan, 0.73063324, 0.40887175,
              nan,        nan, 0.55223401, 0.63741562,        nan,
              nan]), 'split8_train_recall': array([0.45431145, 0.47586873,        nan,        nan, 0.64607465,
       0.50997426,        nan,        nan, 0.46557272, 0.46267696,
              nan,        nan, 0.54440154, 0.53346203,        nan,
              nan]), 'split9_train_recall': array([0.56370038, 0.59827145,        nan,        nan, 0.61971831,
       0.70230474,        nan,        nan, 0.47631242, 0.51952625,
              nan,        nan, 0.54033291, 0.65717029,        nan,
              nan]), 'mean_train_recall': array([0.57191497, 0.58877129,        nan,        nan, 0.59541405,
       0.57764737,        nan,        nan, 0.60921893, 0.54216076,
              nan,        nan, 0.55588571, 0.59401303,        nan,
              nan]), 'std_train_recall': array([0.06362978, 0.07463808,        nan,        nan, 0.07080753,
       0.09709844,        nan,        nan, 0.09743487, 0.10706896,
              nan,        nan, 0.06161787, 0.05943449,        nan,
              nan]), 'split0_test_roc_auc': array([0.99131008, 0.99107642,        nan,        nan, 0.99144214,
       0.99180544,        nan,        nan, 0.99139294, 0.99106255,
              nan,        nan, 0.99173834, 0.99184777,        nan,
              nan]), 'split1_test_roc_auc': array([0.98966302, 0.98917543,        nan,        nan, 0.98833493,
       0.98713155,        nan,        nan, 0.98937847, 0.98971503,
              nan,        nan, 0.9874956 , 0.98943302,        nan,
              nan]), 'split2_test_roc_auc': array([0.99093892, 0.99093604,        nan,        nan, 0.98941101,
       0.99096729,        nan,        nan, 0.99090089, 0.98946456,
              nan,        nan, 0.99078494, 0.99004658,        nan,
              nan]), 'split3_test_roc_auc': array([0.9884908 , 0.98746923,        nan,        nan, 0.98898982,
       0.98919775,        nan,        nan, 0.98901238, 0.98943906,
              nan,        nan, 0.99034441, 0.98884119,        nan,
              nan]), 'split4_test_roc_auc': array([0.98883716, 0.98665639,        nan,        nan, 0.9864205 ,
       0.98745904,        nan,        nan, 0.9866511 , 0.98799976,
              nan,        nan, 0.98671835, 0.98691067,        nan,
              nan]), 'split5_test_roc_auc': array([0.98991342, 0.99011575,        nan,        nan, 0.98979968,
       0.99154787,        nan,        nan, 0.99115164, 0.98984648,
              nan,        nan, 0.99140006, 0.9895685 ,        nan,
              nan]), 'split6_test_roc_auc': array([0.99119111, 0.99115974,        nan,        nan, 0.99093698,
       0.99027342,        nan,        nan, 0.99061355, 0.99057177,
              nan,        nan, 0.9906842 , 0.99089448,        nan,
              nan]), 'split7_test_roc_auc': array([0.98895025, 0.98872425,        nan,        nan, 0.98753439,
       0.98770171,        nan,        nan, 0.98760908, 0.98674139,
              nan,        nan, 0.98854265, 0.98746467,        nan,
              nan]), 'split8_test_roc_auc': array([0.98921801, 0.9902815 ,        nan,        nan, 0.98798197,
       0.99024854,        nan,        nan, 0.98975903, 0.98828094,
              nan,        nan, 0.99150011, 0.98953352,        nan,
              nan]), 'split9_test_roc_auc': array([0.9876282 , 0.98382424,        nan,        nan, 0.98612264,
       0.98695304,        nan,        nan, 0.98724167, 0.98636351,
              nan,        nan, 0.98714341, 0.98744682,        nan,
              nan]), 'mean_test_roc_auc': array([0.9896141 , 0.9889419 ,        nan,        nan, 0.98869741,
       0.98932856,        nan,        nan, 0.98937107, 0.98894851,
              nan,        nan, 0.98963521, 0.98919872,        nan,
              nan]), 'std_test_roc_auc': array([0.00116693, 0.00224296,        nan,        nan, 0.00167835,
       0.00179203,        nan,        nan, 0.00162662, 0.00148001,
              nan,        nan, 0.00185552, 0.00149515,        nan,
              nan]), 'rank_test_roc_auc': array([ 2,  7,  9, 10,  8,  4, 11, 12,  3,  6, 13, 14,  1,  5, 15, 16],
      dtype=int32), 'split0_train_roc_auc': array([0.98882586, 0.98915781,        nan,        nan, 0.98887627,
       0.98938825,        nan,        nan, 0.98956889, 0.98843293,
              nan,        nan, 0.99004278, 0.98981616,        nan,
              nan]), 'split1_train_roc_auc': array([0.98945929, 0.98919347,        nan,        nan, 0.98972775,
       0.98903696,        nan,        nan, 0.99010565, 0.98934705,
              nan,        nan, 0.98928627, 0.98984454,        nan,
              nan]), 'split2_train_roc_auc': array([0.98956916, 0.99003876,        nan,        nan, 0.98964287,
       0.98993738,        nan,        nan, 0.98950145, 0.98780234,
              nan,        nan, 0.99040868, 0.98931974,        nan,
              nan]), 'split3_train_roc_auc': array([0.98922862, 0.99004393,        nan,        nan, 0.98806079,
       0.98914207,        nan,        nan, 0.9891749 , 0.98995431,
              nan,        nan, 0.99062986, 0.99043726,        nan,
              nan]), 'split4_train_roc_auc': array([0.9905071 , 0.98902245,        nan,        nan, 0.98908672,
       0.9898215 ,        nan,        nan, 0.98982135, 0.99070755,
              nan,        nan, 0.98941204, 0.98994744,        nan,
              nan]), 'split5_train_roc_auc': array([0.98907521, 0.98904808,        nan,        nan, 0.98832474,
       0.99017859,        nan,        nan, 0.99063372, 0.9888252 ,
              nan,        nan, 0.98980258, 0.98962722,        nan,
              nan]), 'split6_train_roc_auc': array([0.98981093, 0.98931758,        nan,        nan, 0.98990268,
       0.98879238,        nan,        nan, 0.98948952, 0.98941232,
              nan,        nan, 0.98952373, 0.99001436,        nan,
              nan]), 'split7_train_roc_auc': array([0.98960772, 0.98980618,        nan,        nan, 0.98912791,
       0.98948517,        nan,        nan, 0.98924808, 0.98863503,
              nan,        nan, 0.99062915, 0.98949049,        nan,
              nan]), 'split8_train_roc_auc': array([0.9887373 , 0.98961279,        nan,        nan, 0.98832568,
       0.98994919,        nan,        nan, 0.98921485, 0.98848323,
              nan,        nan, 0.98979773, 0.98940675,        nan,
              nan]), 'split9_train_roc_auc': array([0.99023763, 0.98906329,        nan,        nan, 0.98945055,
       0.98982693,        nan,        nan, 0.98987443, 0.98906313,
              nan,        nan, 0.99027961, 0.99011977,        nan,
              nan]), 'mean_train_roc_auc': array([0.98950588, 0.98943044,        nan,        nan, 0.9890526 ,
       0.98955584,        nan,        nan, 0.98966328, 0.98906631,
              nan,        nan, 0.98998124, 0.98980237,        nan,
              nan]), 'std_train_roc_auc': array([0.00054433, 0.00038878,        nan,        nan, 0.0006136 ,
       0.00043458,        nan,        nan, 0.00043409, 0.00079143,
              nan,        nan, 0.00046882, 0.00033003,        nan,
              nan]), 'split0_test_f1': array([0.70243902, 0.60079051,        nan,        nan, 0.68430335,
       0.61264822,        nan,        nan, 0.6       , 0.69435216,
              nan,        nan, 0.5841785 , 0.70945946,        nan,
              nan]), 'split1_test_f1': array([0.70714286, 0.74375   ,        nan,        nan, 0.72596844,
       0.74267101,        nan,        nan, 0.76311606, 0.60921844,
              nan,        nan, 0.70524412, 0.69724771,        nan,
              nan]), 'split2_test_f1': array([0.71500843, 0.70234114,        nan,        nan, 0.65201465,
       0.69686411,        nan,        nan, 0.69932432, 0.51821862,
              nan,        nan, 0.72240803, 0.64456722,        nan,
              nan]), 'split3_test_f1': array([0.65838509, 0.69288956,        nan,        nan, 0.56183746,
       0.67575758,        nan,        nan, 0.70524899, 0.68390805,
              nan,        nan, 0.70496894, 0.68350168,        nan,
              nan]), 'split4_test_f1': array([0.6446281 , 0.70322581,        nan,        nan, 0.69500924,
       0.72791519,        nan,        nan, 0.70528109, 0.72949389,
              nan,        nan, 0.71880819, 0.71376812,        nan,
              nan]), 'split5_test_f1': array([0.68820679, 0.70450751,        nan,        nan, 0.67572156,
       0.72266244,        nan,        nan, 0.70826307, 0.68064516,
              nan,        nan, 0.60263653, 0.68641115,        nan,
              nan]), 'split6_test_f1': array([0.66772152, 0.63422819,        nan,        nan, 0.64774624,
       0.61830743,        nan,        nan, 0.68135095, 0.67075038,
              nan,        nan, 0.67292645, 0.71171171,        nan,
              nan]), 'split7_test_f1': array([0.71828666, 0.69035533,        nan,        nan, 0.73959938,
       0.52929293,        nan,        nan, 0.73452545, 0.56538462,
              nan,        nan, 0.70050761, 0.7284345 ,        nan,
              nan]), 'split8_test_f1': array([0.58252427, 0.61859583,        nan,        nan, 0.71268058,
       0.63157895,        nan,        nan, 0.6       , 0.59884837,
              nan,        nan, 0.67395264, 0.66173752,        nan,
              nan]), 'split9_test_f1': array([0.68940754, 0.728223  ,        nan,        nan, 0.75517241,
       0.75344564,        nan,        nan, 0.65789474, 0.68508287,
              nan,        nan, 0.69852941, 0.76143791,        nan,
              nan]), 'mean_test_f1': array([0.67737503, 0.68189069,        nan,        nan, 0.68500533,
       0.67111435,        nan,        nan, 0.68550047, 0.64359026,
              nan,        nan, 0.67841604, 0.6998277 ,        nan,
              nan]), 'std_test_f1': array([0.03922921, 0.045173  ,        nan,        nan, 0.05308628,
       0.06808096,        nan,        nan, 0.05031709, 0.06358579,
              nan,        nan, 0.0453404 , 0.03162323,        nan,
              nan]), 'rank_test_f1': array([ 6,  4,  9, 10,  3,  7, 11, 12,  2,  8, 13, 14,  5,  1, 15, 16],
      dtype=int32), 'split0_train_f1': array([0.71609215, 0.62189781,        nan,        nan, 0.69816959,
       0.64436692,        nan,        nan, 0.61143818, 0.71016532,
              nan,        nan, 0.60587985, 0.71906475,        nan,
              nan]), 'split1_train_f1': array([0.66377953, 0.72206304,        nan,        nan, 0.71146368,
       0.71515152,        nan,        nan, 0.72419214, 0.56458699,
              nan,        nan, 0.64887811, 0.63866584,        nan,
              nan]), 'split2_train_f1': array([0.70787563, 0.69983293,        nan,        nan, 0.66572638,
       0.70393215,        nan,        nan, 0.7044399 , 0.55525847,
              nan,        nan, 0.7192336 , 0.64067657,        nan,
              nan]), 'split3_train_f1': array([0.69399214, 0.72562523,        nan,        nan, 0.60659525,
       0.71091766,        nan,        nan, 0.71642276, 0.71158187,
              nan,        nan, 0.74555127, 0.72266928,        nan,
              nan]), 'split4_train_f1': array([0.61451579, 0.71857073,        nan,        nan, 0.69470929,
       0.72662   ,        nan,        nan, 0.72461776, 0.73642575,
              nan,        nan, 0.70365461, 0.71737124,        nan,
              nan]), 'split5_train_f1': array([0.69406065, 0.71234407,        nan,        nan, 0.6776204 ,
       0.74170069,        nan,        nan, 0.73824246, 0.7047619 ,
              nan,        nan, 0.62007998, 0.71528965,        nan,
              nan]), 'split6_train_f1': array([0.69804517, 0.65462662,        nan,        nan, 0.6686832 ,
       0.65480573,        nan,        nan, 0.72230014, 0.71258472,
              nan,        nan, 0.70230726, 0.7394775 ,        nan,
              nan]), 'split7_train_f1': array([0.70645463, 0.68047223,        nan,        nan, 0.73097535,
       0.5251782 ,        nan,        nan, 0.71309804, 0.56245855,
              nan,        nan, 0.67465148, 0.72398686,        nan,
              nan]), 'split8_train_f1': array([0.59792505, 0.61805265,        nan,        nan, 0.70050584,
       0.64932405,        nan,        nan, 0.61041974, 0.6061117 ,
              nan,        nan, 0.67477567, 0.66827892,        nan,
              nan]), 'split9_train_f1': array([0.67523006, 0.70316027,        nan,        nan, 0.72077439,
       0.72636981,        nan,        nan, 0.61551189, 0.64997998,
              nan,        nan, 0.66931007, 0.72467349,        nan,
              nan]), 'mean_train_f1': array([0.67679708, 0.68566456,        nan,        nan, 0.68752234,
       0.67983667,        nan,        nan, 0.6880683 , 0.65139152,
              nan,        nan, 0.67643219, 0.70101541,        nan,
              nan]), 'std_train_f1': array([0.03834892, 0.03853705,        nan,        nan, 0.03373108,
       0.06140834,        nan,        nan, 0.05019408, 0.069021  ,
              nan,        nan, 0.04121779, 0.03525987,        nan,
              nan]), 'split0_test_average_precision': array([0.75575241, 0.77048372,        nan,        nan, 0.76478162,
       0.77387334,        nan,        nan, 0.76893221, 0.76434513,
              nan,        nan, 0.78094501, 0.78572428,        nan,
              nan]), 'split1_test_average_precision': array([0.78074103, 0.77978691,        nan,        nan, 0.77789287,
       0.77742731,        nan,        nan, 0.78790484, 0.7761412 ,
              nan,        nan, 0.77757334, 0.78712042,        nan,
              nan]), 'split2_test_average_precision': array([0.76006048, 0.75558811,        nan,        nan, 0.76952308,
       0.7719634 ,        nan,        nan, 0.75465979, 0.72887432,
              nan,        nan, 0.76390065, 0.76594081,        nan,
              nan]), 'split3_test_average_precision': array([0.7206674 , 0.73771312,        nan,        nan, 0.69451557,
       0.72373884,        nan,        nan, 0.73201626, 0.72108389,
              nan,        nan, 0.7609182 , 0.78375756,        nan,
              nan]), 'split4_test_average_precision': array([0.7611316 , 0.75048119,        nan,        nan, 0.75305502,
       0.76671067,        nan,        nan, 0.75558513, 0.78270444,
              nan,        nan, 0.75701306, 0.76584228,        nan,
              nan]), 'split5_test_average_precision': array([0.76112365, 0.79040031,        nan,        nan, 0.75988946,
       0.7981396 ,        nan,        nan, 0.80100365, 0.76404422,
              nan,        nan, 0.78269158, 0.79701275,        nan,
              nan]), 'split6_test_average_precision': array([0.74916749, 0.74309069,        nan,        nan, 0.74864625,
       0.74306518,        nan,        nan, 0.73986458, 0.74023244,
              nan,        nan, 0.74287359, 0.76046999,        nan,
              nan]), 'split7_test_average_precision': array([0.77165259, 0.76360528,        nan,        nan, 0.77442409,
       0.75694698,        nan,        nan, 0.76098771, 0.74191154,
              nan,        nan, 0.75933409, 0.7770482 ,        nan,
              nan]), 'split8_test_average_precision': array([0.76507692, 0.77746411,        nan,        nan, 0.76277717,
       0.79633857,        nan,        nan, 0.78038127, 0.76473559,
              nan,        nan, 0.80266677, 0.80168278,        nan,
              nan]), 'split9_test_average_precision': array([0.77580354, 0.79137057,        nan,        nan, 0.8048409 ,
       0.79231903,        nan,        nan, 0.76817579, 0.76969945,
              nan,        nan, 0.79243163, 0.80027297,        nan,
              nan]), 'mean_test_average_precision': array([0.76011771, 0.7659984 ,        nan,        nan, 0.7610346 ,
       0.77005229,        nan,        nan, 0.76495112, 0.75537722,
              nan,        nan, 0.77203479, 0.7824872 ,        nan,
              nan]), 'std_test_average_precision': array([0.01589449, 0.01805716,        nan,        nan, 0.02667366,
       0.02259308,        nan,        nan, 0.02003591, 0.01978709,
              nan,        nan, 0.01733512, 0.01412279,        nan,
              nan]), 'rank_test_average_precision': array([ 7,  4,  9, 10,  6,  3, 11, 12,  5,  8, 13, 14,  2,  1, 15, 16],
      dtype=int32), 'split0_train_average_precision': array([0.75532034, 0.76426082,        nan,        nan, 0.75966223,
       0.77150926,        nan,        nan, 0.75974707, 0.7527116 ,
              nan,        nan, 0.77439079, 0.77556096,        nan,
              nan]), 'split1_train_average_precision': array([0.76001128, 0.76173174,        nan,        nan, 0.76283191,
       0.76308929,        nan,        nan, 0.77218286, 0.7562025 ,
              nan,        nan, 0.76373521, 0.77171742,        nan,
              nan]), 'split2_train_average_precision': array([0.77149587, 0.76475279,        nan,        nan, 0.77807918,
       0.78399723,        nan,        nan, 0.76686807, 0.74648971,
              nan,        nan, 0.77606407, 0.7720272 ,        nan,
              nan]), 'split3_train_average_precision': array([0.75772749, 0.77904414,        nan,        nan, 0.73177149,
       0.76222652,        nan,        nan, 0.76624475, 0.76050847,
              nan,        nan, 0.79838537, 0.81346659,        nan,
              nan]), 'split4_train_average_precision': array([0.7704207 , 0.75701894,        nan,        nan, 0.7632    ,
       0.77866377,        nan,        nan, 0.76650033, 0.79239603,
              nan,        nan, 0.77159817, 0.77978569,        nan,
              nan]), 'split5_train_average_precision': array([0.74600036, 0.77239285,        nan,        nan, 0.73945261,
       0.7833496 ,        nan,        nan, 0.80116131, 0.75106579,
              nan,        nan, 0.76827877, 0.78126825,        nan,
              nan]), 'split6_train_average_precision': array([0.77148992, 0.76652751,        nan,        nan, 0.7726423 ,
       0.76930404,        nan,        nan, 0.76472285, 0.76602407,
              nan,        nan, 0.7680416 , 0.78536654,        nan,
              nan]), 'split7_train_average_precision': array([0.77489059, 0.76678893,        nan,        nan, 0.77850779,
       0.76094685,        nan,        nan, 0.76490165, 0.74955415,
              nan,        nan, 0.76705753, 0.78294439,        nan,
              nan]), 'split8_train_average_precision': array([0.7437606 , 0.76167577,        nan,        nan, 0.74032967,
       0.76940528,        nan,        nan, 0.75645132, 0.74664231,
              nan,        nan, 0.77643755, 0.77729519,        nan,
              nan]), 'split9_train_average_precision': array([0.7555121 , 0.77152098,        nan,        nan, 0.78109996,
       0.77222841,        nan,        nan, 0.74940274, 0.75055982,
              nan,        nan, 0.7702995 , 0.77766583,        nan,
              nan]), 'mean_train_average_precision': array([0.76066292, 0.76657145,        nan,        nan, 0.76075771,
       0.77147202,        nan,        nan, 0.76681829, 0.75721544,
              nan,        nan, 0.77342885, 0.78170981,        nan,
              nan]), 'std_train_average_precision': array([0.01047383, 0.00601075,        nan,        nan, 0.01700891,
       0.00791045,        nan,        nan, 0.01295182, 0.01309604,
              nan,        nan, 0.0091815 , 0.01137778,        nan,
              nan])}, 'n_splits_': 10}
 _ _ _ _ _ _ _ _ _ _ MODEL # 1  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.55 
        MEAN TEST SCORE :  5.02 STD TEST SCORE :  0.092 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  5 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.994    0.994    0.993    0.993    0.994    0.994    0.993    0.993  
TEST   0.994    0.994    0.994    0.992    0.994    0.993    0.993    0.994    0.992    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.781    0.863    0.843    0.824    0.898    0.784    0.844    0.845    0.874    0.842  
TEST   0.771    0.876    0.855    0.768    0.923    0.804    0.805    0.848    0.926    0.873  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.661    0.539    0.610    0.599    0.467    0.622    0.595    0.607    0.454    0.564  
TEST   0.645    0.593    0.614    0.576    0.495    0.602    0.570    0.623    0.425    0.570  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.990    0.989    0.991    0.989    0.990    0.990    0.989    0.990  
TEST   0.991    0.990    0.991    0.988    0.989    0.990    0.991    0.989    0.989    0.988  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.755    0.760    0.771    0.758    0.770    0.746    0.771    0.775    0.744    0.756  
TEST   0.756    0.781    0.760    0.721    0.761    0.761    0.749    0.772    0.765    0.776  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.716    0.664    0.708    0.694    0.615    0.694    0.698    0.706    0.598    0.675  
TEST   0.702    0.707    0.715    0.658    0.645    0.688    0.668    0.718    0.583    0.689  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#1_acc.png





Saving image with name:  Model#1_prec.png


Saving image with name:  Model#1_rec.png


Saving image with name:  Model#1_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 2  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.462 
        MEAN TEST SCORE :  6.716 STD TEST SCORE :  0.022 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  4 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.994    0.993    0.994    0.993    0.994    0.993    0.994  
TEST   0.993    0.994    0.994    0.993    0.994    0.994    0.992    0.994    0.993    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.893    0.763    0.83     0.826    0.742    0.845    0.878    0.855    0.881    0.853  
TEST   0.889    0.778    0.83     0.782    0.715    0.861    0.836    0.846    0.937    0.882  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.477    0.685    0.605    0.647    0.697    0.616    0.522    0.565    0.476    0.598  
TEST   0.454    0.713    0.609    0.622    0.692    0.596    0.511    0.583    0.462    0.620  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.990    0.990    0.989    0.989    0.989    0.990    0.99     0.989  
TEST   0.991    0.989    0.991    0.987    0.987    0.990    0.991    0.989    0.99     0.984  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.764    0.762    0.765    0.779    0.757    0.772    0.767    0.767    0.762    0.772  
TEST   0.770    0.780    0.756    0.738    0.750    0.790    0.743    0.764    0.777    0.791  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.622    0.722    0.700    0.726    0.719    0.712    0.655    0.68     0.618    0.703  
TEST   0.601    0.744    0.702    0.693    0.703    0.705    0.634    0.69     0.619    0.728  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#2_acc.png





Saving image with name:  Model#2_prec.png


Saving image with name:  Model#2_rec.png


Saving image with name:  Model#2_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 3  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.01 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  9 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#3_acc.png





Saving image with name:  Model#3_prec.png


Saving image with name:  Model#3_rec.png


Saving image with name:  Model#3_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 4  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.01 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  10 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#4_acc.png





Saving image with name:  Model#4_prec.png


Saving image with name:  Model#4_rec.png


Saving image with name:  Model#4_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 5  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.314 
        MEAN TEST SCORE :  4.735 STD TEST SCORE :  0.17 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  3 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.994    0.993    0.994    0.993    0.994    0.994    0.993    0.994  
TEST   0.994    0.993    0.993    0.991    0.994    0.993    0.993    0.994    0.994    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.839    0.693    0.894    0.866    0.843    0.820    0.888    0.823    0.765    0.861  
TEST   0.836    0.697    0.886    0.803    0.832    0.847    0.847    0.803    0.822    0.901  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.598    0.731    0.530    0.467    0.591    0.577    0.536    0.658    0.646    0.62   
TEST   0.579    0.757    0.516    0.432    0.597    0.562    0.524    0.686    0.629    0.65   
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.990    0.990    0.988    0.989    0.988    0.990    0.989    0.988    0.989  
TEST   0.991    0.988    0.989    0.989    0.986    0.990    0.991    0.988    0.988    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.760    0.763    0.778    0.732    0.763    0.739    0.773    0.779    0.740    0.781  
TEST   0.765    0.778    0.770    0.695    0.753    0.760    0.749    0.774    0.763    0.805  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.698    0.711    0.666    0.607    0.695    0.678    0.669    0.731    0.701    0.721  
TEST   0.684    0.726    0.652    0.562    0.695    0.676    0.648    0.740    0.713    0.755  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#5_acc.png





Saving image with name:  Model#5_prec.png


Saving image with name:  Model#5_rec.png


Saving image with name:  Model#5_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 6  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.965 
        MEAN TEST SCORE :  5.86 STD TEST SCORE :  0.209 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  6 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.994    0.994    0.994    0.993    0.992    0.993    0.994  
TEST   0.993    0.994    0.994    0.993    0.995    0.994    0.992    0.992    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.899    0.808    0.881    0.810    0.835    0.827    0.890    0.922    0.893    0.752  
TEST   0.906    0.814    0.873    0.764    0.821    0.823    0.856    0.903    0.939    0.778  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.502    0.642    0.586    0.634    0.643    0.672    0.518    0.367    0.510    0.702  
TEST   0.463    0.683    0.580    0.606    0.654    0.644    0.484    0.374    0.476    0.730  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.990    0.989    0.990    0.990    0.989    0.989    0.99     0.990  
TEST   0.992    0.987    0.991    0.989    0.987    0.992    0.990    0.988    0.99     0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.772    0.763    0.784    0.762    0.779    0.783    0.769    0.761    0.769    0.772  
TEST   0.774    0.777    0.772    0.724    0.767    0.798    0.743    0.757    0.796    0.792  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.644    0.715    0.704    0.711    0.727    0.742    0.655    0.525    0.649    0.726  
TEST   0.613    0.743    0.697    0.676    0.728    0.723    0.618    0.529    0.632    0.753  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#6_acc.png





Saving image with name:  Model#6_prec.png


Saving image with name:  Model#6_rec.png


Saving image with name:  Model#6_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 7  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  11 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#7_acc.png





Saving image with name:  Model#7_prec.png


Saving image with name:  Model#7_rec.png


Saving image with name:  Model#7_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 8  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.01 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  12 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#8_acc.png





Saving image with name:  Model#8_prec.png


Saving image with name:  Model#8_rec.png


Saving image with name:  Model#8_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 9  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   61.736 
        MEAN TEST SCORE :  5.051 STD TEST SCORE :  0.025 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  7 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.993    0.994    0.995    0.994    0.993    0.993    0.993  
TEST   0.993    0.995    0.994    0.992    0.994    0.994    0.992    0.993    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.892    0.798    0.836    0.721    0.788    0.883    0.788    0.696    0.886    0.870  
TEST   0.909    0.814    0.838    0.699    0.761    0.879    0.746    0.708    0.934    0.897  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.465    0.663    0.608    0.712    0.670    0.634    0.666    0.731    0.466    0.476  
TEST   0.448    0.719    0.600    0.712    0.657    0.593    0.627    0.763    0.442    0.519  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.990    0.990    0.989    0.990    0.991    0.989    0.989    0.989    0.990  
TEST   0.991    0.989    0.991    0.989    0.987    0.991    0.991    0.988    0.990    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.760    0.772    0.767    0.766    0.767    0.801    0.765    0.765    0.756    0.749  
TEST   0.769    0.788    0.755    0.732    0.756    0.801    0.740    0.761    0.780    0.768  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.611    0.724    0.704    0.716    0.725    0.738    0.722    0.713    0.61     0.616  
TEST   0.600    0.763    0.699    0.705    0.705    0.708    0.681    0.735    0.60     0.658  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#9_acc.png





Saving image with name:  Model#9_prec.png


Saving image with name:  Model#9_rec.png


Saving image with name:  Model#9_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 10  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   38.154 
        MEAN TEST SCORE :  6.782 STD TEST SCORE :  0.031 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  8 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.992    0.992    0.994    0.994    0.994    0.994    0.992    0.993    0.993  
TEST   0.994    0.993    0.992    0.992    0.995    0.993    0.992    0.992    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.789    0.902    0.908    0.769    0.848    0.798    0.821    0.901    0.878    0.868  
TEST   0.783    0.921    0.859    0.726    0.810    0.793    0.774    0.865    0.929    0.903  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.646    0.411    0.400    0.662    0.651    0.631    0.629    0.409    0.463    0.520  
TEST   0.624    0.455    0.371    0.647    0.663    0.596    0.592    0.420    0.442    0.552  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.988    0.989    0.988    0.990    0.991    0.989    0.989    0.989    0.988    0.989  
TEST   0.991    0.990    0.989    0.989    0.988    0.990    0.991    0.987    0.988    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.753    0.756    0.746    0.761    0.792    0.751    0.766    0.750    0.747    0.751  
TEST   0.764    0.776    0.729    0.721    0.783    0.764    0.740    0.742    0.765    0.770  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.710    0.565    0.555    0.712    0.736    0.705    0.713    0.562    0.606    0.650  
TEST   0.694    0.609    0.518    0.684    0.729    0.681    0.671    0.565    0.599    0.685  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#10_acc.png





Saving image with name:  Model#10_prec.png


Saving image with name:  Model#10_rec.png


Saving image with name:  Model#10_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 11  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.015 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  13 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#11_acc.png





Saving image with name:  Model#11_prec.png


Saving image with name:  Model#11_rec.png


Saving image with name:  Model#11_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 12  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.01 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  14 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#12_acc.png





Saving image with name:  Model#12_prec.png


Saving image with name:  Model#12_rec.png


Saving image with name:  Model#12_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 13  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   31.776 
        MEAN TEST SCORE :  4.713 STD TEST SCORE :  0.025 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  2 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.993    0.994    0.995    0.994    0.993    0.994    0.994    0.994    0.994  
TEST   0.993    0.994    0.994    0.993    0.995    0.993    0.993    0.994    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.907    0.882    0.844    0.862    0.870    0.896    0.836    0.867    0.887    0.879  
TEST   0.911    0.890    0.854    0.822    0.869    0.904    0.799    0.859    0.944    0.918  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.455    0.513    0.626    0.657    0.591    0.474    0.606    0.552    0.544    0.540  
TEST   0.430    0.584    0.626    0.617    0.613    0.452    0.581    0.591    0.524    0.564  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.989    0.990    0.991    0.989    0.990    0.990    0.991    0.990    0.990  
TEST   0.992    0.987    0.991    0.990    0.987    0.991    0.991    0.989    0.992    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.774    0.764    0.776    0.798    0.772    0.768    0.768    0.767    0.776    0.770  
TEST   0.781    0.778    0.764    0.761    0.757    0.783    0.743    0.759    0.803    0.792  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.606    0.649    0.719    0.746    0.704    0.620    0.702    0.675    0.675    0.669  
TEST   0.584    0.705    0.722    0.705    0.719    0.603    0.673    0.701    0.674    0.699  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#13_acc.png





Saving image with name:  Model#13_prec.png


Saving image with name:  Model#13_rec.png


Saving image with name:  Model#13_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 14  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   37.296 
        MEAN TEST SCORE :  5.861 STD TEST SCORE :  0.016 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  1 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.993    0.994    0.994    0.994    0.994    0.994    0.994    0.994  
TEST   0.994    0.994    0.993    0.993    0.994    0.994    0.993    0.994    0.994    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.821    0.897    0.897    0.920    0.856    0.873    0.842    0.838    0.894    0.808  
TEST   0.817    0.900    0.884    0.898    0.831    0.895    0.801    0.826    0.952    0.847  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.639    0.496    0.498    0.595    0.618    0.606    0.659    0.637    0.533    0.657  
TEST   0.627    0.569    0.507    0.552    0.625    0.556    0.641    0.651    0.507    0.691  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.990    0.989    0.990    0.990    0.99     0.990    0.989    0.989    0.990  
TEST   0.992    0.989    0.990    0.989    0.987    0.99     0.991    0.987    0.990    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.776    0.772    0.772    0.813    0.780    0.781    0.785    0.783    0.777    0.778  
TEST   0.786    0.787    0.766    0.784    0.766    0.797    0.760    0.777    0.802    0.800  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.719    0.639    0.641    0.723    0.717    0.715    0.739    0.724    0.668    0.725  
TEST   0.709    0.697    0.645    0.684    0.714    0.686    0.712    0.728    0.662    0.761  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#14_acc.png





Saving image with name:  Model#14_prec.png


Saving image with name:  Model#14_rec.png


Saving image with name:  Model#14_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 15  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.015 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  15 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#15_acc.png





Saving image with name:  Model#15_prec.png


Saving image with name:  Model#15_rec.png


Saving image with name:  Model#15_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 16  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.005 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  16 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#16_acc.png





Saving image with name:  Model#16_prec.png


Saving image with name:  Model#16_rec.png


Saving image with name:  Model#16_auc.png


BEST MODEL HISTORY PER EPOCH
SELECTED EPOCHS   : 50
PARAMS            : {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'} 

                   0      1
TRAIN ACC      0.989  0.992
TEST ACC       0.991  0.993
TRAIN LOSS     0.042  0.025
TEST LOSS      0.028  0.021
precision      0.609  0.767
val_precision  0.731  0.734
recall         0.207  0.493
val_recall     0.344  0.683 




<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f49688ae9e8>
237858/237858 - 20s
CONFUSION MATRIX
Predicted       0     1
True                   
0          234315  704 
1          901     1938
tn, fp, fn, tp
234315 704 901 1938
P: [0.01193569 0.7335352  1.        ]
R: [1.         0.68263473 0.        ]
THRES: [0. 1.]
dict_keys(['scoring', 'estimator', 'n_jobs', 'iid', 'refit', 'cv', 'verbose', 'pre_dispatch', 'error_score', 'return_train_score', 'param_grid', 'multimetric_', 'best_index_', 'best_score_', 'best_params_', 'best_estimator_', 'refit_time_', 'scorer_', 'cv_results_', 'n_splits_'])
Error: best_params_ - KeyError('keras_eval_metric',)
Error: cv_results_ - KeyError('param_keras_eval_metric',)
Error: param_grid - KeyError('keras_eval_metric',)
Saving  scoring -> scoring_rnn.history 
 ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
Saving  n_jobs -> n_jobs_rnn.history 
 1
Saving  iid -> iid_rnn.history 
 deprecated
Saving  refit -> refit_rnn.history 
 recall
Saving  cv -> cv_rnn.history 
 10
Saving  verbose -> verbose_rnn.history 
 2
Saving  pre_dispatch -> pre_dispatch_rnn.history 
 1*n_jobs
Saving  error_score -> error_score_rnn.history 
 nan
Saving  return_train_score -> return_train_score_rnn.history 
 True
Saving  param_grid -> param_grid_rnn.history 
 dict_keys(['rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'optimizer', 'modelType', 'epochs', 'output_layer_activation', 'rnn_layer_activation', 'hidden_layer_activation', 'dropout', 'dropout_rate'])
Saving  best_index_ -> best_index__rnn.history 
 8
Saving  best_score_ -> best_score__rnn.history 
 0.6079742135467515
Saving  best_params_ -> best_params__rnn.history 
 dict_keys(['dropout', 'dropout_rate', 'epochs', 'hidden_layer_activation', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'modelType', 'optimizer', 'output_layer_activation', 'rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'rnn_layer_activation'])
Saving  refit_time_ -> refit_time__rnn.history 
 234.40723180770874
Saving  cv_results_ -> cv_results__rnn.history 
 dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_epochs', 'param_hidden_layer_activation', 'param_hidden_layers', 'param_hidden_layers_neurons', 'param_loss', 'param_modelType', 'param_optimizer', 'param_output_layer_activation', 'param_rnn_hidden_layers', 'param_rnn_hidden_layers_neurons', 'param_rnn_layer_activation', 'params', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'split5_test_accuracy', 'split6_test_accuracy', 'split7_test_accuracy', 'split8_test_accuracy', 'split9_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'split5_train_accuracy', 'split6_train_accuracy', 'split7_train_accuracy', 'split8_train_accuracy', 'split9_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'split5_test_precision', 'split6_test_precision', 'split7_test_precision', 'split8_test_precision', 'split9_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'split5_train_precision', 'split6_train_precision', 'split7_train_precision', 'split8_train_precision', 'split9_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'split5_test_recall', 'split6_test_recall', 'split7_test_recall', 'split8_test_recall', 'split9_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'split5_train_recall', 'split6_train_recall', 'split7_train_recall', 'split8_train_recall', 'split9_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_roc_auc', 'split1_test_roc_auc', 'split2_test_roc_auc', 'split3_test_roc_auc', 'split4_test_roc_auc', 'split5_test_roc_auc', 'split6_test_roc_auc', 'split7_test_roc_auc', 'split8_test_roc_auc', 'split9_test_roc_auc', 'mean_test_roc_auc', 'std_test_roc_auc', 'rank_test_roc_auc', 'split0_train_roc_auc', 'split1_train_roc_auc', 'split2_train_roc_auc', 'split3_train_roc_auc', 'split4_train_roc_auc', 'split5_train_roc_auc', 'split6_train_roc_auc', 'split7_train_roc_auc', 'split8_train_roc_auc', 'split9_train_roc_auc', 'mean_train_roc_auc', 'std_train_roc_auc', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'split5_test_f1', 'split6_test_f1', 'split7_test_f1', 'split8_test_f1', 'split9_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'split5_train_f1', 'split6_train_f1', 'split7_train_f1', 'split8_train_f1', 'split9_train_f1', 'mean_train_f1', 'std_train_f1', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'split5_test_average_precision', 'split6_test_average_precision', 'split7_test_average_precision', 'split8_test_average_precision', 'split9_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'split5_train_average_precision', 'split6_train_average_precision', 'split7_train_average_precision', 'split8_train_average_precision', 'split9_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision'])
Saving  n_splits_ -> n_splits__rnn.history 
 10
Saving history
BEST ESTIMATOR
<tensorflow.python.keras.engine.sequential.Sequential object at 0x7f4a4018ef60>
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_120 (LSTM)              (None, 50)                12600     
_________________________________________________________________
dense_240 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_240 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_241 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
None
{'name': 'sequential_160', 'layers': [{'class_name': 'LSTM', 'config': {'name': 'lstm_120', 'trainable': True, 'batch_input_shape': (None, 25, 12), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 50, 'activation': 'sigmoid', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2}}, {'class_name': 'Dense', 'config': {'name': 'dense_240', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_240', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}, {'class_name': 'Dense', 'config': {'name': 'dense_241', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_241', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_80', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_242', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_242', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}]}
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_120 (LSTM)              (None, 50)                12600     
_________________________________________________________________
dense_240 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_240 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_241 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
None
[[0.00026626]
 [0.0008024 ]
 [0.00028929]
 ...
 [0.00025037]
 [0.00110546]
 [0.00048279]]
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
