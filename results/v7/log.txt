Versions
Tensorflow :  2.1.0
Pandas     :  0.24.2
Numpy      :  0.24.2
Sklearn    :  0.22.1
NO GPUs available
CMD: pwd
OUT: /home/ec2-user/SageMaker
----------
CMD: ls
OUT: banksim1.zip
bs140513_032310.csv
bsNET140513_032310.csv
err.txt
labels_hash.data
logs
log.txt
lost+found
Makefile
results
rnn_data.data
RNN_Detection.ipynb
RNN_Detection.py
rnn_mod_data.data
scaler.data
X_test.data
X_train.data
X_val.data
y_test.data
y_train.data
y_val.data
----------
CMD: ./trin
OUT: [Errno 2] No such file or directory: './trin': './trin'
----------

    DATA PREPROCESSING
    DOWNLOAD FROM KAGGLE: False
    GENERATE DATA:        False
    READ FROM CLOUD:      False
    SAVE TO CLOUD:        False



_ _ _ _ _ _ _ _ _ _  IMPORT DATA FROM CSV _ _ _ _ _ _ _ _ _ _ 


Deleting the columns 'zipcodeOri','zipMerchant' because all the fields are equal.


Data Shape: (594643, 8) 

Preview: 

    step       customer  age gender       merchant             category  amount  fraud
0  0     'C1093826151'  '4'  'M'    'M348934600'   'es_transportation'  4.55    0    
1  0     'C352968107'   '2'  'M'    'M348934600'   'es_transportation'  39.68   0    
2  0     'C2054744914'  '4'  'F'    'M1823072687'  'es_transportation'  26.89   0    
3  0     'C1760612790'  '3'  'M'    'M348934600'   'es_transportation'  17.25   0    
4  0     'C757503768'   '5'  'M'    'M348934600'   'es_transportation'  35.72   0     

 Data Information: 

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 594643 entries, 0 to 594642
Data columns (total 8 columns):
step        594643 non-null int64
customer    594643 non-null object
age         594643 non-null object
gender      594643 non-null object
merchant    594643 non-null object
category    594643 non-null object
amount      594643 non-null float64
fraud       594643 non-null int64
dtypes: float64(1), int64(2), object(5)
memory usage: 36.3+ MB

None
Does it has null values? False


_ _ _ _ _ _ _ _ _ _   READ DATA LOCALLY  _ _ _ _ _ _ _ _ _ _ 




SHAPES & KEYS:
    X_train          : (285428, 25, 12)
    y_train          : (285428,)
    X_test           : (237858, 25, 12)
    y_test           : (237858,)
    X_val            : (71357, 25, 12)
    y_val            : (71357,)
    labels_hash Keys : dict_keys(['customer', 'age', 'gender', 'merchant', 'category'])
    


_ _ _ _ _ _ _ _ _ _  INITIALIZING GRID SEARCH RNN MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________
        input_shape :  (25, 12)
        output_dim  :  1
        main scoring:  recall
        all scoring :  ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
        early_stopping_monitor   : val_recall
        model_checkpoint_monitor : val_recall
        verbose: 2
        
rnn_hidden_layers : [0, 1]
rnn_hidden_layers_neurons : [50, 100]
hidden_layers : [2]
hidden_layers_neurons : [200, 300]
loss : ['binary_crossentropy']
optimizer : ['adam']
modelType : ['LSTM', 'GRU']
epochs : [50]
output_layer_activation : ['sigmoid']
rnn_layer_activation : ['sigmoid']
hidden_layer_activation : ['sigmoid']
dropout : [True]
dropout_rate : [0.2]





_ _ _ _ _ _ _ _ _ _  TRAINING RNN _ _ _ _ _ _ _ _ _ _ 



        Class weights: 
[ 0.50613724 41.23490321]
{0: 0.506137243010707, 1: 41.23490320716556}

        for classes: 
[0. 1.]

        # Frauds: 3461
        # of Non-Frauds: 281967
        
INPUTS
        X:      (285428, 25, 12)
        y:      (285428,)
        X_test: (237858, 25, 12)
        y_test: (237858,)
        
Fitting 10 folds for each of 16 candidates, totalling 160 fits
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff390039390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3900396a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff390039860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff390039c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff390039ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3707ec2e8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3707ec588>, <tensorflow.python.keras.metrics.AUC object at 0x7ff3707ec898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff39032cef0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff39032cf98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff39032cfd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff390039080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff3900390f0>]
          

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 50)                12600     
_________________________________________________________________
dense (Dense)                (None, 200)               10200     
_________________________________________________________________
activation (Activation)      (None, 200)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_1 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout (Dropout)            (None, 200)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall improved from inf to 0.24868, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 106s - loss: 0.0428 - tp: 646.0000 - fp: 445.0000 - tn: 253314.0000 - fn: 2480.0000 - accuracy: 0.9886 - precision: 0.5921 - recall: 0.2067 - auc: 0.8942 - val_loss: 0.0317 - val_tp: 706.0000 - val_fp: 226.0000 - val_tn: 234793.0000 - val_fn: 2133.0000 - val_accuracy: 0.9901 - val_precision: 0.7575 - val_recall: 0.2487 - val_auc: 0.9459
256885/256885 - 106s - loss: 0.0428 - tp: 646.0000 - fp: 445.0000 - tn: 253314.0000 - fn: 2480.0000 - accuracy: 0.9886 - precision: 0.5921 - recall: 0.2067 - auc: 0.8942 - val_loss: 0.0317 - val_tp: 706.0000 - val_fp: 226.0000 - val_tn: 234793.0000 - val_fn: 2133.0000 - val_accuracy: 0.9901 - val_precision: 0.7575 - val_recall: 0.2487 - val_auc: 0.9459
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.24868
256885/256885 - 103s - loss: 0.0262 - tp: 1472.0000 - fp: 462.0000 - tn: 253297.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7611 - recall: 0.4709 - auc: 0.9642 - val_loss: 0.0261 - val_tp: 1233.0000 - val_fp: 190.0000 - val_tn: 234829.0000 - val_fn: 1606.0000 - val_accuracy: 0.9924 - val_precision: 0.8665 - val_recall: 0.4343 - val_auc: 0.9409
256885/256885 - 103s - loss: 0.0262 - tp: 1472.0000 - fp: 462.0000 - tn: 253297.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7611 - recall: 0.4709 - auc: 0.9642 - val_loss: 0.0261 - val_tp: 1233.0000 - val_fp: 190.0000 - val_tn: 234829.0000 - val_fn: 1606.0000 - val_accuracy: 0.9924 - val_precision: 0.8665 - val_recall: 0.4343 - val_auc: 0.9409
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3303e78d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3303cf518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff330389cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff330391470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff330391710>, <tensorflow.python.keras.metrics.Precision object at 0x7ff330391ac8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff330391d68>, <tensorflow.python.keras.metrics.AUC object at 0x7ff330391f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3c84a42b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3900390f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff390039278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff3900392b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff390039358>]
          

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_3 (Dense)              (None, 200)               10200     
_________________________________________________________________
activation_3 (Activation)    (None, 200)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_4 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_5 (Activation)    (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.24868
256885/256885 - 106s - loss: 0.0429 - tp: 563.0000 - fp: 388.0000 - tn: 253370.0000 - fn: 2564.0000 - accuracy: 0.9885 - precision: 0.5920 - recall: 0.1800 - auc: 0.9011 - val_loss: 0.0317 - val_tp: 709.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2130.0000 - val_accuracy: 0.9901 - val_precision: 0.7535 - val_recall: 0.2497 - val_auc: 0.9470
256885/256885 - 106s - loss: 0.0429 - tp: 563.0000 - fp: 388.0000 - tn: 253370.0000 - fn: 2564.0000 - accuracy: 0.9885 - precision: 0.5920 - recall: 0.1800 - auc: 0.9011 - val_loss: 0.0317 - val_tp: 709.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2130.0000 - val_accuracy: 0.9901 - val_precision: 0.7535 - val_recall: 0.2497 - val_auc: 0.9470
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.24868
256885/256885 - 102s - loss: 0.0265 - tp: 1435.0000 - fp: 446.0000 - tn: 253312.0000 - fn: 1692.0000 - accuracy: 0.9917 - precision: 0.7629 - recall: 0.4589 - auc: 0.9654 - val_loss: 0.0210 - val_tp: 1620.0000 - val_fp: 431.0000 - val_tn: 234588.0000 - val_fn: 1219.0000 - val_accuracy: 0.9931 - val_precision: 0.7899 - val_recall: 0.5706 - val_auc: 0.9760
256885/256885 - 102s - loss: 0.0265 - tp: 1435.0000 - fp: 446.0000 - tn: 253312.0000 - fn: 1692.0000 - accuracy: 0.9917 - precision: 0.7629 - recall: 0.4589 - auc: 0.9654 - val_loss: 0.0210 - val_tp: 1620.0000 - val_fp: 431.0000 - val_tn: 234588.0000 - val_fn: 1219.0000 - val_accuracy: 0.9931 - val_precision: 0.7899 - val_recall: 0.5706 - val_auc: 0.9760
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff354575c50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3700eada0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff3700ea240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff3700ea278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff370083c88>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3b44a5f60>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3544ad048>, <tensorflow.python.keras.metrics.AUC object at 0x7ff3544ad2e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3900392b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3540130b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff39032cf98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff35456f940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff354575a58>]
          

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_6 (Dense)              (None, 200)               10200     
_________________________________________________________________
activation_6 (Activation)    (None, 200)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 200)               40200     
_________________________________________________________________
activation_7 (Activation)    (None, 200)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 201       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.24868
256885/256885 - 106s - loss: 0.0425 - tp: 583.0000 - fp: 403.0000 - tn: 253366.0000 - fn: 2533.0000 - accuracy: 0.9886 - precision: 0.5913 - recall: 0.1871 - auc: 0.9018 - val_loss: 0.0301 - val_tp: 1244.0000 - val_fp: 866.0000 - val_tn: 234153.0000 - val_fn: 1595.0000 - val_accuracy: 0.9897 - val_precision: 0.5896 - val_recall: 0.4382 - val_auc: 0.9731
256885/256885 - 106s - loss: 0.0425 - tp: 583.0000 - fp: 403.0000 - tn: 253366.0000 - fn: 2533.0000 - accuracy: 0.9886 - precision: 0.5913 - recall: 0.1871 - auc: 0.9018 - val_loss: 0.0301 - val_tp: 1244.0000 - val_fp: 866.0000 - val_tn: 234153.0000 - val_fn: 1595.0000 - val_accuracy: 0.9897 - val_precision: 0.5896 - val_recall: 0.4382 - val_auc: 0.9731
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.24868
256885/256885 - 102s - loss: 0.0259 - tp: 1462.0000 - fp: 451.0000 - tn: 253318.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7642 - recall: 0.4692 - auc: 0.9650 - val_loss: 0.0247 - val_tp: 1265.0000 - val_fp: 179.0000 - val_tn: 234840.0000 - val_fn: 1574.0000 - val_accuracy: 0.9926 - val_precision: 0.8760 - val_recall: 0.4456 - val_auc: 0.9501
256885/256885 - 102s - loss: 0.0259 - tp: 1462.0000 - fp: 451.0000 - tn: 253318.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7642 - recall: 0.4692 - auc: 0.9650 - val_loss: 0.0247 - val_tp: 1265.0000 - val_fp: 179.0000 - val_tn: 234840.0000 - val_fn: 1574.0000 - val_accuracy: 0.9926 - val_precision: 0.8760 - val_recall: 0.4456 - val_auc: 0.9501
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff33032bba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff370400978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff3704d9240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff370175358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff3701755f8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3701759b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff370175c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff370175f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff354575a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff354575978>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff3545759e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff3303a2160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff3900392b0>]
          

Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_3 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_9 (Dense)              (None, 200)               10200     
_________________________________________________________________
activation_9 (Activation)    (None, 200)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_10 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_11 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall improved from 0.24868 to 0.24023, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 106s - loss: 0.0426 - tp: 571.0000 - fp: 393.0000 - tn: 253399.0000 - fn: 2522.0000 - accuracy: 0.9887 - precision: 0.5923 - recall: 0.1846 - auc: 0.9008 - val_loss: 0.0316 - val_tp: 682.0000 - val_fp: 215.0000 - val_tn: 234804.0000 - val_fn: 2157.0000 - val_accuracy: 0.9900 - val_precision: 0.7603 - val_recall: 0.2402 - val_auc: 0.9527
256885/256885 - 106s - loss: 0.0426 - tp: 571.0000 - fp: 393.0000 - tn: 253399.0000 - fn: 2522.0000 - accuracy: 0.9887 - precision: 0.5923 - recall: 0.1846 - auc: 0.9008 - val_loss: 0.0316 - val_tp: 682.0000 - val_fp: 215.0000 - val_tn: 234804.0000 - val_fn: 2157.0000 - val_accuracy: 0.9900 - val_precision: 0.7603 - val_recall: 0.2402 - val_auc: 0.9527
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.24023
256885/256885 - 102s - loss: 0.0263 - tp: 1420.0000 - fp: 428.0000 - tn: 253364.0000 - fn: 1673.0000 - accuracy: 0.9918 - precision: 0.7684 - recall: 0.4591 - auc: 0.9655 - val_loss: 0.0238 - val_tp: 1465.0000 - val_fp: 286.0000 - val_tn: 234733.0000 - val_fn: 1374.0000 - val_accuracy: 0.9930 - val_precision: 0.8367 - val_recall: 0.5160 - val_auc: 0.9520
256885/256885 - 102s - loss: 0.0263 - tp: 1420.0000 - fp: 428.0000 - tn: 253364.0000 - fn: 1673.0000 - accuracy: 0.9918 - precision: 0.7684 - recall: 0.4591 - auc: 0.9655 - val_loss: 0.0238 - val_tp: 1465.0000 - val_fp: 286.0000 - val_tn: 234733.0000 - val_fn: 1374.0000 - val_accuracy: 0.9930 - val_precision: 0.8367 - val_recall: 0.5160 - val_auc: 0.9520
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3305c09e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f01e9a20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2f01f5cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2f01f5e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2f01de128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2f01de4e0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2f01de780>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2f01dea58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3545759e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3900392b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff390039240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff33032bbe0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff33032bc18>]
          

Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_4 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_12 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_12 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_13 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.24023
256885/256885 - 106s - loss: 0.0430 - tp: 616.0000 - fp: 458.0000 - tn: 253281.0000 - fn: 2530.0000 - accuracy: 0.9884 - precision: 0.5736 - recall: 0.1958 - auc: 0.9034 - val_loss: 0.0289 - val_tp: 1164.0000 - val_fp: 633.0000 - val_tn: 234386.0000 - val_fn: 1675.0000 - val_accuracy: 0.9903 - val_precision: 0.6477 - val_recall: 0.4100 - val_auc: 0.9675
256885/256885 - 106s - loss: 0.0430 - tp: 616.0000 - fp: 458.0000 - tn: 253281.0000 - fn: 2530.0000 - accuracy: 0.9884 - precision: 0.5736 - recall: 0.1958 - auc: 0.9034 - val_loss: 0.0289 - val_tp: 1164.0000 - val_fp: 633.0000 - val_tn: 234386.0000 - val_fn: 1675.0000 - val_accuracy: 0.9903 - val_precision: 0.6477 - val_recall: 0.4100 - val_auc: 0.9675
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.24023
256885/256885 - 103s - loss: 0.0262 - tp: 1483.0000 - fp: 453.0000 - tn: 253286.0000 - fn: 1663.0000 - accuracy: 0.9918 - precision: 0.7660 - recall: 0.4714 - auc: 0.9666 - val_loss: 0.0236 - val_tp: 1925.0000 - val_fp: 697.0000 - val_tn: 234322.0000 - val_fn: 914.0000 - val_accuracy: 0.9932 - val_precision: 0.7342 - val_recall: 0.6781 - val_auc: 0.9873
256885/256885 - 103s - loss: 0.0262 - tp: 1483.0000 - fp: 453.0000 - tn: 253286.0000 - fn: 1663.0000 - accuracy: 0.9918 - precision: 0.7660 - recall: 0.4714 - auc: 0.9666 - val_loss: 0.0236 - val_tp: 1925.0000 - val_fp: 697.0000 - val_tn: 234322.0000 - val_fn: 914.0000 - val_accuracy: 0.9932 - val_precision: 0.7342 - val_recall: 0.6781 - val_auc: 0.9873
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff35444f588>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2d8591320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2d85c7ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2d854e320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2d854e5c0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2d854e978>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2d854ec18>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2d854eef0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff33032bc50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff33032b748>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f0263160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f0276550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2f0402f60>]
          

Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_5 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_15 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_15 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_16 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_17 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall improved from 0.24023 to 0.14688, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 107s - loss: 0.0420 - tp: 639.0000 - fp: 362.0000 - tn: 253416.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6384 - recall: 0.2057 - auc: 0.9038 - val_loss: 0.0378 - val_tp: 417.0000 - val_fp: 72.0000 - val_tn: 234947.0000 - val_fn: 2422.0000 - val_accuracy: 0.9895 - val_precision: 0.8528 - val_recall: 0.1469 - val_auc: 0.9179
256885/256885 - 107s - loss: 0.0420 - tp: 639.0000 - fp: 362.0000 - tn: 253416.0000 - fn: 2468.0000 - accuracy: 0.9890 - precision: 0.6384 - recall: 0.2057 - auc: 0.9038 - val_loss: 0.0378 - val_tp: 417.0000 - val_fp: 72.0000 - val_tn: 234947.0000 - val_fn: 2422.0000 - val_accuracy: 0.9895 - val_precision: 0.8528 - val_recall: 0.1469 - val_auc: 0.9179
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 102s - loss: 0.0264 - tp: 1481.0000 - fp: 436.0000 - tn: 253342.0000 - fn: 1626.0000 - accuracy: 0.9920 - precision: 0.7726 - recall: 0.4767 - auc: 0.9645 - val_loss: 0.0207 - val_tp: 1562.0000 - val_fp: 285.0000 - val_tn: 234734.0000 - val_fn: 1277.0000 - val_accuracy: 0.9934 - val_precision: 0.8457 - val_recall: 0.5502 - val_auc: 0.9797
256885/256885 - 102s - loss: 0.0264 - tp: 1481.0000 - fp: 436.0000 - tn: 253342.0000 - fn: 1626.0000 - accuracy: 0.9920 - precision: 0.7726 - recall: 0.4767 - auc: 0.9645 - val_loss: 0.0207 - val_tp: 1562.0000 - val_fp: 285.0000 - val_tn: 234734.0000 - val_fn: 1277.0000 - val_accuracy: 0.9934 - val_precision: 0.8457 - val_recall: 0.5502 - val_auc: 0.9797
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2f042b9b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f042be80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2f04112b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2f0411240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2f04339e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2f0433668>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2f0173ba8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2f03dd0f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff33032bc50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d833e898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f042bc18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f042bf60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2f042bda0>]
          

Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_6 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_18 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_18 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_19 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0420 - tp: 588.0000 - fp: 383.0000 - tn: 253411.0000 - fn: 2503.0000 - accuracy: 0.9888 - precision: 0.6056 - recall: 0.1902 - auc: 0.9006 - val_loss: 0.0293 - val_tp: 1099.0000 - val_fp: 465.0000 - val_tn: 234554.0000 - val_fn: 1740.0000 - val_accuracy: 0.9907 - val_precision: 0.7027 - val_recall: 0.3871 - val_auc: 0.9730
256885/256885 - 106s - loss: 0.0420 - tp: 588.0000 - fp: 383.0000 - tn: 253411.0000 - fn: 2503.0000 - accuracy: 0.9888 - precision: 0.6056 - recall: 0.1902 - auc: 0.9006 - val_loss: 0.0293 - val_tp: 1099.0000 - val_fp: 465.0000 - val_tn: 234554.0000 - val_fn: 1740.0000 - val_accuracy: 0.9907 - val_precision: 0.7027 - val_recall: 0.3871 - val_auc: 0.9730
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 103s - loss: 0.0262 - tp: 1484.0000 - fp: 437.0000 - tn: 253357.0000 - fn: 1607.0000 - accuracy: 0.9920 - precision: 0.7725 - recall: 0.4801 - auc: 0.9639 - val_loss: 0.0221 - val_tp: 1768.0000 - val_fp: 550.0000 - val_tn: 234469.0000 - val_fn: 1071.0000 - val_accuracy: 0.9932 - val_precision: 0.7627 - val_recall: 0.6228 - val_auc: 0.9862
256885/256885 - 103s - loss: 0.0262 - tp: 1484.0000 - fp: 437.0000 - tn: 253357.0000 - fn: 1607.0000 - accuracy: 0.9920 - precision: 0.7725 - recall: 0.4801 - auc: 0.9639 - val_loss: 0.0221 - val_tp: 1768.0000 - val_fp: 550.0000 - val_tn: 234469.0000 - val_fn: 1071.0000 - val_accuracy: 0.9932 - val_precision: 0.7627 - val_recall: 0.6228 - val_auc: 0.9862
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3106cf8d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3106038d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2f0545fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2f056f828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2f056fac8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2f056fe80>, <tensorflow.python.keras.metrics.Recall object at 0x7ff310547160>, <tensorflow.python.keras.metrics.AUC object at 0x7ff310547438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2f042bc18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2f042bef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f042bb70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f042bac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2f042b898>]
          

Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_7 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_21 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_21 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_22 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_23 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0424 - tp: 597.0000 - fp: 421.0000 - tn: 253353.0000 - fn: 2514.0000 - accuracy: 0.9886 - precision: 0.5864 - recall: 0.1919 - auc: 0.9018 - val_loss: 0.0292 - val_tp: 1235.0000 - val_fp: 652.0000 - val_tn: 234367.0000 - val_fn: 1604.0000 - val_accuracy: 0.9905 - val_precision: 0.6545 - val_recall: 0.4350 - val_auc: 0.9748
256885/256885 - 106s - loss: 0.0424 - tp: 597.0000 - fp: 421.0000 - tn: 253353.0000 - fn: 2514.0000 - accuracy: 0.9886 - precision: 0.5864 - recall: 0.1919 - auc: 0.9018 - val_loss: 0.0292 - val_tp: 1235.0000 - val_fp: 652.0000 - val_tn: 234367.0000 - val_fn: 1604.0000 - val_accuracy: 0.9905 - val_precision: 0.6545 - val_recall: 0.4350 - val_auc: 0.9748
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 102s - loss: 0.0254 - tp: 1515.0000 - fp: 457.0000 - tn: 253317.0000 - fn: 1596.0000 - accuracy: 0.9920 - precision: 0.7683 - recall: 0.4870 - auc: 0.9663 - val_loss: 0.0204 - val_tp: 1782.0000 - val_fp: 488.0000 - val_tn: 234531.0000 - val_fn: 1057.0000 - val_accuracy: 0.9935 - val_precision: 0.7850 - val_recall: 0.6277 - val_auc: 0.9836
256885/256885 - 102s - loss: 0.0254 - tp: 1515.0000 - fp: 457.0000 - tn: 253317.0000 - fn: 1596.0000 - accuracy: 0.9920 - precision: 0.7683 - recall: 0.4870 - auc: 0.9663 - val_loss: 0.0204 - val_tp: 1782.0000 - val_fp: 488.0000 - val_tn: 234531.0000 - val_fn: 1057.0000 - val_accuracy: 0.9935 - val_precision: 0.7850 - val_recall: 0.6277 - val_auc: 0.9836
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3703b8ba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3703b8518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff3703bdd30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2f05f8e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff35444a128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2f0487cc0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3300cb1d0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff3300cb6a0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2f042bc18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2f042bac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f042b710>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f042bda0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7586d30>]
          

Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_8 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_24 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_24 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_25 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_26 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 106s - loss: 0.0422 - tp: 557.0000 - fp: 371.0000 - tn: 253407.0000 - fn: 2551.0000 - accuracy: 0.9886 - precision: 0.6002 - recall: 0.1792 - auc: 0.9041 - val_loss: 0.0301 - val_tp: 887.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1952.0000 - val_accuracy: 0.9905 - val_precision: 0.7361 - val_recall: 0.3124 - val_auc: 0.9582
256886/256886 - 106s - loss: 0.0422 - tp: 557.0000 - fp: 371.0000 - tn: 253407.0000 - fn: 2551.0000 - accuracy: 0.9886 - precision: 0.6002 - recall: 0.1792 - auc: 0.9041 - val_loss: 0.0301 - val_tp: 887.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1952.0000 - val_accuracy: 0.9905 - val_precision: 0.7361 - val_recall: 0.3124 - val_auc: 0.9582
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 103s - loss: 0.0267 - tp: 1429.0000 - fp: 447.0000 - tn: 253331.0000 - fn: 1679.0000 - accuracy: 0.9917 - precision: 0.7617 - recall: 0.4598 - auc: 0.9665 - val_loss: 0.0232 - val_tp: 1857.0000 - val_fp: 776.0000 - val_tn: 234243.0000 - val_fn: 982.0000 - val_accuracy: 0.9926 - val_precision: 0.7053 - val_recall: 0.6541 - val_auc: 0.9848
256886/256886 - 103s - loss: 0.0267 - tp: 1429.0000 - fp: 447.0000 - tn: 253331.0000 - fn: 1679.0000 - accuracy: 0.9917 - precision: 0.7617 - recall: 0.4598 - auc: 0.9665 - val_loss: 0.0232 - val_tp: 1857.0000 - val_fp: 776.0000 - val_tn: 234243.0000 - val_fn: 982.0000 - val_accuracy: 0.9926 - val_precision: 0.7053 - val_recall: 0.6541 - val_auc: 0.9848
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3300d27f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff3300cbd30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff370140f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff3701409b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff370140588>, <tensorflow.python.keras.metrics.Precision object at 0x7ff310413ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff310413208>, <tensorflow.python.keras.metrics.AUC object at 0x7ff310413e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d856d710>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d856d048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2d856d5f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2d855b748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff3102ceb38>]
          

Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_27 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_27 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_28 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 200)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_29 (Activation)   (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 106s - loss: 0.0432 - tp: 580.0000 - fp: 427.0000 - tn: 253335.0000 - fn: 2544.0000 - accuracy: 0.9884 - precision: 0.5760 - recall: 0.1857 - auc: 0.8960 - val_loss: 0.0328 - val_tp: 639.0000 - val_fp: 192.0000 - val_tn: 234827.0000 - val_fn: 2200.0000 - val_accuracy: 0.9899 - val_precision: 0.7690 - val_recall: 0.2251 - val_auc: 0.9384
256886/256886 - 106s - loss: 0.0432 - tp: 580.0000 - fp: 427.0000 - tn: 253335.0000 - fn: 2544.0000 - accuracy: 0.9884 - precision: 0.5760 - recall: 0.1857 - auc: 0.8960 - val_loss: 0.0328 - val_tp: 639.0000 - val_fp: 192.0000 - val_tn: 234827.0000 - val_fn: 2200.0000 - val_accuracy: 0.9899 - val_precision: 0.7690 - val_recall: 0.2251 - val_auc: 0.9384
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 103s - loss: 0.0253 - tp: 1496.0000 - fp: 446.0000 - tn: 253316.0000 - fn: 1628.0000 - accuracy: 0.9919 - precision: 0.7703 - recall: 0.4789 - auc: 0.9679 - val_loss: 0.0284 - val_tp: 1219.0000 - val_fp: 164.0000 - val_tn: 234855.0000 - val_fn: 1620.0000 - val_accuracy: 0.9925 - val_precision: 0.8814 - val_recall: 0.4294 - val_auc: 0.9212
256886/256886 - 103s - loss: 0.0253 - tp: 1496.0000 - fp: 446.0000 - tn: 253316.0000 - fn: 1628.0000 - accuracy: 0.9919 - precision: 0.7703 - recall: 0.4789 - auc: 0.9679 - val_loss: 0.0284 - val_tp: 1219.0000 - val_fp: 164.0000 - val_tn: 234855.0000 - val_fn: 1620.0000 - val_accuracy: 0.9925 - val_precision: 0.8814 - val_recall: 0.4294 - val_auc: 0.9212
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b639ac18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5183be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b63b5c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b633e3c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b633e668>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b633ea20>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b633ecc0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b633ef98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3300e0fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff35458dd68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff3300d2588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b518e3c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d856d048>]
          

Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_10 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_30 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_30 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_31 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_32 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0435 - tp: 602.0000 - fp: 462.0000 - tn: 253297.0000 - fn: 2524.0000 - accuracy: 0.9884 - precision: 0.5658 - recall: 0.1926 - auc: 0.8959 - val_loss: 0.0282 - val_tp: 1074.0000 - val_fp: 442.0000 - val_tn: 234577.0000 - val_fn: 1765.0000 - val_accuracy: 0.9907 - val_precision: 0.7084 - val_recall: 0.3783 - val_auc: 0.9724
256885/256885 - 132s - loss: 0.0435 - tp: 602.0000 - fp: 462.0000 - tn: 253297.0000 - fn: 2524.0000 - accuracy: 0.9884 - precision: 0.5658 - recall: 0.1926 - auc: 0.8959 - val_loss: 0.0282 - val_tp: 1074.0000 - val_fp: 442.0000 - val_tn: 234577.0000 - val_fn: 1765.0000 - val_accuracy: 0.9907 - val_precision: 0.7084 - val_recall: 0.3783 - val_auc: 0.9724
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 129s - loss: 0.0258 - tp: 1519.0000 - fp: 480.0000 - tn: 253279.0000 - fn: 1607.0000 - accuracy: 0.9919 - precision: 0.7599 - recall: 0.4859 - auc: 0.9668 - val_loss: 0.0203 - val_tp: 1709.0000 - val_fp: 445.0000 - val_tn: 234574.0000 - val_fn: 1130.0000 - val_accuracy: 0.9934 - val_precision: 0.7934 - val_recall: 0.6020 - val_auc: 0.9830
256885/256885 - 129s - loss: 0.0258 - tp: 1519.0000 - fp: 480.0000 - tn: 253279.0000 - fn: 1607.0000 - accuracy: 0.9919 - precision: 0.7599 - recall: 0.4859 - auc: 0.9668 - val_loss: 0.0203 - val_tp: 1709.0000 - val_fp: 445.0000 - val_tn: 234574.0000 - val_fn: 1130.0000 - val_accuracy: 0.9934 - val_precision: 0.7934 - val_recall: 0.6020 - val_auc: 0.9830
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff370408ba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f028b630>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2d859aba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2f01c2588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2f01c21d0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2f01c2080>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2f01cb710>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2f01cbf28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d856d5f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b639acc0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b639ac88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f02e18d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2f02e14a8>]
          

Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_11 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_33 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_33 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_34 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_35 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0423 - tp: 619.0000 - fp: 384.0000 - tn: 253374.0000 - fn: 2508.0000 - accuracy: 0.9887 - precision: 0.6171 - recall: 0.1980 - auc: 0.8995 - val_loss: 0.0281 - val_tp: 1030.0000 - val_fp: 406.0000 - val_tn: 234613.0000 - val_fn: 1809.0000 - val_accuracy: 0.9907 - val_precision: 0.7173 - val_recall: 0.3628 - val_auc: 0.9730
256885/256885 - 131s - loss: 0.0423 - tp: 619.0000 - fp: 384.0000 - tn: 253374.0000 - fn: 2508.0000 - accuracy: 0.9887 - precision: 0.6171 - recall: 0.1980 - auc: 0.8995 - val_loss: 0.0281 - val_tp: 1030.0000 - val_fp: 406.0000 - val_tn: 234613.0000 - val_fn: 1809.0000 - val_accuracy: 0.9907 - val_precision: 0.7173 - val_recall: 0.3628 - val_auc: 0.9730
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0252 - tp: 1550.0000 - fp: 460.0000 - tn: 253298.0000 - fn: 1577.0000 - accuracy: 0.9921 - precision: 0.7711 - recall: 0.4957 - auc: 0.9677 - val_loss: 0.0201 - val_tp: 1707.0000 - val_fp: 440.0000 - val_tn: 234579.0000 - val_fn: 1132.0000 - val_accuracy: 0.9934 - val_precision: 0.7951 - val_recall: 0.6013 - val_auc: 0.9851
256885/256885 - 128s - loss: 0.0252 - tp: 1550.0000 - fp: 460.0000 - tn: 253298.0000 - fn: 1577.0000 - accuracy: 0.9921 - precision: 0.7711 - recall: 0.4957 - auc: 0.9677 - val_loss: 0.0201 - val_tp: 1707.0000 - val_fp: 440.0000 - val_tn: 234579.0000 - val_fn: 1132.0000 - val_accuracy: 0.9934 - val_precision: 0.7951 - val_recall: 0.6013 - val_auc: 0.9851
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2d82da080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2d82d4ef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2d8307080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2d8307ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2d8307d68>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2d8307f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2d8135400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2d81356d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2f0156b38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2f02e1080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f02e1748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f02c7518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d856d5f8>]
          

Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_36 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_36 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_37 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_38 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0433 - tp: 521.0000 - fp: 367.0000 - tn: 253402.0000 - fn: 2595.0000 - accuracy: 0.9885 - precision: 0.5867 - recall: 0.1672 - auc: 0.8990 - val_loss: 0.0305 - val_tp: 671.0000 - val_fp: 193.0000 - val_tn: 234826.0000 - val_fn: 2168.0000 - val_accuracy: 0.9901 - val_precision: 0.7766 - val_recall: 0.2364 - val_auc: 0.9604
256885/256885 - 132s - loss: 0.0433 - tp: 521.0000 - fp: 367.0000 - tn: 253402.0000 - fn: 2595.0000 - accuracy: 0.9885 - precision: 0.5867 - recall: 0.1672 - auc: 0.8990 - val_loss: 0.0305 - val_tp: 671.0000 - val_fp: 193.0000 - val_tn: 234826.0000 - val_fn: 2168.0000 - val_accuracy: 0.9901 - val_precision: 0.7766 - val_recall: 0.2364 - val_auc: 0.9604
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0266 - tp: 1440.0000 - fp: 472.0000 - tn: 253297.0000 - fn: 1676.0000 - accuracy: 0.9916 - precision: 0.7531 - recall: 0.4621 - auc: 0.9653 - val_loss: 0.0227 - val_tp: 1467.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1372.0000 - val_accuracy: 0.9929 - val_precision: 0.8255 - val_recall: 0.5167 - val_auc: 0.9616
256885/256885 - 127s - loss: 0.0266 - tp: 1440.0000 - fp: 472.0000 - tn: 253297.0000 - fn: 1676.0000 - accuracy: 0.9916 - precision: 0.7531 - recall: 0.4621 - auc: 0.9653 - val_loss: 0.0227 - val_tp: 1467.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1372.0000 - val_accuracy: 0.9929 - val_precision: 0.8255 - val_recall: 0.5167 - val_auc: 0.9616
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff354588eb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff330597470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff31063c5c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff31071be80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff31071ba58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff31071bc50>, <tensorflow.python.keras.metrics.Recall object at 0x7ff31071b240>, <tensorflow.python.keras.metrics.AUC object at 0x7ff31071b908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2f02e1080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d856d5f8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2d856d710>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2d82f9438>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d82f9358>]
          

Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_39 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_39 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_40 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_41 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0427 - tp: 575.0000 - fp: 392.0000 - tn: 253400.0000 - fn: 2518.0000 - accuracy: 0.9887 - precision: 0.5946 - recall: 0.1859 - auc: 0.8993 - val_loss: 0.0332 - val_tp: 793.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 2046.0000 - val_accuracy: 0.9903 - val_precision: 0.7509 - val_recall: 0.2793 - val_auc: 0.9316
256885/256885 - 131s - loss: 0.0427 - tp: 575.0000 - fp: 392.0000 - tn: 253400.0000 - fn: 2518.0000 - accuracy: 0.9887 - precision: 0.5946 - recall: 0.1859 - auc: 0.8993 - val_loss: 0.0332 - val_tp: 793.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 2046.0000 - val_accuracy: 0.9903 - val_precision: 0.7509 - val_recall: 0.2793 - val_auc: 0.9316
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0263 - tp: 1428.0000 - fp: 485.0000 - tn: 253307.0000 - fn: 1665.0000 - accuracy: 0.9916 - precision: 0.7465 - recall: 0.4617 - auc: 0.9655 - val_loss: 0.0225 - val_tp: 1471.0000 - val_fp: 288.0000 - val_tn: 234731.0000 - val_fn: 1368.0000 - val_accuracy: 0.9930 - val_precision: 0.8363 - val_recall: 0.5181 - val_auc: 0.9619
256885/256885 - 127s - loss: 0.0263 - tp: 1428.0000 - fp: 485.0000 - tn: 253307.0000 - fn: 1665.0000 - accuracy: 0.9916 - precision: 0.7465 - recall: 0.4617 - auc: 0.9655 - val_loss: 0.0225 - val_tp: 1471.0000 - val_fp: 288.0000 - val_tn: 234731.0000 - val_fn: 1368.0000 - val_accuracy: 0.9930 - val_precision: 0.8363 - val_recall: 0.5181 - val_auc: 0.9619
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b79c97b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b7a24fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b79e4470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b79e4f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b79f0208>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b79f05c0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b79f0860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b79f0b38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d82f9438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff370408f60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff354588550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff354588e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7a2f3c8>]
          

Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_14 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_42 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_42 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_43 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_44 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0423 - tp: 629.0000 - fp: 397.0000 - tn: 253342.0000 - fn: 2517.0000 - accuracy: 0.9887 - precision: 0.6131 - recall: 0.1999 - auc: 0.9046 - val_loss: 0.0534 - val_tp: 1875.0000 - val_fp: 2318.0000 - val_tn: 232701.0000 - val_fn: 964.0000 - val_accuracy: 0.9862 - val_precision: 0.4472 - val_recall: 0.6604 - val_auc: 0.9775
256885/256885 - 132s - loss: 0.0423 - tp: 629.0000 - fp: 397.0000 - tn: 253342.0000 - fn: 2517.0000 - accuracy: 0.9887 - precision: 0.6131 - recall: 0.1999 - auc: 0.9046 - val_loss: 0.0534 - val_tp: 1875.0000 - val_fp: 2318.0000 - val_tn: 232701.0000 - val_fn: 964.0000 - val_accuracy: 0.9862 - val_precision: 0.4472 - val_recall: 0.6604 - val_auc: 0.9775
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0262 - tp: 1494.0000 - fp: 449.0000 - tn: 253290.0000 - fn: 1652.0000 - accuracy: 0.9918 - precision: 0.7689 - recall: 0.4749 - auc: 0.9680 - val_loss: 0.0215 - val_tp: 1496.0000 - val_fp: 265.0000 - val_tn: 234754.0000 - val_fn: 1343.0000 - val_accuracy: 0.9932 - val_precision: 0.8495 - val_recall: 0.5269 - val_auc: 0.9676
256885/256885 - 128s - loss: 0.0262 - tp: 1494.0000 - fp: 449.0000 - tn: 253290.0000 - fn: 1652.0000 - accuracy: 0.9918 - precision: 0.7689 - recall: 0.4749 - auc: 0.9680 - val_loss: 0.0215 - val_tp: 1496.0000 - val_fp: 265.0000 - val_tn: 234754.0000 - val_fn: 1343.0000 - val_accuracy: 0.9932 - val_precision: 0.8495 - val_recall: 0.5269 - val_auc: 0.9676
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0216 - tp: 1901.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1245.0000 - accuracy: 0.9935 - precision: 0.8212 - recall: 0.6043 - auc: 0.9704 - val_loss: 0.0197 - val_tp: 1649.0000 - val_fp: 248.0000 - val_tn: 234771.0000 - val_fn: 1190.0000 - val_accuracy: 0.9940 - val_precision: 0.8693 - val_recall: 0.5808 - val_auc: 0.9671
256885/256885 - 128s - loss: 0.0216 - tp: 1901.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1245.0000 - accuracy: 0.9935 - precision: 0.8212 - recall: 0.6043 - auc: 0.9704 - val_loss: 0.0197 - val_tp: 1649.0000 - val_fp: 248.0000 - val_tn: 234771.0000 - val_fn: 1190.0000 - val_accuracy: 0.9940 - val_precision: 0.8693 - val_recall: 0.5808 - val_auc: 0.9671
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff35446c2e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b7a0da20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff35444a630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff35444ad30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff35444af98>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3703b89b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3c84b01d0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff35445e588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff354588550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3106039e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff354013320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff3540132e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff3106235f8>]
          

Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_15 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_45 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_45 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_46 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_47 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0431 - tp: 582.0000 - fp: 410.0000 - tn: 253368.0000 - fn: 2525.0000 - accuracy: 0.9886 - precision: 0.5867 - recall: 0.1873 - auc: 0.8931 - val_loss: 0.0289 - val_tp: 1219.0000 - val_fp: 687.0000 - val_tn: 234332.0000 - val_fn: 1620.0000 - val_accuracy: 0.9903 - val_precision: 0.6396 - val_recall: 0.4294 - val_auc: 0.9712
256885/256885 - 131s - loss: 0.0431 - tp: 582.0000 - fp: 410.0000 - tn: 253368.0000 - fn: 2525.0000 - accuracy: 0.9886 - precision: 0.5867 - recall: 0.1873 - auc: 0.8931 - val_loss: 0.0289 - val_tp: 1219.0000 - val_fp: 687.0000 - val_tn: 234332.0000 - val_fn: 1620.0000 - val_accuracy: 0.9903 - val_precision: 0.6396 - val_recall: 0.4294 - val_auc: 0.9712
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0265 - tp: 1467.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1640.0000 - accuracy: 0.9919 - precision: 0.7701 - recall: 0.4722 - auc: 0.9640 - val_loss: 0.0229 - val_tp: 1906.0000 - val_fp: 754.0000 - val_tn: 234265.0000 - val_fn: 933.0000 - val_accuracy: 0.9929 - val_precision: 0.7165 - val_recall: 0.6714 - val_auc: 0.9867
256885/256885 - 128s - loss: 0.0265 - tp: 1467.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1640.0000 - accuracy: 0.9919 - precision: 0.7701 - recall: 0.4722 - auc: 0.9640 - val_loss: 0.0229 - val_tp: 1906.0000 - val_fp: 754.0000 - val_tn: 234265.0000 - val_fn: 933.0000 - val_accuracy: 0.9929 - val_precision: 0.7165 - val_recall: 0.6714 - val_auc: 0.9867
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b7f52ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b7f52be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b7cfc0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b769b860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5b2e128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3102bb6d8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b7cdaa90>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b7cda518>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff354013eb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3103d17b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5b33208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7f4c470>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7f4cdd8>]
          

Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_16 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_48 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_48 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_49 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_50 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0421 - tp: 576.0000 - fp: 397.0000 - tn: 253397.0000 - fn: 2515.0000 - accuracy: 0.9887 - precision: 0.5920 - recall: 0.1863 - auc: 0.9041 - val_loss: 0.0298 - val_tp: 669.0000 - val_fp: 200.0000 - val_tn: 234819.0000 - val_fn: 2170.0000 - val_accuracy: 0.9900 - val_precision: 0.7699 - val_recall: 0.2356 - val_auc: 0.9621
256885/256885 - 132s - loss: 0.0421 - tp: 576.0000 - fp: 397.0000 - tn: 253397.0000 - fn: 2515.0000 - accuracy: 0.9887 - precision: 0.5920 - recall: 0.1863 - auc: 0.9041 - val_loss: 0.0298 - val_tp: 669.0000 - val_fp: 200.0000 - val_tn: 234819.0000 - val_fn: 2170.0000 - val_accuracy: 0.9900 - val_precision: 0.7699 - val_recall: 0.2356 - val_auc: 0.9621
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0259 - tp: 1486.0000 - fp: 425.0000 - tn: 253369.0000 - fn: 1605.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4808 - auc: 0.9663 - val_loss: 0.0261 - val_tp: 1251.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 1588.0000 - val_accuracy: 0.9925 - val_precision: 0.8706 - val_recall: 0.4406 - val_auc: 0.9387
256885/256885 - 128s - loss: 0.0259 - tp: 1486.0000 - fp: 425.0000 - tn: 253369.0000 - fn: 1605.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4808 - auc: 0.9663 - val_loss: 0.0261 - val_tp: 1251.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 1588.0000 - val_accuracy: 0.9925 - val_precision: 0.8706 - val_recall: 0.4406 - val_auc: 0.9387
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2d8338630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2d8338978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b77be2e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff3100ed7f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff3100ed160>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3100edb38>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3100ede48>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b52f4860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b60d6e80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d832b470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2d832b390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2d832b400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d832b358>]
          

Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_17 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_51 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_51 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_52 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_53 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0426 - tp: 540.0000 - fp: 403.0000 - tn: 253371.0000 - fn: 2571.0000 - accuracy: 0.9884 - precision: 0.5726 - recall: 0.1736 - auc: 0.9005 - val_loss: 0.0302 - val_tp: 726.0000 - val_fp: 216.0000 - val_tn: 234803.0000 - val_fn: 2113.0000 - val_accuracy: 0.9902 - val_precision: 0.7707 - val_recall: 0.2557 - val_auc: 0.9614
256885/256885 - 131s - loss: 0.0426 - tp: 540.0000 - fp: 403.0000 - tn: 253371.0000 - fn: 2571.0000 - accuracy: 0.9884 - precision: 0.5726 - recall: 0.1736 - auc: 0.9005 - val_loss: 0.0302 - val_tp: 726.0000 - val_fp: 216.0000 - val_tn: 234803.0000 - val_fn: 2113.0000 - val_accuracy: 0.9902 - val_precision: 0.7707 - val_recall: 0.2557 - val_auc: 0.9614
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 129s - loss: 0.0268 - tp: 1437.0000 - fp: 466.0000 - tn: 253308.0000 - fn: 1674.0000 - accuracy: 0.9917 - precision: 0.7551 - recall: 0.4619 - auc: 0.9644 - val_loss: 0.0232 - val_tp: 1914.0000 - val_fp: 836.0000 - val_tn: 234183.0000 - val_fn: 925.0000 - val_accuracy: 0.9926 - val_precision: 0.6960 - val_recall: 0.6742 - val_auc: 0.9851
256885/256885 - 129s - loss: 0.0268 - tp: 1437.0000 - fp: 466.0000 - tn: 253308.0000 - fn: 1674.0000 - accuracy: 0.9917 - precision: 0.7551 - recall: 0.4619 - auc: 0.9644 - val_loss: 0.0232 - val_tp: 1914.0000 - val_fp: 836.0000 - val_tn: 234183.0000 - val_fn: 925.0000 - val_accuracy: 0.9926 - val_precision: 0.6960 - val_recall: 0.6742 - val_auc: 0.9851
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff310769940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b6aece10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6aec6a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b6aec7b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b6aec390>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b6aecc50>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3102bb588>, <tensorflow.python.keras.metrics.AUC object at 0x7ff3107c2ac8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d832b390>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6702f60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6a4ae48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6a45eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6a817b8>]
          

Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_18 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_54 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_54 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_55 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_56 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 132s - loss: 0.0417 - tp: 612.0000 - fp: 375.0000 - tn: 253403.0000 - fn: 2496.0000 - accuracy: 0.9888 - precision: 0.6201 - recall: 0.1969 - auc: 0.9048 - val_loss: 0.0381 - val_tp: 1688.0000 - val_fp: 1798.0000 - val_tn: 233221.0000 - val_fn: 1151.0000 - val_accuracy: 0.9876 - val_precision: 0.4842 - val_recall: 0.5946 - val_auc: 0.9783
256886/256886 - 132s - loss: 0.0417 - tp: 612.0000 - fp: 375.0000 - tn: 253403.0000 - fn: 2496.0000 - accuracy: 0.9888 - precision: 0.6201 - recall: 0.1969 - auc: 0.9048 - val_loss: 0.0381 - val_tp: 1688.0000 - val_fp: 1798.0000 - val_tn: 233221.0000 - val_fn: 1151.0000 - val_accuracy: 0.9876 - val_precision: 0.4842 - val_recall: 0.5946 - val_auc: 0.9783
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 129s - loss: 0.0259 - tp: 1484.0000 - fp: 450.0000 - tn: 253328.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7673 - recall: 0.4775 - auc: 0.9648 - val_loss: 0.0205 - val_tp: 1654.0000 - val_fp: 390.0000 - val_tn: 234629.0000 - val_fn: 1185.0000 - val_accuracy: 0.9934 - val_precision: 0.8092 - val_recall: 0.5826 - val_auc: 0.9761
256886/256886 - 129s - loss: 0.0259 - tp: 1484.0000 - fp: 450.0000 - tn: 253328.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7673 - recall: 0.4775 - auc: 0.9648 - val_loss: 0.0205 - val_tp: 1654.0000 - val_fp: 390.0000 - val_tn: 234629.0000 - val_fn: 1185.0000 - val_accuracy: 0.9934 - val_precision: 0.8092 - val_recall: 0.5826 - val_auc: 0.9761
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.14688
256886/256886 - 128s - loss: 0.0216 - tp: 1876.0000 - fp: 424.0000 - tn: 253354.0000 - fn: 1232.0000 - accuracy: 0.9936 - precision: 0.8157 - recall: 0.6036 - auc: 0.9683 - val_loss: 0.0210 - val_tp: 1577.0000 - val_fp: 212.0000 - val_tn: 234807.0000 - val_fn: 1262.0000 - val_accuracy: 0.9938 - val_precision: 0.8815 - val_recall: 0.5555 - val_auc: 0.9602
256886/256886 - 128s - loss: 0.0216 - tp: 1876.0000 - fp: 424.0000 - tn: 253354.0000 - fn: 1232.0000 - accuracy: 0.9936 - precision: 0.8157 - recall: 0.6036 - auc: 0.9683 - val_loss: 0.0210 - val_tp: 1577.0000 - val_fp: 212.0000 - val_tn: 234807.0000 - val_fn: 1262.0000 - val_accuracy: 0.9938 - val_precision: 0.8815 - val_recall: 0.5555 - val_auc: 0.9602
Epoch 4/50
Epoch 4/50

Epoch 00004: val_recall did not improve from 0.14688
256886/256886 - 127s - loss: 0.0204 - tp: 1955.0000 - fp: 385.0000 - tn: 253393.0000 - fn: 1153.0000 - accuracy: 0.9940 - precision: 0.8355 - recall: 0.6290 - auc: 0.9701 - val_loss: 0.0202 - val_tp: 1680.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 1159.0000 - val_accuracy: 0.9940 - val_precision: 0.8660 - val_recall: 0.5918 - val_auc: 0.9584
256886/256886 - 127s - loss: 0.0204 - tp: 1955.0000 - fp: 385.0000 - tn: 253393.0000 - fn: 1153.0000 - accuracy: 0.9940 - precision: 0.8355 - recall: 0.6290 - auc: 0.9701 - val_loss: 0.0202 - val_tp: 1680.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 1159.0000 - val_accuracy: 0.9940 - val_precision: 0.8660 - val_recall: 0.5918 - val_auc: 0.9584
Epoch 00004: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 8.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff310517940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f03ee390>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2f03ee908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff3101eac18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff3101ea860>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3101ea940>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b74a09b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b74a0e10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6a45d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6a81a90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff310769fd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff310769048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d8029898>]
          

Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_19 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_57 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_57 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_58 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_59 (Activation)   (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 131s - loss: 0.0428 - tp: 564.0000 - fp: 382.0000 - tn: 253380.0000 - fn: 2560.0000 - accuracy: 0.9885 - precision: 0.5962 - recall: 0.1805 - auc: 0.9032 - val_loss: 0.0305 - val_tp: 1177.0000 - val_fp: 716.0000 - val_tn: 234303.0000 - val_fn: 1662.0000 - val_accuracy: 0.9900 - val_precision: 0.6218 - val_recall: 0.4146 - val_auc: 0.9752
256886/256886 - 131s - loss: 0.0428 - tp: 564.0000 - fp: 382.0000 - tn: 253380.0000 - fn: 2560.0000 - accuracy: 0.9885 - precision: 0.5962 - recall: 0.1805 - auc: 0.9032 - val_loss: 0.0305 - val_tp: 1177.0000 - val_fp: 716.0000 - val_tn: 234303.0000 - val_fn: 1662.0000 - val_accuracy: 0.9900 - val_precision: 0.6218 - val_recall: 0.4146 - val_auc: 0.9752
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 129s - loss: 0.0271 - tp: 1425.0000 - fp: 468.0000 - tn: 253294.0000 - fn: 1699.0000 - accuracy: 0.9916 - precision: 0.7528 - recall: 0.4561 - auc: 0.9618 - val_loss: 0.0214 - val_tp: 1621.0000 - val_fp: 394.0000 - val_tn: 234625.0000 - val_fn: 1218.0000 - val_accuracy: 0.9932 - val_precision: 0.8045 - val_recall: 0.5710 - val_auc: 0.9804
256886/256886 - 129s - loss: 0.0271 - tp: 1425.0000 - fp: 468.0000 - tn: 253294.0000 - fn: 1699.0000 - accuracy: 0.9916 - precision: 0.7528 - recall: 0.4561 - auc: 0.9618 - val_loss: 0.0214 - val_tp: 1621.0000 - val_fp: 394.0000 - val_tn: 234625.0000 - val_fn: 1218.0000 - val_accuracy: 0.9932 - val_precision: 0.8045 - val_recall: 0.5710 - val_auc: 0.9804
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5f43400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5f8f4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5f8fd68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5f8f6d8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5fbb4e0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5fbbb00>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5fbb6d8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5fbb198>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3107690f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff3107694a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f03dd6a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b77c3e10>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6a81a90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b77c3e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b46c5be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5d82748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5fa6048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff310662550>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5e05dd8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5fbb320>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5fbb358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5f5c400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6834c18>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5f43400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff310652e80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff310652cc0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b66e9ba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b66e9eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b66df198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b66df438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b66df6d8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b66dfa90>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b66dfd30>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b66dffd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3107694a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5f8fd68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5f8f080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b66e9c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b66e9c18>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b66419b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b6641cc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6641f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b66ce240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b66ce4e0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b66ce898>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b66ceb38>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b66cee10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b66e99e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b66f6ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b66f6c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6641a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6641a20>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b661d320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b661d5c0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b661d860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b661db00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b661dda0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b661dfd0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b6653438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b6653710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6641710>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b66c79b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b66c7be0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b66c7b00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b661d080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b65a3eb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b657e208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b657e4a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b657e748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b657e9e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b657eda0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b657ef98>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b65b1358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b661d2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b66419e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6641908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b65a3f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b65a3f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b6641b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b65b1358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b65b1320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b65b1048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b65b11d0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b650b6a0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b650b9e8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b650bcf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b65a3cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b661d208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b65a3eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b65a3dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b65a3cc0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b65b0208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b65b04a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b65b0748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b65b09e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b65b0c88>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b65b0f60>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b651d320>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b651d5f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6641be0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b64cffd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b64cff60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b64cff28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6582940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b64a2eb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b64a72b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b64a7550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b64a77f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b64a7a90>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b64a7e48>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b64e2128>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b64e2400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b65b0198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6511198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6511278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b64a2fd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b64a2ef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b64e2860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b64e2358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b64e2198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b64ef1d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5a867f0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5a86a58>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5a86d30>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5a86fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b64a2e80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b65b00f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6511198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b64a2eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b64a2940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5a4f4a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5a4f7b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5a4fa58>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5a4fcf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5a4ff98>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5a94390>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5a94630>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5a94908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b64e28d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b64e1ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b64e1c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5a4f550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5a4f518>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5a29320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5a295c0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5a29860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5a29b00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5a29da0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5a29fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5a2d438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5a2d710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5a4f2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5aa54a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5aa56d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5aa55f8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5a29080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5a2d860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5a2d550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5a2d080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5a2d0b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5a29b00>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5a298d0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5a29668>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5a29c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5a292b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5a4f1d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5aa54a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5aa55f8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5a2dac8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b59c87b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b59c8ac8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b59c8d68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b59c8f98>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b59592e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b59596a0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5959940>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5959c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5a2d908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5a350f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5a35048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b59c8860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b59c8828>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b592c5c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b592c8d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b592cb70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b592ce10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b59310f0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b59314a8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5931748>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5931a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b59c85f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b599f7b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b599f898>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b592c668>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b592c630>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b587de80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b593a1d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b593a470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b593a710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b593a9b0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b593ad68>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b593afd0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b58b2320>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b592c320>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b595e5c0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b595e6a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b587df28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b587def0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5850ac8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5850dd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b58570b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5857358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b58575f8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b58579b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5857c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5857f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b587dcc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b59316a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5931550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5850b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5850b38>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b58509e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5850c50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5931940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5896208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5896128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b58352b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b58355f8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5835908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5850908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b587d860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b599f898>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b595e908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5850fd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b57fad68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b58580b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5858358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b58585f8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5858898>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5858c50>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5858ef0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b57ce208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5850b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b585e4a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b585e588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b57fae10>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b57fadd8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b574bb70>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b574be80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5753160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5753400>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b57536a0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5753a58>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5753cf8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5753fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b57faba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b57ced68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b57cee48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b574bc18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b574bbe0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b7654cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b7654940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b7665d30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b7665080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b766c240>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b766c2b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b765cc88>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b765c0f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b574b9b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b76540f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b7654ef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7654e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7654eb8>]
          

Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 50)                9600      
_________________________________________________________________
dense_60 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_60 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_61 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_62 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0425 - tp: 587.0000 - fp: 417.0000 - tn: 253342.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5847 - recall: 0.1878 - auc: 0.9016 - val_loss: 0.0286 - val_tp: 941.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1898.0000 - val_accuracy: 0.9907 - val_precision: 0.7462 - val_recall: 0.3315 - val_auc: 0.9665
256885/256885 - 110s - loss: 0.0425 - tp: 587.0000 - fp: 417.0000 - tn: 253342.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5847 - recall: 0.1878 - auc: 0.9016 - val_loss: 0.0286 - val_tp: 941.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1898.0000 - val_accuracy: 0.9907 - val_precision: 0.7462 - val_recall: 0.3315 - val_auc: 0.9665
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0256 - tp: 1525.0000 - fp: 437.0000 - tn: 253322.0000 - fn: 1601.0000 - accuracy: 0.9921 - precision: 0.7773 - recall: 0.4878 - auc: 0.9653 - val_loss: 0.0204 - val_tp: 1733.0000 - val_fp: 407.0000 - val_tn: 234612.0000 - val_fn: 1106.0000 - val_accuracy: 0.9936 - val_precision: 0.8098 - val_recall: 0.6104 - val_auc: 0.9840
256885/256885 - 106s - loss: 0.0256 - tp: 1525.0000 - fp: 437.0000 - tn: 253322.0000 - fn: 1601.0000 - accuracy: 0.9921 - precision: 0.7773 - recall: 0.4878 - auc: 0.9653 - val_loss: 0.0204 - val_tp: 1733.0000 - val_fp: 407.0000 - val_tn: 234612.0000 - val_fn: 1106.0000 - val_accuracy: 0.9936 - val_precision: 0.8098 - val_recall: 0.6104 - val_auc: 0.9840
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b73c80f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5aeb898>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b4766fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4766ef0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b7bddc88>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b7a0d7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b73a12b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b73a1da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b76540f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5ce55c0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b739ba90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5cbdba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7396a90>]
          

Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_63 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_63 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_64 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_65 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 111s - loss: 0.0416 - tp: 640.0000 - fp: 410.0000 - tn: 253348.0000 - fn: 2487.0000 - accuracy: 0.9887 - precision: 0.6095 - recall: 0.2047 - auc: 0.9059 - val_loss: 0.0284 - val_tp: 1182.0000 - val_fp: 585.0000 - val_tn: 234434.0000 - val_fn: 1657.0000 - val_accuracy: 0.9906 - val_precision: 0.6689 - val_recall: 0.4163 - val_auc: 0.9655
256885/256885 - 111s - loss: 0.0416 - tp: 640.0000 - fp: 410.0000 - tn: 253348.0000 - fn: 2487.0000 - accuracy: 0.9887 - precision: 0.6095 - recall: 0.2047 - auc: 0.9059 - val_loss: 0.0284 - val_tp: 1182.0000 - val_fp: 585.0000 - val_tn: 234434.0000 - val_fn: 1657.0000 - val_accuracy: 0.9906 - val_precision: 0.6689 - val_recall: 0.4163 - val_auc: 0.9655
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0255 - tp: 1507.0000 - fp: 457.0000 - tn: 253301.0000 - fn: 1620.0000 - accuracy: 0.9919 - precision: 0.7673 - recall: 0.4819 - auc: 0.9665 - val_loss: 0.0229 - val_tp: 1294.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 1545.0000 - val_accuracy: 0.9928 - val_precision: 0.8803 - val_recall: 0.4558 - val_auc: 0.9641
256885/256885 - 108s - loss: 0.0255 - tp: 1507.0000 - fp: 457.0000 - tn: 253301.0000 - fn: 1620.0000 - accuracy: 0.9919 - precision: 0.7673 - recall: 0.4819 - auc: 0.9665 - val_loss: 0.0229 - val_tp: 1294.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 1545.0000 - val_accuracy: 0.9928 - val_precision: 0.8803 - val_recall: 0.4558 - val_auc: 0.9641
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b4468b38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b4468fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b4446f28>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4446588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4446780>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b4446240>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b44466a0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b4491b00>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b739ba90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5cbdba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b7390eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b73c8198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b73c8080>]
          

Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_2 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_66 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_66 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_67 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_68 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 111s - loss: 0.0423 - tp: 604.0000 - fp: 418.0000 - tn: 253351.0000 - fn: 2512.0000 - accuracy: 0.9886 - precision: 0.5910 - recall: 0.1938 - auc: 0.9054 - val_loss: 0.0289 - val_tp: 1013.0000 - val_fp: 386.0000 - val_tn: 234633.0000 - val_fn: 1826.0000 - val_accuracy: 0.9907 - val_precision: 0.7241 - val_recall: 0.3568 - val_auc: 0.9625
256885/256885 - 111s - loss: 0.0423 - tp: 604.0000 - fp: 418.0000 - tn: 253351.0000 - fn: 2512.0000 - accuracy: 0.9886 - precision: 0.5910 - recall: 0.1938 - auc: 0.9054 - val_loss: 0.0289 - val_tp: 1013.0000 - val_fp: 386.0000 - val_tn: 234633.0000 - val_fn: 1826.0000 - val_accuracy: 0.9907 - val_precision: 0.7241 - val_recall: 0.3568 - val_auc: 0.9625
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0258 - tp: 1478.0000 - fp: 454.0000 - tn: 253315.0000 - fn: 1638.0000 - accuracy: 0.9919 - precision: 0.7650 - recall: 0.4743 - auc: 0.9682 - val_loss: 0.0228 - val_tp: 1274.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 1565.0000 - val_accuracy: 0.9928 - val_precision: 0.8978 - val_recall: 0.4487 - val_auc: 0.9670
256885/256885 - 108s - loss: 0.0258 - tp: 1478.0000 - fp: 454.0000 - tn: 253315.0000 - fn: 1638.0000 - accuracy: 0.9919 - precision: 0.7650 - recall: 0.4743 - auc: 0.9682 - val_loss: 0.0228 - val_tp: 1274.0000 - val_fp: 145.0000 - val_tn: 234874.0000 - val_fn: 1565.0000 - val_accuracy: 0.9928 - val_precision: 0.8978 - val_recall: 0.4487 - val_auc: 0.9670
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b588c860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b7391b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b73890b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b7389898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b7389b38>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b7389ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b44731d0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b44734a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b73c80b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b44613c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4455048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4468198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b44689e8>]
          

Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_3 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_69 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_69 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_70 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_71 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0416 - tp: 568.0000 - fp: 360.0000 - tn: 253432.0000 - fn: 2525.0000 - accuracy: 0.9888 - precision: 0.6121 - recall: 0.1836 - auc: 0.9074 - val_loss: 0.0280 - val_tp: 928.0000 - val_fp: 294.0000 - val_tn: 234725.0000 - val_fn: 1911.0000 - val_accuracy: 0.9907 - val_precision: 0.7594 - val_recall: 0.3269 - val_auc: 0.9667
256885/256885 - 110s - loss: 0.0416 - tp: 568.0000 - fp: 360.0000 - tn: 253432.0000 - fn: 2525.0000 - accuracy: 0.9888 - precision: 0.6121 - recall: 0.1836 - auc: 0.9074 - val_loss: 0.0280 - val_tp: 928.0000 - val_fp: 294.0000 - val_tn: 234725.0000 - val_fn: 1911.0000 - val_accuracy: 0.9907 - val_precision: 0.7594 - val_recall: 0.3269 - val_auc: 0.9667
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 107s - loss: 0.0243 - tp: 1569.0000 - fp: 399.0000 - tn: 253393.0000 - fn: 1524.0000 - accuracy: 0.9925 - precision: 0.7973 - recall: 0.5073 - auc: 0.9694 - val_loss: 0.0196 - val_tp: 1840.0000 - val_fp: 456.0000 - val_tn: 234563.0000 - val_fn: 999.0000 - val_accuracy: 0.9939 - val_precision: 0.8014 - val_recall: 0.6481 - val_auc: 0.9825
256885/256885 - 107s - loss: 0.0243 - tp: 1569.0000 - fp: 399.0000 - tn: 253393.0000 - fn: 1524.0000 - accuracy: 0.9925 - precision: 0.7973 - recall: 0.5073 - auc: 0.9694 - val_loss: 0.0196 - val_tp: 1840.0000 - val_fp: 456.0000 - val_tn: 234563.0000 - val_fn: 999.0000 - val_accuracy: 0.9939 - val_precision: 0.8014 - val_recall: 0.6481 - val_auc: 0.9825
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b47386d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5d3de80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b47335c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4733e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4478128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b44784e0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b4478780>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b4478a58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b4468198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b73c8080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6a7d160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6a7d208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6a7d128>]
          

Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_4 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_72 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_72 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_73 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_74 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 111s - loss: 0.0414 - tp: 635.0000 - fp: 357.0000 - tn: 253382.0000 - fn: 2511.0000 - accuracy: 0.9888 - precision: 0.6401 - recall: 0.2018 - auc: 0.9142 - val_loss: 0.0283 - val_tp: 1026.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1813.0000 - val_accuracy: 0.9908 - val_precision: 0.7365 - val_recall: 0.3614 - val_auc: 0.9597
256885/256885 - 111s - loss: 0.0414 - tp: 635.0000 - fp: 357.0000 - tn: 253382.0000 - fn: 2511.0000 - accuracy: 0.9888 - precision: 0.6401 - recall: 0.2018 - auc: 0.9142 - val_loss: 0.0283 - val_tp: 1026.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1813.0000 - val_accuracy: 0.9908 - val_precision: 0.7365 - val_recall: 0.3614 - val_auc: 0.9597
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 107s - loss: 0.0251 - tp: 1569.0000 - fp: 431.0000 - tn: 253308.0000 - fn: 1577.0000 - accuracy: 0.9922 - precision: 0.7845 - recall: 0.4987 - auc: 0.9654 - val_loss: 0.0204 - val_tp: 1631.0000 - val_fp: 304.0000 - val_tn: 234715.0000 - val_fn: 1208.0000 - val_accuracy: 0.9936 - val_precision: 0.8429 - val_recall: 0.5745 - val_auc: 0.9701
256885/256885 - 107s - loss: 0.0251 - tp: 1569.0000 - fp: 431.0000 - tn: 253308.0000 - fn: 1577.0000 - accuracy: 0.9922 - precision: 0.7845 - recall: 0.4987 - auc: 0.9654 - val_loss: 0.0204 - val_tp: 1631.0000 - val_fp: 304.0000 - val_tn: 234715.0000 - val_fn: 1208.0000 - val_accuracy: 0.9936 - val_precision: 0.8429 - val_recall: 0.5745 - val_auc: 0.9701
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b7ae4fd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b46c4320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b46c4c18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b46c7198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b46dce80>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b46dcd30>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b46e97b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b46e92b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5d4f2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4738780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4948080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6fd8cc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6fd8b00>]
          

Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_5 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_75 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_75 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_76 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_77 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0418 - tp: 579.0000 - fp: 398.0000 - tn: 253380.0000 - fn: 2528.0000 - accuracy: 0.9886 - precision: 0.5926 - recall: 0.1864 - auc: 0.9082 - val_loss: 0.0321 - val_tp: 671.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 2168.0000 - val_accuracy: 0.9901 - val_precision: 0.7922 - val_recall: 0.2364 - val_auc: 0.9415
256885/256885 - 110s - loss: 0.0418 - tp: 579.0000 - fp: 398.0000 - tn: 253380.0000 - fn: 2528.0000 - accuracy: 0.9886 - precision: 0.5926 - recall: 0.1864 - auc: 0.9082 - val_loss: 0.0321 - val_tp: 671.0000 - val_fp: 176.0000 - val_tn: 234843.0000 - val_fn: 2168.0000 - val_accuracy: 0.9901 - val_precision: 0.7922 - val_recall: 0.2364 - val_auc: 0.9415
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 107s - loss: 0.0254 - tp: 1492.0000 - fp: 431.0000 - tn: 253347.0000 - fn: 1615.0000 - accuracy: 0.9920 - precision: 0.7759 - recall: 0.4802 - auc: 0.9664 - val_loss: 0.0204 - val_tp: 1759.0000 - val_fp: 429.0000 - val_tn: 234590.0000 - val_fn: 1080.0000 - val_accuracy: 0.9937 - val_precision: 0.8039 - val_recall: 0.6196 - val_auc: 0.9834
256885/256885 - 107s - loss: 0.0254 - tp: 1492.0000 - fp: 431.0000 - tn: 253347.0000 - fn: 1615.0000 - accuracy: 0.9920 - precision: 0.7759 - recall: 0.4802 - auc: 0.9664 - val_loss: 0.0204 - val_tp: 1759.0000 - val_fp: 429.0000 - val_tn: 234590.0000 - val_fn: 1080.0000 - val_accuracy: 0.9937 - val_precision: 0.8039 - val_recall: 0.6196 - val_auc: 0.9834
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b46ab978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b469e198>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b56db978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff3103f8160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff3103f8400>, <tensorflow.python.keras.metrics.Precision object at 0x7ff3103f87b8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff3103f8a58>, <tensorflow.python.keras.metrics.AUC object at 0x7ff3103f8d30>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3102cb940>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6fd8ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6fd8f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6fc4c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6a7d160>]
          

Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_6 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_78 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_78 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_79 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_26 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_80 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0416 - tp: 608.0000 - fp: 372.0000 - tn: 253422.0000 - fn: 2483.0000 - accuracy: 0.9889 - precision: 0.6204 - recall: 0.1967 - auc: 0.9044 - val_loss: 0.0292 - val_tp: 845.0000 - val_fp: 272.0000 - val_tn: 234747.0000 - val_fn: 1994.0000 - val_accuracy: 0.9905 - val_precision: 0.7565 - val_recall: 0.2976 - val_auc: 0.9628
256885/256885 - 109s - loss: 0.0416 - tp: 608.0000 - fp: 372.0000 - tn: 253422.0000 - fn: 2483.0000 - accuracy: 0.9889 - precision: 0.6204 - recall: 0.1967 - auc: 0.9044 - val_loss: 0.0292 - val_tp: 845.0000 - val_fp: 272.0000 - val_tn: 234747.0000 - val_fn: 1994.0000 - val_accuracy: 0.9905 - val_precision: 0.7565 - val_recall: 0.2976 - val_auc: 0.9628
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0252 - tp: 1506.0000 - fp: 414.0000 - tn: 253380.0000 - fn: 1585.0000 - accuracy: 0.9922 - precision: 0.7844 - recall: 0.4872 - auc: 0.9664 - val_loss: 0.0210 - val_tp: 1632.0000 - val_fp: 350.0000 - val_tn: 234669.0000 - val_fn: 1207.0000 - val_accuracy: 0.9935 - val_precision: 0.8234 - val_recall: 0.5749 - val_auc: 0.9675
256885/256885 - 106s - loss: 0.0252 - tp: 1506.0000 - fp: 414.0000 - tn: 253380.0000 - fn: 1585.0000 - accuracy: 0.9922 - precision: 0.7844 - recall: 0.4872 - auc: 0.9664 - val_loss: 0.0210 - val_tp: 1632.0000 - val_fp: 350.0000 - val_tn: 234669.0000 - val_fn: 1207.0000 - val_accuracy: 0.9935 - val_precision: 0.8234 - val_recall: 0.5749 - val_auc: 0.9675
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293e64198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b50dfb70>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b50dffd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b50e6710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b50e69b0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b50e6d68>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b50e6fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b7f99320>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6fd8ba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6a7d160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b56ee630>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b56eec88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b56ee048>]
          

Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_7 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_81 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_81 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_82 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_83 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 111s - loss: 0.0424 - tp: 601.0000 - fp: 407.0000 - tn: 253367.0000 - fn: 2510.0000 - accuracy: 0.9886 - precision: 0.5962 - recall: 0.1932 - auc: 0.9040 - val_loss: 0.0286 - val_tp: 796.0000 - val_fp: 204.0000 - val_tn: 234815.0000 - val_fn: 2043.0000 - val_accuracy: 0.9906 - val_precision: 0.7960 - val_recall: 0.2804 - val_auc: 0.9677
256885/256885 - 111s - loss: 0.0424 - tp: 601.0000 - fp: 407.0000 - tn: 253367.0000 - fn: 2510.0000 - accuracy: 0.9886 - precision: 0.5962 - recall: 0.1932 - auc: 0.9040 - val_loss: 0.0286 - val_tp: 796.0000 - val_fp: 204.0000 - val_tn: 234815.0000 - val_fn: 2043.0000 - val_accuracy: 0.9906 - val_precision: 0.7960 - val_recall: 0.2804 - val_auc: 0.9677
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 107s - loss: 0.0247 - tp: 1554.0000 - fp: 426.0000 - tn: 253348.0000 - fn: 1557.0000 - accuracy: 0.9923 - precision: 0.7848 - recall: 0.4995 - auc: 0.9698 - val_loss: 0.0216 - val_tp: 1900.0000 - val_fp: 533.0000 - val_tn: 234486.0000 - val_fn: 939.0000 - val_accuracy: 0.9938 - val_precision: 0.7809 - val_recall: 0.6692 - val_auc: 0.9873
256885/256885 - 107s - loss: 0.0247 - tp: 1554.0000 - fp: 426.0000 - tn: 253348.0000 - fn: 1557.0000 - accuracy: 0.9923 - precision: 0.7848 - recall: 0.4995 - auc: 0.9698 - val_loss: 0.0216 - val_tp: 1900.0000 - val_fp: 533.0000 - val_tn: 234486.0000 - val_fn: 939.0000 - val_accuracy: 0.9938 - val_precision: 0.7809 - val_recall: 0.6692 - val_auc: 0.9873
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff310436278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff310557320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff310557d68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b7708710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b77086d8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b7708978>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b77312e8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5166208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b56eec88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6fd8b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b50c2fd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6fc4c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff3104116a0>]
          

Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_8 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_84 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_84 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_85 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_28 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_86 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 110s - loss: 0.0413 - tp: 604.0000 - fp: 409.0000 - tn: 253369.0000 - fn: 2504.0000 - accuracy: 0.9887 - precision: 0.5962 - recall: 0.1943 - auc: 0.9133 - val_loss: 0.0292 - val_tp: 800.0000 - val_fp: 247.0000 - val_tn: 234772.0000 - val_fn: 2039.0000 - val_accuracy: 0.9904 - val_precision: 0.7641 - val_recall: 0.2818 - val_auc: 0.9642
256886/256886 - 110s - loss: 0.0413 - tp: 604.0000 - fp: 409.0000 - tn: 253369.0000 - fn: 2504.0000 - accuracy: 0.9887 - precision: 0.5962 - recall: 0.1943 - auc: 0.9133 - val_loss: 0.0292 - val_tp: 800.0000 - val_fp: 247.0000 - val_tn: 234772.0000 - val_fn: 2039.0000 - val_accuracy: 0.9904 - val_precision: 0.7641 - val_recall: 0.2818 - val_auc: 0.9642
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 106s - loss: 0.0255 - tp: 1484.0000 - fp: 456.0000 - tn: 253322.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7649 - recall: 0.4775 - auc: 0.9685 - val_loss: 0.0207 - val_tp: 1617.0000 - val_fp: 349.0000 - val_tn: 234670.0000 - val_fn: 1222.0000 - val_accuracy: 0.9934 - val_precision: 0.8225 - val_recall: 0.5696 - val_auc: 0.9728
256886/256886 - 106s - loss: 0.0255 - tp: 1484.0000 - fp: 456.0000 - tn: 253322.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7649 - recall: 0.4775 - auc: 0.9685 - val_loss: 0.0207 - val_tp: 1617.0000 - val_fp: 349.0000 - val_tn: 234670.0000 - val_fn: 1222.0000 - val_accuracy: 0.9934 - val_precision: 0.8225 - val_recall: 0.5696 - val_auc: 0.9728
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b4e9f940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b6da7f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5ce2400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5cc9cf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b56595f8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5659a20>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5659cc0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5659f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b50c2f60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff310411198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff310436240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff310436a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff310436f60>]
          

Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_9 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_87 (Dense)             (None, 200)               10200     
_________________________________________________________________
activation_87 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_88 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_29 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_89 (Activation)   (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 110s - loss: 0.0432 - tp: 582.0000 - fp: 411.0000 - tn: 253351.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5861 - recall: 0.1863 - auc: 0.8989 - val_loss: 0.0280 - val_tp: 1040.0000 - val_fp: 337.0000 - val_tn: 234682.0000 - val_fn: 1799.0000 - val_accuracy: 0.9910 - val_precision: 0.7553 - val_recall: 0.3663 - val_auc: 0.9669
256886/256886 - 110s - loss: 0.0432 - tp: 582.0000 - fp: 411.0000 - tn: 253351.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5861 - recall: 0.1863 - auc: 0.8989 - val_loss: 0.0280 - val_tp: 1040.0000 - val_fp: 337.0000 - val_tn: 234682.0000 - val_fn: 1799.0000 - val_accuracy: 0.9910 - val_precision: 0.7553 - val_recall: 0.3663 - val_auc: 0.9669
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 107s - loss: 0.0248 - tp: 1559.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 1565.0000 - accuracy: 0.9923 - precision: 0.7890 - recall: 0.4990 - auc: 0.9679 - val_loss: 0.0196 - val_tp: 1710.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1129.0000 - val_accuracy: 0.9938 - val_precision: 0.8346 - val_recall: 0.6023 - val_auc: 0.9803
256886/256886 - 107s - loss: 0.0248 - tp: 1559.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 1565.0000 - accuracy: 0.9923 - precision: 0.7890 - recall: 0.4990 - auc: 0.9679 - val_loss: 0.0196 - val_tp: 1710.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1129.0000 - val_accuracy: 0.9938 - val_precision: 0.8346 - val_recall: 0.6023 - val_auc: 0.9803
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b73c8e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293b0c320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293ac2b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293ac92e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293ac9588>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293ac9940>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293ac9be0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293ac9eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff310436a20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b56eec88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b55cecc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff31017fb00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff310411198>]
          

Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_90 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_90 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_91 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_91 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_30 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_92 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_92 (Activation)   (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0413 - tp: 617.0000 - fp: 401.0000 - tn: 253358.0000 - fn: 2509.0000 - accuracy: 0.9887 - precision: 0.6061 - recall: 0.1974 - auc: 0.9128 - val_loss: 0.0274 - val_tp: 1213.0000 - val_fp: 522.0000 - val_tn: 234497.0000 - val_fn: 1626.0000 - val_accuracy: 0.9910 - val_precision: 0.6991 - val_recall: 0.4273 - val_auc: 0.9705
256885/256885 - 128s - loss: 0.0413 - tp: 617.0000 - fp: 401.0000 - tn: 253358.0000 - fn: 2509.0000 - accuracy: 0.9887 - precision: 0.6061 - recall: 0.1974 - auc: 0.9128 - val_loss: 0.0274 - val_tp: 1213.0000 - val_fp: 522.0000 - val_tn: 234497.0000 - val_fn: 1626.0000 - val_accuracy: 0.9910 - val_precision: 0.6991 - val_recall: 0.4273 - val_auc: 0.9705
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0247 - tp: 1617.0000 - fp: 432.0000 - tn: 253327.0000 - fn: 1509.0000 - accuracy: 0.9924 - precision: 0.7892 - recall: 0.5173 - auc: 0.9668 - val_loss: 0.0246 - val_tp: 2094.0000 - val_fp: 977.0000 - val_tn: 234042.0000 - val_fn: 745.0000 - val_accuracy: 0.9928 - val_precision: 0.6819 - val_recall: 0.7376 - val_auc: 0.9890
256885/256885 - 125s - loss: 0.0247 - tp: 1617.0000 - fp: 432.0000 - tn: 253327.0000 - fn: 1509.0000 - accuracy: 0.9924 - precision: 0.7892 - recall: 0.5173 - auc: 0.9668 - val_loss: 0.0246 - val_tp: 2094.0000 - val_fp: 977.0000 - val_tn: 234042.0000 - val_fn: 745.0000 - val_accuracy: 0.9928 - val_precision: 0.6819 - val_recall: 0.7376 - val_auc: 0.9890
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5e05908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b4582208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b4582da0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4582b00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4582c88>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b4582b70>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293a8e438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b465c588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff310411198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b641e208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b641e0f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b641e1d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b641e048>]
          

Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_11 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_93 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_93 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_94 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_94 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_31 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_95 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_95 (Activation)   (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0423 - tp: 624.0000 - fp: 426.0000 - tn: 253332.0000 - fn: 2503.0000 - accuracy: 0.9886 - precision: 0.5943 - recall: 0.1996 - auc: 0.9018 - val_loss: 0.0285 - val_tp: 900.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1939.0000 - val_accuracy: 0.9907 - val_precision: 0.7692 - val_recall: 0.3170 - val_auc: 0.9640
256885/256885 - 127s - loss: 0.0423 - tp: 624.0000 - fp: 426.0000 - tn: 253332.0000 - fn: 2503.0000 - accuracy: 0.9886 - precision: 0.5943 - recall: 0.1996 - auc: 0.9018 - val_loss: 0.0285 - val_tp: 900.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1939.0000 - val_accuracy: 0.9907 - val_precision: 0.7692 - val_recall: 0.3170 - val_auc: 0.9640
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 124s - loss: 0.0250 - tp: 1570.0000 - fp: 441.0000 - tn: 253317.0000 - fn: 1557.0000 - accuracy: 0.9922 - precision: 0.7807 - recall: 0.5021 - auc: 0.9688 - val_loss: 0.0208 - val_tp: 1809.0000 - val_fp: 490.0000 - val_tn: 234529.0000 - val_fn: 1030.0000 - val_accuracy: 0.9936 - val_precision: 0.7869 - val_recall: 0.6372 - val_auc: 0.9858
256885/256885 - 124s - loss: 0.0250 - tp: 1570.0000 - fp: 441.0000 - tn: 253317.0000 - fn: 1557.0000 - accuracy: 0.9922 - precision: 0.7807 - recall: 0.5021 - auc: 0.9688 - val_loss: 0.0208 - val_tp: 1809.0000 - val_fp: 490.0000 - val_tn: 234529.0000 - val_fn: 1030.0000 - val_accuracy: 0.9936 - val_precision: 0.7869 - val_recall: 0.6372 - val_auc: 0.9858
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b4e58ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff29343dd30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b7b5dc50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292fc7b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292fc7a90>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292fc75c0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292fc73c8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292fc7a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b3f120f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5589320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4e58f98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4e58fd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b4e58d30>]
          

Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_12 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_96 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_96 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_97 (Dense)             (None, 200)               40200     
_________________________________________________________________
activation_97 (Activation)   (None, 200)               0         
_________________________________________________________________
dropout_32 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_98 (Dense)             (None, 1)                 201       
_________________________________________________________________
activation_98 (Activation)   (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0413 - tp: 632.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 2484.0000 - accuracy: 0.9888 - precision: 0.6124 - recall: 0.2028 - auc: 0.9081 - val_loss: 0.0315 - val_tp: 753.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 2086.0000 - val_accuracy: 0.9904 - val_precision: 0.7977 - val_recall: 0.2652 - val_auc: 0.9411
256885/256885 - 127s - loss: 0.0413 - tp: 632.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 2484.0000 - accuracy: 0.9888 - precision: 0.6124 - recall: 0.2028 - auc: 0.9081 - val_loss: 0.0315 - val_tp: 753.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 2086.0000 - val_accuracy: 0.9904 - val_precision: 0.7977 - val_recall: 0.2652 - val_auc: 0.9411
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0237 - tp: 1665.0000 - fp: 422.0000 - tn: 253347.0000 - fn: 1451.0000 - accuracy: 0.9927 - precision: 0.7978 - recall: 0.5343 - auc: 0.9691 - val_loss: 0.0207 - val_tp: 1581.0000 - val_fp: 204.0000 - val_tn: 234815.0000 - val_fn: 1258.0000 - val_accuracy: 0.9939 - val_precision: 0.8857 - val_recall: 0.5569 - val_auc: 0.9605
256885/256885 - 125s - loss: 0.0237 - tp: 1665.0000 - fp: 422.0000 - tn: 253347.0000 - fn: 1451.0000 - accuracy: 0.9927 - precision: 0.7978 - recall: 0.5343 - auc: 0.9691 - val_loss: 0.0207 - val_tp: 1581.0000 - val_fp: 204.0000 - val_tn: 234815.0000 - val_fn: 1258.0000 - val_accuracy: 0.9939 - val_precision: 0.8857 - val_recall: 0.5569 - val_auc: 0.9605
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b4a65320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b4e164e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2933c16d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2933c14e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2933c10f0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2933c1c18>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293bf0fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293bf0198>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b4e58f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4e58cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4e58f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4e58748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b4e58e80>]
          

Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_13 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_99 (Dense)             (None, 200)               20200     
_________________________________________________________________
activation_99 (Activation)   (None, 200)               0         
_________________________________________________________________
dense_100 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_100 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_33 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_101 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_101 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0407 - tp: 626.0000 - fp: 339.0000 - tn: 253453.0000 - fn: 2467.0000 - accuracy: 0.9891 - precision: 0.6487 - recall: 0.2024 - auc: 0.9135 - val_loss: 0.0304 - val_tp: 968.0000 - val_fp: 395.0000 - val_tn: 234624.0000 - val_fn: 1871.0000 - val_accuracy: 0.9905 - val_precision: 0.7102 - val_recall: 0.3410 - val_auc: 0.9457
256885/256885 - 128s - loss: 0.0407 - tp: 626.0000 - fp: 339.0000 - tn: 253453.0000 - fn: 2467.0000 - accuracy: 0.9891 - precision: 0.6487 - recall: 0.2024 - auc: 0.9135 - val_loss: 0.0304 - val_tp: 968.0000 - val_fp: 395.0000 - val_tn: 234624.0000 - val_fn: 1871.0000 - val_accuracy: 0.9905 - val_precision: 0.7102 - val_recall: 0.3410 - val_auc: 0.9457
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0240 - tp: 1625.0000 - fp: 434.0000 - tn: 253358.0000 - fn: 1468.0000 - accuracy: 0.9926 - precision: 0.7892 - recall: 0.5254 - auc: 0.9697 - val_loss: 0.0199 - val_tp: 1748.0000 - val_fp: 345.0000 - val_tn: 234674.0000 - val_fn: 1091.0000 - val_accuracy: 0.9940 - val_precision: 0.8352 - val_recall: 0.6157 - val_auc: 0.9797
256885/256885 - 125s - loss: 0.0240 - tp: 1625.0000 - fp: 434.0000 - tn: 253358.0000 - fn: 1468.0000 - accuracy: 0.9926 - precision: 0.7892 - recall: 0.5254 - auc: 0.9697 - val_loss: 0.0199 - val_tp: 1748.0000 - val_fp: 345.0000 - val_tn: 234674.0000 - val_fn: 1091.0000 - val_accuracy: 0.9940 - val_precision: 0.8352 - val_recall: 0.6157 - val_auc: 0.9797
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b7bd1828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293dfe0f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6058a58>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b6b290b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b6b299e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293e770f0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293e772e8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293e77390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b4e58f28>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4e58d30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4e819b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4e81b38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b4e817f0>]
          

Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_102 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_102 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_103 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_103 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_34 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_104 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_104 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0406 - tp: 664.0000 - fp: 345.0000 - tn: 253394.0000 - fn: 2482.0000 - accuracy: 0.9890 - precision: 0.6581 - recall: 0.2111 - auc: 0.9169 - val_loss: 0.0276 - val_tp: 856.0000 - val_fp: 206.0000 - val_tn: 234813.0000 - val_fn: 1983.0000 - val_accuracy: 0.9908 - val_precision: 0.8060 - val_recall: 0.3015 - val_auc: 0.9707
256885/256885 - 128s - loss: 0.0406 - tp: 664.0000 - fp: 345.0000 - tn: 253394.0000 - fn: 2482.0000 - accuracy: 0.9890 - precision: 0.6581 - recall: 0.2111 - auc: 0.9169 - val_loss: 0.0276 - val_tp: 856.0000 - val_fp: 206.0000 - val_tn: 234813.0000 - val_fn: 1983.0000 - val_accuracy: 0.9908 - val_precision: 0.8060 - val_recall: 0.3015 - val_auc: 0.9707
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 124s - loss: 0.0242 - tp: 1621.0000 - fp: 435.0000 - tn: 253304.0000 - fn: 1525.0000 - accuracy: 0.9924 - precision: 0.7884 - recall: 0.5153 - auc: 0.9720 - val_loss: 0.0200 - val_tp: 1924.0000 - val_fp: 589.0000 - val_tn: 234430.0000 - val_fn: 915.0000 - val_accuracy: 0.9937 - val_precision: 0.7656 - val_recall: 0.6777 - val_auc: 0.9847
256885/256885 - 124s - loss: 0.0242 - tp: 1621.0000 - fp: 435.0000 - tn: 253304.0000 - fn: 1525.0000 - accuracy: 0.9924 - precision: 0.7884 - recall: 0.5153 - auc: 0.9720 - val_loss: 0.0200 - val_tp: 1924.0000 - val_fp: 589.0000 - val_tn: 234430.0000 - val_fn: 915.0000 - val_accuracy: 0.9937 - val_precision: 0.7656 - val_recall: 0.6777 - val_auc: 0.9847
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293cb25f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293cb2f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5cbfc18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b54b7a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b54b7630>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b54b73c8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b54b7048>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b54b7d68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b4e81b38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b70a0710>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b701c128>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b701db00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff29339dac8>]
          

Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_15 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_105 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_105 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_106 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_106 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_35 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_107 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_107 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0402 - tp: 702.0000 - fp: 375.0000 - tn: 253403.0000 - fn: 2405.0000 - accuracy: 0.9892 - precision: 0.6518 - recall: 0.2259 - auc: 0.9159 - val_loss: 0.0283 - val_tp: 829.0000 - val_fp: 228.0000 - val_tn: 234791.0000 - val_fn: 2010.0000 - val_accuracy: 0.9906 - val_precision: 0.7843 - val_recall: 0.2920 - val_auc: 0.9652
256885/256885 - 127s - loss: 0.0402 - tp: 702.0000 - fp: 375.0000 - tn: 253403.0000 - fn: 2405.0000 - accuracy: 0.9892 - precision: 0.6518 - recall: 0.2259 - auc: 0.9159 - val_loss: 0.0283 - val_tp: 829.0000 - val_fp: 228.0000 - val_tn: 234791.0000 - val_fn: 2010.0000 - val_accuracy: 0.9906 - val_precision: 0.7843 - val_recall: 0.2920 - val_auc: 0.9652
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0241 - tp: 1641.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 1466.0000 - accuracy: 0.9926 - precision: 0.7908 - recall: 0.5282 - auc: 0.9675 - val_loss: 0.0374 - val_tp: 2194.0000 - val_fp: 1528.0000 - val_tn: 233491.0000 - val_fn: 645.0000 - val_accuracy: 0.9909 - val_precision: 0.5895 - val_recall: 0.7728 - val_auc: 0.9889
256885/256885 - 125s - loss: 0.0241 - tp: 1641.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 1466.0000 - accuracy: 0.9926 - precision: 0.7908 - recall: 0.5282 - auc: 0.9675 - val_loss: 0.0374 - val_tp: 2194.0000 - val_fp: 1528.0000 - val_tn: 233491.0000 - val_fn: 645.0000 - val_accuracy: 0.9909 - val_precision: 0.5895 - val_recall: 0.7728 - val_auc: 0.9889
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2923c3710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2923c3f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2937aa780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff29245e160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff29245e978>, <tensorflow.python.keras.metrics.Precision object at 0x7ff29245e400>, <tensorflow.python.keras.metrics.Recall object at 0x7ff29245e7b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff29245efd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b701db00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b49a7a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293714198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff29371ab70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2934410b8>]
          

Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_16 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_108 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_108 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_109 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_109 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_36 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_110 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_110 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0411 - tp: 652.0000 - fp: 383.0000 - tn: 253411.0000 - fn: 2439.0000 - accuracy: 0.9890 - precision: 0.6300 - recall: 0.2109 - auc: 0.9063 - val_loss: 0.0328 - val_tp: 535.0000 - val_fp: 110.0000 - val_tn: 234909.0000 - val_fn: 2304.0000 - val_accuracy: 0.9899 - val_precision: 0.8295 - val_recall: 0.1884 - val_auc: 0.9423
256885/256885 - 128s - loss: 0.0411 - tp: 652.0000 - fp: 383.0000 - tn: 253411.0000 - fn: 2439.0000 - accuracy: 0.9890 - precision: 0.6300 - recall: 0.2109 - auc: 0.9063 - val_loss: 0.0328 - val_tp: 535.0000 - val_fp: 110.0000 - val_tn: 234909.0000 - val_fn: 2304.0000 - val_accuracy: 0.9899 - val_precision: 0.8295 - val_recall: 0.1884 - val_auc: 0.9423
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0245 - tp: 1585.0000 - fp: 427.0000 - tn: 253367.0000 - fn: 1506.0000 - accuracy: 0.9925 - precision: 0.7878 - recall: 0.5128 - auc: 0.9659 - val_loss: 0.0260 - val_tp: 1254.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1585.0000 - val_accuracy: 0.9927 - val_precision: 0.8925 - val_recall: 0.4417 - val_auc: 0.9389
256885/256885 - 125s - loss: 0.0245 - tp: 1585.0000 - fp: 427.0000 - tn: 253367.0000 - fn: 1506.0000 - accuracy: 0.9925 - precision: 0.7878 - recall: 0.5128 - auc: 0.9659 - val_loss: 0.0260 - val_tp: 1254.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1585.0000 - val_accuracy: 0.9927 - val_precision: 0.8925 - val_recall: 0.4417 - val_auc: 0.9389
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 24s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2f0339128>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5739278>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b7641320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4694c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4694b70>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b4694be0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b4694198>, <tensorflow.python.keras.metrics.AUC object at 0x7ff330142780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff29371ab70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2923c3fd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2923c3ef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2923c3eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2923c3668>]
          

Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_17 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_111 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_111 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_112 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_112 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_37 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_113 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_113 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0416 - tp: 641.0000 - fp: 446.0000 - tn: 253328.0000 - fn: 2470.0000 - accuracy: 0.9886 - precision: 0.5897 - recall: 0.2060 - auc: 0.9033 - val_loss: 0.0274 - val_tp: 1247.0000 - val_fp: 547.0000 - val_tn: 234472.0000 - val_fn: 1592.0000 - val_accuracy: 0.9910 - val_precision: 0.6951 - val_recall: 0.4392 - val_auc: 0.9742
256885/256885 - 128s - loss: 0.0416 - tp: 641.0000 - fp: 446.0000 - tn: 253328.0000 - fn: 2470.0000 - accuracy: 0.9886 - precision: 0.5897 - recall: 0.2060 - auc: 0.9033 - val_loss: 0.0274 - val_tp: 1247.0000 - val_fp: 547.0000 - val_tn: 234472.0000 - val_fn: 1592.0000 - val_accuracy: 0.9910 - val_precision: 0.6951 - val_recall: 0.4392 - val_auc: 0.9742
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 125s - loss: 0.0243 - tp: 1592.0000 - fp: 430.0000 - tn: 253344.0000 - fn: 1519.0000 - accuracy: 0.9924 - precision: 0.7873 - recall: 0.5117 - auc: 0.9680 - val_loss: 0.0210 - val_tp: 1501.0000 - val_fp: 233.0000 - val_tn: 234786.0000 - val_fn: 1338.0000 - val_accuracy: 0.9934 - val_precision: 0.8656 - val_recall: 0.5287 - val_auc: 0.9671
256885/256885 - 125s - loss: 0.0243 - tp: 1592.0000 - fp: 430.0000 - tn: 253344.0000 - fn: 1519.0000 - accuracy: 0.9924 - precision: 0.7873 - recall: 0.5117 - auc: 0.9680 - val_loss: 0.0210 - val_tp: 1501.0000 - val_fp: 233.0000 - val_tn: 234786.0000 - val_fn: 1338.0000 - val_accuracy: 0.9934 - val_precision: 0.8656 - val_recall: 0.5287 - val_auc: 0.9671
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292f51080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b4994438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b49d2240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b49d2ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b49d2d68>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b49d2f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b49d7400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b49d76d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2923c3ef0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff330117208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2935d4278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b701c128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2f03391d0>]
          

Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_18 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_114 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_114 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_115 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_115 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_38 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_116 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_116 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 127s - loss: 0.0408 - tp: 648.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 2460.0000 - accuracy: 0.9890 - precision: 0.6322 - recall: 0.2085 - auc: 0.9121 - val_loss: 0.0314 - val_tp: 917.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1922.0000 - val_accuracy: 0.9906 - val_precision: 0.7461 - val_recall: 0.3230 - val_auc: 0.9365
256886/256886 - 127s - loss: 0.0408 - tp: 648.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 2460.0000 - accuracy: 0.9890 - precision: 0.6322 - recall: 0.2085 - auc: 0.9121 - val_loss: 0.0314 - val_tp: 917.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1922.0000 - val_accuracy: 0.9906 - val_precision: 0.7461 - val_recall: 0.3230 - val_auc: 0.9365
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 124s - loss: 0.0241 - tp: 1635.0000 - fp: 452.0000 - tn: 253326.0000 - fn: 1473.0000 - accuracy: 0.9925 - precision: 0.7834 - recall: 0.5261 - auc: 0.9672 - val_loss: 0.0199 - val_tp: 1953.0000 - val_fp: 615.0000 - val_tn: 234404.0000 - val_fn: 886.0000 - val_accuracy: 0.9937 - val_precision: 0.7605 - val_recall: 0.6879 - val_auc: 0.9840
256886/256886 - 124s - loss: 0.0241 - tp: 1635.0000 - fp: 452.0000 - tn: 253326.0000 - fn: 1473.0000 - accuracy: 0.9925 - precision: 0.7834 - recall: 0.5261 - auc: 0.9672 - val_loss: 0.0199 - val_tp: 1953.0000 - val_fp: 615.0000 - val_tn: 234404.0000 - val_fn: 886.0000 - val_accuracy: 0.9937 - val_precision: 0.7605 - val_recall: 0.6879 - val_auc: 0.9840
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2925feb00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2925fedd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293764908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff29269b080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff29269ba58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff29269b1d0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff29269b7b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff29269be48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b701c128>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d81016a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293e1bbe0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6f58a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2925fed68>]
          

Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_19 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_117 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_117 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_118 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_118 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_39 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_119 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_119 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 128s - loss: 0.0417 - tp: 648.0000 - fp: 402.0000 - tn: 253360.0000 - fn: 2476.0000 - accuracy: 0.9888 - precision: 0.6171 - recall: 0.2074 - auc: 0.9051 - val_loss: 0.0319 - val_tp: 802.0000 - val_fp: 222.0000 - val_tn: 234797.0000 - val_fn: 2037.0000 - val_accuracy: 0.9905 - val_precision: 0.7832 - val_recall: 0.2825 - val_auc: 0.9355
256886/256886 - 128s - loss: 0.0417 - tp: 648.0000 - fp: 402.0000 - tn: 253360.0000 - fn: 2476.0000 - accuracy: 0.9888 - precision: 0.6171 - recall: 0.2074 - auc: 0.9051 - val_loss: 0.0319 - val_tp: 802.0000 - val_fp: 222.0000 - val_tn: 234797.0000 - val_fn: 2037.0000 - val_accuracy: 0.9905 - val_precision: 0.7832 - val_recall: 0.2825 - val_auc: 0.9355
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 125s - loss: 0.0246 - tp: 1615.0000 - fp: 430.0000 - tn: 253332.0000 - fn: 1509.0000 - accuracy: 0.9925 - precision: 0.7897 - recall: 0.5170 - auc: 0.9674 - val_loss: 0.0196 - val_tp: 1700.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1139.0000 - val_accuracy: 0.9939 - val_precision: 0.8458 - val_recall: 0.5988 - val_auc: 0.9780
256886/256886 - 125s - loss: 0.0246 - tp: 1615.0000 - fp: 430.0000 - tn: 253332.0000 - fn: 1509.0000 - accuracy: 0.9925 - precision: 0.7897 - recall: 0.5170 - auc: 0.9674 - val_loss: 0.0196 - val_tp: 1700.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1139.0000 - val_accuracy: 0.9939 - val_precision: 0.8458 - val_recall: 0.5988 - val_auc: 0.9780
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5cbd2b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b77be080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b77beb38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b77be358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b77be518>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5b3f860>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5b3f7f0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5b3f320>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b76e2e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b76e2ac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b76e2780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff244460940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b450e940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b7fb0198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b6de6160>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6de67b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b6de6828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b6de6c18>, <tensorflow.python.keras.metrics.Precision object at 0x7ff31075f908>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5e34860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b6019e80>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6de68d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6f58a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6f51048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2d8108d30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2d8108c88>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2926b7a20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2926b74a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2926aef28>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2926ae160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2926ae208>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2926aee48>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2926aea58>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2926a4160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d8108c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b7cb10f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b7cb1240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2926b7780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2926b7588>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292687a20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292687828>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292687588>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292687358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293093ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293093f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293082240>, <tensorflow.python.keras.metrics.AUC object at 0x7ff29308aa20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2926b7b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293098208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5e34860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5e34320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292687cf8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff29308afd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff29308a4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293082e80>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293093be0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293093f28>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292687390>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292687a20>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292687080>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292687a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2926b7e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293098208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7ea58d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff29308a128>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b6fa6198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b6fa6588>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6fa6d68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b6fa6d30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293770e48>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293770dd8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293770f28>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293770278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff29308aba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6ce96d8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6ce9668>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6fa6c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6fa60f0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293c63d30>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2d80cdbe0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2d80cdc50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2d80cd978>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2d80cdb70>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2d80cd240>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293c6e2e8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293c6ef60>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6fa6518>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293740390>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b6f8ec88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293c63518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293c63080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293c6ebe0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293c6e2e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293c6e320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293c6e208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2d80cd080>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2d80cd898>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2d80cd908>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2d80cd588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293c630b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6fa6048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293740390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293c63d30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293c63128>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5f23908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5f23e48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5f23860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5f23208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5f0ecf8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5f0ec88>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5f0e9b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5cc3940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293c6ec18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2f07d4400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2f07d4ac8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2f07d4a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5f23c18>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5391710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5391550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b53912b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b70f4a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b70f4080>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b70f4f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b70f4438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b70f4550>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5f23630>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293ceadd8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293ceae10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5391978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5391860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b70f4828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b70f4b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b70f45f8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b70f4940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b70f4ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5391128>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5391630>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b53915c0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b53917b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5f237f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293ceadd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b70f4198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b70f4208>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293b64ba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293b64cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293ef1f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293ef1588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293ef1710>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293ef16d8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293ef1860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293f63710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b70f4d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff31067e8d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff31067ebe0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293b642e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293b64710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292f98a58>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292f98f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292f98080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292f982b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292f98908>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293f9af98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293f9a9e8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293f9a828>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293b64ac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293f63978>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293f633c8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292f98ef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292f98b00>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293f9ac18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293f9a438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293f9a2e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293f9acf8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292f989e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292f98358>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292f98a58>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292f98c88>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292f985f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293b64630>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293f63978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b50e64a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293f9a240>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b4c72fd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b4c726d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b4c72400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4c722e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4c726a0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b4c72ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b4c6bcc0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b4c6b4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293f9aa20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4c7ab70>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b7b762b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7b76240>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b4c72e80>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2addebba8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2addebbe0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2addebc50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2addeb748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b469e2e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b469eb70>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5a56320>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5a56f60>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b4c72e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4e553c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4e554a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4e55898>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2addeb588>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5a56470>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5a56048>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5a566d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b469ec88>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b469e588>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2addeb4a8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2addeb0b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2addebf28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2addebdd8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4c720b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4c72e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b4e554a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5a56dd8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff310231f60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff310231d30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff310231e48>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff310231470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2f045bcf8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b7686f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b7724eb8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b77245c0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5a56080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b689eac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b689e160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b689e860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b689e048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2933cadd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2933ca128>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2933ca0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2933ca160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2933ca2b0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2933ca860>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b5ce5908>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5ce5630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff3102316d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d808e2e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b7738a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7006a20>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7006c88>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b5ce5e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5ce50f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b5ce5cc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5ce5f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2933cacf8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2933ca4a8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2933ca438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2933ca5f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2933caa90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff310231dd8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2d808e2e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b7006198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b7006a20>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293fc9e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293fe0a58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff293fe0748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff293fe0cc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293fe0588>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b3ed8b00>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b3ed8860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b3ed85f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5ce5358>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b4e8f2b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b4e8f978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293fc9d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293fc9ba8>]
          

Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_60 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_120 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_120 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_121 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_121 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_40 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_122 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_122 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0425 - tp: 590.0000 - fp: 389.0000 - tn: 253370.0000 - fn: 2536.0000 - accuracy: 0.9886 - precision: 0.6027 - recall: 0.1887 - auc: 0.9023 - val_loss: 0.0294 - val_tp: 1062.0000 - val_fp: 500.0000 - val_tn: 234519.0000 - val_fn: 1777.0000 - val_accuracy: 0.9904 - val_precision: 0.6799 - val_recall: 0.3741 - val_auc: 0.9716
256885/256885 - 108s - loss: 0.0425 - tp: 590.0000 - fp: 389.0000 - tn: 253370.0000 - fn: 2536.0000 - accuracy: 0.9886 - precision: 0.6027 - recall: 0.1887 - auc: 0.9023 - val_loss: 0.0294 - val_tp: 1062.0000 - val_fp: 500.0000 - val_tn: 234519.0000 - val_fn: 1777.0000 - val_accuracy: 0.9904 - val_precision: 0.6799 - val_recall: 0.3741 - val_auc: 0.9716
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0277 - tp: 1438.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 1688.0000 - accuracy: 0.9916 - precision: 0.7564 - recall: 0.4600 - auc: 0.9614 - val_loss: 0.0244 - val_tp: 1301.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 1538.0000 - val_accuracy: 0.9927 - val_precision: 0.8720 - val_recall: 0.4583 - val_auc: 0.9598
256885/256885 - 105s - loss: 0.0277 - tp: 1438.0000 - fp: 463.0000 - tn: 253296.0000 - fn: 1688.0000 - accuracy: 0.9916 - precision: 0.7564 - recall: 0.4600 - auc: 0.9614 - val_loss: 0.0244 - val_tp: 1301.0000 - val_fp: 191.0000 - val_tn: 234828.0000 - val_fn: 1538.0000 - val_accuracy: 0.9927 - val_precision: 0.8720 - val_recall: 0.4583 - val_auc: 0.9598
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2add9c668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2ade98eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2add732e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2add73d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2add73f98>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293178400>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2931786a0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293178978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2d8108780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293fc9ba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293fc9f60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293fc9240>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293fc9b38>]
          

Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_61 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_123 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_123 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_124 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_124 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_41 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_125 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_125 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0432 - tp: 546.0000 - fp: 391.0000 - tn: 253367.0000 - fn: 2581.0000 - accuracy: 0.9884 - precision: 0.5827 - recall: 0.1746 - auc: 0.9003 - val_loss: 0.0291 - val_tp: 958.0000 - val_fp: 388.0000 - val_tn: 234631.0000 - val_fn: 1881.0000 - val_accuracy: 0.9905 - val_precision: 0.7117 - val_recall: 0.3374 - val_auc: 0.9702
256885/256885 - 108s - loss: 0.0432 - tp: 546.0000 - fp: 391.0000 - tn: 253367.0000 - fn: 2581.0000 - accuracy: 0.9884 - precision: 0.5827 - recall: 0.1746 - auc: 0.9003 - val_loss: 0.0291 - val_tp: 958.0000 - val_fp: 388.0000 - val_tn: 234631.0000 - val_fn: 1881.0000 - val_accuracy: 0.9905 - val_precision: 0.7117 - val_recall: 0.3374 - val_auc: 0.9702
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0272 - tp: 1396.0000 - fp: 468.0000 - tn: 253290.0000 - fn: 1731.0000 - accuracy: 0.9914 - precision: 0.7489 - recall: 0.4464 - auc: 0.9658 - val_loss: 0.0221 - val_tp: 1719.0000 - val_fp: 606.0000 - val_tn: 234413.0000 - val_fn: 1120.0000 - val_accuracy: 0.9927 - val_precision: 0.7394 - val_recall: 0.6055 - val_auc: 0.9784
256885/256885 - 105s - loss: 0.0272 - tp: 1396.0000 - fp: 468.0000 - tn: 253290.0000 - fn: 1731.0000 - accuracy: 0.9914 - precision: 0.7489 - recall: 0.4464 - auc: 0.9658 - val_loss: 0.0221 - val_tp: 1719.0000 - val_fp: 606.0000 - val_tn: 234413.0000 - val_fn: 1120.0000 - val_accuracy: 0.9927 - val_precision: 0.7394 - val_recall: 0.6055 - val_auc: 0.9784
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a212a320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff28f4e8f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a2119630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23a81fb00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23a81f940>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23a81fef0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff28f4ef1d0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff28f4ef4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293fc9f60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293fc9e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2ade8ff28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2add9c6a0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2add9c6d8>]
          

Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_62 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_126 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_126 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_127 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_127 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_42 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_128 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_128 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0429 - tp: 552.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 2564.0000 - accuracy: 0.9885 - precision: 0.5798 - recall: 0.1772 - auc: 0.8991 - val_loss: 0.0308 - val_tp: 1058.0000 - val_fp: 606.0000 - val_tn: 234413.0000 - val_fn: 1781.0000 - val_accuracy: 0.9900 - val_precision: 0.6358 - val_recall: 0.3727 - val_auc: 0.9720
256885/256885 - 109s - loss: 0.0429 - tp: 552.0000 - fp: 400.0000 - tn: 253369.0000 - fn: 2564.0000 - accuracy: 0.9885 - precision: 0.5798 - recall: 0.1772 - auc: 0.8991 - val_loss: 0.0308 - val_tp: 1058.0000 - val_fp: 606.0000 - val_tn: 234413.0000 - val_fn: 1781.0000 - val_accuracy: 0.9900 - val_precision: 0.6358 - val_recall: 0.3727 - val_auc: 0.9720
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0279 - tp: 1374.0000 - fp: 485.0000 - tn: 253284.0000 - fn: 1742.0000 - accuracy: 0.9913 - precision: 0.7391 - recall: 0.4409 - auc: 0.9635 - val_loss: 0.0228 - val_tp: 1456.0000 - val_fp: 325.0000 - val_tn: 234694.0000 - val_fn: 1383.0000 - val_accuracy: 0.9928 - val_precision: 0.8175 - val_recall: 0.5129 - val_auc: 0.9742
256885/256885 - 105s - loss: 0.0279 - tp: 1374.0000 - fp: 485.0000 - tn: 253284.0000 - fn: 1742.0000 - accuracy: 0.9913 - precision: 0.7391 - recall: 0.4409 - auc: 0.9635 - val_loss: 0.0228 - val_tp: 1456.0000 - val_fp: 325.0000 - val_tn: 234694.0000 - val_fn: 1383.0000 - val_accuracy: 0.9928 - val_precision: 0.8175 - val_recall: 0.5129 - val_auc: 0.9742
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff293caac50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b701d0b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b299828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b2993c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b286748>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b286390>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b286048>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b276908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2add9c6d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a21201d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a21085c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2ade988d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293fc9e48>]
          

Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_63 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_129 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_129 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_130 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_130 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_43 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_131 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_131 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0428 - tp: 560.0000 - fp: 447.0000 - tn: 253345.0000 - fn: 2533.0000 - accuracy: 0.9884 - precision: 0.5561 - recall: 0.1811 - auc: 0.8991 - val_loss: 0.0312 - val_tp: 709.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2130.0000 - val_accuracy: 0.9901 - val_precision: 0.7535 - val_recall: 0.2497 - val_auc: 0.9551
256885/256885 - 109s - loss: 0.0428 - tp: 560.0000 - fp: 447.0000 - tn: 253345.0000 - fn: 2533.0000 - accuracy: 0.9884 - precision: 0.5561 - recall: 0.1811 - auc: 0.8991 - val_loss: 0.0312 - val_tp: 709.0000 - val_fp: 232.0000 - val_tn: 234787.0000 - val_fn: 2130.0000 - val_accuracy: 0.9901 - val_precision: 0.7535 - val_recall: 0.2497 - val_auc: 0.9551
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0265 - tp: 1432.0000 - fp: 448.0000 - tn: 253344.0000 - fn: 1661.0000 - accuracy: 0.9918 - precision: 0.7617 - recall: 0.4630 - auc: 0.9663 - val_loss: 0.0218 - val_tp: 1496.0000 - val_fp: 299.0000 - val_tn: 234720.0000 - val_fn: 1343.0000 - val_accuracy: 0.9931 - val_precision: 0.8334 - val_recall: 0.5269 - val_auc: 0.9744
256885/256885 - 106s - loss: 0.0265 - tp: 1432.0000 - fp: 448.0000 - tn: 253344.0000 - fn: 1661.0000 - accuracy: 0.9918 - precision: 0.7617 - recall: 0.4630 - auc: 0.9663 - val_loss: 0.0218 - val_tp: 1496.0000 - val_fp: 299.0000 - val_tn: 234720.0000 - val_fn: 1343.0000 - val_accuracy: 0.9931 - val_precision: 0.8334 - val_recall: 0.5269 - val_auc: 0.9744
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2440c35f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2440ee438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b4822b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b482d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b482f98>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b5595400>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b55956a0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b5595978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a2120160>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293fc9b38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b24f6a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b24f860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2440fe208>]
          

Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_64 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_132 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_132 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_133 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_133 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_44 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_134 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_134 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0437 - tp: 587.0000 - fp: 446.0000 - tn: 253293.0000 - fn: 2559.0000 - accuracy: 0.9883 - precision: 0.5682 - recall: 0.1866 - auc: 0.8987 - val_loss: 0.0316 - val_tp: 806.0000 - val_fp: 281.0000 - val_tn: 234738.0000 - val_fn: 2033.0000 - val_accuracy: 0.9903 - val_precision: 0.7415 - val_recall: 0.2839 - val_auc: 0.9481
256885/256885 - 108s - loss: 0.0437 - tp: 587.0000 - fp: 446.0000 - tn: 253293.0000 - fn: 2559.0000 - accuracy: 0.9883 - precision: 0.5682 - recall: 0.1866 - auc: 0.8987 - val_loss: 0.0316 - val_tp: 806.0000 - val_fp: 281.0000 - val_tn: 234738.0000 - val_fn: 2033.0000 - val_accuracy: 0.9903 - val_precision: 0.7415 - val_recall: 0.2839 - val_auc: 0.9481
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0271 - tp: 1440.0000 - fp: 456.0000 - tn: 253283.0000 - fn: 1706.0000 - accuracy: 0.9916 - precision: 0.7595 - recall: 0.4577 - auc: 0.9647 - val_loss: 0.0214 - val_tp: 1676.0000 - val_fp: 439.0000 - val_tn: 234580.0000 - val_fn: 1163.0000 - val_accuracy: 0.9933 - val_precision: 0.7924 - val_recall: 0.5903 - val_auc: 0.9829
256885/256885 - 105s - loss: 0.0271 - tp: 1440.0000 - fp: 456.0000 - tn: 253283.0000 - fn: 1706.0000 - accuracy: 0.9916 - precision: 0.7595 - recall: 0.4577 - auc: 0.9647 - val_loss: 0.0214 - val_tp: 1676.0000 - val_fp: 439.0000 - val_tn: 234580.0000 - val_fn: 1163.0000 - val_accuracy: 0.9933 - val_precision: 0.7924 - val_recall: 0.5903 - val_auc: 0.9829
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292b355f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292b11e10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292ad12b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292ad1d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292ad1f98>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292dc7400>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292dc76a0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292dc7978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b24f6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2add9c6d8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2440c3198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2440c36a0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292b1b208>]
          

Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_65 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_135 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_135 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_136 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_136 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_45 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_137 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_137 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0426 - tp: 548.0000 - fp: 396.0000 - tn: 253382.0000 - fn: 2559.0000 - accuracy: 0.9885 - precision: 0.5805 - recall: 0.1764 - auc: 0.9040 - val_loss: 0.0329 - val_tp: 646.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 2193.0000 - val_accuracy: 0.9899 - val_precision: 0.7564 - val_recall: 0.2275 - val_auc: 0.9500
256885/256885 - 108s - loss: 0.0426 - tp: 548.0000 - fp: 396.0000 - tn: 253382.0000 - fn: 2559.0000 - accuracy: 0.9885 - precision: 0.5805 - recall: 0.1764 - auc: 0.9040 - val_loss: 0.0329 - val_tp: 646.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 2193.0000 - val_accuracy: 0.9899 - val_precision: 0.7564 - val_recall: 0.2275 - val_auc: 0.9500
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 106s - loss: 0.0278 - tp: 1388.0000 - fp: 468.0000 - tn: 253310.0000 - fn: 1719.0000 - accuracy: 0.9915 - precision: 0.7478 - recall: 0.4467 - auc: 0.9625 - val_loss: 0.0250 - val_tp: 1354.0000 - val_fp: 303.0000 - val_tn: 234716.0000 - val_fn: 1485.0000 - val_accuracy: 0.9925 - val_precision: 0.8171 - val_recall: 0.4769 - val_auc: 0.9543
256885/256885 - 106s - loss: 0.0278 - tp: 1388.0000 - fp: 468.0000 - tn: 253310.0000 - fn: 1719.0000 - accuracy: 0.9915 - precision: 0.7478 - recall: 0.4467 - auc: 0.9625 - val_loss: 0.0250 - val_tp: 1354.0000 - val_fp: 303.0000 - val_tn: 234716.0000 - val_fn: 1485.0000 - val_accuracy: 0.9925 - val_precision: 0.8171 - val_recall: 0.4769 - val_auc: 0.9543
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23ef430b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23ef53c88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23ef60630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ef60828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ef60ac8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ef60e80>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23e72f160>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23e72f438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2440c3198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293fc9b38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff292b35630>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292b356a0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23efc4278>]
          

Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_66 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_138 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_138 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_139 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_139 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_46 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_140 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_140 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0424 - tp: 592.0000 - fp: 376.0000 - tn: 253418.0000 - fn: 2499.0000 - accuracy: 0.9888 - precision: 0.6116 - recall: 0.1915 - auc: 0.8998 - val_loss: 0.0364 - val_tp: 537.0000 - val_fp: 166.0000 - val_tn: 234853.0000 - val_fn: 2302.0000 - val_accuracy: 0.9896 - val_precision: 0.7639 - val_recall: 0.1892 - val_auc: 0.9219
256885/256885 - 110s - loss: 0.0424 - tp: 592.0000 - fp: 376.0000 - tn: 253418.0000 - fn: 2499.0000 - accuracy: 0.9888 - precision: 0.6116 - recall: 0.1915 - auc: 0.8998 - val_loss: 0.0364 - val_tp: 537.0000 - val_fp: 166.0000 - val_tn: 234853.0000 - val_fn: 2302.0000 - val_accuracy: 0.9896 - val_precision: 0.7639 - val_recall: 0.1892 - val_auc: 0.9219
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0272 - tp: 1389.0000 - fp: 476.0000 - tn: 253318.0000 - fn: 1702.0000 - accuracy: 0.9915 - precision: 0.7448 - recall: 0.4494 - auc: 0.9624 - val_loss: 0.0236 - val_tp: 1350.0000 - val_fp: 246.0000 - val_tn: 234773.0000 - val_fn: 1489.0000 - val_accuracy: 0.9927 - val_precision: 0.8459 - val_recall: 0.4755 - val_auc: 0.9642
256885/256885 - 105s - loss: 0.0272 - tp: 1389.0000 - fp: 476.0000 - tn: 253318.0000 - fn: 1702.0000 - accuracy: 0.9915 - precision: 0.7448 - recall: 0.4494 - auc: 0.9624 - val_loss: 0.0236 - val_tp: 1350.0000 - val_fp: 246.0000 - val_tn: 234773.0000 - val_fn: 1489.0000 - val_accuracy: 0.9927 - val_precision: 0.8459 - val_recall: 0.4755 - val_auc: 0.9642
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3105c0da0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2930754e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a9739e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23a9cfe10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23a9cf320>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23a9cfcc0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a9cf198>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23a98ce80>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292b356a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23ef431d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23ef43160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23ef43128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2440c3630>]
          

Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_67 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_141 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_141 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_142 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_142 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_47 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_143 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_143 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 108s - loss: 0.0434 - tp: 513.0000 - fp: 450.0000 - tn: 253324.0000 - fn: 2598.0000 - accuracy: 0.9881 - precision: 0.5327 - recall: 0.1649 - auc: 0.8954 - val_loss: 0.0301 - val_tp: 892.0000 - val_fp: 382.0000 - val_tn: 234637.0000 - val_fn: 1947.0000 - val_accuracy: 0.9902 - val_precision: 0.7002 - val_recall: 0.3142 - val_auc: 0.9686
256885/256885 - 108s - loss: 0.0434 - tp: 513.0000 - fp: 450.0000 - tn: 253324.0000 - fn: 2598.0000 - accuracy: 0.9881 - precision: 0.5327 - recall: 0.1649 - auc: 0.8954 - val_loss: 0.0301 - val_tp: 892.0000 - val_fp: 382.0000 - val_tn: 234637.0000 - val_fn: 1947.0000 - val_accuracy: 0.9902 - val_precision: 0.7002 - val_recall: 0.3142 - val_auc: 0.9686
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 105s - loss: 0.0275 - tp: 1360.0000 - fp: 463.0000 - tn: 253311.0000 - fn: 1751.0000 - accuracy: 0.9914 - precision: 0.7460 - recall: 0.4372 - auc: 0.9620 - val_loss: 0.0219 - val_tp: 1583.0000 - val_fp: 430.0000 - val_tn: 234589.0000 - val_fn: 1256.0000 - val_accuracy: 0.9929 - val_precision: 0.7864 - val_recall: 0.5576 - val_auc: 0.9815
256885/256885 - 105s - loss: 0.0275 - tp: 1360.0000 - fp: 463.0000 - tn: 253311.0000 - fn: 1751.0000 - accuracy: 0.9914 - precision: 0.7460 - recall: 0.4372 - auc: 0.9620 - val_loss: 0.0219 - val_tp: 1583.0000 - val_fp: 430.0000 - val_tn: 234589.0000 - val_fn: 1256.0000 - val_accuracy: 0.9929 - val_precision: 0.7864 - val_recall: 0.5576 - val_auc: 0.9815
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 23s
256885/256885 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23ef84668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23a9e5e80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b2f8320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b2f8dd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293fbd0b8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293fbd470>, <tensorflow.python.keras.metrics.Recall object at 0x7ff293fbd710>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293fbd9e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b24f6a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2440c3668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff28f4974a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f497320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23a9d8278>]
          

Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_68 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_144 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_144 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_145 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_145 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_48 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_146 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_146 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 108s - loss: 0.0424 - tp: 614.0000 - fp: 395.0000 - tn: 253383.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6085 - recall: 0.1976 - auc: 0.9007 - val_loss: 0.0298 - val_tp: 1200.0000 - val_fp: 651.0000 - val_tn: 234368.0000 - val_fn: 1639.0000 - val_accuracy: 0.9904 - val_precision: 0.6483 - val_recall: 0.4227 - val_auc: 0.9721
256886/256886 - 108s - loss: 0.0424 - tp: 614.0000 - fp: 395.0000 - tn: 253383.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6085 - recall: 0.1976 - auc: 0.9007 - val_loss: 0.0298 - val_tp: 1200.0000 - val_fp: 651.0000 - val_tn: 234368.0000 - val_fn: 1639.0000 - val_accuracy: 0.9904 - val_precision: 0.6483 - val_recall: 0.4227 - val_auc: 0.9721
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 105s - loss: 0.0272 - tp: 1414.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1694.0000 - accuracy: 0.9916 - precision: 0.7574 - recall: 0.4550 - auc: 0.9624 - val_loss: 0.0228 - val_tp: 1388.0000 - val_fp: 215.0000 - val_tn: 234804.0000 - val_fn: 1451.0000 - val_accuracy: 0.9930 - val_precision: 0.8659 - val_recall: 0.4889 - val_auc: 0.9731
256886/256886 - 105s - loss: 0.0272 - tp: 1414.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1694.0000 - accuracy: 0.9916 - precision: 0.7574 - recall: 0.4550 - auc: 0.9624 - val_loss: 0.0228 - val_tp: 1388.0000 - val_fp: 215.0000 - val_tn: 234804.0000 - val_fn: 1451.0000 - val_accuracy: 0.9930 - val_precision: 0.8659 - val_recall: 0.4889 - val_auc: 0.9731
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 23s
256886/256886 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a1d53668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a1d2ce80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a1cae320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1caedd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2927910b8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292791470>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292791710>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2927919e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff28f4974a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff292b356a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23ef84208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23ef84710>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2a1d39278>]
          

Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_69 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_147 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_147 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_148 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_148 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_49 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_149 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_149 (Activation)  (None, 1)                 0         
=================================================================
Total params: 118,501
Trainable params: 118,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 108s - loss: 0.0427 - tp: 593.0000 - fp: 378.0000 - tn: 253384.0000 - fn: 2531.0000 - accuracy: 0.9887 - precision: 0.6107 - recall: 0.1898 - auc: 0.9044 - val_loss: 0.0298 - val_tp: 1247.0000 - val_fp: 812.0000 - val_tn: 234207.0000 - val_fn: 1592.0000 - val_accuracy: 0.9899 - val_precision: 0.6056 - val_recall: 0.4392 - val_auc: 0.9713
256886/256886 - 108s - loss: 0.0427 - tp: 593.0000 - fp: 378.0000 - tn: 253384.0000 - fn: 2531.0000 - accuracy: 0.9887 - precision: 0.6107 - recall: 0.1898 - auc: 0.9044 - val_loss: 0.0298 - val_tp: 1247.0000 - val_fp: 812.0000 - val_tn: 234207.0000 - val_fn: 1592.0000 - val_accuracy: 0.9899 - val_precision: 0.6056 - val_recall: 0.4392 - val_auc: 0.9713
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 105s - loss: 0.0273 - tp: 1421.0000 - fp: 459.0000 - tn: 253303.0000 - fn: 1703.0000 - accuracy: 0.9916 - precision: 0.7559 - recall: 0.4549 - auc: 0.9630 - val_loss: 0.0218 - val_tp: 1650.0000 - val_fp: 463.0000 - val_tn: 234556.0000 - val_fn: 1189.0000 - val_accuracy: 0.9931 - val_precision: 0.7809 - val_recall: 0.5812 - val_auc: 0.9823
256886/256886 - 105s - loss: 0.0273 - tp: 1421.0000 - fp: 459.0000 - tn: 253303.0000 - fn: 1703.0000 - accuracy: 0.9916 - precision: 0.7559 - recall: 0.4549 - auc: 0.9630 - val_loss: 0.0218 - val_tp: 1650.0000 - val_fp: 463.0000 - val_tn: 234556.0000 - val_fn: 1189.0000 - val_accuracy: 0.9931 - val_precision: 0.7809 - val_recall: 0.5812 - val_auc: 0.9823
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 23s
256886/256886 - 23s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23e422668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e47ce80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e43b320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23e43bdd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23dc370b8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23dc37470>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23dc37710>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23dc379e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23ef84208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23ef431d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a1d53208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2a1d53710>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23e406278>]
          

Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_70 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_150 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_150 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_151 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_151 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_50 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_152 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_152 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 135s - loss: 0.0428 - tp: 562.0000 - fp: 450.0000 - tn: 253309.0000 - fn: 2564.0000 - accuracy: 0.9883 - precision: 0.5553 - recall: 0.1798 - auc: 0.9003 - val_loss: 0.0342 - val_tp: 1427.0000 - val_fp: 1096.0000 - val_tn: 233923.0000 - val_fn: 1412.0000 - val_accuracy: 0.9895 - val_precision: 0.5656 - val_recall: 0.5026 - val_auc: 0.9768
256885/256885 - 135s - loss: 0.0428 - tp: 562.0000 - fp: 450.0000 - tn: 253309.0000 - fn: 2564.0000 - accuracy: 0.9883 - precision: 0.5553 - recall: 0.1798 - auc: 0.9003 - val_loss: 0.0342 - val_tp: 1427.0000 - val_fp: 1096.0000 - val_tn: 233923.0000 - val_fn: 1412.0000 - val_accuracy: 0.9895 - val_precision: 0.5656 - val_recall: 0.5026 - val_auc: 0.9768
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0276 - tp: 1425.0000 - fp: 482.0000 - tn: 253277.0000 - fn: 1701.0000 - accuracy: 0.9915 - precision: 0.7472 - recall: 0.4559 - auc: 0.9648 - val_loss: 0.0223 - val_tp: 1771.0000 - val_fp: 670.0000 - val_tn: 234349.0000 - val_fn: 1068.0000 - val_accuracy: 0.9927 - val_precision: 0.7255 - val_recall: 0.6238 - val_auc: 0.9840
256885/256885 - 131s - loss: 0.0276 - tp: 1425.0000 - fp: 482.0000 - tn: 253277.0000 - fn: 1701.0000 - accuracy: 0.9915 - precision: 0.7472 - recall: 0.4559 - auc: 0.9648 - val_loss: 0.0223 - val_tp: 1771.0000 - val_fp: 670.0000 - val_tn: 234349.0000 - val_fn: 1068.0000 - val_accuracy: 0.9927 - val_precision: 0.7255 - val_recall: 0.6238 - val_auc: 0.9840
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23e422e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2926c08d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff29273ada0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff29273aba8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff29273a780>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292731f60>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292731208>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292731ba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a1d53710>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff31067e8d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23ef84208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2923c3048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2923c39e8>]
          

Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_71 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_153 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_153 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_154 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_154 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_51 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_155 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_155 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0432 - tp: 540.0000 - fp: 397.0000 - tn: 253361.0000 - fn: 2587.0000 - accuracy: 0.9884 - precision: 0.5763 - recall: 0.1727 - auc: 0.8974 - val_loss: 0.0376 - val_tp: 1508.0000 - val_fp: 1603.0000 - val_tn: 233416.0000 - val_fn: 1331.0000 - val_accuracy: 0.9877 - val_precision: 0.4847 - val_recall: 0.5312 - val_auc: 0.9762
256885/256885 - 134s - loss: 0.0432 - tp: 540.0000 - fp: 397.0000 - tn: 253361.0000 - fn: 2587.0000 - accuracy: 0.9884 - precision: 0.5763 - recall: 0.1727 - auc: 0.8974 - val_loss: 0.0376 - val_tp: 1508.0000 - val_fp: 1603.0000 - val_tn: 233416.0000 - val_fn: 1331.0000 - val_accuracy: 0.9877 - val_precision: 0.4847 - val_recall: 0.5312 - val_auc: 0.9762
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0277 - tp: 1407.0000 - fp: 504.0000 - tn: 253254.0000 - fn: 1720.0000 - accuracy: 0.9913 - precision: 0.7363 - recall: 0.4500 - auc: 0.9659 - val_loss: 0.0226 - val_tp: 1713.0000 - val_fp: 461.0000 - val_tn: 234558.0000 - val_fn: 1126.0000 - val_accuracy: 0.9933 - val_precision: 0.7879 - val_recall: 0.6034 - val_auc: 0.9842
256885/256885 - 131s - loss: 0.0277 - tp: 1407.0000 - fp: 504.0000 - tn: 253254.0000 - fn: 1720.0000 - accuracy: 0.9913 - precision: 0.7363 - recall: 0.4500 - auc: 0.9659 - val_loss: 0.0226 - val_tp: 1713.0000 - val_fp: 461.0000 - val_tn: 234558.0000 - val_fn: 1126.0000 - val_accuracy: 0.9933 - val_precision: 0.7879 - val_recall: 0.6034 - val_auc: 0.9842
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b54db860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2ade5f860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a9a0f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23a9927b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23a992a58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23a992e10>, <tensorflow.python.keras.metrics.Recall object at 0x7ff28f45a0f0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff28f45a3c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2923c3048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2923c3240>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2923c34a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23e422710>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2a1d53710>]
          

Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_72 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_156 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_156 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_157 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_157 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_52 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_158 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_158 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0426 - tp: 591.0000 - fp: 412.0000 - tn: 253357.0000 - fn: 2525.0000 - accuracy: 0.9886 - precision: 0.5892 - recall: 0.1897 - auc: 0.9003 - val_loss: 0.0319 - val_tp: 1265.0000 - val_fp: 789.0000 - val_tn: 234230.0000 - val_fn: 1574.0000 - val_accuracy: 0.9901 - val_precision: 0.6159 - val_recall: 0.4456 - val_auc: 0.9774
256885/256885 - 134s - loss: 0.0426 - tp: 591.0000 - fp: 412.0000 - tn: 253357.0000 - fn: 2525.0000 - accuracy: 0.9886 - precision: 0.5892 - recall: 0.1897 - auc: 0.9003 - val_loss: 0.0319 - val_tp: 1265.0000 - val_fp: 789.0000 - val_tn: 234230.0000 - val_fn: 1574.0000 - val_accuracy: 0.9901 - val_precision: 0.6159 - val_recall: 0.4456 - val_auc: 0.9774
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0274 - tp: 1433.0000 - fp: 467.0000 - tn: 253302.0000 - fn: 1683.0000 - accuracy: 0.9916 - precision: 0.7542 - recall: 0.4599 - auc: 0.9621 - val_loss: 0.0255 - val_tp: 1240.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 1599.0000 - val_accuracy: 0.9924 - val_precision: 0.8564 - val_recall: 0.4368 - val_auc: 0.9524
256885/256885 - 130s - loss: 0.0274 - tp: 1433.0000 - fp: 467.0000 - tn: 253302.0000 - fn: 1683.0000 - accuracy: 0.9916 - precision: 0.7542 - recall: 0.4599 - auc: 0.9621 - val_loss: 0.0255 - val_tp: 1240.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 1599.0000 - val_accuracy: 0.9924 - val_precision: 0.8564 - val_recall: 0.4368 - val_auc: 0.9524
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0230 - tp: 1796.0000 - fp: 427.0000 - tn: 253342.0000 - fn: 1320.0000 - accuracy: 0.9932 - precision: 0.8079 - recall: 0.5764 - auc: 0.9683 - val_loss: 0.0197 - val_tp: 1738.0000 - val_fp: 376.0000 - val_tn: 234643.0000 - val_fn: 1101.0000 - val_accuracy: 0.9938 - val_precision: 0.8221 - val_recall: 0.6122 - val_auc: 0.9781
256885/256885 - 130s - loss: 0.0230 - tp: 1796.0000 - fp: 427.0000 - tn: 253342.0000 - fn: 1320.0000 - accuracy: 0.9932 - precision: 0.8079 - recall: 0.5764 - auc: 0.9683 - val_loss: 0.0197 - val_tp: 1738.0000 - val_fp: 376.0000 - val_tn: 234643.0000 - val_fn: 1101.0000 - val_accuracy: 0.9938 - val_precision: 0.8221 - val_recall: 0.6122 - val_auc: 0.9781
Epoch 00003: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff24410da58>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e90a860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23ebc8f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ebd37b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ebd3a58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ebd3e10>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23ebc00f0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23ebc03c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23e4226d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a1d53710>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a1d536d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f6d0128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff28f6d0048>]
          

Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_73 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_159 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_159 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_160 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_160 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_53 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_161 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_161 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0429 - tp: 556.0000 - fp: 405.0000 - tn: 253387.0000 - fn: 2537.0000 - accuracy: 0.9885 - precision: 0.5786 - recall: 0.1798 - auc: 0.8980 - val_loss: 0.0294 - val_tp: 1069.0000 - val_fp: 542.0000 - val_tn: 234477.0000 - val_fn: 1770.0000 - val_accuracy: 0.9903 - val_precision: 0.6636 - val_recall: 0.3765 - val_auc: 0.9711
256885/256885 - 134s - loss: 0.0429 - tp: 556.0000 - fp: 405.0000 - tn: 253387.0000 - fn: 2537.0000 - accuracy: 0.9885 - precision: 0.5786 - recall: 0.1798 - auc: 0.8980 - val_loss: 0.0294 - val_tp: 1069.0000 - val_fp: 542.0000 - val_tn: 234477.0000 - val_fn: 1770.0000 - val_accuracy: 0.9903 - val_precision: 0.6636 - val_recall: 0.3765 - val_auc: 0.9711
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0272 - tp: 1423.0000 - fp: 452.0000 - tn: 253340.0000 - fn: 1670.0000 - accuracy: 0.9917 - precision: 0.7589 - recall: 0.4601 - auc: 0.9632 - val_loss: 0.0219 - val_tp: 1475.0000 - val_fp: 274.0000 - val_tn: 234745.0000 - val_fn: 1364.0000 - val_accuracy: 0.9931 - val_precision: 0.8433 - val_recall: 0.5195 - val_auc: 0.9783
256885/256885 - 131s - loss: 0.0272 - tp: 1423.0000 - fp: 452.0000 - tn: 253340.0000 - fn: 1670.0000 - accuracy: 0.9917 - precision: 0.7589 - recall: 0.4601 - auc: 0.9632 - val_loss: 0.0219 - val_tp: 1475.0000 - val_fp: 274.0000 - val_tn: 234745.0000 - val_fn: 1364.0000 - val_accuracy: 0.9931 - val_precision: 0.8433 - val_recall: 0.5195 - val_auc: 0.9783
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23d95ec18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23d94c860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23d902f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23d90e7b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23d90ea58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23d90ee10>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23d9120f0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23d9123c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff28f6d0128>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23ef846a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23e93b080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23e93b0b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2923c3048>]
          

Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_74 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_162 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_162 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_163 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_163 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_54 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_164 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_164 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 135s - loss: 0.0428 - tp: 560.0000 - fp: 440.0000 - tn: 253299.0000 - fn: 2586.0000 - accuracy: 0.9882 - precision: 0.5600 - recall: 0.1780 - auc: 0.9080 - val_loss: 0.0294 - val_tp: 887.0000 - val_fp: 352.0000 - val_tn: 234667.0000 - val_fn: 1952.0000 - val_accuracy: 0.9903 - val_precision: 0.7159 - val_recall: 0.3124 - val_auc: 0.9645
256885/256885 - 135s - loss: 0.0428 - tp: 560.0000 - fp: 440.0000 - tn: 253299.0000 - fn: 2586.0000 - accuracy: 0.9882 - precision: 0.5600 - recall: 0.1780 - auc: 0.9080 - val_loss: 0.0294 - val_tp: 887.0000 - val_fp: 352.0000 - val_tn: 234667.0000 - val_fn: 1952.0000 - val_accuracy: 0.9903 - val_precision: 0.7159 - val_recall: 0.3124 - val_auc: 0.9645
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0276 - tp: 1416.0000 - fp: 501.0000 - tn: 253238.0000 - fn: 1730.0000 - accuracy: 0.9913 - precision: 0.7387 - recall: 0.4501 - auc: 0.9633 - val_loss: 0.0302 - val_tp: 2081.0000 - val_fp: 1202.0000 - val_tn: 233817.0000 - val_fn: 758.0000 - val_accuracy: 0.9918 - val_precision: 0.6339 - val_recall: 0.7330 - val_auc: 0.9882
256885/256885 - 130s - loss: 0.0276 - tp: 1416.0000 - fp: 501.0000 - tn: 253238.0000 - fn: 1730.0000 - accuracy: 0.9913 - precision: 0.7387 - recall: 0.4501 - auc: 0.9633 - val_loss: 0.0302 - val_tp: 2081.0000 - val_fp: 1202.0000 - val_tn: 233817.0000 - val_fn: 758.0000 - val_accuracy: 0.9918 - val_precision: 0.6339 - val_recall: 0.7330 - val_auc: 0.9882
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23eb967b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2927fc400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e92a198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2927c8e80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2927c8f60>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2927c8438>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2927c8208>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2927d5be0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2923c3048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23d96f128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23d96f048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f6d0128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2442324a8>]
          

Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_75 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_165 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_165 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_166 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_166 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_55 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_167 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_167 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0425 - tp: 555.0000 - fp: 404.0000 - tn: 253374.0000 - fn: 2552.0000 - accuracy: 0.9885 - precision: 0.5787 - recall: 0.1786 - auc: 0.9033 - val_loss: 0.0312 - val_tp: 638.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 2201.0000 - val_accuracy: 0.9900 - val_precision: 0.7743 - val_recall: 0.2247 - val_auc: 0.9581
256885/256885 - 134s - loss: 0.0425 - tp: 555.0000 - fp: 404.0000 - tn: 253374.0000 - fn: 2552.0000 - accuracy: 0.9885 - precision: 0.5787 - recall: 0.1786 - auc: 0.9033 - val_loss: 0.0312 - val_tp: 638.0000 - val_fp: 186.0000 - val_tn: 234833.0000 - val_fn: 2201.0000 - val_accuracy: 0.9900 - val_precision: 0.7743 - val_recall: 0.2247 - val_auc: 0.9581
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0275 - tp: 1408.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1699.0000 - accuracy: 0.9916 - precision: 0.7566 - recall: 0.4532 - auc: 0.9610 - val_loss: 0.0223 - val_tp: 1469.0000 - val_fp: 297.0000 - val_tn: 234722.0000 - val_fn: 1370.0000 - val_accuracy: 0.9930 - val_precision: 0.8318 - val_recall: 0.5174 - val_auc: 0.9723
256885/256885 - 132s - loss: 0.0275 - tp: 1408.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1699.0000 - accuracy: 0.9916 - precision: 0.7566 - recall: 0.4532 - auc: 0.9610 - val_loss: 0.0223 - val_tp: 1469.0000 - val_fp: 297.0000 - val_tn: 234722.0000 - val_fn: 1370.0000 - val_accuracy: 0.9930 - val_precision: 0.8318 - val_recall: 0.5174 - val_auc: 0.9723
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff3106a2cc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5c2e240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b4a3f748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b4a4d198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b4a4d438>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b4a4d7f0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b4a4da90>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b4a4dd68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23d96f048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff244232198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff244232358>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b8db470>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23e93b080>]
          

Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_76 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_168 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_168 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_169 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_56 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_170 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_170 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0431 - tp: 571.0000 - fp: 427.0000 - tn: 253367.0000 - fn: 2520.0000 - accuracy: 0.9885 - precision: 0.5721 - recall: 0.1847 - auc: 0.8947 - val_loss: 0.0322 - val_tp: 692.0000 - val_fp: 212.0000 - val_tn: 234807.0000 - val_fn: 2147.0000 - val_accuracy: 0.9901 - val_precision: 0.7655 - val_recall: 0.2437 - val_auc: 0.9477
256885/256885 - 134s - loss: 0.0431 - tp: 571.0000 - fp: 427.0000 - tn: 253367.0000 - fn: 2520.0000 - accuracy: 0.9885 - precision: 0.5721 - recall: 0.1847 - auc: 0.8947 - val_loss: 0.0322 - val_tp: 692.0000 - val_fp: 212.0000 - val_tn: 234807.0000 - val_fn: 2147.0000 - val_accuracy: 0.9901 - val_precision: 0.7655 - val_recall: 0.2437 - val_auc: 0.9477
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 129s - loss: 0.0271 - tp: 1399.0000 - fp: 442.0000 - tn: 253352.0000 - fn: 1692.0000 - accuracy: 0.9917 - precision: 0.7599 - recall: 0.4526 - auc: 0.9620 - val_loss: 0.0223 - val_tp: 1512.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1327.0000 - val_accuracy: 0.9931 - val_precision: 0.8253 - val_recall: 0.5326 - val_auc: 0.9720
256885/256885 - 129s - loss: 0.0271 - tp: 1399.0000 - fp: 442.0000 - tn: 253352.0000 - fn: 1692.0000 - accuracy: 0.9917 - precision: 0.7599 - recall: 0.4526 - auc: 0.9620 - val_loss: 0.0223 - val_tp: 1512.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1327.0000 - val_accuracy: 0.9931 - val_precision: 0.8253 - val_recall: 0.5326 - val_auc: 0.9720
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292f7aa20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23ea041d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff244272940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1b15128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a1b153c8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a1b15780>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a1b15a20>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2a1b15cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23e93b080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5ddf9e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b5ddf4e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff244232198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff244232e80>]
          

Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_77 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_171 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_171 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_172 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_172 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_57 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_173 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_173 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 134s - loss: 0.0429 - tp: 520.0000 - fp: 401.0000 - tn: 253373.0000 - fn: 2591.0000 - accuracy: 0.9884 - precision: 0.5646 - recall: 0.1671 - auc: 0.9022 - val_loss: 0.0306 - val_tp: 761.0000 - val_fp: 281.0000 - val_tn: 234738.0000 - val_fn: 2078.0000 - val_accuracy: 0.9901 - val_precision: 0.7303 - val_recall: 0.2681 - val_auc: 0.9597
256885/256885 - 134s - loss: 0.0429 - tp: 520.0000 - fp: 401.0000 - tn: 253373.0000 - fn: 2591.0000 - accuracy: 0.9884 - precision: 0.5646 - recall: 0.1671 - auc: 0.9022 - val_loss: 0.0306 - val_tp: 761.0000 - val_fp: 281.0000 - val_tn: 234738.0000 - val_fn: 2078.0000 - val_accuracy: 0.9901 - val_precision: 0.7303 - val_recall: 0.2681 - val_auc: 0.9597
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 131s - loss: 0.0274 - tp: 1394.0000 - fp: 483.0000 - tn: 253291.0000 - fn: 1717.0000 - accuracy: 0.9914 - precision: 0.7427 - recall: 0.4481 - auc: 0.9646 - val_loss: 0.0219 - val_tp: 1639.0000 - val_fp: 497.0000 - val_tn: 234522.0000 - val_fn: 1200.0000 - val_accuracy: 0.9929 - val_precision: 0.7673 - val_recall: 0.5773 - val_auc: 0.9817
256885/256885 - 131s - loss: 0.0274 - tp: 1394.0000 - fp: 483.0000 - tn: 253291.0000 - fn: 1717.0000 - accuracy: 0.9914 - precision: 0.7427 - recall: 0.4481 - auc: 0.9646 - val_loss: 0.0219 - val_tp: 1639.0000 - val_fp: 497.0000 - val_tn: 234522.0000 - val_fn: 1200.0000 - val_accuracy: 0.9929 - val_precision: 0.7673 - val_recall: 0.5773 - val_auc: 0.9817
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 31s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a157f908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a15771d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a152e940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1535128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a15353c8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a1535780>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a1535a20>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2a1535cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff244232e80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff24424f4e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff24424f9e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b5ddf9e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b5ddf278>]
          

Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_78 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_174 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_174 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_175 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_175 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_58 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_176 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_176 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 134s - loss: 0.0428 - tp: 566.0000 - fp: 374.0000 - tn: 253404.0000 - fn: 2542.0000 - accuracy: 0.9886 - precision: 0.6021 - recall: 0.1821 - auc: 0.9032 - val_loss: 0.0290 - val_tp: 1076.0000 - val_fp: 484.0000 - val_tn: 234535.0000 - val_fn: 1763.0000 - val_accuracy: 0.9906 - val_precision: 0.6897 - val_recall: 0.3790 - val_auc: 0.9665
256886/256886 - 134s - loss: 0.0428 - tp: 566.0000 - fp: 374.0000 - tn: 253404.0000 - fn: 2542.0000 - accuracy: 0.9886 - precision: 0.6021 - recall: 0.1821 - auc: 0.9032 - val_loss: 0.0290 - val_tp: 1076.0000 - val_fp: 484.0000 - val_tn: 234535.0000 - val_fn: 1763.0000 - val_accuracy: 0.9906 - val_precision: 0.6897 - val_recall: 0.3790 - val_auc: 0.9665
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 130s - loss: 0.0272 - tp: 1432.0000 - fp: 473.0000 - tn: 253305.0000 - fn: 1676.0000 - accuracy: 0.9916 - precision: 0.7517 - recall: 0.4607 - auc: 0.9668 - val_loss: 0.0228 - val_tp: 1437.0000 - val_fp: 280.0000 - val_tn: 234739.0000 - val_fn: 1402.0000 - val_accuracy: 0.9929 - val_precision: 0.8369 - val_recall: 0.5062 - val_auc: 0.9663
256886/256886 - 130s - loss: 0.0272 - tp: 1432.0000 - fp: 473.0000 - tn: 253305.0000 - fn: 1676.0000 - accuracy: 0.9916 - precision: 0.7517 - recall: 0.4607 - auc: 0.9668 - val_loss: 0.0228 - val_tp: 1437.0000 - val_fp: 280.0000 - val_tn: 234739.0000 - val_fn: 1402.0000 - val_accuracy: 0.9929 - val_precision: 0.8369 - val_recall: 0.5062 - val_auc: 0.9663
Epoch 00002: early stopping
28542/28542 - 4s
28542/28542 - 3s
256886/256886 - 31s
256886/256886 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23c90b908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23c9021d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23c937940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23c8bf128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23c8bf3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23c8bf780>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23c8bfa20>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23c8bfcf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5ddf4e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b5ddf240>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a15929b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2a15929e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff244232e80>]
          

Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_79 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_177 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_177 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_178 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_178 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_59 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_179 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_179 (Activation)  (None, 1)                 0         
=================================================================
Total params: 166,101
Trainable params: 166,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 136s - loss: 0.0428 - tp: 544.0000 - fp: 401.0000 - tn: 253361.0000 - fn: 2580.0000 - accuracy: 0.9884 - precision: 0.5757 - recall: 0.1741 - auc: 0.9014 - val_loss: 0.0297 - val_tp: 982.0000 - val_fp: 364.0000 - val_tn: 234655.0000 - val_fn: 1857.0000 - val_accuracy: 0.9907 - val_precision: 0.7296 - val_recall: 0.3459 - val_auc: 0.9554
256886/256886 - 136s - loss: 0.0428 - tp: 544.0000 - fp: 401.0000 - tn: 253361.0000 - fn: 2580.0000 - accuracy: 0.9884 - precision: 0.5757 - recall: 0.1741 - auc: 0.9014 - val_loss: 0.0297 - val_tp: 982.0000 - val_fp: 364.0000 - val_tn: 234655.0000 - val_fn: 1857.0000 - val_accuracy: 0.9907 - val_precision: 0.7296 - val_recall: 0.3459 - val_auc: 0.9554
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 132s - loss: 0.0270 - tp: 1431.0000 - fp: 462.0000 - tn: 253300.0000 - fn: 1693.0000 - accuracy: 0.9916 - precision: 0.7559 - recall: 0.4581 - auc: 0.9644 - val_loss: 0.0217 - val_tp: 1572.0000 - val_fp: 319.0000 - val_tn: 234700.0000 - val_fn: 1267.0000 - val_accuracy: 0.9933 - val_precision: 0.8313 - val_recall: 0.5537 - val_auc: 0.9747
256886/256886 - 132s - loss: 0.0270 - tp: 1431.0000 - fp: 462.0000 - tn: 253300.0000 - fn: 1693.0000 - accuracy: 0.9916 - precision: 0.7559 - recall: 0.4581 - auc: 0.9644 - val_loss: 0.0217 - val_tp: 1572.0000 - val_fp: 319.0000 - val_tn: 234700.0000 - val_fn: 1267.0000 - val_accuracy: 0.9933 - val_precision: 0.8313 - val_recall: 0.5537 - val_auc: 0.9747
Epoch 00002: early stopping
28542/28542 - 4s
28542/28542 - 3s
256886/256886 - 31s
256886/256886 - 31s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b44abfd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b5dd89e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292f7ae48>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2930b8128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2930b8908>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2930b8be0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2930b8fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292dca630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a15929e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff244232358>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23c91d4e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23c91d9e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b55f4cc0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292dcada0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292dcaf98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a945c88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b3cf8d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b3cff28>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b3cf6a0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b37eb70>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b37e5f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292b997b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a9c5780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a9c5278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292dcad30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292dca5c0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b37ec50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b37ea90>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b37e6d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b37e518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b3cf828>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b3cf4a8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b3cfeb8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff28f617400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292dcaa90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2926213c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff244232e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b55f4f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292b997b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23a9cfb38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23a9304e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a1db8f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1db8d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a1db89e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a1db8f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a1db8438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2a1db8eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b37e5f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff28f4972b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff28f4975c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f497eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292d6c0b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23da52358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23da522e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23da52160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23da520b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23da96e48>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23da96be0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23da96748>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23da96e80>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23a9cf8d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a973898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a9735c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23da529b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23da52b00>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23da96390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23da96978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23da96438>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23da96518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23da96d68>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23da52fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23da52c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23da52908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23da529e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a9cf6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a973898>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23da96ac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23da96e80>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b288940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b2889b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b28acc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b28ab70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b28ab00>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b28ae80>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b28a278>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b28ab38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23da96080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b511400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b5116a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b288b00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b288ba8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2920aee48>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2920b4748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2920b40b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2920b4240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2920b4d30>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2920b4780>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2920b4828>, <tensorflow.python.keras.metrics.AUC object at 0x7ff293098978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b288278>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23e4dab00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23e4da6d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2920aed68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2920aeac8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2930989b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293098d68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2920aed30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2920b4390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2920b45c0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2920b4c18>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2920b4550>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2920b4f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2920aea90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b2882b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23e4dab00>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff293098b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293098748>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2f07bc2b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f07bc748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b509c320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b5dc2c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff28f6da668>, <tensorflow.python.keras.metrics.Precision object at 0x7ff28f6dad30>, <tensorflow.python.keras.metrics.Recall object at 0x7ff28f6da240>, <tensorflow.python.keras.metrics.AUC object at 0x7ff28f6dad68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff293098cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b6898f60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff292e93f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292e93198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292e93dd8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff292ba35f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292ba3240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a855208>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23a855588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23a855198>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23a8557b8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a855358>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292b4fba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2f07bc278>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff29306c4a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff29306c358>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292ba3f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292ba3470>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23e58bdd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e58b748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e58b0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23e58b128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23e58bf28>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23e58bd68>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23e592f28>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23e592828>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292ba3ac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2d80d9a58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2d80d9e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292b4f860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292b4fb38>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b3b9dd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b375240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b375860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b375048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b3756d8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b375a90>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b3c1d30>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b3c1908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23e58b240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a855358>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a855d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b3b95c0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b3b97f0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b3c1710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b3c1cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b3c1780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b3c16a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b375978>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b3755c0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b3759b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b3759e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b3b9208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23e58b198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2920bb4e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b347940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b347438>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff29366f198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff29366f940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff29366f978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff29366ffd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff29366fd68>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2936f9d30>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2936f9ef0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2936f9828>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b3c1b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a91b470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a91b048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff29366fb38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff29366fa90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23ed31630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23ed31a20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23ed31cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ed310f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ed31da0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ed31898>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23d9f1a20>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23d9f1da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff29366f898>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293fc96a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2937bbf98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2937bb4a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2936f4710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23d9f15c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23d9f1978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23d9f10b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23d9f1518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ed31e48>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ed312e8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23ed31400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23ed31240>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23ed312b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff29366f6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293fc96a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2937bb4a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23d9f1c50>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b8e1be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b8e17f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b8e1588>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b8e1e80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b8297b8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b829b00>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b829c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23dcdfbe0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23d9f1550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff293137e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff293137a20>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b8e1dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b8e1f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b6068f60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b60687b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292fd9cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292fd9d30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292fd9748>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292fd9dd8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b6dd4828>, <tensorflow.python.keras.metrics.AUC object at 0x7ff29213de10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b8e1ba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23dcdfeb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23dcdfdd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2b6068198>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2b6068550>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff29213d748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff29213ddd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b6dd4358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292fdd940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292fd9a20>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292fd9f98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292fd9400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b6068c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b6068438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b8e1cc0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b8e1ba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23dcdfdd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b1fc780>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2928c6ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2928c6eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b527780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b3935f8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b5383be0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b539db38>, <tensorflow.python.keras.metrics.Recall object at 0x7ff28f6c8c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23e92ed68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b5166ba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff292b1b278>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff292b1b080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23ebd35c0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b54d278>]
          

Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_60 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_180 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_180 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_181 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_60 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_182 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_182 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 113s - loss: 0.0414 - tp: 664.0000 - fp: 439.0000 - tn: 253320.0000 - fn: 2462.0000 - accuracy: 0.9887 - precision: 0.6020 - recall: 0.2124 - auc: 0.9083 - val_loss: 0.0284 - val_tp: 981.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1858.0000 - val_accuracy: 0.9909 - val_precision: 0.7587 - val_recall: 0.3455 - val_auc: 0.9648
256885/256885 - 113s - loss: 0.0414 - tp: 664.0000 - fp: 439.0000 - tn: 253320.0000 - fn: 2462.0000 - accuracy: 0.9887 - precision: 0.6020 - recall: 0.2124 - auc: 0.9083 - val_loss: 0.0284 - val_tp: 981.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1858.0000 - val_accuracy: 0.9909 - val_precision: 0.7587 - val_recall: 0.3455 - val_auc: 0.9648
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0253 - tp: 1548.0000 - fp: 435.0000 - tn: 253324.0000 - fn: 1578.0000 - accuracy: 0.9922 - precision: 0.7806 - recall: 0.4952 - auc: 0.9668 - val_loss: 0.0363 - val_tp: 2302.0000 - val_fp: 2328.0000 - val_tn: 232691.0000 - val_fn: 537.0000 - val_accuracy: 0.9880 - val_precision: 0.4972 - val_recall: 0.8108 - val_auc: 0.9887
256885/256885 - 109s - loss: 0.0253 - tp: 1548.0000 - fp: 435.0000 - tn: 253324.0000 - fn: 1578.0000 - accuracy: 0.9922 - precision: 0.7806 - recall: 0.4952 - auc: 0.9668 - val_loss: 0.0363 - val_tp: 2302.0000 - val_fp: 2328.0000 - val_tn: 232691.0000 - val_fn: 537.0000 - val_accuracy: 0.9880 - val_precision: 0.4972 - val_recall: 0.8108 - val_auc: 0.9887
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b67f358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b69ad30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292d8f828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff292d8f978>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff292d8fc18>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292d8ffd0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff292db12b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292db1588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23ebd35c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2928c6518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2928c6cc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2928c6c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2928c6d30>]
          

Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_61 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_183 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_183 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_184 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_184 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_61 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_185 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_185 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 112s - loss: 0.0414 - tp: 611.0000 - fp: 391.0000 - tn: 253367.0000 - fn: 2516.0000 - accuracy: 0.9887 - precision: 0.6098 - recall: 0.1954 - auc: 0.9123 - val_loss: 0.0349 - val_tp: 563.0000 - val_fp: 117.0000 - val_tn: 234902.0000 - val_fn: 2276.0000 - val_accuracy: 0.9899 - val_precision: 0.8279 - val_recall: 0.1983 - val_auc: 0.9258
256885/256885 - 112s - loss: 0.0414 - tp: 611.0000 - fp: 391.0000 - tn: 253367.0000 - fn: 2516.0000 - accuracy: 0.9887 - precision: 0.6098 - recall: 0.1954 - auc: 0.9123 - val_loss: 0.0349 - val_tp: 563.0000 - val_fp: 117.0000 - val_tn: 234902.0000 - val_fn: 2276.0000 - val_accuracy: 0.9899 - val_precision: 0.8279 - val_recall: 0.1983 - val_auc: 0.9258
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0251 - tp: 1562.0000 - fp: 436.0000 - tn: 253322.0000 - fn: 1565.0000 - accuracy: 0.9922 - precision: 0.7818 - recall: 0.4995 - auc: 0.9687 - val_loss: 0.0236 - val_tp: 1329.0000 - val_fp: 148.0000 - val_tn: 234871.0000 - val_fn: 1510.0000 - val_accuracy: 0.9930 - val_precision: 0.8998 - val_recall: 0.4681 - val_auc: 0.9530
256885/256885 - 109s - loss: 0.0251 - tp: 1562.0000 - fp: 436.0000 - tn: 253322.0000 - fn: 1565.0000 - accuracy: 0.9922 - precision: 0.7818 - recall: 0.4995 - auc: 0.9687 - val_loss: 0.0236 - val_tp: 1329.0000 - val_fp: 148.0000 - val_tn: 234871.0000 - val_fn: 1510.0000 - val_accuracy: 0.9930 - val_precision: 0.8998 - val_recall: 0.4681 - val_auc: 0.9530
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff28f4ff438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff28f5124a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2441d0cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2441db470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2441db710>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2441dbac8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2441dbd68>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2441dbf98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2928c6cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2928c6cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b67fd68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b67f780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b67f828>]
          

Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_62 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_186 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_186 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_187 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_187 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_62 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_188 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_188 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 113s - loss: 0.0416 - tp: 592.0000 - fp: 385.0000 - tn: 253384.0000 - fn: 2524.0000 - accuracy: 0.9887 - precision: 0.6059 - recall: 0.1900 - auc: 0.9109 - val_loss: 0.0283 - val_tp: 901.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 1938.0000 - val_accuracy: 0.9907 - val_precision: 0.7688 - val_recall: 0.3174 - val_auc: 0.9739
256885/256885 - 113s - loss: 0.0416 - tp: 592.0000 - fp: 385.0000 - tn: 253384.0000 - fn: 2524.0000 - accuracy: 0.9887 - precision: 0.6059 - recall: 0.1900 - auc: 0.9109 - val_loss: 0.0283 - val_tp: 901.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 1938.0000 - val_accuracy: 0.9907 - val_precision: 0.7688 - val_recall: 0.3174 - val_auc: 0.9739
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0249 - tp: 1551.0000 - fp: 420.0000 - tn: 253349.0000 - fn: 1565.0000 - accuracy: 0.9923 - precision: 0.7869 - recall: 0.4978 - auc: 0.9676 - val_loss: 0.0213 - val_tp: 1602.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1237.0000 - val_accuracy: 0.9936 - val_precision: 0.8494 - val_recall: 0.5643 - val_auc: 0.9652
256885/256885 - 109s - loss: 0.0249 - tp: 1551.0000 - fp: 420.0000 - tn: 253349.0000 - fn: 1565.0000 - accuracy: 0.9923 - precision: 0.7869 - recall: 0.4978 - auc: 0.9676 - val_loss: 0.0213 - val_tp: 1602.0000 - val_fp: 284.0000 - val_tn: 234735.0000 - val_fn: 1237.0000 - val_accuracy: 0.9936 - val_precision: 0.8494 - val_recall: 0.5643 - val_auc: 0.9652
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.9min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23bbdd390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23bbe7cc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23bbee198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23bbeea20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23bbeecc0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23bbeef98>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23c227358>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23c227630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b67f828>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff28f52e828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff28f52ecc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2928c6cc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2928c6d30>]
          

Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_63 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_189 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_189 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_190 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_190 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_63 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_191 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_191 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 113s - loss: 0.0414 - tp: 570.0000 - fp: 380.0000 - tn: 253412.0000 - fn: 2523.0000 - accuracy: 0.9887 - precision: 0.6000 - recall: 0.1843 - auc: 0.9098 - val_loss: 0.0299 - val_tp: 1286.0000 - val_fp: 569.0000 - val_tn: 234450.0000 - val_fn: 1553.0000 - val_accuracy: 0.9911 - val_precision: 0.6933 - val_recall: 0.4530 - val_auc: 0.9780
256885/256885 - 113s - loss: 0.0414 - tp: 570.0000 - fp: 380.0000 - tn: 253412.0000 - fn: 2523.0000 - accuracy: 0.9887 - precision: 0.6000 - recall: 0.1843 - auc: 0.9098 - val_loss: 0.0299 - val_tp: 1286.0000 - val_fp: 569.0000 - val_tn: 234450.0000 - val_fn: 1553.0000 - val_accuracy: 0.9911 - val_precision: 0.6933 - val_recall: 0.4530 - val_auc: 0.9780
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0251 - tp: 1551.0000 - fp: 436.0000 - tn: 253356.0000 - fn: 1542.0000 - accuracy: 0.9923 - precision: 0.7806 - recall: 0.5015 - auc: 0.9662 - val_loss: 0.0223 - val_tp: 2006.0000 - val_fp: 819.0000 - val_tn: 234200.0000 - val_fn: 833.0000 - val_accuracy: 0.9931 - val_precision: 0.7101 - val_recall: 0.7066 - val_auc: 0.9855
256885/256885 - 110s - loss: 0.0251 - tp: 1551.0000 - fp: 436.0000 - tn: 253356.0000 - fn: 1542.0000 - accuracy: 0.9923 - precision: 0.7806 - recall: 0.5015 - auc: 0.9662 - val_loss: 0.0223 - val_tp: 2006.0000 - val_fp: 819.0000 - val_tn: 234200.0000 - val_fn: 833.0000 - val_accuracy: 0.9931 - val_precision: 0.7101 - val_recall: 0.7066 - val_auc: 0.9855
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.9min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff31054c400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff31053e4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff31053e860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff31053e668>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff31053e208>, <tensorflow.python.keras.metrics.Precision object at 0x7ff31053e630>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b45c6f28>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b45c62b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2928c6cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23bbd62e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23bbd6320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23bbd62b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b67f9e8>]
          

Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_64 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_192 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_192 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_193 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_193 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_64 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_194 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_194 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 113s - loss: 0.0419 - tp: 640.0000 - fp: 380.0000 - tn: 253359.0000 - fn: 2506.0000 - accuracy: 0.9888 - precision: 0.6275 - recall: 0.2034 - auc: 0.9085 - val_loss: 0.0288 - val_tp: 1232.0000 - val_fp: 672.0000 - val_tn: 234347.0000 - val_fn: 1607.0000 - val_accuracy: 0.9904 - val_precision: 0.6471 - val_recall: 0.4340 - val_auc: 0.9686
256885/256885 - 113s - loss: 0.0419 - tp: 640.0000 - fp: 380.0000 - tn: 253359.0000 - fn: 2506.0000 - accuracy: 0.9888 - precision: 0.6275 - recall: 0.2034 - auc: 0.9085 - val_loss: 0.0288 - val_tp: 1232.0000 - val_fp: 672.0000 - val_tn: 234347.0000 - val_fn: 1607.0000 - val_accuracy: 0.9904 - val_precision: 0.6471 - val_recall: 0.4340 - val_auc: 0.9686
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 110s - loss: 0.0250 - tp: 1599.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 1547.0000 - accuracy: 0.9924 - precision: 0.7947 - recall: 0.5083 - auc: 0.9673 - val_loss: 0.0200 - val_tp: 1570.0000 - val_fp: 225.0000 - val_tn: 234794.0000 - val_fn: 1269.0000 - val_accuracy: 0.9937 - val_precision: 0.8747 - val_recall: 0.5530 - val_auc: 0.9784
256885/256885 - 110s - loss: 0.0250 - tp: 1599.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 1547.0000 - accuracy: 0.9924 - precision: 0.7947 - recall: 0.5083 - auc: 0.9673 - val_loss: 0.0200 - val_tp: 1570.0000 - val_fp: 225.0000 - val_tn: 234794.0000 - val_fn: 1269.0000 - val_accuracy: 0.9937 - val_precision: 0.8747 - val_recall: 0.5530 - val_auc: 0.9784
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.9min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23bf23780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e1b0b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e7a9c18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23bea3358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23bea35f8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23bea39b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23bea3c50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23bea3f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23bbd62b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b67f828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff31054c320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23bf1f828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2928c6518>]
          

Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_65 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_195 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_195 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_196 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_196 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_65 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_197 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_197 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 112s - loss: 0.0413 - tp: 613.0000 - fp: 392.0000 - tn: 253386.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6100 - recall: 0.1973 - auc: 0.9118 - val_loss: 0.0297 - val_tp: 846.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 1993.0000 - val_accuracy: 0.9905 - val_precision: 0.7628 - val_recall: 0.2980 - val_auc: 0.9592
256885/256885 - 112s - loss: 0.0413 - tp: 613.0000 - fp: 392.0000 - tn: 253386.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6100 - recall: 0.1973 - auc: 0.9118 - val_loss: 0.0297 - val_tp: 846.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 1993.0000 - val_accuracy: 0.9905 - val_precision: 0.7628 - val_recall: 0.2980 - val_auc: 0.9592
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0255 - tp: 1506.0000 - fp: 450.0000 - tn: 253328.0000 - fn: 1601.0000 - accuracy: 0.9920 - precision: 0.7699 - recall: 0.4847 - auc: 0.9669 - val_loss: 0.0207 - val_tp: 1811.0000 - val_fp: 478.0000 - val_tn: 234541.0000 - val_fn: 1028.0000 - val_accuracy: 0.9937 - val_precision: 0.7912 - val_recall: 0.6379 - val_auc: 0.9856
256885/256885 - 109s - loss: 0.0255 - tp: 1506.0000 - fp: 450.0000 - tn: 253328.0000 - fn: 1601.0000 - accuracy: 0.9920 - precision: 0.7699 - recall: 0.4847 - auc: 0.9669 - val_loss: 0.0207 - val_tp: 1811.0000 - val_fp: 478.0000 - val_tn: 234541.0000 - val_fn: 1028.0000 - val_accuracy: 0.9937 - val_precision: 0.7912 - val_recall: 0.6379 - val_auc: 0.9856
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2365ff6a0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2365dae48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff236599588>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff236599e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23c1320f0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23c1324a8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23c132748>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23c132a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff31054c9e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2928c6cf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23e786780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23e786c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2365e12b0>]
          

Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_66 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_198 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_198 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_199 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_199 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_66 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_200 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_200 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 112s - loss: 0.0414 - tp: 630.0000 - fp: 366.0000 - tn: 253428.0000 - fn: 2461.0000 - accuracy: 0.9890 - precision: 0.6325 - recall: 0.2038 - auc: 0.9104 - val_loss: 0.0303 - val_tp: 1415.0000 - val_fp: 872.0000 - val_tn: 234147.0000 - val_fn: 1424.0000 - val_accuracy: 0.9903 - val_precision: 0.6187 - val_recall: 0.4984 - val_auc: 0.9748
256885/256885 - 112s - loss: 0.0414 - tp: 630.0000 - fp: 366.0000 - tn: 253428.0000 - fn: 2461.0000 - accuracy: 0.9890 - precision: 0.6325 - recall: 0.2038 - auc: 0.9104 - val_loss: 0.0303 - val_tp: 1415.0000 - val_fp: 872.0000 - val_tn: 234147.0000 - val_fn: 1424.0000 - val_accuracy: 0.9903 - val_precision: 0.6187 - val_recall: 0.4984 - val_auc: 0.9748
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0251 - tp: 1557.0000 - fp: 416.0000 - tn: 253378.0000 - fn: 1534.0000 - accuracy: 0.9924 - precision: 0.7892 - recall: 0.5037 - auc: 0.9651 - val_loss: 0.0250 - val_tp: 1332.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1507.0000 - val_accuracy: 0.9929 - val_precision: 0.8763 - val_recall: 0.4692 - val_auc: 0.9441
256885/256885 - 109s - loss: 0.0251 - tp: 1557.0000 - fp: 416.0000 - tn: 253378.0000 - fn: 1534.0000 - accuracy: 0.9924 - precision: 0.7892 - recall: 0.5037 - auc: 0.9651 - val_loss: 0.0250 - val_tp: 1332.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1507.0000 - val_accuracy: 0.9929 - val_precision: 0.8763 - val_recall: 0.4692 - val_auc: 0.9441
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0206 - tp: 1895.0000 - fp: 361.0000 - tn: 253433.0000 - fn: 1196.0000 - accuracy: 0.9939 - precision: 0.8400 - recall: 0.6131 - auc: 0.9725 - val_loss: 0.0264 - val_tp: 2254.0000 - val_fp: 1524.0000 - val_tn: 233495.0000 - val_fn: 585.0000 - val_accuracy: 0.9911 - val_precision: 0.5966 - val_recall: 0.7939 - val_auc: 0.9880
256885/256885 - 109s - loss: 0.0206 - tp: 1895.0000 - fp: 361.0000 - tn: 253433.0000 - fn: 1196.0000 - accuracy: 0.9939 - precision: 0.8400 - recall: 0.6131 - auc: 0.9725 - val_loss: 0.0264 - val_tp: 2254.0000 - val_fp: 1524.0000 - val_tn: 233495.0000 - val_fn: 585.0000 - val_accuracy: 0.9911 - val_precision: 0.5966 - val_recall: 0.7939 - val_auc: 0.9880
Epoch 00003: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 5.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2352680b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b196400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b14ac88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b153400>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b1536a0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b153a58>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b153cf8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b153fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2365e12b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23bbd62b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2365ff6d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2365ff748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff31054c9e8>]
          

Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_67 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_201 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_201 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_202 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_202 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_67 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_203 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_203 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 112s - loss: 0.0414 - tp: 577.0000 - fp: 365.0000 - tn: 253409.0000 - fn: 2534.0000 - accuracy: 0.9887 - precision: 0.6125 - recall: 0.1855 - auc: 0.9126 - val_loss: 0.0290 - val_tp: 946.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1893.0000 - val_accuracy: 0.9907 - val_precision: 0.7532 - val_recall: 0.3332 - val_auc: 0.9582
256885/256885 - 112s - loss: 0.0414 - tp: 577.0000 - fp: 365.0000 - tn: 253409.0000 - fn: 2534.0000 - accuracy: 0.9887 - precision: 0.6125 - recall: 0.1855 - auc: 0.9126 - val_loss: 0.0290 - val_tp: 946.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1893.0000 - val_accuracy: 0.9907 - val_precision: 0.7532 - val_recall: 0.3332 - val_auc: 0.9582
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 109s - loss: 0.0256 - tp: 1531.0000 - fp: 465.0000 - tn: 253309.0000 - fn: 1580.0000 - accuracy: 0.9920 - precision: 0.7670 - recall: 0.4921 - auc: 0.9664 - val_loss: 0.0240 - val_tp: 1979.0000 - val_fp: 762.0000 - val_tn: 234257.0000 - val_fn: 860.0000 - val_accuracy: 0.9932 - val_precision: 0.7220 - val_recall: 0.6971 - val_auc: 0.9874
256885/256885 - 109s - loss: 0.0256 - tp: 1531.0000 - fp: 465.0000 - tn: 253309.0000 - fn: 1580.0000 - accuracy: 0.9920 - precision: 0.7670 - recall: 0.4921 - auc: 0.9664 - val_loss: 0.0240 - val_tp: 1979.0000 - val_fp: 762.0000 - val_tn: 234257.0000 - val_fn: 860.0000 - val_accuracy: 0.9932 - val_precision: 0.7220 - val_recall: 0.6971 - val_auc: 0.9874
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23638dfd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff234667390>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff234667358>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b18bf60>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23af0c710>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2345f8b70>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2345f84e0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2345f8048>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2365ff748>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b1ac518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23509efd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23463be10>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff234684da0>]
          

Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_68 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_204 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_204 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_205 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_205 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_68 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_206 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_206 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 113s - loss: 0.0417 - tp: 581.0000 - fp: 373.0000 - tn: 253405.0000 - fn: 2527.0000 - accuracy: 0.9887 - precision: 0.6090 - recall: 0.1869 - auc: 0.9090 - val_loss: 0.0279 - val_tp: 1302.0000 - val_fp: 680.0000 - val_tn: 234339.0000 - val_fn: 1537.0000 - val_accuracy: 0.9907 - val_precision: 0.6569 - val_recall: 0.4586 - val_auc: 0.9691
256886/256886 - 113s - loss: 0.0417 - tp: 581.0000 - fp: 373.0000 - tn: 253405.0000 - fn: 2527.0000 - accuracy: 0.9887 - precision: 0.6090 - recall: 0.1869 - auc: 0.9090 - val_loss: 0.0279 - val_tp: 1302.0000 - val_fp: 680.0000 - val_tn: 234339.0000 - val_fn: 1537.0000 - val_accuracy: 0.9907 - val_precision: 0.6569 - val_recall: 0.4586 - val_auc: 0.9691
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 110s - loss: 0.0249 - tp: 1568.0000 - fp: 457.0000 - tn: 253321.0000 - fn: 1540.0000 - accuracy: 0.9922 - precision: 0.7743 - recall: 0.5045 - auc: 0.9689 - val_loss: 0.0213 - val_tp: 1900.0000 - val_fp: 560.0000 - val_tn: 234459.0000 - val_fn: 939.0000 - val_accuracy: 0.9937 - val_precision: 0.7724 - val_recall: 0.6692 - val_auc: 0.9869
256886/256886 - 110s - loss: 0.0249 - tp: 1568.0000 - fp: 457.0000 - tn: 253321.0000 - fn: 1540.0000 - accuracy: 0.9922 - precision: 0.7743 - recall: 0.5045 - auc: 0.9689 - val_loss: 0.0213 - val_tp: 1900.0000 - val_fp: 560.0000 - val_tn: 234459.0000 - val_fn: 939.0000 - val_accuracy: 0.9937 - val_precision: 0.7724 - val_recall: 0.6692 - val_auc: 0.9869
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 21s
256886/256886 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.9min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff29373af60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a1d17a58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b36abe0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b36a710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b54db00>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b54d0f0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b54d940>, <tensorflow.python.keras.metrics.AUC object at 0x7ff28f638cc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff234684da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23463bef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2354bf978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2350c4940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff234672438>]
          

Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_69 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_207 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_207 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_208 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_208 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_69 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_209 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_209 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 113s - loss: 0.0415 - tp: 577.0000 - fp: 365.0000 - tn: 253397.0000 - fn: 2547.0000 - accuracy: 0.9887 - precision: 0.6125 - recall: 0.1847 - auc: 0.9125 - val_loss: 0.0365 - val_tp: 432.0000 - val_fp: 79.0000 - val_tn: 234940.0000 - val_fn: 2407.0000 - val_accuracy: 0.9895 - val_precision: 0.8454 - val_recall: 0.1522 - val_auc: 0.9243
256886/256886 - 113s - loss: 0.0415 - tp: 577.0000 - fp: 365.0000 - tn: 253397.0000 - fn: 2547.0000 - accuracy: 0.9887 - precision: 0.6125 - recall: 0.1847 - auc: 0.9125 - val_loss: 0.0365 - val_tp: 432.0000 - val_fp: 79.0000 - val_tn: 234940.0000 - val_fn: 2407.0000 - val_accuracy: 0.9895 - val_precision: 0.8454 - val_recall: 0.1522 - val_auc: 0.9243
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 109s - loss: 0.0253 - tp: 1538.0000 - fp: 467.0000 - tn: 253295.0000 - fn: 1586.0000 - accuracy: 0.9920 - precision: 0.7671 - recall: 0.4923 - auc: 0.9692 - val_loss: 0.0226 - val_tp: 1966.0000 - val_fp: 721.0000 - val_tn: 234298.0000 - val_fn: 873.0000 - val_accuracy: 0.9933 - val_precision: 0.7317 - val_recall: 0.6925 - val_auc: 0.9869
256886/256886 - 109s - loss: 0.0253 - tp: 1538.0000 - fp: 467.0000 - tn: 253295.0000 - fn: 1586.0000 - accuracy: 0.9920 - precision: 0.7671 - recall: 0.4923 - auc: 0.9692 - val_loss: 0.0226 - val_tp: 1966.0000 - val_fp: 721.0000 - val_tn: 234298.0000 - val_fn: 873.0000 - val_accuracy: 0.9933 - val_precision: 0.7317 - val_recall: 0.6925 - val_auc: 0.9869
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 21s
256886/256886 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.9min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23dff77b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23db3ef60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a12406a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1240f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2345ab208>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2345ab5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2345ab860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2345abb38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff234672160>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a00980b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff29373a470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff29373ab00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23db673c8>]
          

Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_70 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_210 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_210 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_211 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_211 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_70 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_212 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_212 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0410 - tp: 636.0000 - fp: 398.0000 - tn: 253361.0000 - fn: 2490.0000 - accuracy: 0.9888 - precision: 0.6151 - recall: 0.2035 - auc: 0.9127 - val_loss: 0.0363 - val_tp: 621.0000 - val_fp: 134.0000 - val_tn: 234885.0000 - val_fn: 2218.0000 - val_accuracy: 0.9901 - val_precision: 0.8225 - val_recall: 0.2187 - val_auc: 0.9097
256885/256885 - 130s - loss: 0.0410 - tp: 636.0000 - fp: 398.0000 - tn: 253361.0000 - fn: 2490.0000 - accuracy: 0.9888 - precision: 0.6151 - recall: 0.2035 - auc: 0.9127 - val_loss: 0.0363 - val_tp: 621.0000 - val_fp: 134.0000 - val_tn: 234885.0000 - val_fn: 2218.0000 - val_accuracy: 0.9901 - val_precision: 0.8225 - val_recall: 0.2187 - val_auc: 0.9097
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0240 - tp: 1673.0000 - fp: 432.0000 - tn: 253327.0000 - fn: 1453.0000 - accuracy: 0.9927 - precision: 0.7948 - recall: 0.5352 - auc: 0.9697 - val_loss: 0.0193 - val_tp: 1751.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1088.0000 - val_accuracy: 0.9940 - val_precision: 0.8378 - val_recall: 0.6168 - val_auc: 0.9827
256885/256885 - 127s - loss: 0.0240 - tp: 1673.0000 - fp: 432.0000 - tn: 253327.0000 - fn: 1453.0000 - accuracy: 0.9927 - precision: 0.7948 - recall: 0.5352 - auc: 0.9697 - val_loss: 0.0193 - val_tp: 1751.0000 - val_fp: 339.0000 - val_tn: 234680.0000 - val_fn: 1088.0000 - val_accuracy: 0.9940 - val_precision: 0.8378 - val_recall: 0.6168 - val_auc: 0.9827
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a0098438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23d57a518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23c3cdda0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23c3eaa20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23c3ea320>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23c3eada0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23c3ea400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292c2c128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff29373ab00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23463bef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23dff77f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23dff7860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2350c4940>]
          

Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_71 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_213 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_213 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_214 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_214 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_71 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_215 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_215 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0413 - tp: 588.0000 - fp: 367.0000 - tn: 253391.0000 - fn: 2539.0000 - accuracy: 0.9887 - precision: 0.6157 - recall: 0.1880 - auc: 0.9154 - val_loss: 0.0273 - val_tp: 1103.0000 - val_fp: 386.0000 - val_tn: 234633.0000 - val_fn: 1736.0000 - val_accuracy: 0.9911 - val_precision: 0.7408 - val_recall: 0.3885 - val_auc: 0.9673
256885/256885 - 130s - loss: 0.0413 - tp: 588.0000 - fp: 367.0000 - tn: 253391.0000 - fn: 2539.0000 - accuracy: 0.9887 - precision: 0.6157 - recall: 0.1880 - auc: 0.9154 - val_loss: 0.0273 - val_tp: 1103.0000 - val_fp: 386.0000 - val_tn: 234633.0000 - val_fn: 1736.0000 - val_accuracy: 0.9911 - val_precision: 0.7408 - val_recall: 0.3885 - val_auc: 0.9673
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0250 - tp: 1621.0000 - fp: 424.0000 - tn: 253334.0000 - fn: 1506.0000 - accuracy: 0.9925 - precision: 0.7927 - recall: 0.5184 - auc: 0.9675 - val_loss: 0.0241 - val_tp: 1291.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1548.0000 - val_accuracy: 0.9929 - val_precision: 0.8953 - val_recall: 0.4547 - val_auc: 0.9526
256885/256885 - 127s - loss: 0.0250 - tp: 1621.0000 - fp: 424.0000 - tn: 253334.0000 - fn: 1506.0000 - accuracy: 0.9925 - precision: 0.7927 - recall: 0.5184 - auc: 0.9675 - val_loss: 0.0241 - val_tp: 1291.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1548.0000 - val_accuracy: 0.9929 - val_precision: 0.8953 - val_recall: 0.4547 - val_auc: 0.9526
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23d4b0cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23a7aae48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a7aa400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff28f609a58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239f92208>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23deebf60>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a739860>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23a739c50>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23dff7860>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a780f28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b1cf0b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23a7c5eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff239f49b38>]
          

Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_72 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_216 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_216 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_217 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_217 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_72 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_218 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_218 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0410 - tp: 657.0000 - fp: 442.0000 - tn: 253327.0000 - fn: 2459.0000 - accuracy: 0.9887 - precision: 0.5978 - recall: 0.2108 - auc: 0.9104 - val_loss: 0.0292 - val_tp: 936.0000 - val_fp: 261.0000 - val_tn: 234758.0000 - val_fn: 1903.0000 - val_accuracy: 0.9909 - val_precision: 0.7820 - val_recall: 0.3297 - val_auc: 0.9482
256885/256885 - 130s - loss: 0.0410 - tp: 657.0000 - fp: 442.0000 - tn: 253327.0000 - fn: 2459.0000 - accuracy: 0.9887 - precision: 0.5978 - recall: 0.2108 - auc: 0.9104 - val_loss: 0.0292 - val_tp: 936.0000 - val_fp: 261.0000 - val_tn: 234758.0000 - val_fn: 1903.0000 - val_accuracy: 0.9909 - val_precision: 0.7820 - val_recall: 0.3297 - val_auc: 0.9482
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0245 - tp: 1634.0000 - fp: 454.0000 - tn: 253315.0000 - fn: 1482.0000 - accuracy: 0.9925 - precision: 0.7826 - recall: 0.5244 - auc: 0.9653 - val_loss: 0.0193 - val_tp: 1780.0000 - val_fp: 369.0000 - val_tn: 234650.0000 - val_fn: 1059.0000 - val_accuracy: 0.9940 - val_precision: 0.8283 - val_recall: 0.6270 - val_auc: 0.9857
256885/256885 - 128s - loss: 0.0245 - tp: 1634.0000 - fp: 454.0000 - tn: 253315.0000 - fn: 1482.0000 - accuracy: 0.9925 - precision: 0.7826 - recall: 0.5244 - auc: 0.9653 - val_loss: 0.0193 - val_tp: 1780.0000 - val_fp: 369.0000 - val_tn: 234650.0000 - val_fn: 1059.0000 - val_accuracy: 0.9940 - val_precision: 0.8283 - val_recall: 0.6270 - val_auc: 0.9857
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23a4f5be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23992c2b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23992c438>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b1cf160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239bd24e0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23a566390>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a1dbcc0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2398bb898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23a7c5eb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2398fff98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff239948f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2398f9f98>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2399382e8>]
          

Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_73 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_219 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_219 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_220 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_220 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_73 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_221 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_221 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 132s - loss: 0.0408 - tp: 599.0000 - fp: 406.0000 - tn: 253386.0000 - fn: 2494.0000 - accuracy: 0.9887 - precision: 0.5960 - recall: 0.1937 - auc: 0.9159 - val_loss: 0.0298 - val_tp: 1468.0000 - val_fp: 1027.0000 - val_tn: 233992.0000 - val_fn: 1371.0000 - val_accuracy: 0.9899 - val_precision: 0.5884 - val_recall: 0.5171 - val_auc: 0.9774
256885/256885 - 132s - loss: 0.0408 - tp: 599.0000 - fp: 406.0000 - tn: 253386.0000 - fn: 2494.0000 - accuracy: 0.9887 - precision: 0.5960 - recall: 0.1937 - auc: 0.9159 - val_loss: 0.0298 - val_tp: 1468.0000 - val_fp: 1027.0000 - val_tn: 233992.0000 - val_fn: 1371.0000 - val_accuracy: 0.9899 - val_precision: 0.5884 - val_recall: 0.5171 - val_auc: 0.9774
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0245 - tp: 1586.0000 - fp: 454.0000 - tn: 253338.0000 - fn: 1507.0000 - accuracy: 0.9924 - precision: 0.7775 - recall: 0.5128 - auc: 0.9673 - val_loss: 0.0195 - val_tp: 1801.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1038.0000 - val_accuracy: 0.9938 - val_precision: 0.8051 - val_recall: 0.6344 - val_auc: 0.9802
256885/256885 - 128s - loss: 0.0245 - tp: 1586.0000 - fp: 454.0000 - tn: 253338.0000 - fn: 1507.0000 - accuracy: 0.9924 - precision: 0.7775 - recall: 0.5128 - auc: 0.9673 - val_loss: 0.0195 - val_tp: 1801.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1038.0000 - val_accuracy: 0.9938 - val_precision: 0.8051 - val_recall: 0.6344 - val_auc: 0.9802
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff235ede748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff235f628d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff235f62240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff235f63080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff235f63a90>, <tensorflow.python.keras.metrics.Precision object at 0x7ff235f63400>, <tensorflow.python.keras.metrics.Recall object at 0x7ff236306358>, <tensorflow.python.keras.metrics.AUC object at 0x7ff236306a58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2398f9f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a181dfd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2399385c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23a4f5dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23ca05128>]
          

Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_74 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_222 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_222 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_223 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_223 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_74 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_224 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_224 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0415 - tp: 659.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 2487.0000 - accuracy: 0.9886 - precision: 0.5991 - recall: 0.2095 - auc: 0.9118 - val_loss: 0.0281 - val_tp: 1024.0000 - val_fp: 365.0000 - val_tn: 234654.0000 - val_fn: 1815.0000 - val_accuracy: 0.9908 - val_precision: 0.7372 - val_recall: 0.3607 - val_auc: 0.9648
256885/256885 - 130s - loss: 0.0415 - tp: 659.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 2487.0000 - accuracy: 0.9886 - precision: 0.5991 - recall: 0.2095 - auc: 0.9118 - val_loss: 0.0281 - val_tp: 1024.0000 - val_fp: 365.0000 - val_tn: 234654.0000 - val_fn: 1815.0000 - val_accuracy: 0.9908 - val_precision: 0.7372 - val_recall: 0.3607 - val_auc: 0.9648
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0248 - tp: 1635.0000 - fp: 453.0000 - tn: 253286.0000 - fn: 1511.0000 - accuracy: 0.9924 - precision: 0.7830 - recall: 0.5197 - auc: 0.9675 - val_loss: 0.0203 - val_tp: 1836.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1003.0000 - val_accuracy: 0.9940 - val_precision: 0.8081 - val_recall: 0.6467 - val_auc: 0.9842
256885/256885 - 127s - loss: 0.0248 - tp: 1635.0000 - fp: 453.0000 - tn: 253286.0000 - fn: 1511.0000 - accuracy: 0.9924 - precision: 0.7830 - recall: 0.5197 - auc: 0.9675 - val_loss: 0.0203 - val_tp: 1836.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1003.0000 - val_accuracy: 0.9940 - val_precision: 0.8081 - val_recall: 0.6467 - val_auc: 0.9842
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 27s
256885/256885 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2443b1860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff235653b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23aefe0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23aefe898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23aefeb38>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23aefeef0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23aef21d0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23aef24a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23a4f5dd8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a181d0f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff235f54ac8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff235f54dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff235f54b70>]
          

Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_75 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_225 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_225 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_226 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_226 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_75 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_227 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_227 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0403 - tp: 656.0000 - fp: 367.0000 - tn: 253411.0000 - fn: 2451.0000 - accuracy: 0.9890 - precision: 0.6413 - recall: 0.2111 - auc: 0.9147 - val_loss: 0.0266 - val_tp: 1443.0000 - val_fp: 708.0000 - val_tn: 234311.0000 - val_fn: 1396.0000 - val_accuracy: 0.9912 - val_precision: 0.6709 - val_recall: 0.5083 - val_auc: 0.9767
256885/256885 - 130s - loss: 0.0403 - tp: 656.0000 - fp: 367.0000 - tn: 253411.0000 - fn: 2451.0000 - accuracy: 0.9890 - precision: 0.6413 - recall: 0.2111 - auc: 0.9147 - val_loss: 0.0266 - val_tp: 1443.0000 - val_fp: 708.0000 - val_tn: 234311.0000 - val_fn: 1396.0000 - val_accuracy: 0.9912 - val_precision: 0.6709 - val_recall: 0.5083 - val_auc: 0.9767
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0241 - tp: 1690.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1417.0000 - accuracy: 0.9928 - precision: 0.7987 - recall: 0.5439 - auc: 0.9642 - val_loss: 0.0204 - val_tp: 1855.0000 - val_fp: 539.0000 - val_tn: 234480.0000 - val_fn: 984.0000 - val_accuracy: 0.9936 - val_precision: 0.7749 - val_recall: 0.6534 - val_auc: 0.9827
256885/256885 - 128s - loss: 0.0241 - tp: 1690.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1417.0000 - accuracy: 0.9928 - precision: 0.7987 - recall: 0.5439 - auc: 0.9642 - val_loss: 0.0204 - val_tp: 1855.0000 - val_fp: 539.0000 - val_tn: 234480.0000 - val_fn: 984.0000 - val_accuracy: 0.9936 - val_precision: 0.7749 - val_recall: 0.6534 - val_auc: 0.9827
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23eb9dd30>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23eb9ddd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23eb9df98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23d690da0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a199d8d0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a199d668>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a199d2b0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff235f0a358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff235f54b70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a20c5470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff235f62278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23bdc57f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff237e9f048>]
          

Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_76 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_228 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_228 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_229 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_229 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_76 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_230 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_230 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0403 - tp: 650.0000 - fp: 379.0000 - tn: 253415.0000 - fn: 2441.0000 - accuracy: 0.9890 - precision: 0.6317 - recall: 0.2103 - auc: 0.9123 - val_loss: 0.0339 - val_tp: 1592.0000 - val_fp: 1195.0000 - val_tn: 233824.0000 - val_fn: 1247.0000 - val_accuracy: 0.9897 - val_precision: 0.5712 - val_recall: 0.5608 - val_auc: 0.9794
256885/256885 - 130s - loss: 0.0403 - tp: 650.0000 - fp: 379.0000 - tn: 253415.0000 - fn: 2441.0000 - accuracy: 0.9890 - precision: 0.6317 - recall: 0.2103 - auc: 0.9123 - val_loss: 0.0339 - val_tp: 1592.0000 - val_fp: 1195.0000 - val_tn: 233824.0000 - val_fn: 1247.0000 - val_accuracy: 0.9897 - val_precision: 0.5712 - val_recall: 0.5608 - val_auc: 0.9794
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 128s - loss: 0.0240 - tp: 1641.0000 - fp: 424.0000 - tn: 253370.0000 - fn: 1450.0000 - accuracy: 0.9927 - precision: 0.7947 - recall: 0.5309 - auc: 0.9669 - val_loss: 0.0215 - val_tp: 1456.0000 - val_fp: 187.0000 - val_tn: 234832.0000 - val_fn: 1383.0000 - val_accuracy: 0.9934 - val_precision: 0.8862 - val_recall: 0.5129 - val_auc: 0.9637
256885/256885 - 128s - loss: 0.0240 - tp: 1641.0000 - fp: 424.0000 - tn: 253370.0000 - fn: 1450.0000 - accuracy: 0.9927 - precision: 0.7947 - recall: 0.5309 - auc: 0.9669 - val_loss: 0.0215 - val_tp: 1456.0000 - val_fp: 187.0000 - val_tn: 234832.0000 - val_fn: 1383.0000 - val_accuracy: 0.9934 - val_precision: 0.8862 - val_recall: 0.5129 - val_auc: 0.9637
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0203 - tp: 1926.0000 - fp: 385.0000 - tn: 253409.0000 - fn: 1165.0000 - accuracy: 0.9940 - precision: 0.8334 - recall: 0.6231 - auc: 0.9696 - val_loss: 0.0199 - val_tp: 1598.0000 - val_fp: 175.0000 - val_tn: 234844.0000 - val_fn: 1241.0000 - val_accuracy: 0.9940 - val_precision: 0.9013 - val_recall: 0.5629 - val_auc: 0.9655
256885/256885 - 127s - loss: 0.0203 - tp: 1926.0000 - fp: 385.0000 - tn: 253409.0000 - fn: 1165.0000 - accuracy: 0.9940 - precision: 0.8334 - recall: 0.6231 - auc: 0.9696 - val_loss: 0.0199 - val_tp: 1598.0000 - val_fp: 175.0000 - val_tn: 234844.0000 - val_fn: 1241.0000 - val_accuracy: 0.9940 - val_precision: 0.9013 - val_recall: 0.5629 - val_auc: 0.9655
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23aaf8be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23aaf89e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23aaf8c88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2354d2550>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2354d2438>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2354d2128>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2354d2048>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2352d4e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff237e9f048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff236020e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23d633860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f722e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23aaf8ba8>]
          

Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_77 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_231 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_231 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_232 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_232 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_77 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_233 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_233 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256885/256885 - 130s - loss: 0.0404 - tp: 610.0000 - fp: 373.0000 - tn: 253401.0000 - fn: 2501.0000 - accuracy: 0.9888 - precision: 0.6205 - recall: 0.1961 - auc: 0.9162 - val_loss: 0.0336 - val_tp: 497.0000 - val_fp: 93.0000 - val_tn: 234926.0000 - val_fn: 2342.0000 - val_accuracy: 0.9898 - val_precision: 0.8424 - val_recall: 0.1751 - val_auc: 0.9360
256885/256885 - 130s - loss: 0.0404 - tp: 610.0000 - fp: 373.0000 - tn: 253401.0000 - fn: 2501.0000 - accuracy: 0.9888 - precision: 0.6205 - recall: 0.1961 - auc: 0.9162 - val_loss: 0.0336 - val_tp: 497.0000 - val_fp: 93.0000 - val_tn: 234926.0000 - val_fn: 2342.0000 - val_accuracy: 0.9898 - val_precision: 0.8424 - val_recall: 0.1751 - val_auc: 0.9360
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256885/256885 - 127s - loss: 0.0243 - tp: 1635.0000 - fp: 451.0000 - tn: 253323.0000 - fn: 1476.0000 - accuracy: 0.9925 - precision: 0.7838 - recall: 0.5256 - auc: 0.9675 - val_loss: 0.0195 - val_tp: 1577.0000 - val_fp: 221.0000 - val_tn: 234798.0000 - val_fn: 1262.0000 - val_accuracy: 0.9938 - val_precision: 0.8771 - val_recall: 0.5555 - val_auc: 0.9805
256885/256885 - 127s - loss: 0.0243 - tp: 1635.0000 - fp: 451.0000 - tn: 253323.0000 - fn: 1476.0000 - accuracy: 0.9925 - precision: 0.7838 - recall: 0.5256 - auc: 0.9675 - val_loss: 0.0195 - val_tp: 1577.0000 - val_fp: 221.0000 - val_tn: 234798.0000 - val_fn: 1262.0000 - val_accuracy: 0.9938 - val_precision: 0.8771 - val_recall: 0.5555 - val_auc: 0.9805
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 26s
256885/256885 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23a27d5f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23a27d048>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23a27def0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ac6f320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ac6f780>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23eb7b8d0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a157d68>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23a157a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff28f722da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23bdc57f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a1617f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23a161320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23a161828>]
          

Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_78 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_234 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_234 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_235 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_235 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_78 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_236 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_236 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 130s - loss: 0.0404 - tp: 674.0000 - fp: 360.0000 - tn: 253418.0000 - fn: 2434.0000 - accuracy: 0.9891 - precision: 0.6518 - recall: 0.2169 - auc: 0.9148 - val_loss: 0.0259 - val_tp: 1277.0000 - val_fp: 418.0000 - val_tn: 234601.0000 - val_fn: 1562.0000 - val_accuracy: 0.9917 - val_precision: 0.7534 - val_recall: 0.4498 - val_auc: 0.9771
256886/256886 - 130s - loss: 0.0404 - tp: 674.0000 - fp: 360.0000 - tn: 253418.0000 - fn: 2434.0000 - accuracy: 0.9891 - precision: 0.6518 - recall: 0.2169 - auc: 0.9148 - val_loss: 0.0259 - val_tp: 1277.0000 - val_fp: 418.0000 - val_tn: 234601.0000 - val_fn: 1562.0000 - val_accuracy: 0.9917 - val_precision: 0.7534 - val_recall: 0.4498 - val_auc: 0.9771
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 127s - loss: 0.0237 - tp: 1687.0000 - fp: 444.0000 - tn: 253334.0000 - fn: 1421.0000 - accuracy: 0.9927 - precision: 0.7916 - recall: 0.5428 - auc: 0.9680 - val_loss: 0.0218 - val_tp: 1500.0000 - val_fp: 202.0000 - val_tn: 234817.0000 - val_fn: 1339.0000 - val_accuracy: 0.9935 - val_precision: 0.8813 - val_recall: 0.5284 - val_auc: 0.9591
256886/256886 - 127s - loss: 0.0237 - tp: 1687.0000 - fp: 444.0000 - tn: 253334.0000 - fn: 1421.0000 - accuracy: 0.9927 - precision: 0.7916 - recall: 0.5428 - auc: 0.9680 - val_loss: 0.0218 - val_tp: 1500.0000 - val_fp: 202.0000 - val_tn: 234817.0000 - val_fn: 1339.0000 - val_accuracy: 0.9935 - val_precision: 0.8813 - val_recall: 0.5284 - val_auc: 0.9591
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 27s
256886/256886 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2397a5780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2388526a0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23973f400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23973fe80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239748160>, <tensorflow.python.keras.metrics.Precision object at 0x7ff239748518>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2397487b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff239748a90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23a133b38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a1617f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23a161320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23a1617b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23a27dd30>]
          

Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_79 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_237 (Dense)            (None, 300)               30300     
_________________________________________________________________
activation_237 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_238 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_238 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_79 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_239 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_239 (Activation)  (None, 1)                 0         
=================================================================
Total params: 155,101
Trainable params: 155,101
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
256886/256886 - 131s - loss: 0.0410 - tp: 632.0000 - fp: 380.0000 - tn: 253382.0000 - fn: 2492.0000 - accuracy: 0.9888 - precision: 0.6245 - recall: 0.2023 - auc: 0.9128 - val_loss: 0.0317 - val_tp: 704.0000 - val_fp: 153.0000 - val_tn: 234866.0000 - val_fn: 2135.0000 - val_accuracy: 0.9904 - val_precision: 0.8215 - val_recall: 0.2480 - val_auc: 0.9409
256886/256886 - 131s - loss: 0.0410 - tp: 632.0000 - fp: 380.0000 - tn: 253382.0000 - fn: 2492.0000 - accuracy: 0.9888 - precision: 0.6245 - recall: 0.2023 - auc: 0.9128 - val_loss: 0.0317 - val_tp: 704.0000 - val_fp: 153.0000 - val_tn: 234866.0000 - val_fn: 2135.0000 - val_accuracy: 0.9904 - val_precision: 0.8215 - val_recall: 0.2480 - val_auc: 0.9409
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
256886/256886 - 128s - loss: 0.0247 - tp: 1619.0000 - fp: 440.0000 - tn: 253322.0000 - fn: 1505.0000 - accuracy: 0.9924 - precision: 0.7863 - recall: 0.5182 - auc: 0.9683 - val_loss: 0.0209 - val_tp: 1467.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1372.0000 - val_accuracy: 0.9935 - val_precision: 0.8945 - val_recall: 0.5167 - val_auc: 0.9694
256886/256886 - 128s - loss: 0.0247 - tp: 1619.0000 - fp: 440.0000 - tn: 253322.0000 - fn: 1505.0000 - accuracy: 0.9924 - precision: 0.7863 - recall: 0.5182 - auc: 0.9683 - val_loss: 0.0209 - val_tp: 1467.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1372.0000 - val_accuracy: 0.9935 - val_precision: 0.8945 - val_recall: 0.5167 - val_auc: 0.9694
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 26s
256886/256886 - 27s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff235381860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2353810b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff235381128>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff235381c88>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff235381cc0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ad868d0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23a2f5710>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23aaff208>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2397a5320>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff238eb38d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23510c898>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2353817f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2353817b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2353c5d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2353c5748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2353c5a20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2353c5c88>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2353c5d30>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2353c5c18>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23663b400>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23663b240>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff235381c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2354c7470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2354c7320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2354c7908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2354c7e80>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b7569b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b756320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b756a20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b756f98>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b9ddbe0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b9ddc88>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b9dda58>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b9ddcf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2353c5550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff236635e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff236635860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b756b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b756588>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b9dd9b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b9dde10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b9dddd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b9ddb70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b9dd2e8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b756390>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b756438>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b756cc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b756a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2353c5828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff236635e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b9ddd68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b9ddcf8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a177cd68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff293ae3668>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a1550b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2930b85c0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2930b8128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2930b8588>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2930b8978>, <tensorflow.python.keras.metrics.AUC object at 0x7ff292dcacf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b9dd630>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23db05080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23db05198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2a177ce80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2a177ccf8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff244383f60>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23b8e1fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23b8e19b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23b8e1c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23b8e16d8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23e79ba90>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23e79ba58>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23e79b400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a177c668>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a1db8470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a1db80f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff244383400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff244383da0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23e79b828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e79bcf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e79b550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23e79bd30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23e79bb38>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23b8e19b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23b8e1828>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b8e1278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff244383e48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a177cbe0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a1db8470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff244383f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff244383f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2b3ebc438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2b3ebc1d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2b3ebcbe0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2b3ebcf28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2b3ebccc0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2b3ebc2e8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2936c9128>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2936c9cf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23e79b320>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23e19b668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23e19bbe0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2937321d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff293732898>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23ec1a6a0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23ec1a4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23ec1a080>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ec1a710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ec372b0>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ec37898>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23ec37da0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23ec37978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2b3ebc7b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b87e2b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b87e7f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b87eef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b87ea90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23ec373c8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23ec37a58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23ec370f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23ec37b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23ec1a400>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23ec1a438>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23ec1aac8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23b9a2dd8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23ec1a550>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2b3ebc8d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2b3ebc7b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b87e2b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b87eef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23e65bcf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff23e6774a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff23e677c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff23e677080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff23e677908>, <tensorflow.python.keras.metrics.Precision object at 0x7ff23e677ba8>, <tensorflow.python.keras.metrics.Recall object at 0x7ff23e6774e0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff23e5d3780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23ec37d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a1783400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2441782b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23e65b860>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23e65b6d8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2925254e0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff292525470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff292525f28>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2925250b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff28f45a710>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2441352b0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff244135128>, <tensorflow.python.keras.metrics.AUC object at 0x7ff244135518>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23e65bfd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b1f3f98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23b1f3320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff292525a90>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff292525898>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff244135080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff244135208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2441356a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff244135438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff244135c88>, <tensorflow.python.keras.metrics.Precision object at 0x7ff292525668>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2925254e0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2925252e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff292525978>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff28f45a780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff28f45add8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff28f45aef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23e65b3c8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff23b831b70>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a1b207f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a1b20828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a1b20710>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a1b20a58>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a1b20080>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2440574e0>, <tensorflow.python.keras.metrics.AUC object at 0x7ff244057860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2441351d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff2a1b3b908>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff2a1b3b9e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b831240>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff23b8310b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a198a358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a198a0b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a198acf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a198ada0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a198ab38>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a193d978>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a193d630>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2a193d2b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23b831828>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23daaea90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23daae2b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2a198acc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2a198aa90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2a193d828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2a193d7f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff2a193d5f8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a193dc88>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2a193d7b8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff2a198a518>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2a198a358>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2a198a4a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a198a390>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23b8311d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23daaea90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff2a193d4a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2a193d198>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff239fa7b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff239fa7710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff239d3f1d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff239d3fe48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239d3f588>, <tensorflow.python.keras.metrics.Precision object at 0x7ff239ef0160>, <tensorflow.python.keras.metrics.Recall object at 0x7ff239f657b8>, <tensorflow.python.keras.metrics.AUC object at 0x7ff239f654a8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff2a193d2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff239f21198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff239f21048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff239fa73c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff239fa7fd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff239e35cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff239e35470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff239e35240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff239e35b38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239e2d630>, <tensorflow.python.keras.metrics.Precision object at 0x7ff239e2d908>, <tensorflow.python.keras.metrics.Recall object at 0x7ff239e2d748>, <tensorflow.python.keras.metrics.AUC object at 0x7ff239e585f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff239fa75c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff239f3f940>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff239f3f4e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff239e35ef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff239e35550>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff239e58630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff239e58ac8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff239e2d4a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff239e2df28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff239e2d128>, <tensorflow.python.keras.metrics.Precision object at 0x7ff239e35128>, <tensorflow.python.keras.metrics.Recall object at 0x7ff239e35358>, <tensorflow.python.keras.metrics.AUC object at 0x7ff239e35fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff239e35860>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff239fa7668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff239f3f940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff239e584a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff239e58438>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff239b80c50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff239b807b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff239982ef0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff239982048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff2399824a8>, <tensorflow.python.keras.metrics.Precision object at 0x7ff239ba5080>, <tensorflow.python.keras.metrics.Recall object at 0x7ff239ba5550>, <tensorflow.python.keras.metrics.AUC object at 0x7ff239ba5be0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff239e585c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff239d81710>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff239d81c18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff239b80f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff239b80d68>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=300, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     300
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7ff2353c5198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7ff2f07bc240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7ff244232ef0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7ff2a2101e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7ff293c6ef60>, <tensorflow.python.keras.metrics.Precision object at 0x7ff293b25be0>, <tensorflow.python.keras.metrics.Recall object at 0x7ff2b57fac50>, <tensorflow.python.keras.metrics.AUC object at 0x7ff2b661d278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7ff23eb9dd68>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7ff23a7b6550>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7ff23d544dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7ff23b1cbeb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7ff2365ff208>]
          

Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 50)                9600      
_________________________________________________________________
dense_240 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_240 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_241 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 285428 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.14688
285428/285428 - 123s - loss: 0.0410 - tp: 704.0000 - fp: 420.0000 - tn: 281547.0000 - fn: 2757.0000 - accuracy: 0.9889 - precision: 0.6263 - recall: 0.2034 - auc: 0.9104 - val_loss: 0.0275 - val_tp: 1060.0000 - val_fp: 344.0000 - val_tn: 234675.0000 - val_fn: 1779.0000 - val_accuracy: 0.9911 - val_precision: 0.7550 - val_recall: 0.3734 - val_auc: 0.9663
285428/285428 - 123s - loss: 0.0410 - tp: 704.0000 - fp: 420.0000 - tn: 281547.0000 - fn: 2757.0000 - accuracy: 0.9889 - precision: 0.6263 - recall: 0.2034 - auc: 0.9104 - val_loss: 0.0275 - val_tp: 1060.0000 - val_fp: 344.0000 - val_tn: 234675.0000 - val_fn: 1779.0000 - val_accuracy: 0.9911 - val_precision: 0.7550 - val_recall: 0.3734 - val_auc: 0.9663
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.14688
285428/285428 - 119s - loss: 0.0240 - tp: 1794.0000 - fp: 431.0000 - tn: 281536.0000 - fn: 1667.0000 - accuracy: 0.9926 - precision: 0.8063 - recall: 0.5183 - auc: 0.9698 - val_loss: 0.0201 - val_tp: 1513.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1326.0000 - val_accuracy: 0.9937 - val_precision: 0.8974 - val_recall: 0.5329 - val_auc: 0.9755
285428/285428 - 119s - loss: 0.0240 - tp: 1794.0000 - fp: 431.0000 - tn: 281536.0000 - fn: 1667.0000 - accuracy: 0.9926 - precision: 0.8063 - recall: 0.5183 - auc: 0.9698 - val_loss: 0.0201 - val_tp: 1513.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1326.0000 - val_accuracy: 0.9937 - val_precision: 0.8974 - val_recall: 0.5329 - val_auc: 0.9755
Epoch 00002: early stopping


_ _ _ _ _ _ _ _ _ _  RNN TRAINING RESULTS _ _ _ _ _ _ _ _ _ _ 



          BEST ESTIMATOR:          <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff23b67fac8> 
          BEST SCORE:              0.6690951314976192
          BEST PARAMS:             {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}
          BEST INDEX IN CV SEARCH: 12
          SCORER FUNCTIONS:        {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}
          

          HISTORY OBJ:             GridSearchCV(cv=10, error_score=nan,
             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff3904699b0>,
             iid='deprecated', n_jobs=1,
             param_grid={'dropout': [True], 'dropout_rate': [0.2],
                         'epochs': [50], 'hidden_layer_activation': ['sigmoid'],
                         'hidden_layers': [2],
                         'hidden_layers_neurons': [200, 300],
                         'loss': ['binary_crossentropy'],
                         'modelType': ['LSTM', 'GRU'], 'optimizer': ['adam'],
                         'output_layer_activation': ['sigmoid'],
                         'rnn_hidden_layers': [0, 1],
                         'rnn_hidden_layers_neurons': [50, 100],
                         'rnn_layer_activation': ['sigmoid']},
             pre_dispatch='1*n_jobs', refit='recall', return_train_score=True,
             scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1',
                      'average_precision'],
             verbose=2)        
        


cv_results_dict: 
    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_dropout param_dropout_rate param_epochs param_hidden_layer_activation param_hidden_layers param_hidden_layers_neurons           param_loss param_modelType param_optimizer param_output_layer_activation param_rnn_hidden_layers param_rnn_hidden_layers_neurons param_rnn_layer_activation                                                                                                                                                                                                                                                                                                                                                    params  split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  split5_test_accuracy  split6_test_accuracy  split7_test_accuracy  split8_test_accuracy  split9_test_accuracy  mean_test_accuracy  std_test_accuracy  rank_test_accuracy  split0_train_accuracy  split1_train_accuracy  split2_train_accuracy  split3_train_accuracy  split4_train_accuracy  split5_train_accuracy  split6_train_accuracy  split7_train_accuracy  split8_train_accuracy  split9_train_accuracy  mean_train_accuracy  std_train_accuracy  split0_test_precision  split1_test_precision  split2_test_precision  split3_test_precision  split4_test_precision  split5_test_precision  split6_test_precision  split7_test_precision  split8_test_precision  split9_test_precision  mean_test_precision  std_test_precision  rank_test_precision  split0_train_precision  split1_train_precision  split2_train_precision  split3_train_precision  split4_train_precision  split5_train_precision  split6_train_precision  split7_train_precision  split8_train_precision  split9_train_precision  mean_train_precision  std_train_precision  split0_test_recall  split1_test_recall  split2_test_recall  split3_test_recall  split4_test_recall  split5_test_recall  split6_test_recall  split7_test_recall  split8_test_recall  split9_test_recall  mean_test_recall  std_test_recall  rank_test_recall  split0_train_recall  split1_train_recall  split2_train_recall  split3_train_recall  split4_train_recall  split5_train_recall  split6_train_recall  split7_train_recall  split8_train_recall  split9_train_recall  mean_train_recall  std_train_recall  split0_test_roc_auc  split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  split4_test_roc_auc  split5_test_roc_auc  split6_test_roc_auc  split7_test_roc_auc  split8_test_roc_auc  split9_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  rank_test_roc_auc  split0_train_roc_auc  split1_train_roc_auc  split2_train_roc_auc  split3_train_roc_auc  split4_train_roc_auc  split5_train_roc_auc  split6_train_roc_auc  split7_train_roc_auc  split8_train_roc_auc  split9_train_roc_auc  mean_train_roc_auc  std_train_roc_auc  split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  split5_test_f1  split6_test_f1  split7_test_f1  split8_test_f1  split9_test_f1  mean_test_f1  std_test_f1  rank_test_f1  split0_train_f1  split1_train_f1  split2_train_f1  split3_train_f1  split4_train_f1  split5_train_f1  split6_train_f1  split7_train_f1  split8_train_f1  split9_train_f1  mean_train_f1  std_train_f1  split0_test_average_precision  split1_test_average_precision  split2_test_average_precision  split3_test_average_precision  split4_test_average_precision  split5_test_average_precision  split6_test_average_precision  split7_test_average_precision  split8_test_average_precision  split9_test_average_precision  mean_test_average_precision  std_test_average_precision  rank_test_average_precision  split0_train_average_precision  split1_train_average_precision  split2_train_average_precision  split3_train_average_precision  split4_train_average_precision  split5_train_average_precision  split6_train_average_precision  split7_train_average_precision  split8_train_average_precision  split9_train_average_precision  mean_train_average_precision  std_train_average_precision
0   210.088195     0.525313      5.016202         0.010889        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.992713              0.994324              0.992187              0.992082              0.993939              0.993589              0.992362              0.993869              0.993518              0.993413              0.993200            0.000760           5                   0.992370               0.993355               0.992647               0.993223               0.993589               0.993651               0.993686               0.993764               0.992915               0.992456               0.993165             0.000505            0.904459               0.833333               0.850575               0.819820               0.743151               0.897674               0.758503               0.804878               0.789655               0.930636               0.833268             0.059662            4                    0.876615                0.823315                0.895042                0.864617                0.768157                0.868263                0.798699                0.812422                0.728207                0.895861                0.833120              0.053690             0.423881            0.643713            0.428986            0.494565            0.688889            0.545198            0.602703            0.660000            0.648725            0.477745            0.561440          0.095003         7                 0.434101             0.578190             0.446085             0.518267             0.682454             0.560026             0.635393             0.630665             0.661197             0.429577             0.557596           0.091523          0.990913             0.988529             0.990593             0.989219             0.986512             0.990958             0.990162             0.988581             0.989419             0.986707             0.989159           0.001523          5                  0.989064              0.989218              0.989330              0.989604              0.989452              0.988287              0.989145              0.989894              0.989052              0.990041              0.989309            0.000468           0.577236        0.726351        0.570328        0.616949        0.714992        0.678383        0.671687        0.725275        0.712286        0.631373        0.662486      0.056919     7             0.580659         0.679316         0.595417         0.648070         0.722774         0.680884         0.707748         0.710098         0.693086         0.580701         0.659875       0.052470      0.744943                       0.766552                       0.743812                       0.715006                       0.749814                       0.779780                       0.731347                       0.760802                       0.761507                       0.782178                       0.753574                     0.019885                    6                            0.744253                        0.746640                        0.758600                        0.753974                        0.762293                        0.758425                        0.755463                        0.764323                        0.738873                        0.758132                        0.754098                      0.007831                   
1   299.736384     82.226317     6.728386         0.017930        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993799              0.994535              0.992923              0.992222              0.994570              0.993133              0.991451              0.992993              0.994149              0.994044              0.993382            0.000971           4                   0.993674               0.993592               0.993044               0.993304               0.994040               0.993203               0.992627               0.992927               0.994149               0.993499               0.993406             0.000457            0.821138               0.834586               0.845411               0.820175               0.863636               0.751592               0.857955               0.720588               0.915179               0.852321               0.828258             0.053093            5                    0.823631                0.824638                0.847360                0.868492                0.891041                0.740035                0.884393                0.722950                0.877292                0.835332                0.831516              0.055075             0.602985            0.664671            0.507246            0.508152            0.603175            0.666667            0.408108            0.700000            0.580737            0.599407            0.584115          0.083878         4                 0.611004             0.601535             0.520218             0.523117             0.584870             0.675249             0.445487             0.674381             0.600386             0.579706             0.581595           0.066875          0.991540             0.990496             0.990145             0.989820             0.985706             0.989464             0.990241             0.987172             0.993050             0.983111             0.989075           0.002787          6                  0.989296              0.990319              0.988670              0.989383              0.990084              0.989437              0.989640              0.989256              0.990412              0.988333              0.989483            0.000635           0.695353        0.740000        0.634058        0.627517        0.710280        0.706587        0.553114        0.710145        0.710572        0.703833        0.679146      0.053693     5             0.701561         0.695636         0.644661         0.652946         0.706198         0.706160         0.592513         0.697821         0.712894         0.684429         0.679482       0.036237      0.775070                       0.778737                       0.739034                       0.715818                       0.780966                       0.765989                       0.729147                       0.738217                       0.819068                       0.758184                       0.760023                     0.028920                    5                            0.761216                        0.762845                        0.742338                        0.756052                        0.790196                        0.749684                        0.752688                        0.740743                        0.789606                        0.746300                        0.759167                      0.016843                   
2   0.434993       0.001293      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 9                  NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  9                   NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               9                NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                9                 NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           9            NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          9                           NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
3   0.439488       0.001358      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 10                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  10                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               10               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                10                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           10           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          10                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
4   219.589940     1.273905      4.679675         0.053131        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.993974              0.993589              0.992678              0.993028              0.994149              0.993694              0.992397              0.993974              0.993553              0.994675              0.993571            0.000660           2                   0.993838               0.992759               0.992806               0.994317               0.993635               0.993869               0.993721               0.994071               0.993483               0.993958               0.993646             0.000484            0.849785               0.899471               0.886364               0.792388               0.839450               0.842520               0.795367               0.790850               0.885845               0.874494               0.845653             0.039288            2                    0.834998                0.895690                0.917655                0.838656                0.862350                0.826792                0.852240                0.809431                0.835989                0.853100                0.852690              0.030812             0.591045            0.508982            0.452174            0.622283            0.580952            0.604520            0.556757            0.691429            0.549575            0.640950            0.579867          0.064414         6                 0.615163             0.458587             0.447047             0.653734             0.571519             0.623753             0.578454             0.667631             0.574003             0.607875             0.579777           0.070407          0.991085             0.987853             0.989329             0.989908             0.987301             0.990720             0.990283             0.988166             0.989159             0.987832             0.989164           0.001261          4                  0.989064              0.989456              0.988317              0.989976              0.989925              0.989126              0.989302              0.989609              0.989320              0.990453              0.989455            0.000558           0.697183        0.650096        0.598848        0.697108        0.686679        0.703947        0.655008        0.737805        0.678322        0.739726        0.684472      0.040027     4             0.708418         0.606599         0.601208         0.734738         0.687440         0.711062         0.689150         0.731725         0.680656         0.709907         0.686090       0.044388      0.767695                       0.773913                       0.756504                       0.753227                       0.759187                       0.782138                       0.729462                       0.776334                       0.777920                       0.798214                       0.767459                     0.017961                    4                            0.764651                        0.759666                        0.769963                        0.783973                        0.770945                        0.762909                        0.762728                        0.778302                        0.752775                        0.775953                        0.768187                      0.008960                   
5   254.988917     0.652611      5.804205         0.031685        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993308              0.994675              0.993624              0.993168              0.994324              0.992012              0.991557              0.993729              0.994219              0.994639              0.993526            0.001004           3                   0.993219               0.993814               0.993927               0.994215               0.993990               0.991557               0.992814               0.993519               0.994048               0.993966               0.993507             0.000767            0.703390               0.825000               0.875576               0.828897               0.776173               0.643182               0.868571               0.870130               0.838129               0.896552               0.812560             0.077771            7                    0.715174                0.814906                0.896939                0.856319                0.797327                0.619521                0.914172                0.884166                0.787824                0.862673                0.814902              0.086337             0.743284            0.691617            0.550725            0.592391            0.682540            0.799435            0.410811            0.574286            0.660057            0.617211            0.632235          0.103905         2                 0.735765             0.636393             0.564185             0.624313             0.682772             0.782427             0.444516             0.534876             0.695302             0.599232             0.629978           0.095012          0.992119             0.989070             0.990580             0.986966             0.989226             0.990280             0.990417             0.987897             0.992327             0.986602             0.989548           0.001873          3                  0.990330              0.989639              0.989782              0.988775              0.990493              0.989512              0.988520              0.990392              0.990325              0.989444              0.989721            0.000652           0.722787        0.752443        0.676157        0.690967        0.726351        0.712846        0.557798        0.691910        0.738510        0.731107        0.700088      0.052456     2             0.725323         0.714670         0.692671         0.722139         0.735616         0.691509         0.598172         0.666533         0.738677         0.707216         0.699253       0.039715      0.779678                       0.784629                       0.779311                       0.757517                       0.772560                       0.797834                       0.741325                       0.766580                       0.806593                       0.799370                       0.778540                     0.019073                    2                            0.774949                        0.769043                        0.792537                        0.779124                        0.782707                        0.781379                        0.769586                        0.772394                        0.783254                        0.777342                        0.778231                      0.006822                   
6   0.436999       0.001352      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 11                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  11                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               11               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                11                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           11           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          11                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
7   0.440706       0.001586      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 12                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  12                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               12               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                12                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           12           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          12                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
8   216.609680     0.731069      5.297986         0.016354        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.992818              0.993799              0.992643              0.992152              0.993974              0.992432              0.991767              0.993273              0.993028              0.993834              0.992972            0.000712           7                   0.992666               0.993125               0.992853               0.993386               0.993526               0.992549               0.992818               0.993188               0.993086               0.993176               0.993037             0.000295            0.906250               0.781362               0.829268               0.810345               0.801688               0.867021               0.832512               0.811024               0.932584               0.836820               0.840887             0.045266            3                    0.882389                0.776514                0.838624                0.863399                0.824224                0.838728                0.863902                0.820537                0.877551                0.801319                0.838719              0.032353             0.432836            0.652695            0.492754            0.510870            0.603175            0.460452            0.456757            0.588571            0.470255            0.593472            0.526184          0.072586         8                 0.458413             0.611129             0.508665             0.535403             0.599174             0.475378             0.478486             0.559949             0.498069             0.583547             0.530821           0.052336          0.990570             0.988217             0.989460             0.988654             0.986966             0.989803             0.989951             0.986980             0.985517             0.985790             0.988191           0.001705          8                  0.987932              0.988796              0.988073              0.988576              0.988835              0.988162              0.988456              0.989077              0.985944              0.988271              0.988212            0.000832           0.585859        0.711256        0.618182        0.626667        0.688406        0.601476        0.589878        0.682119        0.625235        0.694444        0.642352      0.044613     8             0.603368         0.683966         0.633240         0.660946         0.693908         0.606820         0.615865         0.665648         0.635468         0.675310         0.647454       0.031174      0.752923                       0.756649                       0.722700                       0.709121                       0.742799                       0.733503                       0.716173                       0.733479                       0.761781                       0.754838                       0.738397                     0.017396                    8                            0.742511                        0.736633                        0.729612                        0.753204                        0.753054                        0.716128                        0.742154                        0.736753                        0.744140                        0.735862                        0.739005                      0.010391                   
9   282.021650     38.729920     7.009823         0.022194        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.992993              0.994324              0.994044              0.992362              0.992503              0.992888              0.991907              0.993378              0.993203              0.994044              0.993165            0.000756           6                   0.993114               0.993511               0.994079               0.993328               0.992273               0.993223               0.993355               0.993207               0.993040               0.993413               0.993254             0.000427            0.740214               0.830769               0.843137               0.826087               0.638356               0.871921               0.793249               0.801498               0.916230               0.884793               0.814625             0.075480            6                    0.757887                0.814927                0.849627                0.866951                0.668115                0.857592                0.854508                0.799037                0.857530                0.849268                0.817544              0.059400             0.620896            0.646707            0.623188            0.516304            0.739683            0.500000            0.508108            0.611429            0.495751            0.569733            0.583180          0.075632         5                 0.637876             0.604093             0.621951             0.526673             0.733312             0.527197             0.539631             0.586628             0.509331             0.557298             0.584399           0.064665          0.990636             0.987931             0.990756             0.988073             0.985359             0.989363             0.989673             0.986549             0.990540             0.985139             0.988402           0.002033          7                  0.988836              0.987221              0.989957              0.987978              0.989034              0.988672              0.988195              0.989292              0.988935              0.988374              0.988649            0.000718           0.675325        0.727273        0.716667        0.635452        0.685294        0.635548        0.619440        0.693679        0.643382        0.693141        0.672520      0.035211     6             0.692722         0.693848         0.718177         0.655270         0.699197         0.652980         0.661511         0.676552         0.639080         0.672980         0.676232       0.023360      0.737566                       0.765396                       0.762574                       0.709447                       0.737899                       0.761044                       0.715125                       0.731262                       0.767807                       0.758808                       0.744693                     0.020355                    7                            0.737264                        0.744007                        0.780559                        0.751159                        0.748310                        0.742829                        0.743933                        0.734195                        0.742657                        0.744909                        0.746982                      0.012095                   
10  0.440620       0.001471      0.000000         0.000000        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 13                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  13                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               13               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                13                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           13           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          13                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
11  0.444292       0.001357      0.000000         0.000000        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 14                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  14                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               14               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                14                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           14           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          14                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
12  237.314744     32.655983     4.933188         0.047430        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.988368              0.994009              0.993659              0.992397              0.994429              0.993729              0.990330              0.993939              0.994184              0.994499              0.992954            0.001936           8                   0.988730               0.992872               0.993721               0.993674               0.993853               0.993900               0.991716               0.993561               0.993986               0.993670               0.992968             0.001553            0.502683               0.931217               0.859649               0.709141               0.882353               0.830189               0.597917               0.764179               0.855513               0.792208               0.772505             0.127603            8                    0.523644                0.912214                0.864983                0.750854                0.894313                0.819502                0.621010                0.752338                0.798624                0.761158                0.769864              0.114724             0.838806            0.526946            0.568116            0.695652            0.571429            0.621469            0.775676            0.731429            0.637394            0.724036            0.669095          0.095386         1                 0.818298             0.458587             0.571566             0.710314             0.564844             0.635661             0.799418             0.698168             0.672458             0.698784             0.662810           0.103971          0.991480             0.990223             0.990135             0.988908             0.988505             0.991014             0.991779             0.987813             0.990591             0.986505             0.989695           0.001622          2                  0.989488              0.990585              0.989220              0.989715              0.990016              0.989783              0.991020              0.989481              0.989528              0.990191              0.989903            0.000531           0.628635        0.673040        0.684119        0.702332        0.693642        0.710824        0.675294        0.747445        0.730519        0.756589        0.700244      0.036373     1             0.638622         0.610343         0.688309         0.730022         0.692383         0.715969         0.699010         0.724241         0.730131         0.728638         0.695767       0.039108      0.786023                       0.789850                       0.755060                       0.744157                       0.775831                       0.782169                       0.772646                       0.768439                       0.794117                       0.794158                       0.776245                     0.015838                    3                            0.776140                        0.775406                        0.770541                        0.778612                        0.784705                        0.767720                        0.800423                        0.772215                        0.773064                        0.773545                        0.777237                      0.008897                   
13  275.292904     38.074840     6.088252         0.013099        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.994324              0.993729              0.994429              0.993098              0.994429              0.993589              0.993343              0.994009              0.993588              0.994359              0.993890            0.000462           1                   0.994161               0.992763               0.994231               0.994180               0.994114               0.994040               0.994215               0.993958               0.993717               0.993390               0.993877             0.000448            0.853061               0.910053               0.852273               0.810909               0.809524               0.808664               0.891304               0.877637               0.942708               0.948980               0.870511             0.050150            1                    0.857206                0.908505                0.850043                0.834870                0.836214                0.806854                0.920377                0.892695                0.894820                0.902825                0.870441              0.036266             0.623881            0.514970            0.652174            0.605978            0.647619            0.632768            0.554054            0.594286            0.512748            0.551929            0.589041          0.049765         3                 0.624120             0.450911             0.636714             0.644035             0.645900             0.666881             0.568424             0.569592             0.544723             0.511524             0.586282           0.066030          0.992220             0.990032             0.991331             0.990313             0.988771             0.988685             0.992164             0.989011             0.990024             0.987533             0.990008           0.001476          1                  0.990705              0.989776              0.990813              0.990884              0.990096              0.989181              0.990813              0.990393              0.988329              0.990127              0.990112            0.000785           0.720690        0.657744        0.738916        0.693624        0.719577        0.709984        0.683333        0.708688        0.664220        0.697936        0.699471      0.024262     3             0.722325         0.602693         0.728073         0.727140         0.728838         0.730220         0.702800         0.695447         0.677200         0.653045         0.696778       0.039857      0.801867                       0.787850                       0.777656                       0.749733                       0.774394                       0.786531                       0.779009                       0.785342                       0.799009                       0.808162                       0.784955                     0.015729                    1                            0.786581                        0.770942                        0.788964                        0.783347                        0.782510                        0.773847                        0.810472                        0.788591                        0.775045                        0.781037                        0.784134                      0.010574                   
14  0.445230       0.001720      0.000000         0.000000        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 15                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  15                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               15               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                15                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           15           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          15                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
15  0.446767       0.001521      0.000000         0.000000        True          0.2                50           sigmoid                       2                   300                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 16                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  16                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               16               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                16                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           16           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          16                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
Total time: 24683.06  seconds or 411.38 minutes. Saving model to: customer_batches_rnn_best_model.h5
Saving best estimator at rnn_model.h5 and weights at rnn_model_weights.h5
<tensorflow.python.keras.engine.sequential.Sequential object at 0x7ff3300d2208>
{'scoring': ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], 'estimator': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff3904699b0>, 'n_jobs': 1, 'iid': 'deprecated', 'refit': 'recall', 'cv': 10, 'verbose': 2, 'pre_dispatch': '1*n_jobs', 'error_score': nan, 'return_train_score': True, 'param_grid': {'rnn_hidden_layers': [0, 1], 'rnn_hidden_layers_neurons': [50, 100], 'hidden_layers': [2], 'hidden_layers_neurons': [200, 300], 'loss': ['binary_crossentropy'], 'optimizer': ['adam'], 'modelType': ['LSTM', 'GRU'], 'epochs': [50], 'output_layer_activation': ['sigmoid'], 'rnn_layer_activation': ['sigmoid'], 'hidden_layer_activation': ['sigmoid'], 'dropout': [True], 'dropout_rate': [0.2]}, 'multimetric_': True, 'best_index_': 12, 'best_score_': 0.6690951314976192, 'best_params_': {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, 'best_estimator_': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff23b67fac8>, 'refit_time_': 246.79227089881897, 'scorer_': {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}, 'cv_results_': {'mean_fit_time': array([210.08819492, 299.73638351,   0.43499322,   0.43948765,
       219.58993969, 254.9889168 ,   0.4369987 ,   0.44070613,
       216.60968034, 282.02165036,   0.44061954,   0.44429183,
       237.31474402, 275.29290357,   0.44523022,   0.44676733]), 'std_fit_time': array([5.25313181e-01, 8.22263171e+01, 1.29321850e-03, 1.35763840e-03,
       1.27390520e+00, 6.52610803e-01, 1.35200095e-03, 1.58635081e-03,
       7.31069232e-01, 3.87299201e+01, 1.47129262e-03, 1.35713861e-03,
       3.26559830e+01, 3.80748401e+01, 1.71994945e-03, 1.52066076e-03]), 'mean_score_time': array([5.01620197, 6.728386  , 0.        , 0.        , 4.67967451,
       5.80420454, 0.        , 0.        , 5.29798636, 7.00982275,
       0.        , 0.        , 4.9331882 , 6.08825176, 0.        ,
       0.        ]), 'std_score_time': array([0.01088936, 0.01793046, 0.        , 0.        , 0.05313091,
       0.03168462, 0.        , 0.        , 0.01635378, 0.02219399,
       0.        , 0.        , 0.04742968, 0.01309879, 0.        ,
       0.        ]), 'param_dropout': masked_array(data=[True, True, True, True, True, True, True, True, True,
                   True, True, True, True, True, True, True],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_dropout_rate': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
                   0.2, 0.2, 0.2, 0.2, 0.2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_epochs': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
                   50, 50],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers_neurons': masked_array(data=[200, 200, 200, 200, 200, 200, 200, 200, 300, 300, 300,
                   300, 300, 300, 300, 300],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_loss': masked_array(data=['binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_modelType': masked_array(data=['LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU', 'GRU',
                   'GRU', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU',
                   'GRU', 'GRU'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_optimizer': masked_array(data=['adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_output_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers': masked_array(data=[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers_neurons': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,
                   50, 100, 50, 100],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}], 'split0_test_accuracy': array([0.99271275, 0.99379883,        nan,        nan, 0.993974  ,
       0.99330834,        nan,        nan, 0.99281785, 0.99299303,
              nan,        nan, 0.98836843, 0.99432435,        nan,
              nan]), 'split1_test_accuracy': array([0.99432435, 0.99453456,        nan,        nan, 0.99358862,
       0.9946747 ,        nan,        nan, 0.99379883, 0.99432435,
              nan,        nan, 0.99400904, 0.99372876,        nan,
              nan]), 'split2_test_accuracy': array([0.99218723, 0.99292296,        nan,        nan, 0.99267771,
       0.99362366,        nan,        nan, 0.99264268, 0.99404407,
              nan,        nan, 0.99365869, 0.99442946,        nan,
              nan]), 'split3_test_accuracy': array([0.99208212, 0.99222226,        nan,        nan, 0.99302806,
       0.9931682 ,        nan,        nan, 0.99215219, 0.9923624 ,
              nan,        nan, 0.99239744, 0.99309813,        nan,
              nan]), 'split4_test_accuracy': array([0.99393897, 0.9945696 ,        nan,        nan, 0.99414918,
       0.99432435,        nan,        nan, 0.993974  , 0.99250254,
              nan,        nan, 0.99442946, 0.99442946,        nan,
              nan]), 'split5_test_accuracy': array([0.99358862, 0.99313317,        nan,        nan, 0.99369373,
       0.99201205,        nan,        nan, 0.99243247, 0.99288792,
              nan,        nan, 0.99372876, 0.99358862,        nan,
              nan]), 'split6_test_accuracy': array([0.9923624 , 0.99145149,        nan,        nan, 0.99239744,
       0.9915566 ,        nan,        nan, 0.99176681, 0.99190695,
              nan,        nan, 0.99033038, 0.99334338,        nan,
              nan]), 'split7_test_accuracy': array([0.9938689 , 0.99299303,        nan,        nan, 0.993974  ,
       0.99372876,        nan,        nan, 0.99327331, 0.99337841,
              nan,        nan, 0.99393897, 0.99400904,        nan,
              nan]), 'split8_test_accuracy': array([0.99351832, 0.99414897,        nan,        nan, 0.99355336,
       0.99421905,        nan,        nan, 0.99302782, 0.993203  ,
              nan,        nan, 0.99418401, 0.9935884 ,        nan,
              nan]), 'split9_test_accuracy': array([0.99341322, 0.99404387,        nan,        nan, 0.99467451,
       0.99463948,        nan,        nan, 0.99383365, 0.99404387,
              nan,        nan, 0.99449933, 0.99435919,        nan,
              nan]), 'mean_test_accuracy': array([0.99319969, 0.99338187,        nan,        nan, 0.99357106,
       0.99352552,        nan,        nan, 0.99297196, 0.99316465,
              nan,        nan, 0.99295445, 0.99388988,        nan,
              nan]), 'std_test_accuracy': array([0.00075959, 0.00097132,        nan,        nan, 0.0006605 ,
       0.00100368,        nan,        nan, 0.00071217, 0.00075553,
              nan,        nan, 0.00193594, 0.00046245,        nan,
              nan]), 'rank_test_accuracy': array([ 5,  4,  9, 10,  2,  3, 11, 12,  7,  6, 13, 14,  8,  1, 15, 16],
      dtype=int32), 'split0_train_accuracy': array([0.99237013, 0.99367421,        nan,        nan, 0.99383771,
       0.99321876,        nan,        nan, 0.99266598, 0.99311365,
              nan,        nan, 0.98873037, 0.99416081,        nan,
              nan]), 'split1_train_accuracy': array([0.993355  , 0.99359246,        nan,        nan, 0.99275941,
       0.99381435,        nan,        nan, 0.99312533, 0.99351071,
              nan,        nan, 0.9928723 , 0.9927633 ,        nan,
              nan]), 'split2_train_accuracy': array([0.99264651, 0.99304358,        nan,        nan, 0.99280612,
       0.99392724,        nan,        nan, 0.99285283, 0.99407906,
              nan,        nan, 0.99372093, 0.99423088,        nan,
              nan]), 'split3_train_accuracy': array([0.99322265, 0.9933044 ,        nan,        nan, 0.99431652,
       0.99421531,        nan,        nan, 0.99338615, 0.99332775,
              nan,        nan, 0.99367421, 0.99418028,        nan,
              nan]), 'split4_train_accuracy': array([0.99358857, 0.99404013,        nan,        nan, 0.99363528,
       0.99398953,        nan,        nan, 0.99352629, 0.99227281,
              nan,        nan, 0.99385328, 0.9941141 ,        nan,
              nan]), 'split5_train_accuracy': array([0.99365086, 0.99320318,        nan,        nan, 0.99386885,
       0.99155653,        nan,        nan, 0.9925492 , 0.99322265,
              nan,        nan, 0.99389999, 0.99404013,        nan,
              nan]), 'split6_train_accuracy': array([0.99368589, 0.99262705,        nan,        nan, 0.99372093,
       0.99281391,        nan,        nan, 0.9928178 , 0.993355  ,
              nan,        nan, 0.99171614, 0.99421531,        nan,
              nan]), 'split7_train_accuracy': array([0.99376375, 0.9929268 ,        nan,        nan, 0.99407128,
       0.9935185 ,        nan,        nan, 0.99318761, 0.99320708,
              nan,        nan, 0.99356132, 0.99395839,        nan,
              nan]), 'split8_train_accuracy': array([0.99291515, 0.99414916,        nan,        nan, 0.99348349,
       0.99404794,        nan,        nan, 0.99308643, 0.99303971,
              nan,        nan, 0.99398566, 0.99371706,        nan,
              nan]), 'split9_train_accuracy': array([0.9924558 , 0.99349906,        nan,        nan, 0.99395841,
       0.9939662 ,        nan,        nan, 0.99317596, 0.99341342,
              nan,        nan, 0.99367034, 0.99339006,        nan,
              nan]), 'mean_train_accuracy': array([0.99316543, 0.993406  ,        nan,        nan, 0.9936458 ,
       0.99350683,        nan,        nan, 0.99303736, 0.99325419,
              nan,        nan, 0.99296845, 0.99387703,        nan,
              nan]), 'std_train_accuracy': array([0.00050505, 0.00045705,        nan,        nan, 0.00048354,
       0.00076662,        nan,        nan, 0.00029515, 0.00042652,
              nan,        nan, 0.00155347, 0.00044774,        nan,
              nan]), 'split0_test_precision': array([0.9044586 , 0.82113821,        nan,        nan, 0.84978541,
       0.70338983,        nan,        nan, 0.90625   , 0.74021352,
              nan,        nan, 0.50268336, 0.85306122,        nan,
              nan]), 'split1_test_precision': array([0.83333333, 0.83458647,        nan,        nan, 0.8994709 ,
       0.825     ,        nan,        nan, 0.78136201, 0.83076923,
              nan,        nan, 0.93121693, 0.91005291,        nan,
              nan]), 'split2_test_precision': array([0.85057471, 0.84541063,        nan,        nan, 0.88636364,
       0.87557604,        nan,        nan, 0.82926829, 0.84313725,
              nan,        nan, 0.85964912, 0.85227273,        nan,
              nan]), 'split3_test_precision': array([0.81981982, 0.82017544,        nan,        nan, 0.79238754,
       0.82889734,        nan,        nan, 0.81034483, 0.82608696,
              nan,        nan, 0.70914127, 0.81090909,        nan,
              nan]), 'split4_test_precision': array([0.74315068, 0.86363636,        nan,        nan, 0.83944954,
       0.77617329,        nan,        nan, 0.80168776, 0.63835616,
              nan,        nan, 0.88235294, 0.80952381,        nan,
              nan]), 'split5_test_precision': array([0.89767442, 0.75159236,        nan,        nan, 0.84251969,
       0.64318182,        nan,        nan, 0.86702128, 0.87192118,
              nan,        nan, 0.83018868, 0.80866426,        nan,
              nan]), 'split6_test_precision': array([0.7585034 , 0.85795455,        nan,        nan, 0.7953668 ,
       0.86857143,        nan,        nan, 0.83251232, 0.79324895,
              nan,        nan, 0.59791667, 0.89130435,        nan,
              nan]), 'split7_test_precision': array([0.80487805, 0.72058824,        nan,        nan, 0.79084967,
       0.87012987,        nan,        nan, 0.81102362, 0.80149813,
              nan,        nan, 0.7641791 , 0.87763713,        nan,
              nan]), 'split8_test_precision': array([0.78965517, 0.91517857,        nan,        nan, 0.88584475,
       0.8381295 ,        nan,        nan, 0.93258427, 0.91623037,
              nan,        nan, 0.85551331, 0.94270833,        nan,
              nan]), 'split9_test_precision': array([0.93063584, 0.85232068,        nan,        nan, 0.87449393,
       0.89655172,        nan,        nan, 0.83682008, 0.88479263,
              nan,        nan, 0.79220779, 0.94897959,        nan,
              nan]), 'mean_test_precision': array([0.8332684 , 0.82825815,        nan,        nan, 0.84565319,
       0.81256008,        nan,        nan, 0.84088745, 0.81462544,
              nan,        nan, 0.77250492, 0.87051134,        nan,
              nan]), 'std_test_precision': array([0.05966247, 0.05309274,        nan,        nan, 0.03928815,
       0.0777713 ,        nan,        nan, 0.0452657 , 0.07547979,
              nan,        nan, 0.12760298, 0.05015023,        nan,
              nan]), 'rank_test_precision': array([ 4,  5,  9, 10,  2,  7, 11, 12,  3,  6, 13, 14,  8,  1, 15, 16],
      dtype=int32), 'split0_train_precision': array([0.87661499, 0.82363088,        nan,        nan, 0.83499783,
       0.71517413,        nan,        nan, 0.88238916, 0.75788674,
              nan,        nan, 0.52364381, 0.85720562,        nan,
              nan]), 'split1_train_precision': array([0.82331512, 0.82463832,        nan,        nan, 0.89569019,
       0.81490581,        nan,        nan, 0.77651361, 0.81492666,
              nan,        nan, 0.91221374, 0.90850515,        nan,
              nan]), 'split2_train_precision': array([0.89504185, 0.84736017,        nan,        nan, 0.91765481,
       0.89693878,        nan,        nan, 0.83862434, 0.84962736,
              nan,        nan, 0.864983  , 0.85004284,        nan,
              nan]), 'split3_train_precision': array([0.86461704, 0.86849168,        nan,        nan, 0.83865616,
       0.85631929,        nan,        nan, 0.86339937, 0.86695051,
              nan,        nan, 0.75085441, 0.83487008,        nan,
              nan]), 'split4_train_precision': array([0.76815742, 0.89104116,        nan,        nan, 0.86235012,
       0.79732739,        nan,        nan, 0.82422387, 0.66811468,
              nan,        nan, 0.89431303, 0.83621399,        nan,
              nan]), 'split5_train_precision': array([0.86826347, 0.74003527,        nan,        nan, 0.82679181,
       0.6195209 ,        nan,        nan, 0.838728  , 0.85759162,
              nan,        nan, 0.81950207, 0.80685358,        nan,
              nan]), 'split6_train_precision': array([0.79869866, 0.88439306,        nan,        nan, 0.85224023,
       0.91417166,        nan,        nan, 0.86390187, 0.8545082 ,
              nan,        nan, 0.6210103 , 0.92037716,        nan,
              nan]), 'split7_train_precision': array([0.81242236, 0.72294969,        nan,        nan, 0.80943102,
       0.88416578,        nan,        nan, 0.82053698, 0.79903678,
              nan,        nan, 0.75233807, 0.89269521,        nan,
              nan]), 'split8_train_precision': array([0.72820695, 0.87729196,        nan,        nan, 0.83598875,
       0.78782355,        nan,        nan, 0.87755102, 0.85752979,
              nan,        nan, 0.79862438, 0.8948203 ,        nan,
              nan]), 'split9_train_precision': array([0.89586115, 0.8353321 ,        nan,        nan, 0.85309973,
       0.86267281,        nan,        nan, 0.80131868, 0.84926829,
              nan,        nan, 0.7611576 , 0.90282486,        nan,
              nan]), 'mean_train_precision': array([0.8331199 , 0.83151643,        nan,        nan, 0.85269007,
       0.81490201,        nan,        nan, 0.83871869, 0.81754406,
              nan,        nan, 0.76986404, 0.87044088,        nan,
              nan]), 'std_train_precision': array([0.0536898 , 0.05507478,        nan,        nan, 0.03081246,
       0.0863371 ,        nan,        nan, 0.03235321, 0.05939973,
              nan,        nan, 0.11472396, 0.03626598,        nan,
              nan]), 'split0_test_recall': array([0.4238806 , 0.60298507,        nan,        nan, 0.59104478,
       0.74328358,        nan,        nan, 0.43283582, 0.62089552,
              nan,        nan, 0.83880597, 0.6238806 ,        nan,
              nan]), 'split1_test_recall': array([0.64371257, 0.66467066,        nan,        nan, 0.50898204,
       0.69161677,        nan,        nan, 0.65269461, 0.64670659,
              nan,        nan, 0.52694611, 0.51497006,        nan,
              nan]), 'split2_test_recall': array([0.42898551, 0.50724638,        nan,        nan, 0.45217391,
       0.55072464,        nan,        nan, 0.49275362, 0.62318841,
              nan,        nan, 0.56811594, 0.65217391,        nan,
              nan]), 'split3_test_recall': array([0.49456522, 0.50815217,        nan,        nan, 0.62228261,
       0.5923913 ,        nan,        nan, 0.51086957, 0.51630435,
              nan,        nan, 0.69565217, 0.60597826,        nan,
              nan]), 'split4_test_recall': array([0.68888889, 0.6031746 ,        nan,        nan, 0.58095238,
       0.68253968,        nan,        nan, 0.6031746 , 0.73968254,
              nan,        nan, 0.57142857, 0.64761905,        nan,
              nan]), 'split5_test_recall': array([0.54519774, 0.66666667,        nan,        nan, 0.60451977,
       0.79943503,        nan,        nan, 0.46045198, 0.5       ,
              nan,        nan, 0.62146893, 0.63276836,        nan,
              nan]), 'split6_test_recall': array([0.6027027 , 0.40810811,        nan,        nan, 0.55675676,
       0.41081081,        nan,        nan, 0.45675676, 0.50810811,
              nan,        nan, 0.77567568, 0.55405405,        nan,
              nan]), 'split7_test_recall': array([0.66      , 0.7       ,        nan,        nan, 0.69142857,
       0.57428571,        nan,        nan, 0.58857143, 0.61142857,
              nan,        nan, 0.73142857, 0.59428571,        nan,
              nan]), 'split8_test_recall': array([0.64872521, 0.58073654,        nan,        nan, 0.54957507,
       0.66005666,        nan,        nan, 0.47025496, 0.49575071,
              nan,        nan, 0.63739377, 0.51274788,        nan,
              nan]), 'split9_test_recall': array([0.47774481, 0.59940653,        nan,        nan, 0.64094955,
       0.61721068,        nan,        nan, 0.59347181, 0.56973294,
              nan,        nan, 0.72403561, 0.55192878,        nan,
              nan]), 'mean_test_recall': array([0.56144032, 0.58411467,        nan,        nan, 0.57986654,
       0.63223549,        nan,        nan, 0.52618352, 0.58317977,
              nan,        nan, 0.66909513, 0.58904067,        nan,
              nan]), 'std_test_recall': array([0.09500269, 0.08387817,        nan,        nan, 0.06441422,
       0.10390497,        nan,        nan, 0.07258597, 0.0756317 ,
              nan,        nan, 0.09538632, 0.04976541,        nan,
              nan]), 'rank_test_recall': array([ 7,  4,  9, 10,  6,  2, 11, 12,  8,  5, 13, 14,  1,  3, 15, 16],
      dtype=int32), 'split0_train_recall': array([0.43410109, 0.61100448,        nan,        nan, 0.61516315,
       0.73576456,        nan,        nan, 0.45841331, 0.63787588,
              nan,        nan, 0.81829814, 0.62412028,        nan,
              nan]), 'split1_train_recall': array([0.57818996, 0.60153502,        nan,        nan, 0.4585865 ,
       0.63639271,        nan,        nan, 0.61112888, 0.60409338,
              nan,        nan, 0.4585865 , 0.45091142,        nan,
              nan]), 'split2_train_recall': array([0.44608472, 0.52021823,        nan,        nan, 0.4470475 ,
       0.56418485,        nan,        nan, 0.50866496, 0.62195122,
              nan,        nan, 0.57156611, 0.63671374,        nan,
              nan]), 'split3_train_recall': array([0.51826705, 0.52311672,        nan,        nan, 0.65373424,
       0.62431296,        nan,        nan, 0.53540252, 0.52667313,
              nan,        nan, 0.71031361, 0.64403492,        nan,
              nan]), 'split4_train_recall': array([0.68245391, 0.58486968,        nan,        nan, 0.57151939,
       0.68277177,        nan,        nan, 0.59917355, 0.73331214,
              nan,        nan, 0.56484425, 0.64589955,        nan,
              nan]), 'split5_train_recall': array([0.56002575, 0.67524944,        nan,        nan, 0.62375282,
       0.78242678,        nan,        nan, 0.47537818, 0.52719665,
              nan,        nan, 0.63566141, 0.66688124,        nan,
              nan]), 'split6_train_recall': array([0.63539308, 0.4454869 ,        nan,        nan, 0.57845357,
       0.44451634,        nan,        nan, 0.47848593, 0.53963119,
              nan,        nan, 0.79941766, 0.56842446,        nan,
              nan]), 'split7_train_recall': array([0.63066538, 0.67438123,        nan,        nan, 0.66763099,
       0.53487625,        nan,        nan, 0.55994857, 0.58662809,
              nan,        nan, 0.69816779, 0.56959177,        nan,
              nan]), 'split8_train_recall': array([0.66119691, 0.6003861 ,        nan,        nan, 0.57400257,
       0.69530245,        nan,        nan, 0.4980695 , 0.50933076,
              nan,        nan, 0.67245817, 0.54472329,        nan,
              nan]), 'split9_train_recall': array([0.42957746, 0.57970551,        nan,        nan, 0.60787452,
       0.59923175,        nan,        nan, 0.58354673, 0.55729834,
              nan,        nan, 0.69878361, 0.51152369,        nan,
              nan]), 'mean_train_recall': array([0.55759553, 0.58159533,        nan,        nan, 0.57977652,
       0.62997804,        nan,        nan, 0.53082121, 0.58439908,
              nan,        nan, 0.66280973, 0.58628244,        nan,
              nan]), 'std_train_recall': array([0.09152347, 0.06687495,        nan,        nan, 0.07040672,
       0.09501241,        nan,        nan, 0.05233558, 0.0646654 ,
              nan,        nan, 0.10397076, 0.06602997,        nan,
              nan]), 'split0_test_roc_auc': array([0.9909126 , 0.99154045,        nan,        nan, 0.99108488,
       0.99211867,        nan,        nan, 0.99057047, 0.99063582,
              nan,        nan, 0.99148003, 0.99222037,        nan,
              nan]), 'split1_test_roc_auc': array([0.98852863, 0.99049598,        nan,        nan, 0.98785297,
       0.98906961,        nan,        nan, 0.98821744, 0.98793098,
              nan,        nan, 0.99022342, 0.99003217,        nan,
              nan]), 'split2_test_roc_auc': array([0.99059333, 0.99014515,        nan,        nan, 0.98932949,
       0.99057976,        nan,        nan, 0.98945994, 0.99075574,
              nan,        nan, 0.99013549, 0.99133107,        nan,
              nan]), 'split3_test_roc_auc': array([0.98921854, 0.98981993,        nan,        nan, 0.98990789,
       0.98696578,        nan,        nan, 0.98865437, 0.98807251,
              nan,        nan, 0.98890764, 0.99031336,        nan,
              nan]), 'split4_test_roc_auc': array([0.98651187, 0.98570563,        nan,        nan, 0.98730147,
       0.98922594,        nan,        nan, 0.986966  , 0.98535868,
              nan,        nan, 0.98850466, 0.98877092,        nan,
              nan]), 'split5_test_roc_auc': array([0.99095783, 0.98946367,        nan,        nan, 0.99071992,
       0.9902804 ,        nan,        nan, 0.98980319, 0.98936276,
              nan,        nan, 0.99101435, 0.98868453,        nan,
              nan]), 'split6_test_roc_auc': array([0.99016185, 0.99024061,        nan,        nan, 0.9902833 ,
       0.99041732,        nan,        nan, 0.9899507 , 0.98967326,
              nan,        nan, 0.99177898, 0.99216376,        nan,
              nan]), 'split7_test_roc_auc': array([0.98858065, 0.9871724 ,        nan,        nan, 0.98816636,
       0.9878973 ,        nan,        nan, 0.98697985, 0.98654914,
              nan,        nan, 0.98781278, 0.98901054,        nan,
              nan]), 'split8_test_roc_auc': array([0.98941895, 0.99305005,        nan,        nan, 0.98915877,
       0.99232729,        nan,        nan, 0.98551662, 0.99054048,
              nan,        nan, 0.99059143, 0.99002404,        nan,
              nan]), 'split9_test_roc_auc': array([0.98670712, 0.98311125,        nan,        nan, 0.98783178,
       0.98660222,        nan,        nan, 0.98579045, 0.9851389 ,
              nan,        nan, 0.98650512, 0.98753252,        nan,
              nan]), 'mean_test_roc_auc': array([0.98915914, 0.98907451,        nan,        nan, 0.98916368,
       0.98954843,        nan,        nan, 0.9881909 , 0.98840183,
              nan,        nan, 0.98969539, 0.99000833,        nan,
              nan]), 'std_test_roc_auc': array([0.00152302, 0.00278653,        nan,        nan, 0.00126104,
       0.00187329,        nan,        nan, 0.00170487, 0.00203262,
              nan,        nan, 0.00162178, 0.00147619,        nan,
              nan]), 'rank_test_roc_auc': array([ 5,  6,  9, 10,  4,  3, 11, 12,  8,  7, 13, 14,  2,  1, 15, 16],
      dtype=int32), 'split0_train_roc_auc': array([0.98906387, 0.98929609,        nan,        nan, 0.98906386,
       0.99032979,        nan,        nan, 0.98793191, 0.98883601,
              nan,        nan, 0.98948783, 0.99070511,        nan,
              nan]), 'split1_train_roc_auc': array([0.98921792, 0.99031896,        nan,        nan, 0.98945616,
       0.98963919,        nan,        nan, 0.98879646, 0.98722061,
              nan,        nan, 0.99058498, 0.98977553,        nan,
              nan]), 'split2_train_roc_auc': array([0.98933005, 0.98867037,        nan,        nan, 0.98831726,
       0.98978222,        nan,        nan, 0.98807305, 0.98995662,
              nan,        nan, 0.98921958, 0.9908128 ,        nan,
              nan]), 'split3_train_roc_auc': array([0.98960352, 0.98938295,        nan,        nan, 0.98997614,
       0.9887746 ,        nan,        nan, 0.98857633, 0.98797844,
              nan,        nan, 0.9897148 , 0.9908839 ,        nan,
              nan]), 'split4_train_roc_auc': array([0.98945164, 0.99008381,        nan,        nan, 0.98992503,
       0.99049311,        nan,        nan, 0.98883518, 0.98903436,
              nan,        nan, 0.99001637, 0.99009629,        nan,
              nan]), 'split5_train_roc_auc': array([0.98828666, 0.98943724,        nan,        nan, 0.98912602,
       0.98951224,        nan,        nan, 0.98816199, 0.98867182,
              nan,        nan, 0.98978338, 0.98918127,        nan,
              nan]), 'split6_train_roc_auc': array([0.98914501, 0.98963999,        nan,        nan, 0.98930223,
       0.98851974,        nan,        nan, 0.98845554, 0.98819482,
              nan,        nan, 0.99102023, 0.9908126 ,        nan,
              nan]), 'split7_train_roc_auc': array([0.98989426, 0.98925583,        nan,        nan, 0.98960946,
       0.9903921 ,        nan,        nan, 0.98907687, 0.98929211,
              nan,        nan, 0.98948141, 0.99039282,        nan,
              nan]), 'split8_train_roc_auc': array([0.98905243, 0.99041248,        nan,        nan, 0.98932044,
       0.9903255 ,        nan,        nan, 0.98594369, 0.98893512,
              nan,        nan, 0.9895282 , 0.98832878,        nan,
              nan]), 'split9_train_roc_auc': array([0.99004103, 0.98833269,        nan,        nan, 0.99045291,
       0.98944384,        nan,        nan, 0.98827099, 0.98837446,
              nan,        nan, 0.99019054, 0.99012728,        nan,
              nan]), 'mean_train_roc_auc': array([0.98930864, 0.98948304,        nan,        nan, 0.98945495,
       0.98972123,        nan,        nan, 0.9882122 , 0.98864944,
              nan,        nan, 0.98990273, 0.99011164,        nan,
              nan]), 'std_train_roc_auc': array([0.00046821, 0.00063487,        nan,        nan, 0.00055761,
       0.00065208,        nan,        nan, 0.0008318 , 0.00071839,
              nan,        nan, 0.00053068, 0.00078538,        nan,
              nan]), 'split0_test_f1': array([0.57723577, 0.69535284,        nan,        nan, 0.6971831 ,
       0.72278665,        nan,        nan, 0.58585859, 0.67532468,
              nan,        nan, 0.62863535, 0.72068966,        nan,
              nan]), 'split1_test_f1': array([0.72635135, 0.74      ,        nan,        nan, 0.6500956 ,
       0.752443  ,        nan,        nan, 0.71125612, 0.72727273,
              nan,        nan, 0.67304015, 0.65774379,        nan,
              nan]), 'split2_test_f1': array([0.57032755, 0.63405797,        nan,        nan, 0.59884837,
       0.67615658,        nan,        nan, 0.61818182, 0.71666667,
              nan,        nan, 0.68411867, 0.73891626,        nan,
              nan]), 'split3_test_f1': array([0.61694915, 0.62751678,        nan,        nan, 0.69710807,
       0.69096672,        nan,        nan, 0.62666667, 0.63545151,
              nan,        nan, 0.70233196, 0.69362364,        nan,
              nan]), 'split4_test_f1': array([0.71499176, 0.71028037,        nan,        nan, 0.68667917,
       0.72635135,        nan,        nan, 0.6884058 , 0.68529412,
              nan,        nan, 0.69364162, 0.71957672,        nan,
              nan]), 'split5_test_f1': array([0.67838313, 0.70658683,        nan,        nan, 0.70394737,
       0.71284635,        nan,        nan, 0.60147601, 0.63554758,
              nan,        nan, 0.71082391, 0.70998415,        nan,
              nan]), 'split6_test_f1': array([0.67168675, 0.55311355,        nan,        nan, 0.65500795,
       0.55779817,        nan,        nan, 0.58987784, 0.61943987,
              nan,        nan, 0.67529412, 0.68333333,        nan,
              nan]), 'split7_test_f1': array([0.72527473, 0.71014493,        nan,        nan, 0.73780488,
       0.6919105 ,        nan,        nan, 0.68211921, 0.69367909,
              nan,        nan, 0.74744526, 0.70868825,        nan,
              nan]), 'split8_test_f1': array([0.71228616, 0.71057192,        nan,        nan, 0.67832168,
       0.7385103 ,        nan,        nan, 0.6252354 , 0.64338235,
              nan,        nan, 0.73051948, 0.66422018,        nan,
              nan]), 'split9_test_f1': array([0.63137255, 0.70383275,        nan,        nan, 0.73972603,
       0.73110721,        nan,        nan, 0.69444444, 0.69314079,
              nan,        nan, 0.75658915, 0.69793621,        nan,
              nan]), 'mean_test_f1': array([0.66248589, 0.67914579,        nan,        nan, 0.68447222,
       0.70008768,        nan,        nan, 0.64235219, 0.67251994,
              nan,        nan, 0.70024397, 0.69947122,        nan,
              nan]), 'std_test_f1': array([0.05691917, 0.05369251,        nan,        nan, 0.04002737,
       0.05245613,        nan,        nan, 0.04461264, 0.03521121,
              nan,        nan, 0.03637251, 0.02426239,        nan,
              nan]), 'rank_test_f1': array([ 7,  5,  9, 10,  4,  2, 11, 12,  8,  6, 13, 14,  1,  3, 15, 16],
      dtype=int32), 'split0_train_f1': array([0.58065896, 0.70156107,        nan,        nan, 0.70841776,
       0.72532324,        nan,        nan, 0.60336842, 0.6927219 ,
              nan,        nan, 0.63862189, 0.72232506,        nan,
              nan]), 'split1_train_f1': array([0.67931618, 0.69563609,        nan,        nan, 0.60659898,
       0.7146705 ,        nan,        nan, 0.68396564, 0.69384757,
              nan,        nan, 0.61034263, 0.60269288,        nan,
              nan]), 'split2_train_f1': array([0.59541658, 0.64466097,        nan,        nan, 0.60120846,
       0.69267139,        nan,        nan, 0.63324011, 0.71817676,
              nan,        nan, 0.68830918, 0.72807339,        nan,
              nan]), 'split3_train_f1': array([0.64806954, 0.65294592,        nan,        nan, 0.73473837,
       0.72213912,        nan,        nan, 0.66094592, 0.65526951,
              nan,        nan, 0.7300216 , 0.72713999,        nan,
              nan]), 'split4_train_f1': array([0.72277394, 0.70619843,        nan,        nan, 0.68744026,
       0.73561644,        nan,        nan, 0.6939076 , 0.69919685,
              nan,        nan, 0.69238262, 0.72883788,        nan,
              nan]), 'split5_train_f1': array([0.68088437, 0.70615954,        nan,        nan, 0.71106219,
       0.69150903,        nan,        nan, 0.60682005, 0.65297987,
              nan,        nan, 0.71596882, 0.73022026,        nan,
              nan]), 'split6_train_f1': array([0.70774775, 0.59251291,        nan,        nan, 0.68915013,
       0.59817153,        nan,        nan, 0.61586508, 0.66151101,
              nan,        nan, 0.6990099 , 0.7028    ,        nan,
              nan]), 'split7_train_f1': array([0.71009772, 0.69782139,        nan,        nan, 0.7317245 ,
       0.66653315,        nan,        nan, 0.66564769, 0.67655236,
              nan,        nan, 0.72424141, 0.69544741,        nan,
              nan]), 'split8_train_f1': array([0.693086  , 0.71289398,        nan,        nan, 0.68065624,
       0.73867715,        nan,        nan, 0.63546798, 0.63907953,
              nan,        nan, 0.730131  , 0.6772    ,        nan,
              nan]), 'split9_train_f1': array([0.580701  , 0.68442933,        nan,        nan, 0.70990654,
       0.70721572,        nan,        nan, 0.67531024, 0.67298029,
              nan,        nan, 0.72863818, 0.65304454,        nan,
              nan]), 'mean_train_f1': array([0.6598752 , 0.67948196,        nan,        nan, 0.68609034,
       0.69925273,        nan,        nan, 0.64745387, 0.67623156,
              nan,        nan, 0.69576672, 0.69677814,        nan,
              nan]), 'std_train_f1': array([0.05246969, 0.03623722,        nan,        nan, 0.044388  ,
       0.03971453,        nan,        nan, 0.03117413, 0.02335969,
              nan,        nan, 0.03910775, 0.03985735,        nan,
              nan]), 'split0_test_average_precision': array([0.74494271, 0.77506987,        nan,        nan, 0.76769451,
       0.779678  ,        nan,        nan, 0.75292277, 0.73756603,
              nan,        nan, 0.78602253, 0.80186722,        nan,
              nan]), 'split1_test_average_precision': array([0.76655249, 0.77873685,        nan,        nan, 0.77391255,
       0.78462872,        nan,        nan, 0.75664851, 0.7653956 ,
              nan,        nan, 0.78985026, 0.78784981,        nan,
              nan]), 'split2_test_average_precision': array([0.74381164, 0.73903443,        nan,        nan, 0.75650393,
       0.7793114 ,        nan,        nan, 0.72270027, 0.76257437,
              nan,        nan, 0.75506015, 0.77765602,        nan,
              nan]), 'split3_test_average_precision': array([0.71500564, 0.71581788,        nan,        nan, 0.75322729,
       0.75751693,        nan,        nan, 0.70912146, 0.70944677,
              nan,        nan, 0.74415736, 0.74973277,        nan,
              nan]), 'split4_test_average_precision': array([0.74981396, 0.78096586,        nan,        nan, 0.75918663,
       0.77256   ,        nan,        nan, 0.74279913, 0.73789887,
              nan,        nan, 0.77583115, 0.77439427,        nan,
              nan]), 'split5_test_average_precision': array([0.77977965, 0.765989  ,        nan,        nan, 0.78213755,
       0.79783429,        nan,        nan, 0.73350269, 0.76104371,
              nan,        nan, 0.78216947, 0.78653117,        nan,
              nan]), 'split6_test_average_precision': array([0.73134737, 0.72914716,        nan,        nan, 0.72946163,
       0.74132527,        nan,        nan, 0.71617313, 0.71512504,
              nan,        nan, 0.77264604, 0.77900899,        nan,
              nan]), 'split7_test_average_precision': array([0.76080219, 0.73821729,        nan,        nan, 0.77633371,
       0.76657994,        nan,        nan, 0.73347853, 0.73126211,
              nan,        nan, 0.76843918, 0.78534226,        nan,
              nan]), 'split8_test_average_precision': array([0.76150737, 0.81906814,        nan,        nan, 0.77792037,
       0.80659299,        nan,        nan, 0.76178133, 0.76780696,
              nan,        nan, 0.79411677, 0.79900892,        nan,
              nan]), 'split9_test_average_precision': array([0.78217812, 0.75818435,        nan,        nan, 0.79821352,
       0.79936983,        nan,        nan, 0.75483844, 0.75880839,
              nan,        nan, 0.79415847, 0.80816223,        nan,
              nan]), 'mean_test_average_precision': array([0.75357411, 0.76002308,        nan,        nan, 0.76745917,
       0.77853974,        nan,        nan, 0.73839663, 0.74469278,
              nan,        nan, 0.77624514, 0.78495537,        nan,
              nan]), 'std_test_average_precision': array([0.01988477, 0.02892048,        nan,        nan, 0.01796105,
       0.019073  ,        nan,        nan, 0.01739578, 0.02035458,
              nan,        nan, 0.01583845, 0.01572861,        nan,
              nan]), 'rank_test_average_precision': array([ 6,  5,  9, 10,  4,  2, 11, 12,  8,  7, 13, 14,  3,  1, 15, 16],
      dtype=int32), 'split0_train_average_precision': array([0.74425327, 0.76121551,        nan,        nan, 0.76465134,
       0.77494906,        nan,        nan, 0.74251091, 0.73726367,
              nan,        nan, 0.77614001, 0.78658113,        nan,
              nan]), 'split1_train_average_precision': array([0.74664037, 0.76284452,        nan,        nan, 0.75966628,
       0.76904251,        nan,        nan, 0.73663332, 0.74400653,
              nan,        nan, 0.77540602, 0.77094233,        nan,
              nan]), 'split2_train_average_precision': array([0.75859984, 0.74233808,        nan,        nan, 0.76996261,
       0.79253685,        nan,        nan, 0.72961207, 0.78055899,
              nan,        nan, 0.77054073, 0.78896388,        nan,
              nan]), 'split3_train_average_precision': array([0.75397417, 0.75605213,        nan,        nan, 0.78397344,
       0.77912406,        nan,        nan, 0.7532038 , 0.75115881,
              nan,        nan, 0.77861221, 0.78334734,        nan,
              nan]), 'split4_train_average_precision': array([0.76229275, 0.79019598,        nan,        nan, 0.77094534,
       0.78270718,        nan,        nan, 0.75305423, 0.74831027,
              nan,        nan, 0.78470452, 0.78251037,        nan,
              nan]), 'split5_train_average_precision': array([0.75842495, 0.74968433,        nan,        nan, 0.76290914,
       0.78137865,        nan,        nan, 0.71612787, 0.74282925,
              nan,        nan, 0.76771958, 0.77384662,        nan,
              nan]), 'split6_train_average_precision': array([0.7554631 , 0.75268832,        nan,        nan, 0.76272784,
       0.76958561,        nan,        nan, 0.74215392, 0.74393342,
              nan,        nan, 0.800423  , 0.81047213,        nan,
              nan]), 'split7_train_average_precision': array([0.76432338, 0.74074304,        nan,        nan, 0.77830153,
       0.77239415,        nan,        nan, 0.73675348, 0.73419508,
              nan,        nan, 0.77221476, 0.78859112,        nan,
              nan]), 'split8_train_average_precision': array([0.73887269, 0.78960634,        nan,        nan, 0.75277467,
       0.78325415,        nan,        nan, 0.74413994, 0.74265727,
              nan,        nan, 0.77306447, 0.77504538,        nan,
              nan]), 'split9_train_average_precision': array([0.75813185, 0.74629956,        nan,        nan, 0.77595346,
       0.777342  ,        nan,        nan, 0.73586209, 0.74490877,
              nan,        nan, 0.77354483, 0.78103685,        nan,
              nan]), 'mean_train_average_precision': array([0.75409764, 0.75916678,        nan,        nan, 0.76818657,
       0.77823142,        nan,        nan, 0.73900516, 0.74698221,
              nan,        nan, 0.77723701, 0.78413371,        nan,
              nan]), 'std_train_average_precision': array([0.00783069, 0.01684308,        nan,        nan, 0.00896045,
       0.00682226,        nan,        nan, 0.01039098, 0.01209533,
              nan,        nan, 0.00889656, 0.0105744 ,        nan,
              nan])}, 'n_splits_': 10}
 _ _ _ _ _ _ _ _ _ _ MODEL # 1  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.525 
        MEAN TEST SCORE :  5.016 STD TEST SCORE :  0.011 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  5 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.992    0.993    0.993    0.993    0.994    0.994    0.994    0.994    0.993    0.992  
TEST   0.993    0.994    0.992    0.992    0.994    0.994    0.992    0.994    0.994    0.993  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.877    0.823    0.895    0.865    0.768    0.868    0.799    0.812    0.728    0.896  
TEST   0.904    0.833    0.851    0.820    0.743    0.898    0.759    0.805    0.790    0.931  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.434    0.578    0.446    0.518    0.682    0.560    0.635    0.631    0.661    0.430  
TEST   0.424    0.644    0.429    0.495    0.689    0.545    0.603    0.660    0.649    0.478  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.989    0.990    0.989    0.988    0.989    0.990    0.989    0.990  
TEST   0.991    0.989    0.991    0.989    0.987    0.991    0.990    0.989    0.989    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.744    0.747    0.759    0.754    0.762    0.758    0.755    0.764    0.739    0.758  
TEST   0.745    0.767    0.744    0.715    0.750    0.780    0.731    0.761    0.762    0.782  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.581    0.679    0.595    0.648    0.723    0.681    0.708    0.710    0.693    0.581  
TEST   0.577    0.726    0.570    0.617    0.715    0.678    0.672    0.725    0.712    0.631  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#1_acc.png





Saving image with name:  Model#1_prec.png


Saving image with name:  Model#1_rec.png


Saving image with name:  Model#1_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 2  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   82.226 
        MEAN TEST SCORE :  6.728 STD TEST SCORE :  0.018 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  4 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.994    0.993    0.993    0.994    0.993    0.993    0.993    0.994    0.993  
TEST   0.994    0.995    0.993    0.992    0.995    0.993    0.991    0.993    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.824    0.825    0.847    0.868    0.891    0.740    0.884    0.723    0.877    0.835  
TEST   0.821    0.835    0.845    0.820    0.864    0.752    0.858    0.721    0.915    0.852  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.611    0.602    0.520    0.523    0.585    0.675    0.445    0.674    0.600    0.580  
TEST   0.603    0.665    0.507    0.508    0.603    0.667    0.408    0.700    0.581    0.599  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.99     0.989    0.989    0.990    0.989    0.99     0.989    0.990    0.988  
TEST   0.992    0.99     0.990    0.990    0.986    0.989    0.99     0.987    0.993    0.983  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.761    0.763    0.742    0.756    0.790    0.750    0.753    0.741    0.790    0.746  
TEST   0.775    0.779    0.739    0.716    0.781    0.766    0.729    0.738    0.819    0.758  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.702    0.696    0.645    0.653    0.706    0.706    0.593    0.698    0.713    0.684  
TEST   0.695    0.740    0.634    0.628    0.710    0.707    0.553    0.710    0.711    0.704  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#2_acc.png





Saving image with name:  Model#2_prec.png


Saving image with name:  Model#2_rec.png


Saving image with name:  Model#2_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 3  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  9 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#3_acc.png





Saving image with name:  Model#3_prec.png


Saving image with name:  Model#3_rec.png


Saving image with name:  Model#3_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 4  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  10 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#4_acc.png





Saving image with name:  Model#4_prec.png


Saving image with name:  Model#4_rec.png


Saving image with name:  Model#4_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 5  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   1.274 
        MEAN TEST SCORE :  4.68 STD TEST SCORE :  0.053 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  2 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.993    0.994    0.994    0.994    0.994    0.994    0.993    0.994  
TEST   0.994    0.994    0.993    0.993    0.994    0.994    0.992    0.994    0.994    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.835    0.896    0.918    0.839    0.862    0.827    0.852    0.809    0.836    0.853  
TEST   0.850    0.899    0.886    0.792    0.839    0.843    0.795    0.791    0.886    0.874  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.615    0.459    0.447    0.654    0.572    0.624    0.578    0.668    0.574    0.608  
TEST   0.591    0.509    0.452    0.622    0.581    0.605    0.557    0.691    0.550    0.641  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.988    0.99     0.990    0.989    0.989    0.990    0.989    0.990  
TEST   0.991    0.988    0.989    0.99     0.987    0.991    0.990    0.988    0.989    0.988  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.765    0.760    0.770    0.784    0.771    0.763    0.763    0.778    0.753    0.776  
TEST   0.768    0.774    0.757    0.753    0.759    0.782    0.729    0.776    0.778    0.798  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.708    0.607    0.601    0.735    0.687    0.711    0.689    0.732    0.681    0.71   
TEST   0.697    0.650    0.599    0.697    0.687    0.704    0.655    0.738    0.678    0.74   
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#5_acc.png





Saving image with name:  Model#5_prec.png


Saving image with name:  Model#5_rec.png


Saving image with name:  Model#5_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 6  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.653 
        MEAN TEST SCORE :  5.804 STD TEST SCORE :  0.032 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  3 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.994    0.994    0.992    0.993    0.994    0.994    0.994  
TEST   0.993    0.995    0.994    0.993    0.994    0.992    0.992    0.994    0.994    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.715    0.815    0.897    0.856    0.797    0.620    0.914    0.884    0.788    0.863  
TEST   0.703    0.825    0.876    0.829    0.776    0.643    0.869    0.870    0.838    0.897  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.736    0.636    0.564    0.624    0.683    0.782    0.445    0.535    0.695    0.599  
TEST   0.743    0.692    0.551    0.592    0.683    0.799    0.411    0.574    0.660    0.617  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.990    0.990    0.989    0.990    0.99     0.989    0.990    0.990    0.989  
TEST   0.992    0.989    0.991    0.987    0.989    0.99     0.990    0.988    0.992    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.775    0.769    0.793    0.779    0.783    0.781    0.770    0.772    0.783    0.777  
TEST   0.780    0.785    0.779    0.758    0.773    0.798    0.741    0.767    0.807    0.799  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.725    0.715    0.693    0.722    0.736    0.692    0.598    0.667    0.739    0.707  
TEST   0.723    0.752    0.676    0.691    0.726    0.713    0.558    0.692    0.739    0.731  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#6_acc.png





Saving image with name:  Model#6_prec.png


Saving image with name:  Model#6_rec.png


Saving image with name:  Model#6_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 7  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  11 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#7_acc.png





Saving image with name:  Model#7_prec.png


Saving image with name:  Model#7_rec.png


Saving image with name:  Model#7_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 8  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  12 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#8_acc.png





Saving image with name:  Model#8_prec.png


Saving image with name:  Model#8_rec.png


Saving image with name:  Model#8_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 9  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.731 
        MEAN TEST SCORE :  5.298 STD TEST SCORE :  0.016 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  7 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.993    0.993    0.993    0.994    0.993    0.993    0.993    0.993    0.993  
TEST   0.993    0.994    0.993    0.992    0.994    0.992    0.992    0.993    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.882    0.777    0.839    0.863    0.824    0.839    0.864    0.821    0.878    0.801  
TEST   0.906    0.781    0.829    0.810    0.802    0.867    0.833    0.811    0.933    0.837  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.458    0.611    0.509    0.535    0.599    0.475    0.478    0.560    0.498    0.584  
TEST   0.433    0.653    0.493    0.511    0.603    0.460    0.457    0.589    0.470    0.593  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.988    0.989    0.988    0.989    0.989    0.988    0.988    0.989    0.986    0.988  
TEST   0.991    0.988    0.989    0.989    0.987    0.990    0.990    0.987    0.986    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.743    0.737    0.730    0.753    0.753    0.716    0.742    0.737    0.744    0.736  
TEST   0.753    0.757    0.723    0.709    0.743    0.734    0.716    0.733    0.762    0.755  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.603    0.684    0.633    0.661    0.694    0.607    0.616    0.666    0.635    0.675  
TEST   0.586    0.711    0.618    0.627    0.688    0.601    0.590    0.682    0.625    0.694  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#9_acc.png





Saving image with name:  Model#9_prec.png


Saving image with name:  Model#9_rec.png


Saving image with name:  Model#9_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 10  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   38.73 
        MEAN TEST SCORE :  7.01 STD TEST SCORE :  0.022 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  6 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.993    0.992    0.993    0.993    0.993    0.993    0.993  
TEST   0.993    0.994    0.994    0.992    0.993    0.993    0.992    0.993    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.758    0.815    0.850    0.867    0.668    0.858    0.855    0.799    0.858    0.849  
TEST   0.740    0.831    0.843    0.826    0.638    0.872    0.793    0.801    0.916    0.885  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.638    0.604    0.622    0.527    0.733    0.527    0.540    0.587    0.509    0.557  
TEST   0.621    0.647    0.623    0.516    0.740    0.500    0.508    0.611    0.496    0.570  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.987    0.990    0.988    0.989    0.989    0.988    0.989    0.989    0.988  
TEST   0.991    0.988    0.991    0.988    0.985    0.989    0.990    0.987    0.991    0.985  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.737    0.744    0.781    0.751    0.748    0.743    0.744    0.734    0.743    0.745  
TEST   0.738    0.765    0.763    0.709    0.738    0.761    0.715    0.731    0.768    0.759  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.693    0.694    0.718    0.655    0.699    0.653    0.662    0.677    0.639    0.673  
TEST   0.675    0.727    0.717    0.635    0.685    0.636    0.619    0.694    0.643    0.693  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#10_acc.png





Saving image with name:  Model#10_prec.png


Saving image with name:  Model#10_rec.png


Saving image with name:  Model#10_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 11  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  13 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#11_acc.png





Saving image with name:  Model#11_prec.png


Saving image with name:  Model#11_rec.png


Saving image with name:  Model#11_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 12  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  14 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#12_acc.png





Saving image with name:  Model#12_prec.png


Saving image with name:  Model#12_rec.png


Saving image with name:  Model#12_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 13  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   32.656 
        MEAN TEST SCORE :  4.933 STD TEST SCORE :  0.047 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.002 STD TRAIN SCORE:  8 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.993    0.994    0.994    0.994    0.994    0.992    0.994    0.994    0.994  
TEST   0.988    0.994    0.994    0.992    0.994    0.994    0.990    0.994    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.524    0.912    0.865    0.751    0.894    0.82     0.621    0.752    0.799    0.761  
TEST   0.503    0.931    0.860    0.709    0.882    0.83     0.598    0.764    0.856    0.792  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.818    0.459    0.572    0.710    0.565    0.636    0.799    0.698    0.672    0.699  
TEST   0.839    0.527    0.568    0.696    0.571    0.621    0.776    0.731    0.637    0.724  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.991    0.989    0.990    0.990    0.990    0.991    0.989    0.990    0.990  
TEST   0.991    0.990    0.990    0.989    0.989    0.991    0.992    0.988    0.991    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.776    0.775    0.771    0.779    0.785    0.768    0.800    0.772    0.773    0.774  
TEST   0.786    0.790    0.755    0.744    0.776    0.782    0.773    0.768    0.794    0.794  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.639    0.610    0.688    0.730    0.692    0.716    0.699    0.724    0.730    0.729  
TEST   0.629    0.673    0.684    0.702    0.694    0.711    0.675    0.747    0.731    0.757  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#13_acc.png





Saving image with name:  Model#13_prec.png


Saving image with name:  Model#13_rec.png


Saving image with name:  Model#13_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 14  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   38.075 
        MEAN TEST SCORE :  6.088 STD TEST SCORE :  0.013 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.0 STD TRAIN SCORE:  1 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.994    0.994    0.994    0.994    0.994    0.994    0.994    0.993  
TEST   0.994    0.994    0.994    0.993    0.994    0.994    0.993    0.994    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.857    0.909    0.850    0.835    0.836    0.807    0.920    0.893    0.895    0.903  
TEST   0.853    0.910    0.852    0.811    0.810    0.809    0.891    0.878    0.943    0.949  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.624    0.451    0.637    0.644    0.646    0.667    0.568    0.570    0.545    0.512  
TEST   0.624    0.515    0.652    0.606    0.648    0.633    0.554    0.594    0.513    0.552  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.991    0.99     0.991    0.991    0.990    0.989    0.991    0.990    0.988    0.990  
TEST   0.992    0.99     0.991    0.990    0.989    0.989    0.992    0.989    0.990    0.988  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.787    0.771    0.789    0.783    0.783    0.774    0.810    0.789    0.775    0.781  
TEST   0.802    0.788    0.778    0.750    0.774    0.787    0.779    0.785    0.799    0.808  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.722    0.603    0.728    0.727    0.729    0.73     0.703    0.695    0.677    0.653  
TEST   0.721    0.658    0.739    0.694    0.720    0.71     0.683    0.709    0.664    0.698  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#14_acc.png





Saving image with name:  Model#14_prec.png


Saving image with name:  Model#14_rec.png


Saving image with name:  Model#14_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 15  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  15 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#15_acc.png





Saving image with name:  Model#15_prec.png


Saving image with name:  Model#15_rec.png


Saving image with name:  Model#15_auc.png
 _ _ _ _ _ _ _ _ _ _ MODEL # 16  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  300 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  16 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#16_acc.png





Saving image with name:  Model#16_prec.png


Saving image with name:  Model#16_rec.png


Saving image with name:  Model#16_auc.png


BEST MODEL HISTORY PER EPOCH
SELECTED EPOCHS   : 50
PARAMS            : {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 300, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'} 

                   0      1
TRAIN ACC      0.989  0.993
TEST ACC       0.991  0.994
TRAIN LOSS     0.041  0.024
TEST LOSS      0.027  0.020
precision      0.626  0.806
val_precision  0.755  0.897
recall         0.203  0.518
val_recall     0.373  0.533 




<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff23b67fac8>
237858/237858 - 20s
CONFUSION MATRIX
Predicted       0     1
True                   
0          234846  173 
1          1326    1513
tn, fp, fn, tp
234846 173 1326 1513
fpr:  [0.00000000e+00 7.36110697e-04 1.00000000e+00]
tpr:  [0.         0.53293413 1.        ]
ROC AUC:  0.766099010519547
PREC:  [0.01193569 0.89739027 1.        ]
REC:  [1.         0.53293413 0.        ]
pr_auc:  0.7179495796286043
average_precision:  0.4838246605677545
P: [0.01193569 0.89739027 1.        ]
R: [1.         0.53293413 0.        ]
THRES: [0. 1.]
dict_keys(['scoring', 'estimator', 'n_jobs', 'iid', 'refit', 'cv', 'verbose', 'pre_dispatch', 'error_score', 'return_train_score', 'param_grid', 'multimetric_', 'best_index_', 'best_score_', 'best_params_', 'best_estimator_', 'refit_time_', 'scorer_', 'cv_results_', 'n_splits_'])
Saving history
History saved successfully.
Saving history per parts
Saving  scoring -> scoring_rnn.history 
 ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
Saving  estimator -> estimator_rnn.history 
 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff3904699b0>
Error saving: estimator.history - TypeError("can't pickle _thread.RLock objects",)
Saving: estimator.history.txt
Saving  n_jobs -> n_jobs_rnn.history 
 1
Saving  iid -> iid_rnn.history 
 deprecated
Saving  refit -> refit_rnn.history 
 recall
Saving  cv -> cv_rnn.history 
 10
Saving  verbose -> verbose_rnn.history 
 2
Saving  pre_dispatch -> pre_dispatch_rnn.history 
 1*n_jobs
Saving  error_score -> error_score_rnn.history 
 nan
Saving  return_train_score -> return_train_score_rnn.history 
 True
Saving  param_grid -> param_grid_rnn.history 
 dict_keys(['rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'optimizer', 'modelType', 'epochs', 'output_layer_activation', 'rnn_layer_activation', 'hidden_layer_activation', 'dropout', 'dropout_rate'])
Saving  multimetric_ -> multimetric__rnn.history 
 True
Saving  best_index_ -> best_index__rnn.history 
 12
Saving  best_score_ -> best_score__rnn.history 
 0.6690951314976192
Saving  best_params_ -> best_params__rnn.history 
 dict_keys(['dropout', 'dropout_rate', 'epochs', 'hidden_layer_activation', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'modelType', 'optimizer', 'output_layer_activation', 'rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'rnn_layer_activation'])
Saving  best_estimator_ -> best_estimator__rnn.history 
 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff23b67fac8>
Error saving: best_estimator_.history - TypeError("can't pickle _thread.RLock objects",)
Saving: best_estimator_.history.txt
Saving  refit_time_ -> refit_time__rnn.history 
 246.79227089881897
Saving  scorer_ -> scorer__rnn.history 
 dict_keys(['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'])
Saving  cv_results_ -> cv_results__rnn.history 
 dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_dropout', 'param_dropout_rate', 'param_epochs', 'param_hidden_layer_activation', 'param_hidden_layers', 'param_hidden_layers_neurons', 'param_loss', 'param_modelType', 'param_optimizer', 'param_output_layer_activation', 'param_rnn_hidden_layers', 'param_rnn_hidden_layers_neurons', 'param_rnn_layer_activation', 'params', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'split5_test_accuracy', 'split6_test_accuracy', 'split7_test_accuracy', 'split8_test_accuracy', 'split9_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'split5_train_accuracy', 'split6_train_accuracy', 'split7_train_accuracy', 'split8_train_accuracy', 'split9_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'split5_test_precision', 'split6_test_precision', 'split7_test_precision', 'split8_test_precision', 'split9_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'split5_train_precision', 'split6_train_precision', 'split7_train_precision', 'split8_train_precision', 'split9_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'split5_test_recall', 'split6_test_recall', 'split7_test_recall', 'split8_test_recall', 'split9_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'split5_train_recall', 'split6_train_recall', 'split7_train_recall', 'split8_train_recall', 'split9_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_roc_auc', 'split1_test_roc_auc', 'split2_test_roc_auc', 'split3_test_roc_auc', 'split4_test_roc_auc', 'split5_test_roc_auc', 'split6_test_roc_auc', 'split7_test_roc_auc', 'split8_test_roc_auc', 'split9_test_roc_auc', 'mean_test_roc_auc', 'std_test_roc_auc', 'rank_test_roc_auc', 'split0_train_roc_auc', 'split1_train_roc_auc', 'split2_train_roc_auc', 'split3_train_roc_auc', 'split4_train_roc_auc', 'split5_train_roc_auc', 'split6_train_roc_auc', 'split7_train_roc_auc', 'split8_train_roc_auc', 'split9_train_roc_auc', 'mean_train_roc_auc', 'std_train_roc_auc', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'split5_test_f1', 'split6_test_f1', 'split7_test_f1', 'split8_test_f1', 'split9_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'split5_train_f1', 'split6_train_f1', 'split7_train_f1', 'split8_train_f1', 'split9_train_f1', 'mean_train_f1', 'std_train_f1', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'split5_test_average_precision', 'split6_test_average_precision', 'split7_test_average_precision', 'split8_test_average_precision', 'split9_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'split5_train_average_precision', 'split6_train_average_precision', 'split7_train_average_precision', 'split8_train_average_precision', 'split9_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision'])
Saving  n_splits_ -> n_splits__rnn.history 
 10
History parts saved successfully.
BEST ESTIMATOR
<tensorflow.python.keras.engine.sequential.Sequential object at 0x7ff3300d2208>
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 50)                9600      
_________________________________________________________________
dense_240 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_240 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_241 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
None
{'name': 'sequential_160', 'layers': [{'class_name': 'GRU', 'config': {'name': 'gru_120', 'trainable': True, 'batch_input_shape': (None, 25, 12), 'dtype': 'float32', 'return_sequences': False, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'time_major': False, 'units': 50, 'activation': 'sigmoid', 'recurrent_activation': 'sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'recurrent_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 2, 'reset_after': True}}, {'class_name': 'Dense', 'config': {'name': 'dense_240', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_240', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}, {'class_name': 'Dense', 'config': {'name': 'dense_241', 'trainable': True, 'dtype': 'float32', 'units': 300, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_241', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_80', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_242', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Activation', 'config': {'name': 'activation_242', 'trainable': True, 'dtype': 'float32', 'activation': 'sigmoid'}}]}
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 50)                9600      
_________________________________________________________________
dense_240 (Dense)            (None, 300)               15300     
_________________________________________________________________
activation_240 (Activation)  (None, 300)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 300)               90300     
_________________________________________________________________
activation_241 (Activation)  (None, 300)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 300)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 301       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 115,501
Trainable params: 115,501
Non-trainable params: 0
_________________________________________________________________
None
[[0.00011707]
 [0.00050969]
 [0.00012087]
 ...
 [0.00012513]
 [0.00026273]
 [0.00021005]]
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
