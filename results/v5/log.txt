Versions
Tensorflow :  2.1.0
Pandas     :  0.24.2
Numpy      :  0.24.2
Sklearn    :  0.22.1
NO GPUs available
CMD: pwd
OUT: /home/ec2-user/SageMaker
----------
CMD: ls
OUT: banksim1.zip
bs140513_032310.csv
bsNET140513_032310.csv
err.txt
kernel-setup.err
kernel-setup.out
kernel-setup.sh
labels_hash.data
log.txt
lost+found
Makefile
results
rnn_data.data
rnn_fraud_cust_batches_v1.py
RNN_Fraud_Detection.ipynb
rnn_mod_data.data
scaler.data
SlidingWindow-RNN_Fraud_Detection.ipynb
SlidingWindow-RNN_Fraud_Detection.py
X_test.data
X_train.data
X_val.data
y_test.data
y_train.data
y_val.data
----------
CMD: ./trin
OUT: [Errno 2] No such file or directory: './trin': './trin'
----------

    DATA PREPROCESSING
    DOWNLOAD FROM KAGGLE: False
    GENERATE DATA:        False
    READ FROM CLOUD:      False
    SAVE TO CLOUD:        False



_ _ _ _ _ _ _ _ _ _  IMPORT DATA FROM CSV _ _ _ _ _ _ _ _ _ _ 


Deleting the columns 'zipcodeOri','zipMerchant' because all the fields are equal.


Data Shape: (594643, 8) 

Preview: 

    step       customer  age gender       merchant             category  amount  fraud
0  0     'C1093826151'  '4'  'M'    'M348934600'   'es_transportation'  4.55    0    
1  0     'C352968107'   '2'  'M'    'M348934600'   'es_transportation'  39.68   0    
2  0     'C2054744914'  '4'  'F'    'M1823072687'  'es_transportation'  26.89   0    
3  0     'C1760612790'  '3'  'M'    'M348934600'   'es_transportation'  17.25   0    
4  0     'C757503768'   '5'  'M'    'M348934600'   'es_transportation'  35.72   0     

 Data Information: 

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 594643 entries, 0 to 594642
Data columns (total 8 columns):
step        594643 non-null int64
customer    594643 non-null object
age         594643 non-null object
gender      594643 non-null object
merchant    594643 non-null object
category    594643 non-null object
amount      594643 non-null float64
fraud       594643 non-null int64
dtypes: float64(1), int64(2), object(5)
memory usage: 36.3+ MB

None
Does it has null values? False


_ _ _ _ _ _ _ _ _ _   READ DATA LOCALLY  _ _ _ _ _ _ _ _ _ _ 




SHAPES & KEYS:
    X_train          : (285428, 25, 12)
    y_train          : (285428,)
    X_test           : (237858, 25, 12)
    y_test           : (237858,)
    X_val            : (71357, 25, 12)
    y_val            : (71357,)
    labels_hash Keys : dict_keys(['customer', 'age', 'gender', 'merchant', 'category'])
    


_ _ _ _ _ _ _ _ _ _  INITIALIZING GRID SEARCH RNN MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________
        input_shape :  (25, 12)
        output_dim  :  1
        main scoring:  recall
        all scoring :  ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
        early_stopping_monitor   : val_recall
        model_checkpoint_monitor : val_recall
        verbose: 2
        
rnn_hidden_layers : [0, 1]
rnn_hidden_layers_neurons : [50, 100]
hidden_layers : [2]
hidden_layers_neurons : [100, 200]
loss : ['binary_crossentropy']
optimizer : ['adam']
modelType : ['LSTM', 'GRU']
epochs : [50]
output_layer_activation : ['sigmoid']
rnn_layer_activation : ['sigmoid']
hidden_layer_activation : ['sigmoid']
dropout : [True]
dropout_rate : [0.2]





_ _ _ _ _ _ _ _ _ _  TRAINING RNN _ _ _ _ _ _ _ _ _ _ 



        Class weights: 
[ 0.50613724 41.23490321]
{0: 0.506137243010707, 1: 41.23490320716556}

        for classes: 
[0. 1.]

        # Frauds: 3461
        # of Non-Frauds: 281967
        
INPUTS
        X:      (285428, 25, 12)
        y:      (285428,)
        X_test: (237858, 25, 12)
        y_test: (237858,)
        
Fitting 10 folds for each of 16 candidates, totalling 160 fits
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd608021e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5e87c7278>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5e87c7438>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5e87c7828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5e87c7ac8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5e87c7e80>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5e87ef160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5e87ef470>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd608021a20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd608021ac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd608021b38>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd608021b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd608021be0>]
          

Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm (LSTM)                  (None, 50)                12600     
_________________________________________________________________
dense (Dense)                (None, 100)               5100      
_________________________________________________________________
activation (Activation)      (None, 100)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_1 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout (Dropout)            (None, 100)               0         
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_2 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall improved from -inf to 0.31560, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 106s - loss: 0.0432 - tp: 573.0000 - fp: 371.0000 - tn: 253388.0000 - fn: 2553.0000 - accuracy: 0.9886 - precision: 0.6070 - recall: 0.1833 - auc: 0.8993 - val_loss: 0.0295 - val_tp: 896.0000 - val_fp: 373.0000 - val_tn: 234646.0000 - val_fn: 1943.0000 - val_accuracy: 0.9903 - val_precision: 0.7061 - val_recall: 0.3156 - val_auc: 0.9629
256885/256885 - 106s - loss: 0.0432 - tp: 573.0000 - fp: 371.0000 - tn: 253388.0000 - fn: 2553.0000 - accuracy: 0.9886 - precision: 0.6070 - recall: 0.1833 - auc: 0.8993 - val_loss: 0.0295 - val_tp: 896.0000 - val_fp: 373.0000 - val_tn: 234646.0000 - val_fn: 1943.0000 - val_accuracy: 0.9903 - val_precision: 0.7061 - val_recall: 0.3156 - val_auc: 0.9629
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.31560 to 0.62099, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 102s - loss: 0.0260 - tp: 1466.0000 - fp: 443.0000 - tn: 253316.0000 - fn: 1660.0000 - accuracy: 0.9918 - precision: 0.7679 - recall: 0.4690 - auc: 0.9661 - val_loss: 0.0209 - val_tp: 1763.0000 - val_fp: 593.0000 - val_tn: 234426.0000 - val_fn: 1076.0000 - val_accuracy: 0.9930 - val_precision: 0.7483 - val_recall: 0.6210 - val_auc: 0.9827
256885/256885 - 102s - loss: 0.0260 - tp: 1466.0000 - fp: 443.0000 - tn: 253316.0000 - fn: 1660.0000 - accuracy: 0.9918 - precision: 0.7679 - recall: 0.4690 - auc: 0.9661 - val_loss: 0.0209 - val_tp: 1763.0000 - val_fp: 593.0000 - val_tn: 234426.0000 - val_fn: 1076.0000 - val_accuracy: 0.9930 - val_precision: 0.7483 - val_recall: 0.6210 - val_auc: 0.9827
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5a84a5978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5a8369cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5a8373278>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5a8373a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5a8373cc0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5a8373f98>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5cc3cf358>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5cc3cf668>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd608021ac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd608021be0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd608021d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd608021da0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd608021e48>]
          

Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_3 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_3 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_4 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_4 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_5 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 105s - loss: 0.0484 - tp: 464.0000 - fp: 530.0000 - tn: 253228.0000 - fn: 2663.0000 - accuracy: 0.9876 - precision: 0.4668 - recall: 0.1484 - auc: 0.8624 - val_loss: 0.0313 - val_tp: 554.0000 - val_fp: 148.0000 - val_tn: 234871.0000 - val_fn: 2285.0000 - val_accuracy: 0.9898 - val_precision: 0.7892 - val_recall: 0.1951 - val_auc: 0.9598
256885/256885 - 105s - loss: 0.0484 - tp: 464.0000 - fp: 530.0000 - tn: 253228.0000 - fn: 2663.0000 - accuracy: 0.9876 - precision: 0.4668 - recall: 0.1484 - auc: 0.8624 - val_loss: 0.0313 - val_tp: 554.0000 - val_fp: 148.0000 - val_tn: 234871.0000 - val_fn: 2285.0000 - val_accuracy: 0.9898 - val_precision: 0.7892 - val_recall: 0.1951 - val_auc: 0.9598
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.62099
256885/256885 - 102s - loss: 0.0265 - tp: 1401.0000 - fp: 414.0000 - tn: 253344.0000 - fn: 1726.0000 - accuracy: 0.9917 - precision: 0.7719 - recall: 0.4480 - auc: 0.9666 - val_loss: 0.0235 - val_tp: 1165.0000 - val_fp: 125.0000 - val_tn: 234894.0000 - val_fn: 1674.0000 - val_accuracy: 0.9924 - val_precision: 0.9031 - val_recall: 0.4104 - val_auc: 0.9667
256885/256885 - 102s - loss: 0.0265 - tp: 1401.0000 - fp: 414.0000 - tn: 253344.0000 - fn: 1726.0000 - accuracy: 0.9917 - precision: 0.7719 - recall: 0.4480 - auc: 0.9666 - val_loss: 0.0235 - val_tp: 1165.0000 - val_fp: 125.0000 - val_tn: 234894.0000 - val_fn: 1674.0000 - val_accuracy: 0.9924 - val_precision: 0.9031 - val_recall: 0.4104 - val_auc: 0.9667
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5cc50aa90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5cc50ae10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5e828b0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5cc013358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5e83bd128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5e83bd860>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5a8145940>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5e827fbe0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd608021d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5e8071eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5cc55a4a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5cc50ad30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5cc50abe0>]
          

Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_2 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_6 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_6 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_7 (Dense)              (None, 100)               10100     
_________________________________________________________________
activation_7 (Activation)    (None, 100)               0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 101       
_________________________________________________________________
activation_8 (Activation)    (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 106s - loss: 0.0433 - tp: 575.0000 - fp: 359.0000 - tn: 253410.0000 - fn: 2541.0000 - accuracy: 0.9887 - precision: 0.6156 - recall: 0.1845 - auc: 0.8944 - val_loss: 0.0290 - val_tp: 1154.0000 - val_fp: 644.0000 - val_tn: 234375.0000 - val_fn: 1685.0000 - val_accuracy: 0.9902 - val_precision: 0.6418 - val_recall: 0.4065 - val_auc: 0.9697
256885/256885 - 106s - loss: 0.0433 - tp: 575.0000 - fp: 359.0000 - tn: 253410.0000 - fn: 2541.0000 - accuracy: 0.9887 - precision: 0.6156 - recall: 0.1845 - auc: 0.8944 - val_loss: 0.0290 - val_tp: 1154.0000 - val_fp: 644.0000 - val_tn: 234375.0000 - val_fn: 1685.0000 - val_accuracy: 0.9902 - val_precision: 0.6418 - val_recall: 0.4065 - val_auc: 0.9697
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.62099
256885/256885 - 102s - loss: 0.0255 - tp: 1481.0000 - fp: 476.0000 - tn: 253293.0000 - fn: 1635.0000 - accuracy: 0.9918 - precision: 0.7568 - recall: 0.4753 - auc: 0.9687 - val_loss: 0.0201 - val_tp: 1624.0000 - val_fp: 306.0000 - val_tn: 234713.0000 - val_fn: 1215.0000 - val_accuracy: 0.9936 - val_precision: 0.8415 - val_recall: 0.5720 - val_auc: 0.9820
256885/256885 - 102s - loss: 0.0255 - tp: 1481.0000 - fp: 476.0000 - tn: 253293.0000 - fn: 1635.0000 - accuracy: 0.9918 - precision: 0.7568 - recall: 0.4753 - auc: 0.9687 - val_loss: 0.0201 - val_tp: 1624.0000 - val_fp: 306.0000 - val_tn: 234713.0000 - val_fn: 1215.0000 - val_accuracy: 0.9936 - val_precision: 0.8415 - val_recall: 0.5720 - val_auc: 0.9820
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5e810e358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5a83eee48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5e8100d68>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5a8568438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5a85686d8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5a8568a90>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5a8568d30>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5a8568f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5cc50ad30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5cc50af28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5cc50aa58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5cc50aac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5cc55ae10>]
          

Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_3 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_9 (Dense)              (None, 100)               5100      
_________________________________________________________________
activation_9 (Activation)    (None, 100)               0         
_________________________________________________________________
dense_10 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_10 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_11 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 105s - loss: 0.0445 - tp: 557.0000 - fp: 401.0000 - tn: 253391.0000 - fn: 2536.0000 - accuracy: 0.9886 - precision: 0.5814 - recall: 0.1801 - auc: 0.8900 - val_loss: 0.0294 - val_tp: 989.0000 - val_fp: 443.0000 - val_tn: 234576.0000 - val_fn: 1850.0000 - val_accuracy: 0.9904 - val_precision: 0.6906 - val_recall: 0.3484 - val_auc: 0.9652
256885/256885 - 105s - loss: 0.0445 - tp: 557.0000 - fp: 401.0000 - tn: 253391.0000 - fn: 2536.0000 - accuracy: 0.9886 - precision: 0.5814 - recall: 0.1801 - auc: 0.8900 - val_loss: 0.0294 - val_tp: 989.0000 - val_fp: 443.0000 - val_tn: 234576.0000 - val_fn: 1850.0000 - val_accuracy: 0.9904 - val_precision: 0.6906 - val_recall: 0.3484 - val_auc: 0.9652
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.62099
256885/256885 - 102s - loss: 0.0257 - tp: 1466.0000 - fp: 419.0000 - tn: 253373.0000 - fn: 1627.0000 - accuracy: 0.9920 - precision: 0.7777 - recall: 0.4740 - auc: 0.9653 - val_loss: 0.0213 - val_tp: 1482.0000 - val_fp: 251.0000 - val_tn: 234768.0000 - val_fn: 1357.0000 - val_accuracy: 0.9932 - val_precision: 0.8552 - val_recall: 0.5220 - val_auc: 0.9682
256885/256885 - 102s - loss: 0.0257 - tp: 1466.0000 - fp: 419.0000 - tn: 253373.0000 - fn: 1627.0000 - accuracy: 0.9920 - precision: 0.7777 - recall: 0.4740 - auc: 0.9653 - val_loss: 0.0213 - val_tp: 1482.0000 - val_fp: 251.0000 - val_tn: 234768.0000 - val_fn: 1357.0000 - val_accuracy: 0.9932 - val_precision: 0.8552 - val_recall: 0.5220 - val_auc: 0.9682
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5a8192cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5e8188a20>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5e8188978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5e8188c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5e849e3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5cc01f710>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5a84a5630>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5a84a56a0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5e811c7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5e8491400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e8491588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5e84914a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5e84915c0>]
          

Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_4 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_12 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_12 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_13 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_13 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_4 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_14 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 105s - loss: 0.0446 - tp: 549.0000 - fp: 363.0000 - tn: 253376.0000 - fn: 2597.0000 - accuracy: 0.9885 - precision: 0.6020 - recall: 0.1745 - auc: 0.8905 - val_loss: 0.0305 - val_tp: 833.0000 - val_fp: 323.0000 - val_tn: 234696.0000 - val_fn: 2006.0000 - val_accuracy: 0.9902 - val_precision: 0.7206 - val_recall: 0.2934 - val_auc: 0.9582
256885/256885 - 105s - loss: 0.0446 - tp: 549.0000 - fp: 363.0000 - tn: 253376.0000 - fn: 2597.0000 - accuracy: 0.9885 - precision: 0.6020 - recall: 0.1745 - auc: 0.8905 - val_loss: 0.0305 - val_tp: 833.0000 - val_fp: 323.0000 - val_tn: 234696.0000 - val_fn: 2006.0000 - val_accuracy: 0.9902 - val_precision: 0.7206 - val_recall: 0.2934 - val_auc: 0.9582
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.62099
256885/256885 - 101s - loss: 0.0264 - tp: 1441.0000 - fp: 429.0000 - tn: 253310.0000 - fn: 1705.0000 - accuracy: 0.9917 - precision: 0.7706 - recall: 0.4580 - auc: 0.9678 - val_loss: 0.0206 - val_tp: 1683.0000 - val_fp: 426.0000 - val_tn: 234593.0000 - val_fn: 1156.0000 - val_accuracy: 0.9933 - val_precision: 0.7980 - val_recall: 0.5928 - val_auc: 0.9816
256885/256885 - 101s - loss: 0.0264 - tp: 1441.0000 - fp: 429.0000 - tn: 253310.0000 - fn: 1705.0000 - accuracy: 0.9917 - precision: 0.7706 - recall: 0.4580 - auc: 0.9678 - val_loss: 0.0206 - val_tp: 1683.0000 - val_fp: 426.0000 - val_tn: 234593.0000 - val_fn: 1156.0000 - val_accuracy: 0.9933 - val_precision: 0.7980 - val_recall: 0.5928 - val_auc: 0.9816
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5505a6470>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5881900b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd552fe6518>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd552fe6898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd552fdb5f8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd552fdbcf8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd552fdb208>, <tensorflow.python.keras.metrics.AUC object at 0x7fd552fdb470>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5a8402da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5a846c5f8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e8491400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5e84914a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5e8491f60>]
          

Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_5 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_15 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_15 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_16 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_16 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_5 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_17 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 105s - loss: 0.0435 - tp: 573.0000 - fp: 395.0000 - tn: 253383.0000 - fn: 2534.0000 - accuracy: 0.9886 - precision: 0.5919 - recall: 0.1844 - auc: 0.8961 - val_loss: 0.0284 - val_tp: 985.0000 - val_fp: 364.0000 - val_tn: 234655.0000 - val_fn: 1854.0000 - val_accuracy: 0.9907 - val_precision: 0.7302 - val_recall: 0.3470 - val_auc: 0.9695
256885/256885 - 105s - loss: 0.0435 - tp: 573.0000 - fp: 395.0000 - tn: 253383.0000 - fn: 2534.0000 - accuracy: 0.9886 - precision: 0.5919 - recall: 0.1844 - auc: 0.8961 - val_loss: 0.0284 - val_tp: 985.0000 - val_fp: 364.0000 - val_tn: 234655.0000 - val_fn: 1854.0000 - val_accuracy: 0.9907 - val_precision: 0.7302 - val_recall: 0.3470 - val_auc: 0.9695
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.62099
256885/256885 - 102s - loss: 0.0254 - tp: 1513.0000 - fp: 433.0000 - tn: 253345.0000 - fn: 1594.0000 - accuracy: 0.9921 - precision: 0.7775 - recall: 0.4870 - auc: 0.9668 - val_loss: 0.0217 - val_tp: 1763.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1076.0000 - val_accuracy: 0.9937 - val_precision: 0.8047 - val_recall: 0.6210 - val_auc: 0.9876
256885/256885 - 102s - loss: 0.0254 - tp: 1513.0000 - fp: 433.0000 - tn: 253345.0000 - fn: 1594.0000 - accuracy: 0.9921 - precision: 0.7775 - recall: 0.4870 - auc: 0.9668 - val_loss: 0.0217 - val_tp: 1763.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1076.0000 - val_accuracy: 0.9937 - val_precision: 0.8047 - val_recall: 0.6210 - val_auc: 0.9876
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5e84e0128>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5e8418f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5cc44fcc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5cc44fdd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5cc44f7b8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5cc44f7f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5cc44f470>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5880c6780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5505af400>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5e84914a8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e8429e10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5cc540a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd552fca320>]
          

Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_6 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_18 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_18 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_19 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_19 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_6 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_20 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.62099
256885/256885 - 105s - loss: 0.0423 - tp: 579.0000 - fp: 346.0000 - tn: 253448.0000 - fn: 2512.0000 - accuracy: 0.9889 - precision: 0.6259 - recall: 0.1873 - auc: 0.8993 - val_loss: 0.0286 - val_tp: 958.0000 - val_fp: 393.0000 - val_tn: 234626.0000 - val_fn: 1881.0000 - val_accuracy: 0.9904 - val_precision: 0.7091 - val_recall: 0.3374 - val_auc: 0.9663
256885/256885 - 105s - loss: 0.0423 - tp: 579.0000 - fp: 346.0000 - tn: 253448.0000 - fn: 2512.0000 - accuracy: 0.9889 - precision: 0.6259 - recall: 0.1873 - auc: 0.8993 - val_loss: 0.0286 - val_tp: 958.0000 - val_fp: 393.0000 - val_tn: 234626.0000 - val_fn: 1881.0000 - val_accuracy: 0.9904 - val_precision: 0.7091 - val_recall: 0.3374 - val_auc: 0.9663
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.62099 to 0.67841, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 102s - loss: 0.0253 - tp: 1488.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1603.0000 - accuracy: 0.9922 - precision: 0.7836 - recall: 0.4814 - auc: 0.9658 - val_loss: 0.0225 - val_tp: 1926.0000 - val_fp: 648.0000 - val_tn: 234371.0000 - val_fn: 913.0000 - val_accuracy: 0.9934 - val_precision: 0.7483 - val_recall: 0.6784 - val_auc: 0.9879
256885/256885 - 102s - loss: 0.0253 - tp: 1488.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 1603.0000 - accuracy: 0.9922 - precision: 0.7836 - recall: 0.4814 - auc: 0.9658 - val_loss: 0.0225 - val_tp: 1926.0000 - val_fp: 648.0000 - val_tn: 234371.0000 - val_fn: 913.0000 - val_accuracy: 0.9934 - val_precision: 0.7483 - val_recall: 0.6784 - val_auc: 0.9879
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 21s
256885/256885 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd568484198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd56825b198>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5e847d0f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5e847d828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5e847dc88>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5e847deb8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5cc027fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5cc5540b8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd56870a0f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd552fefe48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd552fefe10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd55051d518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5684b1eb8>]
          

Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_7 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_21 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_21 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_22 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_22 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_7 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_23 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 105s - loss: 0.0442 - tp: 521.0000 - fp: 389.0000 - tn: 253385.0000 - fn: 2590.0000 - accuracy: 0.9884 - precision: 0.5725 - recall: 0.1675 - auc: 0.8916 - val_loss: 0.0304 - val_tp: 869.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1970.0000 - val_accuracy: 0.9902 - val_precision: 0.7031 - val_recall: 0.3061 - val_auc: 0.9618
256885/256885 - 105s - loss: 0.0442 - tp: 521.0000 - fp: 389.0000 - tn: 253385.0000 - fn: 2590.0000 - accuracy: 0.9884 - precision: 0.5725 - recall: 0.1675 - auc: 0.8916 - val_loss: 0.0304 - val_tp: 869.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1970.0000 - val_accuracy: 0.9902 - val_precision: 0.7031 - val_recall: 0.3061 - val_auc: 0.9618
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256885/256885 - 102s - loss: 0.0271 - tp: 1357.0000 - fp: 465.0000 - tn: 253309.0000 - fn: 1754.0000 - accuracy: 0.9914 - precision: 0.7448 - recall: 0.4362 - auc: 0.9658 - val_loss: 0.0214 - val_tp: 1656.0000 - val_fp: 452.0000 - val_tn: 234567.0000 - val_fn: 1183.0000 - val_accuracy: 0.9931 - val_precision: 0.7856 - val_recall: 0.5833 - val_auc: 0.9838
256885/256885 - 102s - loss: 0.0271 - tp: 1357.0000 - fp: 465.0000 - tn: 253309.0000 - fn: 1754.0000 - accuracy: 0.9914 - precision: 0.7448 - recall: 0.4362 - auc: 0.9658 - val_loss: 0.0214 - val_tp: 1656.0000 - val_fp: 452.0000 - val_tn: 234567.0000 - val_fn: 1183.0000 - val_accuracy: 0.9931 - val_precision: 0.7856 - val_recall: 0.5833 - val_auc: 0.9838
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52ef68cc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52efb3d68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52ef755c0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52ef75da0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52ef75fd0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52ef04438>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52ef046d8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52ef049e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5684b1eb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd552fefe10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5cc55da20>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5e831acc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52efbc208>]
          

Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_8 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_24 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_24 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_25 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_25 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_8 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_26 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_26 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256886/256886 - 105s - loss: 0.0432 - tp: 568.0000 - fp: 353.0000 - tn: 253425.0000 - fn: 2540.0000 - accuracy: 0.9887 - precision: 0.6167 - recall: 0.1828 - auc: 0.8972 - val_loss: 0.0315 - val_tp: 744.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2095.0000 - val_accuracy: 0.9901 - val_precision: 0.7425 - val_recall: 0.2621 - val_auc: 0.9492
256886/256886 - 105s - loss: 0.0432 - tp: 568.0000 - fp: 353.0000 - tn: 253425.0000 - fn: 2540.0000 - accuracy: 0.9887 - precision: 0.6167 - recall: 0.1828 - auc: 0.8972 - val_loss: 0.0315 - val_tp: 744.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2095.0000 - val_accuracy: 0.9901 - val_precision: 0.7425 - val_recall: 0.2621 - val_auc: 0.9492
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256886/256886 - 102s - loss: 0.0262 - tp: 1430.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1678.0000 - accuracy: 0.9918 - precision: 0.7655 - recall: 0.4601 - auc: 0.9656 - val_loss: 0.0208 - val_tp: 1529.0000 - val_fp: 331.0000 - val_tn: 234688.0000 - val_fn: 1310.0000 - val_accuracy: 0.9931 - val_precision: 0.8220 - val_recall: 0.5386 - val_auc: 0.9776
256886/256886 - 102s - loss: 0.0262 - tp: 1430.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1678.0000 - accuracy: 0.9918 - precision: 0.7655 - recall: 0.4601 - auc: 0.9656 - val_loss: 0.0208 - val_tp: 1529.0000 - val_fp: 331.0000 - val_tn: 234688.0000 - val_fn: 1310.0000 - val_accuracy: 0.9931 - val_precision: 0.8220 - val_recall: 0.5386 - val_auc: 0.9776
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 21s
256886/256886 - 21s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5e83beef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5e83beba8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5880d0198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5684845c0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52ef28438>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52ed2cb70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c6f6a20>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c6f6eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5cc55da20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5684f9eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e8053240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e9f7c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5e83bed30>]
          

Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 50)                12600     
_________________________________________________________________
dense_27 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_27 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_28 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_28 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 100)               0         
_________________________________________________________________
dense_29 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_29 (Activation)   (None, 1)                 0         
=================================================================
Total params: 27,901
Trainable params: 27,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256886/256886 - 105s - loss: 0.0438 - tp: 541.0000 - fp: 368.0000 - tn: 253394.0000 - fn: 2583.0000 - accuracy: 0.9885 - precision: 0.5952 - recall: 0.1732 - auc: 0.8930 - val_loss: 0.0303 - val_tp: 910.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1929.0000 - val_accuracy: 0.9903 - val_precision: 0.7126 - val_recall: 0.3205 - val_auc: 0.9504
256886/256886 - 105s - loss: 0.0438 - tp: 541.0000 - fp: 368.0000 - tn: 253394.0000 - fn: 2583.0000 - accuracy: 0.9885 - precision: 0.5952 - recall: 0.1732 - auc: 0.8930 - val_loss: 0.0303 - val_tp: 910.0000 - val_fp: 367.0000 - val_tn: 234652.0000 - val_fn: 1929.0000 - val_accuracy: 0.9903 - val_precision: 0.7126 - val_recall: 0.3205 - val_auc: 0.9504
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256886/256886 - 101s - loss: 0.0257 - tp: 1462.0000 - fp: 448.0000 - tn: 253314.0000 - fn: 1662.0000 - accuracy: 0.9918 - precision: 0.7654 - recall: 0.4680 - auc: 0.9676 - val_loss: 0.0206 - val_tp: 1815.0000 - val_fp: 512.0000 - val_tn: 234507.0000 - val_fn: 1024.0000 - val_accuracy: 0.9935 - val_precision: 0.7800 - val_recall: 0.6393 - val_auc: 0.9851
256886/256886 - 101s - loss: 0.0257 - tp: 1462.0000 - fp: 448.0000 - tn: 253314.0000 - fn: 1662.0000 - accuracy: 0.9918 - precision: 0.7654 - recall: 0.4680 - auc: 0.9676 - val_loss: 0.0206 - val_tp: 1815.0000 - val_fp: 512.0000 - val_tn: 234507.0000 - val_fn: 1024.0000 - val_accuracy: 0.9935 - val_precision: 0.7800 - val_recall: 0.6393 - val_auc: 0.9851
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5a802a898>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5884dbeb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5884d6ac8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5883c6c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5883c6438>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5883c67b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5883c6240>, <tensorflow.python.keras.metrics.AUC object at 0x7fd588390908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e9f79e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5e83bed30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e83bee48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5e83bef60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd588096080>]
          

Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_10 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_30 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_30 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_31 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_31 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_32 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_32 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 131s - loss: 0.0434 - tp: 580.0000 - fp: 343.0000 - tn: 253416.0000 - fn: 2546.0000 - accuracy: 0.9888 - precision: 0.6284 - recall: 0.1855 - auc: 0.8945 - val_loss: 0.0295 - val_tp: 775.0000 - val_fp: 257.0000 - val_tn: 234762.0000 - val_fn: 2064.0000 - val_accuracy: 0.9902 - val_precision: 0.7510 - val_recall: 0.2730 - val_auc: 0.9648
256885/256885 - 131s - loss: 0.0434 - tp: 580.0000 - fp: 343.0000 - tn: 253416.0000 - fn: 2546.0000 - accuracy: 0.9888 - precision: 0.6284 - recall: 0.1855 - auc: 0.8945 - val_loss: 0.0295 - val_tp: 775.0000 - val_fp: 257.0000 - val_tn: 234762.0000 - val_fn: 2064.0000 - val_accuracy: 0.9902 - val_precision: 0.7510 - val_recall: 0.2730 - val_auc: 0.9648
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256885/256885 - 127s - loss: 0.0254 - tp: 1531.0000 - fp: 438.0000 - tn: 253321.0000 - fn: 1595.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4898 - auc: 0.9659 - val_loss: 0.0204 - val_tp: 1551.0000 - val_fp: 276.0000 - val_tn: 234743.0000 - val_fn: 1288.0000 - val_accuracy: 0.9934 - val_precision: 0.8489 - val_recall: 0.5463 - val_auc: 0.9746
256885/256885 - 127s - loss: 0.0254 - tp: 1531.0000 - fp: 438.0000 - tn: 253321.0000 - fn: 1595.0000 - accuracy: 0.9921 - precision: 0.7776 - recall: 0.4898 - auc: 0.9659 - val_loss: 0.0204 - val_tp: 1551.0000 - val_fp: 276.0000 - val_tn: 234743.0000 - val_fn: 1288.0000 - val_accuracy: 0.9934 - val_precision: 0.8489 - val_recall: 0.5463 - val_auc: 0.9746
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5686ea940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd56803d630>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd55021d4e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd55021dbe0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd55021da90>, <tensorflow.python.keras.metrics.Precision object at 0x7fd55021d160>, <tensorflow.python.keras.metrics.Recall object at 0x7fd55021d780>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5a802a6a0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5e83bed30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5e83bef28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5e83bef60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd55006e7f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5686d3b70>]
          

Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_11 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_33 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_33 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_34 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_34 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_35 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_35 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 130s - loss: 0.0460 - tp: 528.0000 - fp: 420.0000 - tn: 253338.0000 - fn: 2599.0000 - accuracy: 0.9882 - precision: 0.5570 - recall: 0.1689 - auc: 0.8775 - val_loss: 0.0302 - val_tp: 842.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1997.0000 - val_accuracy: 0.9903 - val_precision: 0.7259 - val_recall: 0.2966 - val_auc: 0.9596
256885/256885 - 130s - loss: 0.0460 - tp: 528.0000 - fp: 420.0000 - tn: 253338.0000 - fn: 2599.0000 - accuracy: 0.9882 - precision: 0.5570 - recall: 0.1689 - auc: 0.8775 - val_loss: 0.0302 - val_tp: 842.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1997.0000 - val_accuracy: 0.9903 - val_precision: 0.7259 - val_recall: 0.2966 - val_auc: 0.9596
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256885/256885 - 126s - loss: 0.0265 - tp: 1424.0000 - fp: 424.0000 - tn: 253334.0000 - fn: 1703.0000 - accuracy: 0.9917 - precision: 0.7706 - recall: 0.4554 - auc: 0.9644 - val_loss: 0.0206 - val_tp: 1502.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1337.0000 - val_accuracy: 0.9932 - val_precision: 0.8476 - val_recall: 0.5291 - val_auc: 0.9771
256885/256885 - 126s - loss: 0.0265 - tp: 1424.0000 - fp: 424.0000 - tn: 253334.0000 - fn: 1703.0000 - accuracy: 0.9917 - precision: 0.7706 - recall: 0.4554 - auc: 0.9644 - val_loss: 0.0206 - val_tp: 1502.0000 - val_fp: 270.0000 - val_tn: 234749.0000 - val_fn: 1337.0000 - val_accuracy: 0.9932 - val_precision: 0.8476 - val_recall: 0.5291 - val_auc: 0.9771
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd568314b70>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd568314438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd568314fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd568314588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5680430f0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd568043a58>, <tensorflow.python.keras.metrics.Recall object at 0x7fd568043470>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5680438d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd550228048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568314d30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd568314cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd568314dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd568314320>]
          

Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_12 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_36 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_36 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_37 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_37 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_38 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_38 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 131s - loss: 0.0452 - tp: 555.0000 - fp: 424.0000 - tn: 253345.0000 - fn: 2561.0000 - accuracy: 0.9884 - precision: 0.5669 - recall: 0.1781 - auc: 0.8839 - val_loss: 0.0333 - val_tp: 567.0000 - val_fp: 149.0000 - val_tn: 234870.0000 - val_fn: 2272.0000 - val_accuracy: 0.9898 - val_precision: 0.7919 - val_recall: 0.1997 - val_auc: 0.9423
256885/256885 - 131s - loss: 0.0452 - tp: 555.0000 - fp: 424.0000 - tn: 253345.0000 - fn: 2561.0000 - accuracy: 0.9884 - precision: 0.5669 - recall: 0.1781 - auc: 0.8839 - val_loss: 0.0333 - val_tp: 567.0000 - val_fp: 149.0000 - val_tn: 234870.0000 - val_fn: 2272.0000 - val_accuracy: 0.9898 - val_precision: 0.7919 - val_recall: 0.1997 - val_auc: 0.9423
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256885/256885 - 127s - loss: 0.0263 - tp: 1458.0000 - fp: 401.0000 - tn: 253368.0000 - fn: 1658.0000 - accuracy: 0.9920 - precision: 0.7843 - recall: 0.4679 - auc: 0.9641 - val_loss: 0.0200 - val_tp: 1667.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1172.0000 - val_accuracy: 0.9936 - val_precision: 0.8232 - val_recall: 0.5872 - val_auc: 0.9781
256885/256885 - 127s - loss: 0.0263 - tp: 1458.0000 - fp: 401.0000 - tn: 253368.0000 - fn: 1658.0000 - accuracy: 0.9920 - precision: 0.7843 - recall: 0.4679 - auc: 0.9641 - val_loss: 0.0200 - val_tp: 1667.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1172.0000 - val_accuracy: 0.9936 - val_precision: 0.8232 - val_recall: 0.5872 - val_auc: 0.9781
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd550234e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52fcf3be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52fcf3cc0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52fcf3e10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52fc860f0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52fc864a8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52fc86748>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52fc86a58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd568314d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568314320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd568314c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd568314c18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f1cd048>]
          

Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_39 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_39 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_40 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_40 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_13 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_41 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_41 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 131s - loss: 0.0483 - tp: 520.0000 - fp: 527.0000 - tn: 253265.0000 - fn: 2573.0000 - accuracy: 0.9879 - precision: 0.4967 - recall: 0.1681 - auc: 0.8532 - val_loss: 0.0310 - val_tp: 833.0000 - val_fp: 307.0000 - val_tn: 234712.0000 - val_fn: 2006.0000 - val_accuracy: 0.9903 - val_precision: 0.7307 - val_recall: 0.2934 - val_auc: 0.9568
256885/256885 - 131s - loss: 0.0483 - tp: 520.0000 - fp: 527.0000 - tn: 253265.0000 - fn: 2573.0000 - accuracy: 0.9879 - precision: 0.4967 - recall: 0.1681 - auc: 0.8532 - val_loss: 0.0310 - val_tp: 833.0000 - val_fp: 307.0000 - val_tn: 234712.0000 - val_fn: 2006.0000 - val_accuracy: 0.9903 - val_precision: 0.7307 - val_recall: 0.2934 - val_auc: 0.9568
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.67841
256885/256885 - 128s - loss: 0.0264 - tp: 1425.0000 - fp: 408.0000 - tn: 253384.0000 - fn: 1668.0000 - accuracy: 0.9919 - precision: 0.7774 - recall: 0.4607 - auc: 0.9639 - val_loss: 0.0232 - val_tp: 1405.0000 - val_fp: 231.0000 - val_tn: 234788.0000 - val_fn: 1434.0000 - val_accuracy: 0.9930 - val_precision: 0.8588 - val_recall: 0.4949 - val_auc: 0.9524
256885/256885 - 128s - loss: 0.0264 - tp: 1425.0000 - fp: 408.0000 - tn: 253384.0000 - fn: 1668.0000 - accuracy: 0.9919 - precision: 0.7774 - recall: 0.4607 - auc: 0.9639 - val_loss: 0.0232 - val_tp: 1405.0000 - val_fp: 231.0000 - val_tn: 234788.0000 - val_fn: 1434.0000 - val_accuracy: 0.9930 - val_precision: 0.8588 - val_recall: 0.4949 - val_auc: 0.9524
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd568325dd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52c788b00>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f2157b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52f2337b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f2339b0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52f2334e0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f23b710>, <tensorflow.python.keras.metrics.AUC object at 0x7fd588576f60>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd568314c88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd552f8ed30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd552f8ef60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd552f8eef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd552f8ea58>]
          

Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_14 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_42 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_42 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_43 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_43 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_14 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_44 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_44 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.67841
256885/256885 - 130s - loss: 0.0451 - tp: 550.0000 - fp: 369.0000 - tn: 253370.0000 - fn: 2596.0000 - accuracy: 0.9885 - precision: 0.5985 - recall: 0.1748 - auc: 0.8840 - val_loss: 0.0315 - val_tp: 599.0000 - val_fp: 168.0000 - val_tn: 234851.0000 - val_fn: 2240.0000 - val_accuracy: 0.9899 - val_precision: 0.7810 - val_recall: 0.2110 - val_auc: 0.9547
256885/256885 - 130s - loss: 0.0451 - tp: 550.0000 - fp: 369.0000 - tn: 253370.0000 - fn: 2596.0000 - accuracy: 0.9885 - precision: 0.5985 - recall: 0.1748 - auc: 0.8840 - val_loss: 0.0315 - val_tp: 599.0000 - val_fp: 168.0000 - val_tn: 234851.0000 - val_fn: 2240.0000 - val_accuracy: 0.9899 - val_precision: 0.7810 - val_recall: 0.2110 - val_auc: 0.9547
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.67841 to 0.73089, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 126s - loss: 0.0254 - tp: 1535.0000 - fp: 429.0000 - tn: 253310.0000 - fn: 1611.0000 - accuracy: 0.9921 - precision: 0.7816 - recall: 0.4879 - auc: 0.9669 - val_loss: 0.0225 - val_tp: 2075.0000 - val_fp: 1036.0000 - val_tn: 233983.0000 - val_fn: 764.0000 - val_accuracy: 0.9924 - val_precision: 0.6670 - val_recall: 0.7309 - val_auc: 0.9833
256885/256885 - 126s - loss: 0.0254 - tp: 1535.0000 - fp: 429.0000 - tn: 253310.0000 - fn: 1611.0000 - accuracy: 0.9921 - precision: 0.7816 - recall: 0.4879 - auc: 0.9669 - val_loss: 0.0225 - val_tp: 2075.0000 - val_fp: 1036.0000 - val_tn: 233983.0000 - val_fn: 764.0000 - val_accuracy: 0.9924 - val_precision: 0.6670 - val_recall: 0.7309 - val_auc: 0.9833
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5886d7748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5886d7e10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5886d7710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e9df198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e9df438>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e9dfa20>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e9dfda0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e9e6c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd568325f98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd552f8ef60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd552f8ea58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd552f8e780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5886c30b8>]
          

Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_15 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_45 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_45 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_46 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_46 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_15 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_47 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256885/256885 - 131s - loss: 0.0438 - tp: 534.0000 - fp: 345.0000 - tn: 253433.0000 - fn: 2573.0000 - accuracy: 0.9886 - precision: 0.6075 - recall: 0.1719 - auc: 0.8935 - val_loss: 0.0432 - val_tp: 1661.0000 - val_fp: 1736.0000 - val_tn: 233283.0000 - val_fn: 1178.0000 - val_accuracy: 0.9877 - val_precision: 0.4890 - val_recall: 0.5851 - val_auc: 0.9769
256885/256885 - 131s - loss: 0.0438 - tp: 534.0000 - fp: 345.0000 - tn: 253433.0000 - fn: 2573.0000 - accuracy: 0.9886 - precision: 0.6075 - recall: 0.1719 - auc: 0.8935 - val_loss: 0.0432 - val_tp: 1661.0000 - val_fp: 1736.0000 - val_tn: 233283.0000 - val_fn: 1178.0000 - val_accuracy: 0.9877 - val_precision: 0.4890 - val_recall: 0.5851 - val_auc: 0.9769
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73089
256885/256885 - 129s - loss: 0.0256 - tp: 1506.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 1601.0000 - accuracy: 0.9921 - precision: 0.7763 - recall: 0.4847 - auc: 0.9669 - val_loss: 0.0222 - val_tp: 1448.0000 - val_fp: 237.0000 - val_tn: 234782.0000 - val_fn: 1391.0000 - val_accuracy: 0.9932 - val_precision: 0.8593 - val_recall: 0.5100 - val_auc: 0.9595
256885/256885 - 129s - loss: 0.0256 - tp: 1506.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 1601.0000 - accuracy: 0.9921 - precision: 0.7763 - recall: 0.4847 - auc: 0.9669 - val_loss: 0.0222 - val_tp: 1448.0000 - val_fp: 237.0000 - val_tn: 234782.0000 - val_fn: 1391.0000 - val_accuracy: 0.9932 - val_precision: 0.8593 - val_recall: 0.5100 - val_auc: 0.9595
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.73089
256885/256885 - 127s - loss: 0.0211 - tp: 1883.0000 - fp: 405.0000 - tn: 253373.0000 - fn: 1224.0000 - accuracy: 0.9937 - precision: 0.8230 - recall: 0.6061 - auc: 0.9690 - val_loss: 0.0204 - val_tp: 1508.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1331.0000 - val_accuracy: 0.9937 - val_precision: 0.8971 - val_recall: 0.5312 - val_auc: 0.9670
256885/256885 - 127s - loss: 0.0211 - tp: 1883.0000 - fp: 405.0000 - tn: 253373.0000 - fn: 1224.0000 - accuracy: 0.9937 - precision: 0.8230 - recall: 0.6061 - auc: 0.9690 - val_loss: 0.0204 - val_tp: 1508.0000 - val_fp: 173.0000 - val_tn: 234846.0000 - val_fn: 1331.0000 - val_accuracy: 0.9937 - val_precision: 0.8971 - val_recall: 0.5312 - val_auc: 0.9670
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f240ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f240240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f250b38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52f250a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f270ba8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52f270b70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e8d6c50>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e8c65f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd552f8e780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52fa49eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f240320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f240d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f240358>]
          

Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_16 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_48 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_48 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_49 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_49 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_16 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_50 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_50 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256885/256885 - 131s - loss: 0.0423 - tp: 616.0000 - fp: 351.0000 - tn: 253443.0000 - fn: 2475.0000 - accuracy: 0.9890 - precision: 0.6370 - recall: 0.1993 - auc: 0.8998 - val_loss: 0.0291 - val_tp: 838.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 2001.0000 - val_accuracy: 0.9905 - val_precision: 0.7611 - val_recall: 0.2952 - val_auc: 0.9573
256885/256885 - 131s - loss: 0.0423 - tp: 616.0000 - fp: 351.0000 - tn: 253443.0000 - fn: 2475.0000 - accuracy: 0.9890 - precision: 0.6370 - recall: 0.1993 - auc: 0.8998 - val_loss: 0.0291 - val_tp: 838.0000 - val_fp: 263.0000 - val_tn: 234756.0000 - val_fn: 2001.0000 - val_accuracy: 0.9905 - val_precision: 0.7611 - val_recall: 0.2952 - val_auc: 0.9573
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73089
256885/256885 - 127s - loss: 0.0247 - tp: 1583.0000 - fp: 422.0000 - tn: 253372.0000 - fn: 1508.0000 - accuracy: 0.9925 - precision: 0.7895 - recall: 0.5121 - auc: 0.9655 - val_loss: 0.0199 - val_tp: 1660.0000 - val_fp: 338.0000 - val_tn: 234681.0000 - val_fn: 1179.0000 - val_accuracy: 0.9936 - val_precision: 0.8308 - val_recall: 0.5847 - val_auc: 0.9829
256885/256885 - 127s - loss: 0.0247 - tp: 1583.0000 - fp: 422.0000 - tn: 253372.0000 - fn: 1508.0000 - accuracy: 0.9925 - precision: 0.7895 - recall: 0.5121 - auc: 0.9655 - val_loss: 0.0199 - val_tp: 1660.0000 - val_fp: 338.0000 - val_tn: 234681.0000 - val_fn: 1179.0000 - val_accuracy: 0.9936 - val_precision: 0.8308 - val_recall: 0.5847 - val_auc: 0.9829
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f4c5f98>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f38f278>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f38f128>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52ec60c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91c50>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52f383cc0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f383748>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f383400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f240358>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f4c7f60>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f4c7f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f4c7c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f4c7cc0>]
          

Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_17 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_51 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_51 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_52 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_52 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_17 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_53 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_53 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256885/256885 - 130s - loss: 0.0431 - tp: 544.0000 - fp: 335.0000 - tn: 253439.0000 - fn: 2567.0000 - accuracy: 0.9887 - precision: 0.6189 - recall: 0.1749 - auc: 0.8972 - val_loss: 0.0333 - val_tp: 1261.0000 - val_fp: 681.0000 - val_tn: 234338.0000 - val_fn: 1578.0000 - val_accuracy: 0.9905 - val_precision: 0.6493 - val_recall: 0.4442 - val_auc: 0.9776
256885/256885 - 130s - loss: 0.0431 - tp: 544.0000 - fp: 335.0000 - tn: 253439.0000 - fn: 2567.0000 - accuracy: 0.9887 - precision: 0.6189 - recall: 0.1749 - auc: 0.8972 - val_loss: 0.0333 - val_tp: 1261.0000 - val_fp: 681.0000 - val_tn: 234338.0000 - val_fn: 1578.0000 - val_accuracy: 0.9905 - val_precision: 0.6493 - val_recall: 0.4442 - val_auc: 0.9776
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73089
256885/256885 - 128s - loss: 0.0253 - tp: 1505.0000 - fp: 458.0000 - tn: 253316.0000 - fn: 1606.0000 - accuracy: 0.9920 - precision: 0.7667 - recall: 0.4838 - auc: 0.9669 - val_loss: 0.0211 - val_tp: 1589.0000 - val_fp: 341.0000 - val_tn: 234678.0000 - val_fn: 1250.0000 - val_accuracy: 0.9933 - val_precision: 0.8233 - val_recall: 0.5597 - val_auc: 0.9664
256885/256885 - 128s - loss: 0.0253 - tp: 1505.0000 - fp: 458.0000 - tn: 253316.0000 - fn: 1606.0000 - accuracy: 0.9920 - precision: 0.7667 - recall: 0.4838 - auc: 0.9669 - val_loss: 0.0211 - val_tp: 1589.0000 - val_fp: 341.0000 - val_tn: 234678.0000 - val_fn: 1250.0000 - val_accuracy: 0.9933 - val_precision: 0.8233 - val_recall: 0.5597 - val_auc: 0.9664
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f1e10f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f1e1d30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f1e19b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52f1e1e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f1e15c0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52fe304a8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52fe30128>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52fe308d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f4c7f28>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568666f98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5501c6978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5501c6908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5501aeda0>]
          

Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_18 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_54 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_54 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_55 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_55 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_18 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_56 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_56 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256886/256886 - 131s - loss: 0.0454 - tp: 563.0000 - fp: 475.0000 - tn: 253303.0000 - fn: 2545.0000 - accuracy: 0.9882 - precision: 0.5424 - recall: 0.1811 - auc: 0.8843 - val_loss: 0.0313 - val_tp: 1062.0000 - val_fp: 458.0000 - val_tn: 234561.0000 - val_fn: 1777.0000 - val_accuracy: 0.9906 - val_precision: 0.6987 - val_recall: 0.3741 - val_auc: 0.9733
256886/256886 - 131s - loss: 0.0454 - tp: 563.0000 - fp: 475.0000 - tn: 253303.0000 - fn: 2545.0000 - accuracy: 0.9882 - precision: 0.5424 - recall: 0.1811 - auc: 0.8843 - val_loss: 0.0313 - val_tp: 1062.0000 - val_fp: 458.0000 - val_tn: 234561.0000 - val_fn: 1777.0000 - val_accuracy: 0.9906 - val_precision: 0.6987 - val_recall: 0.3741 - val_auc: 0.9733
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73089
256886/256886 - 127s - loss: 0.0261 - tp: 1453.0000 - fp: 454.0000 - tn: 253324.0000 - fn: 1655.0000 - accuracy: 0.9918 - precision: 0.7619 - recall: 0.4675 - auc: 0.9657 - val_loss: 0.0203 - val_tp: 1728.0000 - val_fp: 483.0000 - val_tn: 234536.0000 - val_fn: 1111.0000 - val_accuracy: 0.9933 - val_precision: 0.7815 - val_recall: 0.6087 - val_auc: 0.9814
256886/256886 - 127s - loss: 0.0261 - tp: 1453.0000 - fp: 454.0000 - tn: 253324.0000 - fn: 1655.0000 - accuracy: 0.9918 - precision: 0.7619 - recall: 0.4675 - auc: 0.9657 - val_loss: 0.0203 - val_tp: 1728.0000 - val_fp: 483.0000 - val_tn: 234536.0000 - val_fn: 1111.0000 - val_accuracy: 0.9933 - val_precision: 0.7815 - val_recall: 0.6087 - val_auc: 0.9814
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd56865c7f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52eb6cf28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52ea23780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52ea23f60>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52dfda240>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52dfda5f8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52dfda898>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52dfdaba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5501c6908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f1e1438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f1e1198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f1e11d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52eb663c8>]
          

Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_19 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_57 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_57 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_58 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_58 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_19 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_59 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_59 (Activation)   (None, 1)                 0         
=================================================================
Total params: 65,501
Trainable params: 65,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256886/256886 - 130s - loss: 0.0443 - tp: 538.0000 - fp: 389.0000 - tn: 253373.0000 - fn: 2586.0000 - accuracy: 0.9884 - precision: 0.5804 - recall: 0.1722 - auc: 0.8897 - val_loss: 0.0289 - val_tp: 919.0000 - val_fp: 353.0000 - val_tn: 234666.0000 - val_fn: 1920.0000 - val_accuracy: 0.9904 - val_precision: 0.7225 - val_recall: 0.3237 - val_auc: 0.9725
256886/256886 - 130s - loss: 0.0443 - tp: 538.0000 - fp: 389.0000 - tn: 253373.0000 - fn: 2586.0000 - accuracy: 0.9884 - precision: 0.5804 - recall: 0.1722 - auc: 0.8897 - val_loss: 0.0289 - val_tp: 919.0000 - val_fp: 353.0000 - val_tn: 234666.0000 - val_fn: 1920.0000 - val_accuracy: 0.9904 - val_precision: 0.7225 - val_recall: 0.3237 - val_auc: 0.9725
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73089
256886/256886 - 128s - loss: 0.0254 - tp: 1520.0000 - fp: 453.0000 - tn: 253309.0000 - fn: 1604.0000 - accuracy: 0.9920 - precision: 0.7704 - recall: 0.4866 - auc: 0.9680 - val_loss: 0.0214 - val_tp: 1834.0000 - val_fp: 533.0000 - val_tn: 234486.0000 - val_fn: 1005.0000 - val_accuracy: 0.9935 - val_precision: 0.7748 - val_recall: 0.6460 - val_auc: 0.9851
256886/256886 - 128s - loss: 0.0254 - tp: 1520.0000 - fp: 453.0000 - tn: 253309.0000 - fn: 1604.0000 - accuracy: 0.9920 - precision: 0.7704 - recall: 0.4866 - auc: 0.9680 - val_loss: 0.0214 - val_tp: 1834.0000 - val_fp: 533.0000 - val_tn: 234486.0000 - val_fn: 1005.0000 - val_accuracy: 0.9935 - val_precision: 0.7748 - val_recall: 0.6460 - val_auc: 0.9851
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d234080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e809dd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e809f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e809da0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52d22bef0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e82ecc0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e82e828>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e82e5c0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f1e1438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f1e1240>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f1e11d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52dc720f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f536eb8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e7de208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e7de4a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e7de748>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e7de9e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7dec88>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e7def60>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e788320>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e788630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d234048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e7fab38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e7faf98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e7faf60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e7c8208>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e7bbef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e74b2b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e74b550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e74b7f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e74ba90>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e74be48>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e758128>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e758438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e7de198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e82eb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e82eef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e82e7f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e7bbf28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e7214a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e721908>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e721ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e721e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e736128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e7364e0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e736780>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e736a90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e7bbeb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e769080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e769390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e769128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e721710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e68bda0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e741208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e7414a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e741748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7419e8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e741da0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e741f98>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e6a0390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e721518>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e727630>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e727780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e68bf60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e68bf98>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd568671438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5686716d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd568671978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd568671d68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7a4e48>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e82e240>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52eb4f978>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e7c8c18>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e68bcf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52cfeb160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd568671080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5686710f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd568671160>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e82e240>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52df69fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e7c84a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52dc593c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7e2908>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52df4b278>, <tensorflow.python.keras.metrics.Recall object at 0x7fd568671710>, <tensorflow.python.keras.metrics.AUC object at 0x7fd568671b00>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5686713c8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e804390>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e8099e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52eb54080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52dc52da0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52cf86d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd568671860>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd568671668>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd568671cc0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7e2940>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52d234048>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e7c8518>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e82ee10>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e8129e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52df4b748>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52dc59588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e843b38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e7fab70>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f44d748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f34d208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e82e4a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e7c83c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7bbd30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e7e2cf8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5686719e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd568671a58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52cf86da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f300b70>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52d234048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52d234f98>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52d234cc0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f300710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd568671400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5686716a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd568671b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7e2940>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e7bbdd8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f34ddd8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f34d748>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f44d630>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52fec32e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e82e240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e82eb00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e82efd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52fec3f98>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f34d208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e7c8a90>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e7bbe10>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e7e29e8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd568671518>, <tensorflow.python.keras.metrics.Recall object at 0x7fd568671d68>, <tensorflow.python.keras.metrics.AUC object at 0x7fd568671780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f300908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568586518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52fec3198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52fec3b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52fec3860>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5686a4240>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5686b5fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5686b5be0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5686b5ef0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5686b5860>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52fd31208>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52fd25828>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52fd25908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52fec3d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5681825f8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f44d470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5685a2f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5686a40b8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52fdda518>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52fdc4240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52fdc48d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52fdc4ef0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52fdc4cf8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52fdc4198>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52fdc4048>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52fdfd630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5686a4278>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568671828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd568671940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52fdda2e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52fdda278>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52e9e6320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e9e6358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5a80c69e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5a80c6940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5a80c6e10>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5a80c6b00>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5a80c6160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52ec60908>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52fdda588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd56865f898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd56865fef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd56865f7b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e9e6048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52fd22d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52fd22f60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc91518>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91908>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91d30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91a58>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc91668>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f975588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52e9e6e48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd588393c88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd588393908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd588393470>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52fd11b00>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f975748>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f975780>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc916d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91a90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91ac8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91320>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc91a20>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52cc91438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52fd22b38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e9e6e48>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd588393908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd588393470>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52fd11b00>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52fd22908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52cc91470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc91240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91710>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91630>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc916a0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f975be0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f975cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd568631898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd568631828>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd568631e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd568631eb8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f975438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f975ef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc917f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91780>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91b38>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91320>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc91908>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52fd22e80>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52fd22d68>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd588073ef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd588073518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd588073400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5884f8ba8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f2a12e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52cc91f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc91208>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91d30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91048>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91b70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f975e80>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f975ba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f975978>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52fd22d30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52fd22cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52fd22ef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52fd22f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52eb09cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f9755c0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f975f28>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc912e8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91978>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc91908>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52cc91b38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f2a13c8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52fab7438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5a8084128>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5a8084908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f2a12e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52fab70f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52cc91e80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cc91320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52cc91400>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc91d30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52cc91898>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cc91550>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f975780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52eb09c88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c49a160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f134eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f134f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f134a90>]
          

Model: "sequential_40"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru (GRU)                    (None, 50)                9600      
_________________________________________________________________
dense_60 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_60 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_61 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_61 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_20 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_62 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_62 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73089
256885/256885 - 110s - loss: 0.0452 - tp: 538.0000 - fp: 399.0000 - tn: 253360.0000 - fn: 2588.0000 - accuracy: 0.9884 - precision: 0.5742 - recall: 0.1721 - auc: 0.8855 - val_loss: 0.0288 - val_tp: 926.0000 - val_fp: 313.0000 - val_tn: 234706.0000 - val_fn: 1913.0000 - val_accuracy: 0.9906 - val_precision: 0.7474 - val_recall: 0.3262 - val_auc: 0.9710
256885/256885 - 110s - loss: 0.0452 - tp: 538.0000 - fp: 399.0000 - tn: 253360.0000 - fn: 2588.0000 - accuracy: 0.9884 - precision: 0.5742 - recall: 0.1721 - auc: 0.8855 - val_loss: 0.0288 - val_tp: 926.0000 - val_fp: 313.0000 - val_tn: 234706.0000 - val_fn: 1913.0000 - val_accuracy: 0.9906 - val_precision: 0.7474 - val_recall: 0.3262 - val_auc: 0.9710
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.73089 to 0.73864, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 106s - loss: 0.0256 - tp: 1484.0000 - fp: 379.0000 - tn: 253380.0000 - fn: 1642.0000 - accuracy: 0.9921 - precision: 0.7966 - recall: 0.4747 - auc: 0.9671 - val_loss: 0.0252 - val_tp: 2097.0000 - val_fp: 1161.0000 - val_tn: 233858.0000 - val_fn: 742.0000 - val_accuracy: 0.9920 - val_precision: 0.6436 - val_recall: 0.7386 - val_auc: 0.9859
256885/256885 - 106s - loss: 0.0256 - tp: 1484.0000 - fp: 379.0000 - tn: 253380.0000 - fn: 1642.0000 - accuracy: 0.9921 - precision: 0.7966 - recall: 0.4747 - auc: 0.9671 - val_loss: 0.0252 - val_tp: 2097.0000 - val_fp: 1161.0000 - val_tn: 233858.0000 - val_fn: 742.0000 - val_accuracy: 0.9920 - val_precision: 0.6436 - val_recall: 0.7386 - val_auc: 0.9859
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 19s
256885/256885 - 19s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f8ae4e0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f8ae0f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52f8ae240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c892e80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd568142ba8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c70eba8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f807668>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f807eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f134eb8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c87efd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f801f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52fd11780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f1a5978>]
          

Model: "sequential_41"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_1 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_63 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_63 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_64 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_64 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_21 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_65 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_65 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 110s - loss: 0.0437 - tp: 492.0000 - fp: 279.0000 - tn: 253479.0000 - fn: 2635.0000 - accuracy: 0.9887 - precision: 0.6381 - recall: 0.1573 - auc: 0.8969 - val_loss: 0.0304 - val_tp: 825.0000 - val_fp: 280.0000 - val_tn: 234739.0000 - val_fn: 2014.0000 - val_accuracy: 0.9904 - val_precision: 0.7466 - val_recall: 0.2906 - val_auc: 0.9539
256885/256885 - 110s - loss: 0.0437 - tp: 492.0000 - fp: 279.0000 - tn: 253479.0000 - fn: 2635.0000 - accuracy: 0.9887 - precision: 0.6381 - recall: 0.1573 - auc: 0.8969 - val_loss: 0.0304 - val_tp: 825.0000 - val_fp: 280.0000 - val_tn: 234739.0000 - val_fn: 2014.0000 - val_accuracy: 0.9904 - val_precision: 0.7466 - val_recall: 0.2906 - val_auc: 0.9539
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0257 - tp: 1481.0000 - fp: 414.0000 - tn: 253344.0000 - fn: 1646.0000 - accuracy: 0.9920 - precision: 0.7815 - recall: 0.4736 - auc: 0.9693 - val_loss: 0.0206 - val_tp: 1816.0000 - val_fp: 554.0000 - val_tn: 234465.0000 - val_fn: 1023.0000 - val_accuracy: 0.9934 - val_precision: 0.7662 - val_recall: 0.6397 - val_auc: 0.9827
256885/256885 - 106s - loss: 0.0257 - tp: 1481.0000 - fp: 414.0000 - tn: 253344.0000 - fn: 1646.0000 - accuracy: 0.9920 - precision: 0.7815 - recall: 0.4736 - auc: 0.9693 - val_loss: 0.0206 - val_tp: 1816.0000 - val_fp: 554.0000 - val_tn: 234465.0000 - val_fn: 1023.0000 - val_accuracy: 0.9934 - val_precision: 0.7662 - val_recall: 0.6397 - val_auc: 0.9827
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c57b5c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5685fa320>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c5e8c50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c5e84e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c5e8470>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c5e8860>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c5e84a8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e336710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52fd11780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c5a6390>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f801e48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c8922e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e32fd68>]
          

Model: "sequential_42"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_2 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_66 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_66 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_67 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_67 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_22 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_68 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_68 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 110s - loss: 0.0437 - tp: 505.0000 - fp: 331.0000 - tn: 253438.0000 - fn: 2611.0000 - accuracy: 0.9885 - precision: 0.6041 - recall: 0.1621 - auc: 0.8978 - val_loss: 0.0314 - val_tp: 1252.0000 - val_fp: 800.0000 - val_tn: 234219.0000 - val_fn: 1587.0000 - val_accuracy: 0.9900 - val_precision: 0.6101 - val_recall: 0.4410 - val_auc: 0.9727
256885/256885 - 110s - loss: 0.0437 - tp: 505.0000 - fp: 331.0000 - tn: 253438.0000 - fn: 2611.0000 - accuracy: 0.9885 - precision: 0.6041 - recall: 0.1621 - auc: 0.8978 - val_loss: 0.0314 - val_tp: 1252.0000 - val_fp: 800.0000 - val_tn: 234219.0000 - val_fn: 1587.0000 - val_accuracy: 0.9900 - val_precision: 0.6101 - val_recall: 0.4410 - val_auc: 0.9727
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0261 - tp: 1434.0000 - fp: 413.0000 - tn: 253356.0000 - fn: 1682.0000 - accuracy: 0.9918 - precision: 0.7764 - recall: 0.4602 - auc: 0.9672 - val_loss: 0.0209 - val_tp: 1793.0000 - val_fp: 531.0000 - val_tn: 234488.0000 - val_fn: 1046.0000 - val_accuracy: 0.9934 - val_precision: 0.7715 - val_recall: 0.6316 - val_auc: 0.9802
256885/256885 - 106s - loss: 0.0261 - tp: 1434.0000 - fp: 413.0000 - tn: 253356.0000 - fn: 1682.0000 - accuracy: 0.9918 - precision: 0.7764 - recall: 0.4602 - auc: 0.9672 - val_loss: 0.0209 - val_tp: 1793.0000 - val_fp: 531.0000 - val_tn: 234488.0000 - val_fn: 1046.0000 - val_accuracy: 0.9934 - val_precision: 0.7715 - val_recall: 0.6316 - val_auc: 0.9802
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52de462e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52de469e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52de461d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52de46748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52e0b6e80>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e0b66a0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e0b6cf8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e0b6198>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f801e48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f3299b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e32fcc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c57b588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e135438>]
          

Model: "sequential_43"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_3 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_69 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_69 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_70 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_70 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_23 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_71 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_71 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 110s - loss: 0.0415 - tp: 572.0000 - fp: 345.0000 - tn: 253447.0000 - fn: 2521.0000 - accuracy: 0.9888 - precision: 0.6238 - recall: 0.1849 - auc: 0.9096 - val_loss: 0.0293 - val_tp: 881.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1958.0000 - val_accuracy: 0.9905 - val_precision: 0.7397 - val_recall: 0.3103 - val_auc: 0.9605
256885/256885 - 110s - loss: 0.0415 - tp: 572.0000 - fp: 345.0000 - tn: 253447.0000 - fn: 2521.0000 - accuracy: 0.9888 - precision: 0.6238 - recall: 0.1849 - auc: 0.9096 - val_loss: 0.0293 - val_tp: 881.0000 - val_fp: 310.0000 - val_tn: 234709.0000 - val_fn: 1958.0000 - val_accuracy: 0.9905 - val_precision: 0.7397 - val_recall: 0.3103 - val_auc: 0.9605
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 107s - loss: 0.0256 - tp: 1463.0000 - fp: 426.0000 - tn: 253366.0000 - fn: 1630.0000 - accuracy: 0.9920 - precision: 0.7745 - recall: 0.4730 - auc: 0.9687 - val_loss: 0.0209 - val_tp: 1561.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1278.0000 - val_accuracy: 0.9933 - val_precision: 0.8294 - val_recall: 0.5498 - val_auc: 0.9774
256885/256885 - 107s - loss: 0.0256 - tp: 1463.0000 - fp: 426.0000 - tn: 253366.0000 - fn: 1630.0000 - accuracy: 0.9920 - precision: 0.7745 - recall: 0.4730 - auc: 0.9687 - val_loss: 0.0209 - val_tp: 1561.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1278.0000 - val_accuracy: 0.9933 - val_precision: 0.8294 - val_recall: 0.5498 - val_auc: 0.9774
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 19s
256885/256885 - 19s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f88c5c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52f88c240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52d201390>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52d0e3518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52d33b860>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52d33b7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e0c7e48>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52de1f198>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52cf41390>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f88c048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f88c4a8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f88c0b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52f88c320>]
          

Model: "sequential_44"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_4 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_72 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_72 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_73 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_73 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_24 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_74 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_74 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 110s - loss: 0.0454 - tp: 529.0000 - fp: 378.0000 - tn: 253361.0000 - fn: 2617.0000 - accuracy: 0.9883 - precision: 0.5832 - recall: 0.1682 - auc: 0.8852 - val_loss: 0.0298 - val_tp: 879.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1960.0000 - val_accuracy: 0.9904 - val_precision: 0.7325 - val_recall: 0.3096 - val_auc: 0.9694
256885/256885 - 110s - loss: 0.0454 - tp: 529.0000 - fp: 378.0000 - tn: 253361.0000 - fn: 2617.0000 - accuracy: 0.9883 - precision: 0.5832 - recall: 0.1682 - auc: 0.8852 - val_loss: 0.0298 - val_tp: 879.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1960.0000 - val_accuracy: 0.9904 - val_precision: 0.7325 - val_recall: 0.3096 - val_auc: 0.9694
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 107s - loss: 0.0260 - tp: 1475.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1671.0000 - accuracy: 0.9919 - precision: 0.7808 - recall: 0.4688 - auc: 0.9656 - val_loss: 0.0266 - val_tp: 1960.0000 - val_fp: 698.0000 - val_tn: 234321.0000 - val_fn: 879.0000 - val_accuracy: 0.9934 - val_precision: 0.7374 - val_recall: 0.6904 - val_auc: 0.9887
256885/256885 - 107s - loss: 0.0260 - tp: 1475.0000 - fp: 414.0000 - tn: 253325.0000 - fn: 1671.0000 - accuracy: 0.9919 - precision: 0.7808 - recall: 0.4688 - auc: 0.9656 - val_loss: 0.0266 - val_tp: 1960.0000 - val_fp: 698.0000 - val_tn: 234321.0000 - val_fn: 879.0000 - val_accuracy: 0.9934 - val_precision: 0.7374 - val_recall: 0.6904 - val_auc: 0.9887
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c89acc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52eba3cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52eba3dd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52eba3f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52ebbc208>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52ebbc5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52ebbc860>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52ebbcb70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f88c4a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f88c2b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52f88c588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f88c278>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52ca81390>]
          

Model: "sequential_45"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_5 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_75 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_75 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_76 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_76 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_25 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_77 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_77 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 108s - loss: 0.0436 - tp: 529.0000 - fp: 331.0000 - tn: 253447.0000 - fn: 2578.0000 - accuracy: 0.9887 - precision: 0.6151 - recall: 0.1703 - auc: 0.8964 - val_loss: 0.0294 - val_tp: 934.0000 - val_fp: 360.0000 - val_tn: 234659.0000 - val_fn: 1905.0000 - val_accuracy: 0.9905 - val_precision: 0.7218 - val_recall: 0.3290 - val_auc: 0.9709
256885/256885 - 108s - loss: 0.0436 - tp: 529.0000 - fp: 331.0000 - tn: 253447.0000 - fn: 2578.0000 - accuracy: 0.9887 - precision: 0.6151 - recall: 0.1703 - auc: 0.8964 - val_loss: 0.0294 - val_tp: 934.0000 - val_fp: 360.0000 - val_tn: 234659.0000 - val_fn: 1905.0000 - val_accuracy: 0.9905 - val_precision: 0.7218 - val_recall: 0.3290 - val_auc: 0.9709
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 105s - loss: 0.0260 - tp: 1402.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1705.0000 - accuracy: 0.9917 - precision: 0.7644 - recall: 0.4512 - auc: 0.9677 - val_loss: 0.0204 - val_tp: 1655.0000 - val_fp: 390.0000 - val_tn: 234629.0000 - val_fn: 1184.0000 - val_accuracy: 0.9934 - val_precision: 0.8093 - val_recall: 0.5830 - val_auc: 0.9814
256885/256885 - 105s - loss: 0.0260 - tp: 1402.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1705.0000 - accuracy: 0.9917 - precision: 0.7644 - recall: 0.4512 - auc: 0.9677 - val_loss: 0.0204 - val_tp: 1655.0000 - val_fp: 390.0000 - val_tn: 234629.0000 - val_fn: 1184.0000 - val_accuracy: 0.9934 - val_precision: 0.8093 - val_recall: 0.5830 - val_auc: 0.9814
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5195ffc50>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e8430f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52cfdc0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52dbc33c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52dbc3b70>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52dbc3198>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52dbc3eb8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52dbc3630>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f88c2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd51983e630>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52dc3bf28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52dc3b9e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52dc3bfd0>]
          

Model: "sequential_46"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_6 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_78 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_78 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_79 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_79 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_26 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_80 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_80 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 111s - loss: 0.0445 - tp: 509.0000 - fp: 334.0000 - tn: 253460.0000 - fn: 2582.0000 - accuracy: 0.9886 - precision: 0.6038 - recall: 0.1647 - auc: 0.8859 - val_loss: 0.0309 - val_tp: 716.0000 - val_fp: 229.0000 - val_tn: 234790.0000 - val_fn: 2123.0000 - val_accuracy: 0.9901 - val_precision: 0.7577 - val_recall: 0.2522 - val_auc: 0.9524
256885/256885 - 111s - loss: 0.0445 - tp: 509.0000 - fp: 334.0000 - tn: 253460.0000 - fn: 2582.0000 - accuracy: 0.9886 - precision: 0.6038 - recall: 0.1647 - auc: 0.8859 - val_loss: 0.0309 - val_tp: 716.0000 - val_fp: 229.0000 - val_tn: 234790.0000 - val_fn: 2123.0000 - val_accuracy: 0.9901 - val_precision: 0.7577 - val_recall: 0.2522 - val_auc: 0.9524
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 107s - loss: 0.0256 - tp: 1462.0000 - fp: 413.0000 - tn: 253381.0000 - fn: 1629.0000 - accuracy: 0.9921 - precision: 0.7797 - recall: 0.4730 - auc: 0.9678 - val_loss: 0.0204 - val_tp: 1579.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1260.0000 - val_accuracy: 0.9934 - val_precision: 0.8324 - val_recall: 0.5562 - val_auc: 0.9814
256885/256885 - 107s - loss: 0.0256 - tp: 1462.0000 - fp: 413.0000 - tn: 253381.0000 - fn: 1629.0000 - accuracy: 0.9921 - precision: 0.7797 - recall: 0.4730 - auc: 0.9678 - val_loss: 0.0204 - val_tp: 1579.0000 - val_fp: 318.0000 - val_tn: 234701.0000 - val_fn: 1260.0000 - val_accuracy: 0.9934 - val_precision: 0.8324 - val_recall: 0.5562 - val_auc: 0.9814
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52cf270f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52e4f9630>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c494be0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c4947f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c494c18>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c494630>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5197f9c18>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5197f98d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519836a90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52dc3b9e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52bebee48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c09f518>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52d995da0>]
          

Model: "sequential_47"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_7 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_81 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_81 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_82 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_82 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_27 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_83 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_83 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 110s - loss: 0.0443 - tp: 476.0000 - fp: 331.0000 - tn: 253443.0000 - fn: 2635.0000 - accuracy: 0.9885 - precision: 0.5898 - recall: 0.1530 - auc: 0.8900 - val_loss: 0.0300 - val_tp: 776.0000 - val_fp: 275.0000 - val_tn: 234744.0000 - val_fn: 2063.0000 - val_accuracy: 0.9902 - val_precision: 0.7383 - val_recall: 0.2733 - val_auc: 0.9634
256885/256885 - 110s - loss: 0.0443 - tp: 476.0000 - fp: 331.0000 - tn: 253443.0000 - fn: 2635.0000 - accuracy: 0.9885 - precision: 0.5898 - recall: 0.1530 - auc: 0.8900 - val_loss: 0.0300 - val_tp: 776.0000 - val_fp: 275.0000 - val_tn: 234744.0000 - val_fn: 2063.0000 - val_accuracy: 0.9902 - val_precision: 0.7383 - val_recall: 0.2733 - val_auc: 0.9634
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 107s - loss: 0.0265 - tp: 1402.0000 - fp: 399.0000 - tn: 253375.0000 - fn: 1709.0000 - accuracy: 0.9918 - precision: 0.7785 - recall: 0.4507 - auc: 0.9662 - val_loss: 0.0211 - val_tp: 1470.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1369.0000 - val_accuracy: 0.9931 - val_precision: 0.8405 - val_recall: 0.5178 - val_auc: 0.9773
256885/256885 - 107s - loss: 0.0265 - tp: 1402.0000 - fp: 399.0000 - tn: 253375.0000 - fn: 1709.0000 - accuracy: 0.9918 - precision: 0.7785 - recall: 0.4507 - auc: 0.9662 - val_loss: 0.0211 - val_tp: 1470.0000 - val_fp: 279.0000 - val_tn: 234740.0000 - val_fn: 1369.0000 - val_accuracy: 0.9931 - val_precision: 0.8405 - val_recall: 0.5178 - val_auc: 0.9773
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5199422b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519942710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52e0c7780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c145198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c145978>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c1454a8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c145160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c145da0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52bebee48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52cf27048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52d9b2a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52bf59c18>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519953ef0>]
          

Model: "sequential_48"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_8 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_84 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_84 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_85 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_85 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_28 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_86 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_86 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256886/256886 - 110s - loss: 0.0422 - tp: 555.0000 - fp: 305.0000 - tn: 253473.0000 - fn: 2553.0000 - accuracy: 0.9889 - precision: 0.6453 - recall: 0.1786 - auc: 0.9055 - val_loss: 0.0305 - val_tp: 1280.0000 - val_fp: 734.0000 - val_tn: 234285.0000 - val_fn: 1559.0000 - val_accuracy: 0.9904 - val_precision: 0.6356 - val_recall: 0.4509 - val_auc: 0.9737
256886/256886 - 110s - loss: 0.0422 - tp: 555.0000 - fp: 305.0000 - tn: 253473.0000 - fn: 2553.0000 - accuracy: 0.9889 - precision: 0.6453 - recall: 0.1786 - auc: 0.9055 - val_loss: 0.0305 - val_tp: 1280.0000 - val_fp: 734.0000 - val_tn: 234285.0000 - val_fn: 1559.0000 - val_accuracy: 0.9904 - val_precision: 0.6356 - val_recall: 0.4509 - val_auc: 0.9737
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256886/256886 - 106s - loss: 0.0252 - tp: 1516.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1592.0000 - accuracy: 0.9921 - precision: 0.7782 - recall: 0.4878 - auc: 0.9681 - val_loss: 0.0206 - val_tp: 1563.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 1276.0000 - val_accuracy: 0.9935 - val_precision: 0.8522 - val_recall: 0.5505 - val_auc: 0.9697
256886/256886 - 106s - loss: 0.0252 - tp: 1516.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1592.0000 - accuracy: 0.9921 - precision: 0.7782 - recall: 0.4878 - auc: 0.9681 - val_loss: 0.0206 - val_tp: 1563.0000 - val_fp: 271.0000 - val_tn: 234748.0000 - val_fn: 1276.0000 - val_accuracy: 0.9935 - val_precision: 0.8522 - val_recall: 0.5505 - val_auc: 0.9697
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd525e24630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519538198>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd525e43b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd525e43b00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f7e5be0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e239128>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52e239160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c01e400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519942048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd525e24160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd525e240f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd525e24588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd525e24be0>]
          

Model: "sequential_49"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_9 (GRU)                  (None, 50)                9600      
_________________________________________________________________
dense_87 (Dense)             (None, 100)               5100      
_________________________________________________________________
activation_87 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_88 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_88 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_29 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_89 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_89 (Activation)   (None, 1)                 0         
=================================================================
Total params: 24,901
Trainable params: 24,901
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256886/256886 - 110s - loss: 0.0452 - tp: 498.0000 - fp: 396.0000 - tn: 253366.0000 - fn: 2626.0000 - accuracy: 0.9882 - precision: 0.5570 - recall: 0.1594 - auc: 0.8886 - val_loss: 0.0321 - val_tp: 800.0000 - val_fp: 287.0000 - val_tn: 234732.0000 - val_fn: 2039.0000 - val_accuracy: 0.9902 - val_precision: 0.7360 - val_recall: 0.2818 - val_auc: 0.9395
256886/256886 - 110s - loss: 0.0452 - tp: 498.0000 - fp: 396.0000 - tn: 253366.0000 - fn: 2626.0000 - accuracy: 0.9882 - precision: 0.5570 - recall: 0.1594 - auc: 0.8886 - val_loss: 0.0321 - val_tp: 800.0000 - val_fp: 287.0000 - val_tn: 234732.0000 - val_fn: 2039.0000 - val_accuracy: 0.9902 - val_precision: 0.7360 - val_recall: 0.2818 - val_auc: 0.9395
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256886/256886 - 107s - loss: 0.0263 - tp: 1425.0000 - fp: 403.0000 - tn: 253359.0000 - fn: 1699.0000 - accuracy: 0.9918 - precision: 0.7795 - recall: 0.4561 - auc: 0.9659 - val_loss: 0.0218 - val_tp: 1446.0000 - val_fp: 235.0000 - val_tn: 234784.0000 - val_fn: 1393.0000 - val_accuracy: 0.9932 - val_precision: 0.8602 - val_recall: 0.5093 - val_auc: 0.9668
256886/256886 - 107s - loss: 0.0263 - tp: 1425.0000 - fp: 403.0000 - tn: 253359.0000 - fn: 1699.0000 - accuracy: 0.9918 - precision: 0.7795 - recall: 0.4561 - auc: 0.9659 - val_loss: 0.0218 - val_tp: 1446.0000 - val_fp: 235.0000 - val_tn: 234784.0000 - val_fn: 1393.0000 - val_accuracy: 0.9932 - val_precision: 0.8602 - val_recall: 0.5093 - val_auc: 0.9668
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52f1ba940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519841be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52d41b518>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e0d8a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f18d358>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52f18d748>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f18d9e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f18dcf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd525e24588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd525e24080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd525e24c50>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd525e24ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519942048>]
          

Model: "sequential_50"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_10 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_90 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_90 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_91 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_91 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_30 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_92 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_92 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 127s - loss: 0.0426 - tp: 630.0000 - fp: 343.0000 - tn: 253416.0000 - fn: 2496.0000 - accuracy: 0.9889 - precision: 0.6475 - recall: 0.2015 - auc: 0.9015 - val_loss: 0.0279 - val_tp: 917.0000 - val_fp: 282.0000 - val_tn: 234737.0000 - val_fn: 1922.0000 - val_accuracy: 0.9907 - val_precision: 0.7648 - val_recall: 0.3230 - val_auc: 0.9681
256885/256885 - 127s - loss: 0.0426 - tp: 630.0000 - fp: 343.0000 - tn: 253416.0000 - fn: 2496.0000 - accuracy: 0.9889 - precision: 0.6475 - recall: 0.2015 - auc: 0.9015 - val_loss: 0.0279 - val_tp: 917.0000 - val_fp: 282.0000 - val_tn: 234737.0000 - val_fn: 1922.0000 - val_accuracy: 0.9907 - val_precision: 0.7648 - val_recall: 0.3230 - val_auc: 0.9681
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 124s - loss: 0.0241 - tp: 1616.0000 - fp: 410.0000 - tn: 253349.0000 - fn: 1510.0000 - accuracy: 0.9925 - precision: 0.7976 - recall: 0.5170 - auc: 0.9688 - val_loss: 0.0195 - val_tp: 1581.0000 - val_fp: 221.0000 - val_tn: 234798.0000 - val_fn: 1258.0000 - val_accuracy: 0.9938 - val_precision: 0.8774 - val_recall: 0.5569 - val_auc: 0.9806
256885/256885 - 124s - loss: 0.0241 - tp: 1616.0000 - fp: 410.0000 - tn: 253349.0000 - fn: 1510.0000 - accuracy: 0.9925 - precision: 0.7976 - recall: 0.5170 - auc: 0.9688 - val_loss: 0.0195 - val_tp: 1581.0000 - val_fp: 221.0000 - val_tn: 234798.0000 - val_fn: 1258.0000 - val_accuracy: 0.9938 - val_precision: 0.8774 - val_recall: 0.5569 - val_auc: 0.9806
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519175ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519175c88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5193dd780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519199a58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd51812f390>, <tensorflow.python.keras.metrics.Precision object at 0x7fd51812f6a0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd51812f4a8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd51812fb38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd525e24c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519942048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd525e24d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5197542b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5193f5f98>]
          

Model: "sequential_51"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_11 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_93 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_93 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_94 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_94 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_31 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_95 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_95 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 127s - loss: 0.0443 - tp: 539.0000 - fp: 397.0000 - tn: 253361.0000 - fn: 2588.0000 - accuracy: 0.9884 - precision: 0.5759 - recall: 0.1724 - auc: 0.8928 - val_loss: 0.0288 - val_tp: 1307.0000 - val_fp: 749.0000 - val_tn: 234270.0000 - val_fn: 1532.0000 - val_accuracy: 0.9904 - val_precision: 0.6357 - val_recall: 0.4604 - val_auc: 0.9722
256885/256885 - 127s - loss: 0.0443 - tp: 539.0000 - fp: 397.0000 - tn: 253361.0000 - fn: 2588.0000 - accuracy: 0.9884 - precision: 0.5759 - recall: 0.1724 - auc: 0.8928 - val_loss: 0.0288 - val_tp: 1307.0000 - val_fp: 749.0000 - val_tn: 234270.0000 - val_fn: 1532.0000 - val_accuracy: 0.9904 - val_precision: 0.6357 - val_recall: 0.4604 - val_auc: 0.9722
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 124s - loss: 0.0248 - tp: 1560.0000 - fp: 451.0000 - tn: 253307.0000 - fn: 1567.0000 - accuracy: 0.9921 - precision: 0.7757 - recall: 0.4989 - auc: 0.9713 - val_loss: 0.0200 - val_tp: 1772.0000 - val_fp: 448.0000 - val_tn: 234571.0000 - val_fn: 1067.0000 - val_accuracy: 0.9936 - val_precision: 0.7982 - val_recall: 0.6242 - val_auc: 0.9735
256885/256885 - 124s - loss: 0.0248 - tp: 1560.0000 - fp: 451.0000 - tn: 253307.0000 - fn: 1567.0000 - accuracy: 0.9921 - precision: 0.7757 - recall: 0.4989 - auc: 0.9713 - val_loss: 0.0200 - val_tp: 1772.0000 - val_fp: 448.0000 - val_tn: 234571.0000 - val_fn: 1067.0000 - val_accuracy: 0.9936 - val_precision: 0.7982 - val_recall: 0.6242 - val_auc: 0.9735
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519175dd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd51921c748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd51921c9b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd51928e6d8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd51928ef28>, <tensorflow.python.keras.metrics.Precision object at 0x7fd51927da20>, <tensorflow.python.keras.metrics.Recall object at 0x7fd5192858d0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519285940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd525e24c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519224d68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519240fd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5191aa0b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519252898>]
          

Model: "sequential_52"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_12 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_96 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_96 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_97 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_97 (Activation)   (None, 100)               0         
_________________________________________________________________
dropout_32 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_98 (Dense)             (None, 1)                 101       
_________________________________________________________________
activation_98 (Activation)   (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 127s - loss: 0.0435 - tp: 564.0000 - fp: 343.0000 - tn: 253426.0000 - fn: 2552.0000 - accuracy: 0.9887 - precision: 0.6218 - recall: 0.1810 - auc: 0.8936 - val_loss: 0.0292 - val_tp: 826.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2013.0000 - val_accuracy: 0.9905 - val_precision: 0.7620 - val_recall: 0.2909 - val_auc: 0.9606
256885/256885 - 127s - loss: 0.0435 - tp: 564.0000 - fp: 343.0000 - tn: 253426.0000 - fn: 2552.0000 - accuracy: 0.9887 - precision: 0.6218 - recall: 0.1810 - auc: 0.8936 - val_loss: 0.0292 - val_tp: 826.0000 - val_fp: 258.0000 - val_tn: 234761.0000 - val_fn: 2013.0000 - val_accuracy: 0.9905 - val_precision: 0.7620 - val_recall: 0.2909 - val_auc: 0.9606
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 124s - loss: 0.0253 - tp: 1523.0000 - fp: 458.0000 - tn: 253311.0000 - fn: 1593.0000 - accuracy: 0.9920 - precision: 0.7688 - recall: 0.4888 - auc: 0.9676 - val_loss: 0.0204 - val_tp: 1518.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1321.0000 - val_accuracy: 0.9934 - val_precision: 0.8542 - val_recall: 0.5347 - val_auc: 0.9817
256885/256885 - 124s - loss: 0.0253 - tp: 1523.0000 - fp: 458.0000 - tn: 253311.0000 - fn: 1593.0000 - accuracy: 0.9920 - precision: 0.7688 - recall: 0.4888 - auc: 0.9676 - val_loss: 0.0204 - val_tp: 1518.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1321.0000 - val_accuracy: 0.9934 - val_precision: 0.8542 - val_recall: 0.5347 - val_auc: 0.9817
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 24s
256885/256885 - 24s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50bef2be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52bf43358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52bf43da0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd525e24080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52d3c4cf8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e759f28>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52f8f5c88>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52f8f5710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519240fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52e36ec50>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52e3b3a90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5191d9048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd525e53b00>]
          

Model: "sequential_53"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_13 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_99 (Dense)             (None, 100)               10100     
_________________________________________________________________
activation_99 (Activation)   (None, 100)               0         
_________________________________________________________________
dense_100 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_100 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_33 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_101 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_101 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 126s - loss: 0.0414 - tp: 615.0000 - fp: 318.0000 - tn: 253474.0000 - fn: 2478.0000 - accuracy: 0.9891 - precision: 0.6592 - recall: 0.1988 - auc: 0.9074 - val_loss: 0.0277 - val_tp: 1095.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1744.0000 - val_accuracy: 0.9909 - val_precision: 0.7190 - val_recall: 0.3857 - val_auc: 0.9741
256885/256885 - 126s - loss: 0.0414 - tp: 615.0000 - fp: 318.0000 - tn: 253474.0000 - fn: 2478.0000 - accuracy: 0.9891 - precision: 0.6592 - recall: 0.1988 - auc: 0.9074 - val_loss: 0.0277 - val_tp: 1095.0000 - val_fp: 428.0000 - val_tn: 234591.0000 - val_fn: 1744.0000 - val_accuracy: 0.9909 - val_precision: 0.7190 - val_recall: 0.3857 - val_auc: 0.9741
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 124s - loss: 0.0245 - tp: 1569.0000 - fp: 423.0000 - tn: 253369.0000 - fn: 1524.0000 - accuracy: 0.9924 - precision: 0.7877 - recall: 0.5073 - auc: 0.9688 - val_loss: 0.0210 - val_tp: 1884.0000 - val_fp: 680.0000 - val_tn: 234339.0000 - val_fn: 955.0000 - val_accuracy: 0.9931 - val_precision: 0.7348 - val_recall: 0.6636 - val_auc: 0.9842
256885/256885 - 124s - loss: 0.0245 - tp: 1569.0000 - fp: 423.0000 - tn: 253369.0000 - fn: 1524.0000 - accuracy: 0.9924 - precision: 0.7877 - recall: 0.5073 - auc: 0.9688 - val_loss: 0.0210 - val_tp: 1884.0000 - val_fp: 680.0000 - val_tn: 234339.0000 - val_fn: 955.0000 - val_accuracy: 0.9931 - val_precision: 0.7348 - val_recall: 0.6636 - val_auc: 0.9842
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d0289e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52c955470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c955da0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c95f5f8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c95f898>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c95fc50>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c95fef0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c976240>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd525e53b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5191d22b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5191d8fd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd525d988d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e36ec50>]
          

Model: "sequential_54"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_14 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_102 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_102 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_103 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_103 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_34 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_104 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_104 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 126s - loss: 0.0423 - tp: 588.0000 - fp: 311.0000 - tn: 253428.0000 - fn: 2558.0000 - accuracy: 0.9888 - precision: 0.6541 - recall: 0.1869 - auc: 0.9063 - val_loss: 0.0305 - val_tp: 786.0000 - val_fp: 240.0000 - val_tn: 234779.0000 - val_fn: 2053.0000 - val_accuracy: 0.9904 - val_precision: 0.7661 - val_recall: 0.2769 - val_auc: 0.9498
256885/256885 - 126s - loss: 0.0423 - tp: 588.0000 - fp: 311.0000 - tn: 253428.0000 - fn: 2558.0000 - accuracy: 0.9888 - precision: 0.6541 - recall: 0.1869 - auc: 0.9063 - val_loss: 0.0305 - val_tp: 786.0000 - val_fp: 240.0000 - val_tn: 234779.0000 - val_fn: 2053.0000 - val_accuracy: 0.9904 - val_precision: 0.7661 - val_recall: 0.2769 - val_auc: 0.9498
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 123s - loss: 0.0252 - tp: 1543.0000 - fp: 437.0000 - tn: 253302.0000 - fn: 1603.0000 - accuracy: 0.9921 - precision: 0.7793 - recall: 0.4905 - auc: 0.9665 - val_loss: 0.0206 - val_tp: 1759.0000 - val_fp: 513.0000 - val_tn: 234506.0000 - val_fn: 1080.0000 - val_accuracy: 0.9933 - val_precision: 0.7742 - val_recall: 0.6196 - val_auc: 0.9757
256885/256885 - 123s - loss: 0.0252 - tp: 1543.0000 - fp: 437.0000 - tn: 253302.0000 - fn: 1603.0000 - accuracy: 0.9921 - precision: 0.7793 - recall: 0.4905 - auc: 0.9665 - val_loss: 0.0206 - val_tp: 1759.0000 - val_fp: 513.0000 - val_tn: 234506.0000 - val_fn: 1080.0000 - val_accuracy: 0.9933 - val_precision: 0.7742 - val_recall: 0.6196 - val_auc: 0.9757
Epoch 00002: early stopping
28543/28543 - 4s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519252b70>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5193120b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5192d2320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c77278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c87908>, <tensorflow.python.keras.metrics.Precision object at 0x7fd51a04a7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519fb5dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52eb7f160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5192245c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519268588>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519268390>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5192688d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5192407b8>]
          

Model: "sequential_55"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_15 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_105 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_105 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_106 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_106 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_35 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_107 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_107 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 127s - loss: 0.0417 - tp: 619.0000 - fp: 332.0000 - tn: 253446.0000 - fn: 2488.0000 - accuracy: 0.9890 - precision: 0.6509 - recall: 0.1992 - auc: 0.9067 - val_loss: 0.0277 - val_tp: 1009.0000 - val_fp: 332.0000 - val_tn: 234687.0000 - val_fn: 1830.0000 - val_accuracy: 0.9909 - val_precision: 0.7524 - val_recall: 0.3554 - val_auc: 0.9713
256885/256885 - 127s - loss: 0.0417 - tp: 619.0000 - fp: 332.0000 - tn: 253446.0000 - fn: 2488.0000 - accuracy: 0.9890 - precision: 0.6509 - recall: 0.1992 - auc: 0.9067 - val_loss: 0.0277 - val_tp: 1009.0000 - val_fp: 332.0000 - val_tn: 234687.0000 - val_fn: 1830.0000 - val_accuracy: 0.9909 - val_precision: 0.7524 - val_recall: 0.3554 - val_auc: 0.9713
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 124s - loss: 0.0247 - tp: 1557.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1550.0000 - accuracy: 0.9923 - precision: 0.7828 - recall: 0.5011 - auc: 0.9678 - val_loss: 0.0197 - val_tp: 1686.0000 - val_fp: 340.0000 - val_tn: 234679.0000 - val_fn: 1153.0000 - val_accuracy: 0.9937 - val_precision: 0.8322 - val_recall: 0.5939 - val_auc: 0.9827
256885/256885 - 124s - loss: 0.0247 - tp: 1557.0000 - fp: 432.0000 - tn: 253346.0000 - fn: 1550.0000 - accuracy: 0.9923 - precision: 0.7828 - recall: 0.5011 - auc: 0.9678 - val_loss: 0.0197 - val_tp: 1686.0000 - val_fp: 340.0000 - val_tn: 234679.0000 - val_fn: 1153.0000 - val_accuracy: 0.9937 - val_precision: 0.8322 - val_recall: 0.5939 - val_auc: 0.9827
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d2e6cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5192bb1d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c0b0470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c0b0c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c0b0a58>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c0b00f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c0b0710>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5192521d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5192688d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5192407b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5192406a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519ff8da0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52c0b8ac8>]
          

Model: "sequential_56"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_16 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_108 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_108 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_109 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_109 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_36 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_110 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_110 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 126s - loss: 0.0430 - tp: 554.0000 - fp: 332.0000 - tn: 253462.0000 - fn: 2537.0000 - accuracy: 0.9888 - precision: 0.6253 - recall: 0.1792 - auc: 0.9009 - val_loss: 0.0293 - val_tp: 777.0000 - val_fp: 220.0000 - val_tn: 234799.0000 - val_fn: 2062.0000 - val_accuracy: 0.9904 - val_precision: 0.7793 - val_recall: 0.2737 - val_auc: 0.9626
256885/256885 - 126s - loss: 0.0430 - tp: 554.0000 - fp: 332.0000 - tn: 253462.0000 - fn: 2537.0000 - accuracy: 0.9888 - precision: 0.6253 - recall: 0.1792 - auc: 0.9009 - val_loss: 0.0293 - val_tp: 777.0000 - val_fp: 220.0000 - val_tn: 234799.0000 - val_fn: 2062.0000 - val_accuracy: 0.9904 - val_precision: 0.7793 - val_recall: 0.2737 - val_auc: 0.9626
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 125s - loss: 0.0245 - tp: 1574.0000 - fp: 417.0000 - tn: 253377.0000 - fn: 1517.0000 - accuracy: 0.9925 - precision: 0.7906 - recall: 0.5092 - auc: 0.9671 - val_loss: 0.0195 - val_tp: 1805.0000 - val_fp: 433.0000 - val_tn: 234586.0000 - val_fn: 1034.0000 - val_accuracy: 0.9938 - val_precision: 0.8065 - val_recall: 0.6358 - val_auc: 0.9800
256885/256885 - 125s - loss: 0.0245 - tp: 1574.0000 - fp: 417.0000 - tn: 253377.0000 - fn: 1517.0000 - accuracy: 0.9925 - precision: 0.7906 - recall: 0.5092 - auc: 0.9671 - val_loss: 0.0195 - val_tp: 1805.0000 - val_fp: 433.0000 - val_tn: 234586.0000 - val_fn: 1034.0000 - val_accuracy: 0.9938 - val_precision: 0.8065 - val_recall: 0.6358 - val_auc: 0.9800
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd51927d470>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b93f240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b93f048>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c97b128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50bea3dd8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd525cebc50>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c91d710>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c91d2b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519ff8da0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd51a00bcc0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b920f60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52d82cfd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50b9295f8>]
          

Model: "sequential_57"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_17 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_111 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_111 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_112 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_112 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_37 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_113 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_113 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 127s - loss: 0.0460 - tp: 484.0000 - fp: 469.0000 - tn: 253305.0000 - fn: 2627.0000 - accuracy: 0.9879 - precision: 0.5079 - recall: 0.1556 - auc: 0.8814 - val_loss: 0.0294 - val_tp: 842.0000 - val_fp: 269.0000 - val_tn: 234750.0000 - val_fn: 1997.0000 - val_accuracy: 0.9905 - val_precision: 0.7579 - val_recall: 0.2966 - val_auc: 0.9580
256885/256885 - 127s - loss: 0.0460 - tp: 484.0000 - fp: 469.0000 - tn: 253305.0000 - fn: 2627.0000 - accuracy: 0.9879 - precision: 0.5079 - recall: 0.1556 - auc: 0.8814 - val_loss: 0.0294 - val_tp: 842.0000 - val_fp: 269.0000 - val_tn: 234750.0000 - val_fn: 1997.0000 - val_accuracy: 0.9905 - val_precision: 0.7579 - val_recall: 0.2966 - val_auc: 0.9580
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 126s - loss: 0.0250 - tp: 1521.0000 - fp: 419.0000 - tn: 253355.0000 - fn: 1590.0000 - accuracy: 0.9922 - precision: 0.7840 - recall: 0.4889 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1864.0000 - val_fp: 496.0000 - val_tn: 234523.0000 - val_fn: 975.0000 - val_accuracy: 0.9938 - val_precision: 0.7898 - val_recall: 0.6566 - val_auc: 0.9875
256885/256885 - 126s - loss: 0.0250 - tp: 1521.0000 - fp: 419.0000 - tn: 253355.0000 - fn: 1590.0000 - accuracy: 0.9922 - precision: 0.7840 - recall: 0.4889 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1864.0000 - val_fp: 496.0000 - val_tn: 234523.0000 - val_fn: 975.0000 - val_accuracy: 0.9938 - val_precision: 0.7898 - val_recall: 0.6566 - val_auc: 0.9875
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b069400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b00bc88>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b015a58>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50b015ba8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50b015e48>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50b02a240>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b02a4e0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b02a7f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d82cfd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52d8358d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50be61198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50be61940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5192406a0>]
          

Model: "sequential_58"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_18 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_114 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_114 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_115 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_115 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_38 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_116 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_116 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256886/256886 - 127s - loss: 0.0410 - tp: 637.0000 - fp: 371.0000 - tn: 253407.0000 - fn: 2471.0000 - accuracy: 0.9889 - precision: 0.6319 - recall: 0.2050 - auc: 0.9109 - val_loss: 0.0273 - val_tp: 1080.0000 - val_fp: 368.0000 - val_tn: 234651.0000 - val_fn: 1759.0000 - val_accuracy: 0.9911 - val_precision: 0.7459 - val_recall: 0.3804 - val_auc: 0.9704
256886/256886 - 127s - loss: 0.0410 - tp: 637.0000 - fp: 371.0000 - tn: 253407.0000 - fn: 2471.0000 - accuracy: 0.9889 - precision: 0.6319 - recall: 0.2050 - auc: 0.9109 - val_loss: 0.0273 - val_tp: 1080.0000 - val_fp: 368.0000 - val_tn: 234651.0000 - val_fn: 1759.0000 - val_accuracy: 0.9911 - val_precision: 0.7459 - val_recall: 0.3804 - val_auc: 0.9704
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256886/256886 - 125s - loss: 0.0243 - tp: 1579.0000 - fp: 451.0000 - tn: 253327.0000 - fn: 1529.0000 - accuracy: 0.9923 - precision: 0.7778 - recall: 0.5080 - auc: 0.9695 - val_loss: 0.0220 - val_tp: 1466.0000 - val_fp: 248.0000 - val_tn: 234771.0000 - val_fn: 1373.0000 - val_accuracy: 0.9932 - val_precision: 0.8553 - val_recall: 0.5164 - val_auc: 0.9613
256886/256886 - 125s - loss: 0.0243 - tp: 1579.0000 - fp: 451.0000 - tn: 253327.0000 - fn: 1529.0000 - accuracy: 0.9923 - precision: 0.7778 - recall: 0.5080 - auc: 0.9695 - val_loss: 0.0220 - val_tp: 1466.0000 - val_fp: 248.0000 - val_tn: 234771.0000 - val_fn: 1373.0000 - val_accuracy: 0.9932 - val_precision: 0.8553 - val_recall: 0.5164 - val_auc: 0.9613
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c77e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52cb928d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c21668>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52f46a860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52f46ab00>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52f46a9e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c0d8160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c0d8710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50be61198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50b07c4e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b07c518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50b003908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52d8e94a8>]
          

Model: "sequential_59"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_19 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_117 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_117 (Activation)  (None, 100)               0         
_________________________________________________________________
dense_118 (Dense)            (None, 100)               10100     
_________________________________________________________________
activation_118 (Activation)  (None, 100)               0         
_________________________________________________________________
dropout_39 (Dropout)         (None, 100)               0         
_________________________________________________________________
dense_119 (Dense)            (None, 1)                 101       
_________________________________________________________________
activation_119 (Activation)  (None, 1)                 0         
=================================================================
Total params: 54,501
Trainable params: 54,501
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256886/256886 - 127s - loss: 0.0453 - tp: 531.0000 - fp: 405.0000 - tn: 253357.0000 - fn: 2593.0000 - accuracy: 0.9883 - precision: 0.5673 - recall: 0.1700 - auc: 0.8845 - val_loss: 0.0315 - val_tp: 616.0000 - val_fp: 171.0000 - val_tn: 234848.0000 - val_fn: 2223.0000 - val_accuracy: 0.9899 - val_precision: 0.7827 - val_recall: 0.2170 - val_auc: 0.9559
256886/256886 - 127s - loss: 0.0453 - tp: 531.0000 - fp: 405.0000 - tn: 253357.0000 - fn: 2593.0000 - accuracy: 0.9883 - precision: 0.5673 - recall: 0.1700 - auc: 0.8845 - val_loss: 0.0315 - val_tp: 616.0000 - val_fp: 171.0000 - val_tn: 234848.0000 - val_fn: 2223.0000 - val_accuracy: 0.9899 - val_precision: 0.7827 - val_recall: 0.2170 - val_auc: 0.9559
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256886/256886 - 124s - loss: 0.0269 - tp: 1392.0000 - fp: 429.0000 - tn: 253333.0000 - fn: 1732.0000 - accuracy: 0.9916 - precision: 0.7644 - recall: 0.4456 - auc: 0.9662 - val_loss: 0.0224 - val_tp: 1781.0000 - val_fp: 597.0000 - val_tn: 234422.0000 - val_fn: 1058.0000 - val_accuracy: 0.9930 - val_precision: 0.7489 - val_recall: 0.6273 - val_auc: 0.9844
256886/256886 - 124s - loss: 0.0269 - tp: 1392.0000 - fp: 429.0000 - tn: 253333.0000 - fn: 1732.0000 - accuracy: 0.9916 - precision: 0.7644 - recall: 0.4456 - auc: 0.9662 - val_loss: 0.0224 - val_tp: 1781.0000 - val_fp: 597.0000 - val_tn: 234422.0000 - val_fn: 1058.0000 - val_accuracy: 0.9930 - val_precision: 0.7489 - val_recall: 0.6273 - val_auc: 0.9844
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.3min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d8095c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52bfa3470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c8477f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c8472e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c847cf8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c8475f8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c847978>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52ce717f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50b07c4e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52cb85438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b07c400>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52bfccfd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52bfb24e0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd51948d2b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd51948d550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd51948d7f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd51948da90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd51948dd30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd51948dfd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b86c3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b86c6d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52bfedf60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519463f98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c856cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c856e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52c856e10>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b874630>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b874908>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b874ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50b874e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519968128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5199684e0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519968780>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519968a90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd51948d240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c847320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c8475f8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50b8743c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50b874550>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c2e12b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52c2e1550>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c2e17f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c2e1a90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c2e1d30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c2e1fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c2c63c8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c2c66d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50b874588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c2bd048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd51995e550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd51995e780>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd51995e6a0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c27160>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c27400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c276a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c27940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27be0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c27f98>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c18278>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c18588>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52c2e1240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519c34eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519c34e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519c34f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519c34ef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c185c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c18470>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c18eb8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c180f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27da0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c276d8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c274e0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c27a58>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c270f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c2f23c8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519c34eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519c34f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519c188d0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c27828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c275c0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c27710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c27f60>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27320>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c18748>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c184a8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c18278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c18908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519c56128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519c562b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519c56160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519c56080>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c18668>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c18748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c187f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c18160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c272b0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c27160>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c27208>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c27240>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c274e0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50ba9c240>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50ba9c3c8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50ba9c320>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50ba9c2e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c279b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c273c8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c27780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c27c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27828>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c18710>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c18400>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c18438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c18780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50b86f828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b86fa90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50b86f748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50b86f7f0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519998908>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c18710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c18ef0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c185f8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27198>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c27cc0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c27630>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c27940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c27898>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519efaac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519ef5240>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd5199989e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd5199985f8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519efa978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c27438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c27470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c273c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c27e48>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c27f28>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c189e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c187f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519998b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519f1cac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519998d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519c0db00>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519c0d710>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519c18208>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519c18128>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519c18160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519c27e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519c276a0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c27c88>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519c279b0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519c27940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519efa908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519a555c0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519f0c160>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519f0c208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519f0c048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519e77860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519e77b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519e77dd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519e8a0b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519e8a358>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519e8a710>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519e8a9b0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519e8acc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519c187f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519eac8d0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519eac9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519e777b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519e77780>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519e48cc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519e48ef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519e551d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519e55470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519e55710>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519e55ac8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519e55d68>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519e55fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519e77748>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519c27320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519c27048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519e48ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519e48b70>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519daf860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519dafb38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519dafdd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519db40b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519db4358>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519db4710>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519db49b0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519db4cc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519e48c18>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519de1b38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519de1c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519daf748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519daf550>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519d1d6d8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d1d9e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d1dc88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d1df28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d2d208>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d2d5c0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d2d860>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519d2db70>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519daf7b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519dcd828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519dcd9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519dcd8d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519d1d668>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519d1d9e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d1d940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d1db00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d397b8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d05320>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d057b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d05a58>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519d05d68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519d1d630>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519daf7b8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519dcd9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519dcd8d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519d1df60>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519d059b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d05358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d054a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d05438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d39860>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d1d668>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d1dbe0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519d150f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519d1dd68>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519d05d68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519d05da0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519d05d30>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519d05e10>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519d15710>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d1dc50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d1db38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d1db00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d39518>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d052e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d059e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519d05940>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519d05b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519d15908>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519d15828>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519d158d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519d159b0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     100
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519cd1cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d059e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d056d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d05518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d05320>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d39748>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d1db70>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519d1d7f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519d15940>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519d157f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519b1e978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519b1e908>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519b1e588>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=100, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd519d1d860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519d1de10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519d1dd30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd519d39860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd519d05630>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519d059e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd519d05c18>, <tensorflow.python.keras.metrics.AUC object at 0x7fd519cd1e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519cd1d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd519b23390>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519ae8cc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519ae8c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519b590b8>]
          

Model: "sequential_80"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_60 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_120 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_120 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_121 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_121 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_40 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_122 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_122 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 107s - loss: 0.0420 - tp: 620.0000 - fp: 386.0000 - tn: 253373.0000 - fn: 2506.0000 - accuracy: 0.9887 - precision: 0.6163 - recall: 0.1983 - auc: 0.9009 - val_loss: 0.0288 - val_tp: 1024.0000 - val_fp: 439.0000 - val_tn: 234580.0000 - val_fn: 1815.0000 - val_accuracy: 0.9905 - val_precision: 0.6999 - val_recall: 0.3607 - val_auc: 0.9705
256885/256885 - 107s - loss: 0.0420 - tp: 620.0000 - fp: 386.0000 - tn: 253373.0000 - fn: 2506.0000 - accuracy: 0.9887 - precision: 0.6163 - recall: 0.1983 - auc: 0.9009 - val_loss: 0.0288 - val_tp: 1024.0000 - val_fp: 439.0000 - val_tn: 234580.0000 - val_fn: 1815.0000 - val_accuracy: 0.9905 - val_precision: 0.6999 - val_recall: 0.3607 - val_auc: 0.9705
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 103s - loss: 0.0258 - tp: 1520.0000 - fp: 424.0000 - tn: 253335.0000 - fn: 1606.0000 - accuracy: 0.9921 - precision: 0.7819 - recall: 0.4862 - auc: 0.9647 - val_loss: 0.0203 - val_tp: 1608.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1231.0000 - val_accuracy: 0.9935 - val_precision: 0.8336 - val_recall: 0.5664 - val_auc: 0.9836
256885/256885 - 103s - loss: 0.0258 - tp: 1520.0000 - fp: 424.0000 - tn: 253335.0000 - fn: 1606.0000 - accuracy: 0.9921 - precision: 0.7819 - recall: 0.4862 - auc: 0.9647 - val_loss: 0.0203 - val_tp: 1608.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1231.0000 - val_accuracy: 0.9935 - val_precision: 0.8336 - val_recall: 0.5664 - val_auc: 0.9836
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52dca5be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd519245e10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519245978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52e159358>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c1cc8d0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c1cc940>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c1ccac8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52c1ccba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519ae8c88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52f8f4860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50be4e358>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52fa180b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52d27be10>]
          

Model: "sequential_81"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_61 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_123 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_123 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_124 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_124 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_41 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_125 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_125 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0430 - tp: 600.0000 - fp: 425.0000 - tn: 253333.0000 - fn: 2527.0000 - accuracy: 0.9885 - precision: 0.5854 - recall: 0.1919 - auc: 0.8964 - val_loss: 0.0298 - val_tp: 1216.0000 - val_fp: 701.0000 - val_tn: 234318.0000 - val_fn: 1623.0000 - val_accuracy: 0.9902 - val_precision: 0.6343 - val_recall: 0.4283 - val_auc: 0.9748
256885/256885 - 106s - loss: 0.0430 - tp: 600.0000 - fp: 425.0000 - tn: 253333.0000 - fn: 2527.0000 - accuracy: 0.9885 - precision: 0.5854 - recall: 0.1919 - auc: 0.8964 - val_loss: 0.0298 - val_tp: 1216.0000 - val_fp: 701.0000 - val_tn: 234318.0000 - val_fn: 1623.0000 - val_accuracy: 0.9902 - val_precision: 0.6343 - val_recall: 0.4283 - val_auc: 0.9748
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 103s - loss: 0.0263 - tp: 1464.0000 - fp: 456.0000 - tn: 253302.0000 - fn: 1663.0000 - accuracy: 0.9918 - precision: 0.7625 - recall: 0.4682 - auc: 0.9678 - val_loss: 0.0225 - val_tp: 1802.0000 - val_fp: 522.0000 - val_tn: 234497.0000 - val_fn: 1037.0000 - val_accuracy: 0.9934 - val_precision: 0.7754 - val_recall: 0.6347 - val_auc: 0.9872
256885/256885 - 103s - loss: 0.0263 - tp: 1464.0000 - fp: 456.0000 - tn: 253302.0000 - fn: 1663.0000 - accuracy: 0.9918 - precision: 0.7625 - recall: 0.4682 - auc: 0.9678 - val_loss: 0.0225 - val_tp: 1802.0000 - val_fp: 522.0000 - val_tn: 234497.0000 - val_fn: 1037.0000 - val_accuracy: 0.9934 - val_precision: 0.7754 - val_recall: 0.6347 - val_auc: 0.9872
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d620048>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5198b97f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5198abba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c9b9ba8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c9b9550>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c9b9358>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c9b91d0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50bbf8a20>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d27bcf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c5efcc0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52cc960b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52dca5400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd519ae8c88>]
          

Model: "sequential_82"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_62 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_126 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_126 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_127 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_127 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_42 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_128 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_128 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0419 - tp: 636.0000 - fp: 381.0000 - tn: 253388.0000 - fn: 2480.0000 - accuracy: 0.9889 - precision: 0.6254 - recall: 0.2041 - auc: 0.9004 - val_loss: 0.0297 - val_tp: 1226.0000 - val_fp: 678.0000 - val_tn: 234341.0000 - val_fn: 1613.0000 - val_accuracy: 0.9904 - val_precision: 0.6439 - val_recall: 0.4318 - val_auc: 0.9741
256885/256885 - 106s - loss: 0.0419 - tp: 636.0000 - fp: 381.0000 - tn: 253388.0000 - fn: 2480.0000 - accuracy: 0.9889 - precision: 0.6254 - recall: 0.2041 - auc: 0.9004 - val_loss: 0.0297 - val_tp: 1226.0000 - val_fp: 678.0000 - val_tn: 234341.0000 - val_fn: 1613.0000 - val_accuracy: 0.9904 - val_precision: 0.6439 - val_recall: 0.4318 - val_auc: 0.9741
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 102s - loss: 0.0259 - tp: 1473.0000 - fp: 433.0000 - tn: 253336.0000 - fn: 1643.0000 - accuracy: 0.9919 - precision: 0.7728 - recall: 0.4727 - auc: 0.9650 - val_loss: 0.0207 - val_tp: 1716.0000 - val_fp: 505.0000 - val_tn: 234514.0000 - val_fn: 1123.0000 - val_accuracy: 0.9932 - val_precision: 0.7726 - val_recall: 0.6044 - val_auc: 0.9778
256885/256885 - 102s - loss: 0.0259 - tp: 1473.0000 - fp: 433.0000 - tn: 253336.0000 - fn: 1643.0000 - accuracy: 0.9919 - precision: 0.7728 - recall: 0.4727 - auc: 0.9650 - val_loss: 0.0207 - val_tp: 1716.0000 - val_fp: 505.0000 - val_tn: 234514.0000 - val_fn: 1123.0000 - val_accuracy: 0.9932 - val_precision: 0.7726 - val_recall: 0.6044 - val_auc: 0.9778
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd507506a58>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50752aa58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50752ae10>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd507533630>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5075338d0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd507533c88>, <tensorflow.python.keras.metrics.Recall object at 0x7fd507533f28>, <tensorflow.python.keras.metrics.AUC object at 0x7fd5074ca278>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52dca53c8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52d706b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd519ae8cc0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52e880128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50a04f940>]
          

Model: "sequential_83"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_63 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_129 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_129 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_130 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_130 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_43 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_131 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_131 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0435 - tp: 575.0000 - fp: 462.0000 - tn: 253330.0000 - fn: 2518.0000 - accuracy: 0.9884 - precision: 0.5545 - recall: 0.1859 - auc: 0.8921 - val_loss: 0.0292 - val_tp: 1160.0000 - val_fp: 558.0000 - val_tn: 234461.0000 - val_fn: 1679.0000 - val_accuracy: 0.9906 - val_precision: 0.6752 - val_recall: 0.4086 - val_auc: 0.9741
256885/256885 - 106s - loss: 0.0435 - tp: 575.0000 - fp: 462.0000 - tn: 253330.0000 - fn: 2518.0000 - accuracy: 0.9884 - precision: 0.5545 - recall: 0.1859 - auc: 0.8921 - val_loss: 0.0292 - val_tp: 1160.0000 - val_fp: 558.0000 - val_tn: 234461.0000 - val_fn: 1679.0000 - val_accuracy: 0.9906 - val_precision: 0.6752 - val_recall: 0.4086 - val_auc: 0.9741
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 103s - loss: 0.0256 - tp: 1494.0000 - fp: 452.0000 - tn: 253340.0000 - fn: 1599.0000 - accuracy: 0.9920 - precision: 0.7677 - recall: 0.4830 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1794.0000 - val_fp: 549.0000 - val_tn: 234470.0000 - val_fn: 1045.0000 - val_accuracy: 0.9933 - val_precision: 0.7657 - val_recall: 0.6319 - val_auc: 0.9875
256885/256885 - 103s - loss: 0.0256 - tp: 1494.0000 - fp: 452.0000 - tn: 253340.0000 - fn: 1599.0000 - accuracy: 0.9920 - precision: 0.7677 - recall: 0.4830 - auc: 0.9678 - val_loss: 0.0217 - val_tp: 1794.0000 - val_fp: 549.0000 - val_tn: 234470.0000 - val_fn: 1045.0000 - val_accuracy: 0.9933 - val_precision: 0.7657 - val_recall: 0.6319 - val_auc: 0.9875
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b6f6b438>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b6f72fd0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b6f7c2e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b6f7cac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b6f7cd68>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b6f7cf98>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b6f11400>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6f11710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd519ae8cc0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5198c0d68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50750fe80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50750feb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52cc960b8>]
          

Model: "sequential_84"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_64 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_132 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_132 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_133 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_133 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_44 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_134 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_134 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0440 - tp: 549.0000 - fp: 467.0000 - tn: 253272.0000 - fn: 2597.0000 - accuracy: 0.9881 - precision: 0.5404 - recall: 0.1745 - auc: 0.8968 - val_loss: 0.0354 - val_tp: 1310.0000 - val_fp: 837.0000 - val_tn: 234182.0000 - val_fn: 1529.0000 - val_accuracy: 0.9901 - val_precision: 0.6102 - val_recall: 0.4614 - val_auc: 0.9761
256885/256885 - 106s - loss: 0.0440 - tp: 549.0000 - fp: 467.0000 - tn: 253272.0000 - fn: 2597.0000 - accuracy: 0.9881 - precision: 0.5404 - recall: 0.1745 - auc: 0.8968 - val_loss: 0.0354 - val_tp: 1310.0000 - val_fp: 837.0000 - val_tn: 234182.0000 - val_fn: 1529.0000 - val_accuracy: 0.9901 - val_precision: 0.6102 - val_recall: 0.4614 - val_auc: 0.9761
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 103s - loss: 0.0263 - tp: 1491.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 1655.0000 - accuracy: 0.9918 - precision: 0.7717 - recall: 0.4739 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1587.0000 - val_fp: 351.0000 - val_tn: 234668.0000 - val_fn: 1252.0000 - val_accuracy: 0.9933 - val_precision: 0.8189 - val_recall: 0.5590 - val_auc: 0.9796
256885/256885 - 103s - loss: 0.0263 - tp: 1491.0000 - fp: 441.0000 - tn: 253298.0000 - fn: 1655.0000 - accuracy: 0.9918 - precision: 0.7717 - recall: 0.4739 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1587.0000 - val_fp: 351.0000 - val_tn: 234668.0000 - val_fn: 1252.0000 - val_accuracy: 0.9933 - val_precision: 0.8189 - val_recall: 0.5590 - val_auc: 0.9796
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d33b2b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52d33b978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52d33b908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5195f68d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5197c4d68>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5191f9eb8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52c1042e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52dd452e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50750fe80>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b6f45048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50a3d7588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50a3d7400>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50a3d7470>]
          

Model: "sequential_85"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_65 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_135 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_135 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_136 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_136 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_45 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_137 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_137 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0425 - tp: 606.0000 - fp: 414.0000 - tn: 253364.0000 - fn: 2501.0000 - accuracy: 0.9887 - precision: 0.5941 - recall: 0.1950 - auc: 0.8998 - val_loss: 0.0288 - val_tp: 1027.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1812.0000 - val_accuracy: 0.9905 - val_precision: 0.7020 - val_recall: 0.3617 - val_auc: 0.9650
256885/256885 - 106s - loss: 0.0425 - tp: 606.0000 - fp: 414.0000 - tn: 253364.0000 - fn: 2501.0000 - accuracy: 0.9887 - precision: 0.5941 - recall: 0.1950 - auc: 0.8998 - val_loss: 0.0288 - val_tp: 1027.0000 - val_fp: 436.0000 - val_tn: 234583.0000 - val_fn: 1812.0000 - val_accuracy: 0.9905 - val_precision: 0.7020 - val_recall: 0.3617 - val_auc: 0.9650
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 103s - loss: 0.0258 - tp: 1491.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1616.0000 - accuracy: 0.9919 - precision: 0.7670 - recall: 0.4799 - auc: 0.9664 - val_loss: 0.0207 - val_tp: 1667.0000 - val_fp: 454.0000 - val_tn: 234565.0000 - val_fn: 1172.0000 - val_accuracy: 0.9932 - val_precision: 0.7860 - val_recall: 0.5872 - val_auc: 0.9767
256885/256885 - 103s - loss: 0.0258 - tp: 1491.0000 - fp: 453.0000 - tn: 253325.0000 - fn: 1616.0000 - accuracy: 0.9919 - precision: 0.7670 - recall: 0.4799 - auc: 0.9664 - val_loss: 0.0207 - val_tp: 1667.0000 - val_fp: 454.0000 - val_tn: 234565.0000 - val_fn: 1172.0000 - val_accuracy: 0.9932 - val_precision: 0.7860 - val_recall: 0.5872 - val_auc: 0.9767
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b657278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52c3cc198>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b98a6d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50b2ed0f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50b2ed400>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50b2ed7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b2eda58>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b2edd68>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50a3d7588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50a3d70f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52d33ba90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd519fd00f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50750f9b0>]
          

Model: "sequential_86"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_66 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_138 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_138 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_139 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_139 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_46 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_140 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_140 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0425 - tp: 615.0000 - fp: 402.0000 - tn: 253392.0000 - fn: 2476.0000 - accuracy: 0.9888 - precision: 0.6047 - recall: 0.1990 - auc: 0.8983 - val_loss: 0.0287 - val_tp: 1012.0000 - val_fp: 405.0000 - val_tn: 234614.0000 - val_fn: 1827.0000 - val_accuracy: 0.9906 - val_precision: 0.7142 - val_recall: 0.3565 - val_auc: 0.9713
256885/256885 - 106s - loss: 0.0425 - tp: 615.0000 - fp: 402.0000 - tn: 253392.0000 - fn: 2476.0000 - accuracy: 0.9888 - precision: 0.6047 - recall: 0.1990 - auc: 0.8983 - val_loss: 0.0287 - val_tp: 1012.0000 - val_fp: 405.0000 - val_tn: 234614.0000 - val_fn: 1827.0000 - val_accuracy: 0.9906 - val_precision: 0.7142 - val_recall: 0.3565 - val_auc: 0.9713
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.73864
256885/256885 - 102s - loss: 0.0250 - tp: 1498.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 1593.0000 - accuracy: 0.9922 - precision: 0.7864 - recall: 0.4846 - auc: 0.9675 - val_loss: 0.0206 - val_tp: 1864.0000 - val_fp: 637.0000 - val_tn: 234382.0000 - val_fn: 975.0000 - val_accuracy: 0.9932 - val_precision: 0.7453 - val_recall: 0.6566 - val_auc: 0.9788
256885/256885 - 102s - loss: 0.0250 - tp: 1498.0000 - fp: 407.0000 - tn: 253387.0000 - fn: 1593.0000 - accuracy: 0.9922 - precision: 0.7864 - recall: 0.4846 - auc: 0.9675 - val_loss: 0.0206 - val_tp: 1864.0000 - val_fp: 637.0000 - val_tn: 234382.0000 - val_fn: 975.0000 - val_accuracy: 0.9932 - val_precision: 0.7453 - val_recall: 0.6566 - val_auc: 0.9788
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b6876400>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b6801f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b680a2b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b680aa90>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b680ad30>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b680afd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b681d3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b681d6d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d33b7f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50750f9b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c104860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50a3d7588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50a3d7470>]
          

Model: "sequential_87"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_67 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_141 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_141 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_142 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_142 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_47 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_143 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_143 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.73864
256885/256885 - 106s - loss: 0.0423 - tp: 572.0000 - fp: 403.0000 - tn: 253371.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5867 - recall: 0.1839 - auc: 0.9044 - val_loss: 0.0290 - val_tp: 1019.0000 - val_fp: 444.0000 - val_tn: 234575.0000 - val_fn: 1820.0000 - val_accuracy: 0.9905 - val_precision: 0.6965 - val_recall: 0.3589 - val_auc: 0.9731
256885/256885 - 106s - loss: 0.0423 - tp: 572.0000 - fp: 403.0000 - tn: 253371.0000 - fn: 2539.0000 - accuracy: 0.9885 - precision: 0.5867 - recall: 0.1839 - auc: 0.9044 - val_loss: 0.0290 - val_tp: 1019.0000 - val_fp: 444.0000 - val_tn: 234575.0000 - val_fn: 1820.0000 - val_accuracy: 0.9905 - val_precision: 0.6965 - val_recall: 0.3589 - val_auc: 0.9731
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall improved from 0.73864 to 0.79465, saving model to customer_batches_rnn_best_model.h5
256885/256885 - 102s - loss: 0.0257 - tp: 1473.0000 - fp: 437.0000 - tn: 253337.0000 - fn: 1638.0000 - accuracy: 0.9919 - precision: 0.7712 - recall: 0.4735 - auc: 0.9674 - val_loss: 0.0381 - val_tp: 2256.0000 - val_fp: 1975.0000 - val_tn: 233044.0000 - val_fn: 583.0000 - val_accuracy: 0.9892 - val_precision: 0.5332 - val_recall: 0.7946 - val_auc: 0.9895
256885/256885 - 102s - loss: 0.0257 - tp: 1473.0000 - fp: 437.0000 - tn: 253337.0000 - fn: 1638.0000 - accuracy: 0.9919 - precision: 0.7712 - recall: 0.4735 - auc: 0.9674 - val_loss: 0.0381 - val_tp: 2256.0000 - val_fp: 1975.0000 - val_tn: 233044.0000 - val_fn: 583.0000 - val_accuracy: 0.9892 - val_precision: 0.5332 - val_recall: 0.7946 - val_auc: 0.9895
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 2s
256885/256885 - 22s
256885/256885 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4af9f5940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4af85fb70>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b2234a20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b22344a8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b22346d8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b2234160>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b2234278>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b227f9b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50a3d7588>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c104d30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c104860>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4af841eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4af841e10>]
          

Model: "sequential_88"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_68 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_144 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_144 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_145 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_145 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_48 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_146 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_146 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 106s - loss: 0.0432 - tp: 578.0000 - fp: 379.0000 - tn: 253399.0000 - fn: 2530.0000 - accuracy: 0.9887 - precision: 0.6040 - recall: 0.1860 - auc: 0.8969 - val_loss: 0.0318 - val_tp: 892.0000 - val_fp: 340.0000 - val_tn: 234679.0000 - val_fn: 1947.0000 - val_accuracy: 0.9904 - val_precision: 0.7240 - val_recall: 0.3142 - val_auc: 0.9411
256886/256886 - 106s - loss: 0.0432 - tp: 578.0000 - fp: 379.0000 - tn: 253399.0000 - fn: 2530.0000 - accuracy: 0.9887 - precision: 0.6040 - recall: 0.1860 - auc: 0.8969 - val_loss: 0.0318 - val_tp: 892.0000 - val_fp: 340.0000 - val_tn: 234679.0000 - val_fn: 1947.0000 - val_accuracy: 0.9904 - val_precision: 0.7240 - val_recall: 0.3142 - val_auc: 0.9411
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 103s - loss: 0.0262 - tp: 1454.0000 - fp: 445.0000 - tn: 253333.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7657 - recall: 0.4678 - auc: 0.9665 - val_loss: 0.0214 - val_tp: 1450.0000 - val_fp: 230.0000 - val_tn: 234789.0000 - val_fn: 1389.0000 - val_accuracy: 0.9932 - val_precision: 0.8631 - val_recall: 0.5107 - val_auc: 0.9735
256886/256886 - 103s - loss: 0.0262 - tp: 1454.0000 - fp: 445.0000 - tn: 253333.0000 - fn: 1654.0000 - accuracy: 0.9918 - precision: 0.7657 - recall: 0.4678 - auc: 0.9665 - val_loss: 0.0214 - val_tp: 1450.0000 - val_fp: 230.0000 - val_tn: 234789.0000 - val_fn: 1389.0000 - val_accuracy: 0.9932 - val_precision: 0.8631 - val_recall: 0.5107 - val_auc: 0.9735
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4bc19f4e0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4bc481be0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5195ac240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5195ac9b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5195acac8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52e36ecf8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b2b2eb8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b2299c50>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4afa9cbe0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b22ad400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b6afbc50>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f4789e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4bc4910f0>]
          

Model: "sequential_89"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_69 (LSTM)               (None, 50)                12600     
_________________________________________________________________
dense_147 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_147 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_148 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_148 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_49 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_149 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_149 (Activation)  (None, 1)                 0         
=================================================================
Total params: 63,201
Trainable params: 63,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 106s - loss: 0.0429 - tp: 582.0000 - fp: 413.0000 - tn: 253349.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5849 - recall: 0.1863 - auc: 0.8979 - val_loss: 0.0310 - val_tp: 781.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 2058.0000 - val_accuracy: 0.9903 - val_precision: 0.7502 - val_recall: 0.2751 - val_auc: 0.9496
256886/256886 - 106s - loss: 0.0429 - tp: 582.0000 - fp: 413.0000 - tn: 253349.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5849 - recall: 0.1863 - auc: 0.8979 - val_loss: 0.0310 - val_tp: 781.0000 - val_fp: 260.0000 - val_tn: 234759.0000 - val_fn: 2058.0000 - val_accuracy: 0.9903 - val_precision: 0.7502 - val_recall: 0.2751 - val_auc: 0.9496
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 102s - loss: 0.0259 - tp: 1481.0000 - fp: 458.0000 - tn: 253304.0000 - fn: 1643.0000 - accuracy: 0.9918 - precision: 0.7638 - recall: 0.4741 - auc: 0.9676 - val_loss: 0.0209 - val_tp: 1725.0000 - val_fp: 408.0000 - val_tn: 234611.0000 - val_fn: 1114.0000 - val_accuracy: 0.9936 - val_precision: 0.8087 - val_recall: 0.6076 - val_auc: 0.9855
256886/256886 - 102s - loss: 0.0259 - tp: 1481.0000 - fp: 458.0000 - tn: 253304.0000 - fn: 1643.0000 - accuracy: 0.9918 - precision: 0.7638 - recall: 0.4741 - auc: 0.9676 - val_loss: 0.0209 - val_tp: 1725.0000 - val_fp: 408.0000 - val_tn: 234611.0000 - val_fn: 1114.0000 - val_accuracy: 0.9936 - val_precision: 0.8087 - val_recall: 0.6076 - val_auc: 0.9855
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 2s
256886/256886 - 22s
256886/256886 - 22s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b23ad30>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b574cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b54aac8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50b54ac18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50b54aeb8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50b2bf2b0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b2bf550>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b2bf860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52f4789e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4afa44e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4bc19ff98>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4bc19fbe0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52e0e1f60>]
          

Model: "sequential_90"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_70 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_150 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_150 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_151 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_151 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_50 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_152 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_152 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 132s - loss: 0.0433 - tp: 556.0000 - fp: 411.0000 - tn: 253348.0000 - fn: 2570.0000 - accuracy: 0.9884 - precision: 0.5750 - recall: 0.1779 - auc: 0.8942 - val_loss: 0.0291 - val_tp: 1164.0000 - val_fp: 679.0000 - val_tn: 234340.0000 - val_fn: 1675.0000 - val_accuracy: 0.9901 - val_precision: 0.6316 - val_recall: 0.4100 - val_auc: 0.9700
256885/256885 - 132s - loss: 0.0433 - tp: 556.0000 - fp: 411.0000 - tn: 253348.0000 - fn: 2570.0000 - accuracy: 0.9884 - precision: 0.5750 - recall: 0.1779 - auc: 0.8942 - val_loss: 0.0291 - val_tp: 1164.0000 - val_fp: 679.0000 - val_tn: 234340.0000 - val_fn: 1675.0000 - val_accuracy: 0.9901 - val_precision: 0.6316 - val_recall: 0.4100 - val_auc: 0.9700
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0267 - tp: 1486.0000 - fp: 489.0000 - tn: 253270.0000 - fn: 1640.0000 - accuracy: 0.9917 - precision: 0.7524 - recall: 0.4754 - auc: 0.9631 - val_loss: 0.0219 - val_tp: 1856.0000 - val_fp: 658.0000 - val_tn: 234361.0000 - val_fn: 983.0000 - val_accuracy: 0.9931 - val_precision: 0.7383 - val_recall: 0.6538 - val_auc: 0.9851
256885/256885 - 128s - loss: 0.0267 - tp: 1486.0000 - fp: 489.0000 - tn: 253270.0000 - fn: 1640.0000 - accuracy: 0.9917 - precision: 0.7524 - recall: 0.4754 - auc: 0.9631 - val_loss: 0.0219 - val_tp: 1856.0000 - val_fp: 658.0000 - val_tn: 234361.0000 - val_fn: 983.0000 - val_accuracy: 0.9931 - val_precision: 0.7383 - val_recall: 0.6538 - val_auc: 0.9851
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b6d44f28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4bc018518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b6d4f8d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b6d5e0f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b6d5e390>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b6d5e748>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b6d5e9e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6d5ecf8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4bc19ff98>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4bc4910f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b57c588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50b57c278>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b6afbc50>]
          

Model: "sequential_91"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_71 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_153 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_153 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_154 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_154 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_51 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_155 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_155 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 131s - loss: 0.0429 - tp: 548.0000 - fp: 406.0000 - tn: 253352.0000 - fn: 2579.0000 - accuracy: 0.9884 - precision: 0.5744 - recall: 0.1752 - auc: 0.8990 - val_loss: 0.0302 - val_tp: 1128.0000 - val_fp: 733.0000 - val_tn: 234286.0000 - val_fn: 1711.0000 - val_accuracy: 0.9897 - val_precision: 0.6061 - val_recall: 0.3973 - val_auc: 0.9696
256885/256885 - 131s - loss: 0.0429 - tp: 548.0000 - fp: 406.0000 - tn: 253352.0000 - fn: 2579.0000 - accuracy: 0.9884 - precision: 0.5744 - recall: 0.1752 - auc: 0.8990 - val_loss: 0.0302 - val_tp: 1128.0000 - val_fp: 733.0000 - val_tn: 234286.0000 - val_fn: 1711.0000 - val_accuracy: 0.9897 - val_precision: 0.6061 - val_recall: 0.3973 - val_auc: 0.9696
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0276 - tp: 1379.0000 - fp: 502.0000 - tn: 253256.0000 - fn: 1748.0000 - accuracy: 0.9912 - precision: 0.7331 - recall: 0.4410 - auc: 0.9632 - val_loss: 0.0268 - val_tp: 1137.0000 - val_fp: 170.0000 - val_tn: 234849.0000 - val_fn: 1702.0000 - val_accuracy: 0.9921 - val_precision: 0.8699 - val_recall: 0.4005 - val_auc: 0.9457
256885/256885 - 128s - loss: 0.0276 - tp: 1379.0000 - fp: 502.0000 - tn: 253256.0000 - fn: 1748.0000 - accuracy: 0.9912 - precision: 0.7331 - recall: 0.4410 - auc: 0.9632 - val_loss: 0.0268 - val_tp: 1137.0000 - val_fp: 170.0000 - val_tn: 234849.0000 - val_fn: 1702.0000 - val_accuracy: 0.9921 - val_precision: 0.8699 - val_recall: 0.4005 - val_auc: 0.9457
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b235e470>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b63d8c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b63d8cf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b6404080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4bc021940>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b6397dd8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b6397fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6397860>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b6afbc50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50b57c898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b57c278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b556bef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b55ab6a0>]
          

Model: "sequential_92"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_72 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_156 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_156 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_157 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_157 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_52 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_158 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_158 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 133s - loss: 0.0425 - tp: 599.0000 - fp: 437.0000 - tn: 253332.0000 - fn: 2517.0000 - accuracy: 0.9885 - precision: 0.5782 - recall: 0.1922 - auc: 0.9043 - val_loss: 0.0280 - val_tp: 1213.0000 - val_fp: 630.0000 - val_tn: 234389.0000 - val_fn: 1626.0000 - val_accuracy: 0.9905 - val_precision: 0.6582 - val_recall: 0.4273 - val_auc: 0.9734
256885/256885 - 133s - loss: 0.0425 - tp: 599.0000 - fp: 437.0000 - tn: 253332.0000 - fn: 2517.0000 - accuracy: 0.9885 - precision: 0.5782 - recall: 0.1922 - auc: 0.9043 - val_loss: 0.0280 - val_tp: 1213.0000 - val_fp: 630.0000 - val_tn: 234389.0000 - val_fn: 1626.0000 - val_accuracy: 0.9905 - val_precision: 0.6582 - val_recall: 0.4273 - val_auc: 0.9734
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0256 - tp: 1535.0000 - fp: 430.0000 - tn: 253339.0000 - fn: 1581.0000 - accuracy: 0.9922 - precision: 0.7812 - recall: 0.4926 - auc: 0.9672 - val_loss: 0.0257 - val_tp: 1363.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1476.0000 - val_accuracy: 0.9928 - val_precision: 0.8487 - val_recall: 0.4801 - val_auc: 0.9353
256885/256885 - 127s - loss: 0.0256 - tp: 1535.0000 - fp: 430.0000 - tn: 253339.0000 - fn: 1581.0000 - accuracy: 0.9922 - precision: 0.7812 - recall: 0.4926 - auc: 0.9672 - val_loss: 0.0257 - val_tp: 1363.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1476.0000 - val_accuracy: 0.9928 - val_precision: 0.8487 - val_recall: 0.4801 - val_auc: 0.9353
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b307eb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b6b73358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd519daf9b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50b085be0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50b085048>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50b085ac8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b085fd0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b085198>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b5541240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b55ab6a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50779bb00>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50b2b2ef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52d8c4400>]
          

Model: "sequential_93"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_73 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_159 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_159 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_160 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_160 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_53 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_161 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_161 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 132s - loss: 0.0417 - tp: 632.0000 - fp: 386.0000 - tn: 253406.0000 - fn: 2461.0000 - accuracy: 0.9889 - precision: 0.6208 - recall: 0.2043 - auc: 0.9039 - val_loss: 0.0285 - val_tp: 1216.0000 - val_fp: 672.0000 - val_tn: 234347.0000 - val_fn: 1623.0000 - val_accuracy: 0.9904 - val_precision: 0.6441 - val_recall: 0.4283 - val_auc: 0.9732
256885/256885 - 132s - loss: 0.0417 - tp: 632.0000 - fp: 386.0000 - tn: 253406.0000 - fn: 2461.0000 - accuracy: 0.9889 - precision: 0.6208 - recall: 0.2043 - auc: 0.9039 - val_loss: 0.0285 - val_tp: 1216.0000 - val_fp: 672.0000 - val_tn: 234347.0000 - val_fn: 1623.0000 - val_accuracy: 0.9904 - val_precision: 0.6441 - val_recall: 0.4283 - val_auc: 0.9732
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 130s - loss: 0.0259 - tp: 1482.0000 - fp: 446.0000 - tn: 253346.0000 - fn: 1611.0000 - accuracy: 0.9920 - precision: 0.7687 - recall: 0.4791 - auc: 0.9638 - val_loss: 0.0211 - val_tp: 1759.0000 - val_fp: 523.0000 - val_tn: 234496.0000 - val_fn: 1080.0000 - val_accuracy: 0.9933 - val_precision: 0.7708 - val_recall: 0.6196 - val_auc: 0.9758
256885/256885 - 130s - loss: 0.0259 - tp: 1482.0000 - fp: 446.0000 - tn: 253346.0000 - fn: 1611.0000 - accuracy: 0.9920 - precision: 0.7687 - recall: 0.4791 - auc: 0.9638 - val_loss: 0.0211 - val_tp: 1759.0000 - val_fp: 523.0000 - val_tn: 234496.0000 - val_fn: 1080.0000 - val_accuracy: 0.9933 - val_precision: 0.7708 - val_recall: 0.6196 - val_auc: 0.9758
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d496da0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5077b5898>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52d49eda0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52bfa2470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52bfa2710>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52bfa2ac8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52bfa2d68>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52bfa2fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52c11c9e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50b26a940>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52d8c4908>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd525e4fc50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b55ab0b8>]
          

Model: "sequential_94"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_74 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_162 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_162 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_163 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_163 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_54 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_164 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_164 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 131s - loss: 0.0424 - tp: 614.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 2532.0000 - accuracy: 0.9885 - precision: 0.5979 - recall: 0.1952 - auc: 0.9029 - val_loss: 0.0289 - val_tp: 921.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1918.0000 - val_accuracy: 0.9906 - val_precision: 0.7470 - val_recall: 0.3244 - val_auc: 0.9624
256885/256885 - 131s - loss: 0.0424 - tp: 614.0000 - fp: 413.0000 - tn: 253326.0000 - fn: 2532.0000 - accuracy: 0.9885 - precision: 0.5979 - recall: 0.1952 - auc: 0.9029 - val_loss: 0.0289 - val_tp: 921.0000 - val_fp: 312.0000 - val_tn: 234707.0000 - val_fn: 1918.0000 - val_accuracy: 0.9906 - val_precision: 0.7470 - val_recall: 0.3244 - val_auc: 0.9624
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0260 - tp: 1518.0000 - fp: 451.0000 - tn: 253288.0000 - fn: 1628.0000 - accuracy: 0.9919 - precision: 0.7709 - recall: 0.4825 - auc: 0.9642 - val_loss: 0.0204 - val_tp: 1599.0000 - val_fp: 311.0000 - val_tn: 234708.0000 - val_fn: 1240.0000 - val_accuracy: 0.9935 - val_precision: 0.8372 - val_recall: 0.5632 - val_auc: 0.9773
256885/256885 - 128s - loss: 0.0260 - tp: 1518.0000 - fp: 451.0000 - tn: 253288.0000 - fn: 1628.0000 - accuracy: 0.9919 - precision: 0.7709 - recall: 0.4825 - auc: 0.9642 - val_loss: 0.0204 - val_tp: 1599.0000 - val_fp: 311.0000 - val_tn: 234708.0000 - val_fn: 1240.0000 - val_accuracy: 0.9935 - val_precision: 0.8372 - val_recall: 0.5632 - val_auc: 0.9773
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b1566ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4bc1c8780>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4bc1fa0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b6abfd30>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b6abfc88>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b6abf7b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b6abfda0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6abf668>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b55ab0b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5075ad7f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52d8c4c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b58985c0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b6937390>]
          

Model: "sequential_95"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_75 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_165 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_165 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_166 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_166 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_55 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_167 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_167 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 131s - loss: 0.0415 - tp: 632.0000 - fp: 405.0000 - tn: 253373.0000 - fn: 2475.0000 - accuracy: 0.9888 - precision: 0.6095 - recall: 0.2034 - auc: 0.9056 - val_loss: 0.0346 - val_tp: 600.0000 - val_fp: 164.0000 - val_tn: 234855.0000 - val_fn: 2239.0000 - val_accuracy: 0.9899 - val_precision: 0.7853 - val_recall: 0.2113 - val_auc: 0.9270
256885/256885 - 131s - loss: 0.0415 - tp: 632.0000 - fp: 405.0000 - tn: 253373.0000 - fn: 2475.0000 - accuracy: 0.9888 - precision: 0.6095 - recall: 0.2034 - auc: 0.9056 - val_loss: 0.0346 - val_tp: 600.0000 - val_fp: 164.0000 - val_tn: 234855.0000 - val_fn: 2239.0000 - val_accuracy: 0.9899 - val_precision: 0.7853 - val_recall: 0.2113 - val_auc: 0.9270
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 129s - loss: 0.0259 - tp: 1496.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1611.0000 - accuracy: 0.9921 - precision: 0.7784 - recall: 0.4815 - auc: 0.9641 - val_loss: 0.0205 - val_tp: 1682.0000 - val_fp: 400.0000 - val_tn: 234619.0000 - val_fn: 1157.0000 - val_accuracy: 0.9935 - val_precision: 0.8079 - val_recall: 0.5925 - val_auc: 0.9843
256885/256885 - 129s - loss: 0.0259 - tp: 1496.0000 - fp: 426.0000 - tn: 253352.0000 - fn: 1611.0000 - accuracy: 0.9921 - precision: 0.7784 - recall: 0.4815 - auc: 0.9641 - val_loss: 0.0205 - val_tp: 1682.0000 - val_fp: 400.0000 - val_tn: 234619.0000 - val_fn: 1157.0000 - val_accuracy: 0.9935 - val_precision: 0.8079 - val_recall: 0.5925 - val_auc: 0.9843
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 30s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b5cd2fd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5cfd4a8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b5cda240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b5cdaf60>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5cdab38>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b5cda0b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b5cda198>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b5cda710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b58985c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50a1eda58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4bc1f24e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b5d69978>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b57eec50>]
          

Model: "sequential_96"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_76 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_168 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_168 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_169 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_169 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_56 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_170 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_170 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 133s - loss: 0.0429 - tp: 578.0000 - fp: 412.0000 - tn: 253382.0000 - fn: 2513.0000 - accuracy: 0.9886 - precision: 0.5838 - recall: 0.1870 - auc: 0.8971 - val_loss: 0.0290 - val_tp: 899.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1940.0000 - val_accuracy: 0.9905 - val_precision: 0.7375 - val_recall: 0.3167 - val_auc: 0.9712
256885/256885 - 133s - loss: 0.0429 - tp: 578.0000 - fp: 412.0000 - tn: 253382.0000 - fn: 2513.0000 - accuracy: 0.9886 - precision: 0.5838 - recall: 0.1870 - auc: 0.8971 - val_loss: 0.0290 - val_tp: 899.0000 - val_fp: 320.0000 - val_tn: 234699.0000 - val_fn: 1940.0000 - val_accuracy: 0.9905 - val_precision: 0.7375 - val_recall: 0.3167 - val_auc: 0.9712
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 130s - loss: 0.0260 - tp: 1467.0000 - fp: 450.0000 - tn: 253344.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7653 - recall: 0.4746 - auc: 0.9644 - val_loss: 0.0216 - val_tp: 1494.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1345.0000 - val_accuracy: 0.9930 - val_precision: 0.8231 - val_recall: 0.5262 - val_auc: 0.9696
256885/256885 - 130s - loss: 0.0260 - tp: 1467.0000 - fp: 450.0000 - tn: 253344.0000 - fn: 1624.0000 - accuracy: 0.9919 - precision: 0.7653 - recall: 0.4746 - auc: 0.9644 - val_loss: 0.0216 - val_tp: 1494.0000 - val_fp: 321.0000 - val_tn: 234698.0000 - val_fn: 1345.0000 - val_accuracy: 0.9930 - val_precision: 0.8231 - val_recall: 0.5262 - val_auc: 0.9696
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d56d5f8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b7585f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50b77fcf8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4bc0901d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50a071630>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50a0711d0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52d5f0d30>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52d5f0ba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50b97e5c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b5cd2860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b5cd2ef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52d8c4c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b6ff2dd8>]
          

Model: "sequential_97"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_77 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_171 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_171 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_172 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_172 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_57 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_173 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_173 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 132s - loss: 0.0428 - tp: 578.0000 - fp: 423.0000 - tn: 253351.0000 - fn: 2533.0000 - accuracy: 0.9885 - precision: 0.5774 - recall: 0.1858 - auc: 0.9011 - val_loss: 0.0312 - val_tp: 1326.0000 - val_fp: 839.0000 - val_tn: 234180.0000 - val_fn: 1513.0000 - val_accuracy: 0.9901 - val_precision: 0.6125 - val_recall: 0.4671 - val_auc: 0.9766
256885/256885 - 132s - loss: 0.0428 - tp: 578.0000 - fp: 423.0000 - tn: 253351.0000 - fn: 2533.0000 - accuracy: 0.9885 - precision: 0.5774 - recall: 0.1858 - auc: 0.9011 - val_loss: 0.0312 - val_tp: 1326.0000 - val_fp: 839.0000 - val_tn: 234180.0000 - val_fn: 1513.0000 - val_accuracy: 0.9901 - val_precision: 0.6125 - val_recall: 0.4671 - val_auc: 0.9766
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0260 - tp: 1481.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 1630.0000 - accuracy: 0.9919 - precision: 0.7710 - recall: 0.4761 - auc: 0.9653 - val_loss: 0.0210 - val_tp: 1873.0000 - val_fp: 661.0000 - val_tn: 234358.0000 - val_fn: 966.0000 - val_accuracy: 0.9932 - val_precision: 0.7391 - val_recall: 0.6597 - val_auc: 0.9822
256885/256885 - 128s - loss: 0.0260 - tp: 1481.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 1630.0000 - accuracy: 0.9919 - precision: 0.7710 - recall: 0.4761 - auc: 0.9653 - val_loss: 0.0210 - val_tp: 1873.0000 - val_fp: 661.0000 - val_tn: 234358.0000 - val_fn: 966.0000 - val_accuracy: 0.9932 - val_precision: 0.7391 - val_recall: 0.6597 - val_auc: 0.9822
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 29s
256885/256885 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b66348d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b2b27f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b2270b70>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b2277240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b22774e0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b2277898>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b2277b38>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b2277e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d8c4c88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4bc093668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c0dffd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52d56d160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b61ad978>]
          

Model: "sequential_98"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_78 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_174 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_174 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_175 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_175 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_58 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_176 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_176 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 131s - loss: 0.0432 - tp: 588.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 2520.0000 - accuracy: 0.9885 - precision: 0.5753 - recall: 0.1892 - auc: 0.8952 - val_loss: 0.0316 - val_tp: 661.0000 - val_fp: 199.0000 - val_tn: 234820.0000 - val_fn: 2178.0000 - val_accuracy: 0.9900 - val_precision: 0.7686 - val_recall: 0.2328 - val_auc: 0.9494
256886/256886 - 131s - loss: 0.0432 - tp: 588.0000 - fp: 434.0000 - tn: 253344.0000 - fn: 2520.0000 - accuracy: 0.9885 - precision: 0.5753 - recall: 0.1892 - auc: 0.8952 - val_loss: 0.0316 - val_tp: 661.0000 - val_fp: 199.0000 - val_tn: 234820.0000 - val_fn: 2178.0000 - val_accuracy: 0.9900 - val_precision: 0.7686 - val_recall: 0.2328 - val_auc: 0.9494
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 129s - loss: 0.0259 - tp: 1464.0000 - fp: 472.0000 - tn: 253306.0000 - fn: 1644.0000 - accuracy: 0.9918 - precision: 0.7562 - recall: 0.4710 - auc: 0.9651 - val_loss: 0.0204 - val_tp: 1597.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1242.0000 - val_accuracy: 0.9933 - val_precision: 0.8169 - val_recall: 0.5625 - val_auc: 0.9804
256886/256886 - 129s - loss: 0.0259 - tp: 1464.0000 - fp: 472.0000 - tn: 253306.0000 - fn: 1644.0000 - accuracy: 0.9918 - precision: 0.7562 - recall: 0.4710 - auc: 0.9651 - val_loss: 0.0204 - val_tp: 1597.0000 - val_fp: 358.0000 - val_tn: 234661.0000 - val_fn: 1242.0000 - val_accuracy: 0.9933 - val_precision: 0.8169 - val_recall: 0.5625 - val_auc: 0.9804
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 30s
256886/256886 - 29s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd5197aecf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5582080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b55823c8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52d448a58>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4af8f84e0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4af8f8278>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4af8f8cc0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4af8f80b8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d56dba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b69379e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b61ad978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50bb56e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50bb65748>]
          

Model: "sequential_99"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_79 (LSTM)               (None, 100)               45200     
_________________________________________________________________
dense_177 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_177 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_178 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_178 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_59 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_179 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_179 (Activation)  (None, 1)                 0         
=================================================================
Total params: 105,801
Trainable params: 105,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 132s - loss: 0.0431 - tp: 549.0000 - fp: 393.0000 - tn: 253369.0000 - fn: 2575.0000 - accuracy: 0.9884 - precision: 0.5828 - recall: 0.1757 - auc: 0.9012 - val_loss: 0.0299 - val_tp: 1239.0000 - val_fp: 853.0000 - val_tn: 234166.0000 - val_fn: 1600.0000 - val_accuracy: 0.9897 - val_precision: 0.5923 - val_recall: 0.4364 - val_auc: 0.9695
256886/256886 - 132s - loss: 0.0431 - tp: 549.0000 - fp: 393.0000 - tn: 253369.0000 - fn: 2575.0000 - accuracy: 0.9884 - precision: 0.5828 - recall: 0.1757 - auc: 0.9012 - val_loss: 0.0299 - val_tp: 1239.0000 - val_fp: 853.0000 - val_tn: 234166.0000 - val_fn: 1600.0000 - val_accuracy: 0.9897 - val_precision: 0.5923 - val_recall: 0.4364 - val_auc: 0.9695
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 128s - loss: 0.0265 - tp: 1440.0000 - fp: 475.0000 - tn: 253287.0000 - fn: 1684.0000 - accuracy: 0.9916 - precision: 0.7520 - recall: 0.4609 - auc: 0.9668 - val_loss: 0.0271 - val_tp: 1231.0000 - val_fp: 160.0000 - val_tn: 234859.0000 - val_fn: 1608.0000 - val_accuracy: 0.9926 - val_precision: 0.8850 - val_recall: 0.4336 - val_auc: 0.9330
256886/256886 - 128s - loss: 0.0265 - tp: 1440.0000 - fp: 475.0000 - tn: 253287.0000 - fn: 1684.0000 - accuracy: 0.9916 - precision: 0.7520 - recall: 0.4609 - auc: 0.9668 - val_loss: 0.0271 - val_tp: 1231.0000 - val_fp: 160.0000 - val_tn: 234859.0000 - val_fn: 1608.0000 - val_accuracy: 0.9926 - val_precision: 0.8850 - val_recall: 0.4336 - val_auc: 0.9330
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.79465
256886/256886 - 128s - loss: 0.0217 - tp: 1856.0000 - fp: 421.0000 - tn: 253341.0000 - fn: 1268.0000 - accuracy: 0.9934 - precision: 0.8151 - recall: 0.5941 - auc: 0.9706 - val_loss: 0.0214 - val_tp: 2076.0000 - val_fp: 788.0000 - val_tn: 234231.0000 - val_fn: 763.0000 - val_accuracy: 0.9935 - val_precision: 0.7249 - val_recall: 0.7312 - val_auc: 0.9858
256886/256886 - 128s - loss: 0.0217 - tp: 1856.0000 - fp: 421.0000 - tn: 253341.0000 - fn: 1268.0000 - accuracy: 0.9934 - precision: 0.8151 - recall: 0.5941 - auc: 0.9706 - val_loss: 0.0214 - val_tp: 2076.0000 - val_fp: 788.0000 - val_tn: 234231.0000 - val_fn: 763.0000 - val_accuracy: 0.9935 - val_precision: 0.7249 - val_recall: 0.7312 - val_auc: 0.9858
Epoch 00003: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 29s
256886/256886 - 30s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.6min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b5b5bef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5b5bd30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b5f46f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5197ae2b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5618f28>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b5618518>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b5618128>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b5618390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b61ad978>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b5c28390>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50bb65748>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50a2d4748>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b5b52fd0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c0dffd0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5618400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b56189e8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b56188d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5618ba8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b56186d8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b5ffcb70>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b5b5bf60>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b5b5bd68>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b55fccf8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b1803208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b17f7f60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b17f7f28>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b5ffce48>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5b5bbe0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b5b5b630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b5f462e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5618cf8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b56189e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b5618dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b5618a90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b5fe74a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4e45780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b55fcdd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b55fcc88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b55fc748>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4dd2a90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4dd2eb8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4de4198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4de4438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4de46d8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4de4a90>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4de4d30>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4de4f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b55fc1d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4e17320>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4e17470>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4dd2c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4dd2c88>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4da3860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4da3cc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4da3f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4db3240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4db34e0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4db3898>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4db3b38>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4db3e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4dd29e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b56189e8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b5618d68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b5618e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4da3ac8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4e0b0b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4e0b358>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4e0b5f8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4e0b898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4e0bb38>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4e0bef0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4d181d0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4d184e0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4da38d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4d3ea90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4d3ec18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4d3eb38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4d019e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4cef7f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cefc18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4cefeb8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4c7d198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4c7d438>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4c7d7f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4c7da90>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4c7dda0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4e0b048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4d29080>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4d291d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4cef9b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4cef9e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4cef7f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cef9e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4c56ba8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4c8f160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4c8fa90>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b560b438>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b560b6d8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b560b9e8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4cef748>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4e0b048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4d291d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4cefeb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4cefe48>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b560ba90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b560b438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b560b0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b560b128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b560b1d0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4c8f908>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4cefd68>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4cefb00>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4cefcf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4c56fd0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b560bd30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b560be80>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b560bcf8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4cefb00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cef9b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4c8f198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4c8f7f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b560b128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b560b438>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b560b6a0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b560b5f8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b560b9b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4c1fda0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4c1fc18>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4c1feb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4c7f668>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b560b5c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b560b438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b560b048>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b560b198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b560bc50>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4c8f908>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4cefda0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4cefd30>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4c7f710>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4beba58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4bebd30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4c5d5c0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4c5d6d8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4bfa080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cefda0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4cef860>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4c8f160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4c8fa90>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b560b898>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b560b2b0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b560b7f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b560b5f8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4b460f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4bb7f28>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4bb7fd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4bb7f98>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b560b278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b560b518>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b560b320>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b560b198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4c8f7f0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4c8f908>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4cefb00>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4bfa3c8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4bfa240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4b02d68>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4b460b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4b46048>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4b46320>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4bfa198>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cefd68>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4cef9b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4c8f198>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4c8f9e8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b560b518>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b560b898>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b560ba90>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b560b2b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4acfb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4b02ef0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4b02ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4b02e48>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4cfb0f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4cfb390>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4cfb630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4cfb8d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4cfbb70>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4cfbf28>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4a78208>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4a78518>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4b025c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4a9a898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4a9aba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4a9a940>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4a60a58>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4a31d68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4aa0128>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4aa03c8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4aa0668>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4aa0908>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4aa0cc0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4aa0f60>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b49c72b0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4cfb080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b560b978>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b560bba8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b560b438>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4a31eb8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4997390>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4997710>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b49979b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4997c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4997ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b49a42e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b49a4588>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b49a4898>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4a31c88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b49c7e80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b49c7f60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b49c7f28>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b49974e0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b48fdc18>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b48fdf60>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4bf1240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4bf14e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4bf1780>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4bf1b38>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4bf1dd8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4916128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b49972b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b49b7400>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b49b7550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b48fdcc0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b48fdcf8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b48fdcc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4916128>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b49160f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b49162b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b48ea320>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b48ea6d8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b48ea9b0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b48eacc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b48fdb70>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b49972b0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b49b7550>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b48fdf60>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b48fdef0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 LSTM
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b48eada0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b48ea940>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b48ea7f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b48ea588>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b48ea3c8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4916080>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4916da0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b48b0eb8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b48fdba8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b48fde80>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b48fdcf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b48fde10>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b48eacc0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=LSTM, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4913080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4916048>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4916dd8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b49163c8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b48ea588>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b48ea940>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b48ea6d8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b48ea780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b48ea9b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b48b0eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b48b0a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b48b0fd0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b48b0f98>]
          

Model: "sequential_120"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_60 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_180 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_180 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_181 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_181 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_60 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_182 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_182 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 111s - loss: 0.0413 - tp: 631.0000 - fp: 363.0000 - tn: 253396.0000 - fn: 2495.0000 - accuracy: 0.9889 - precision: 0.6348 - recall: 0.2019 - auc: 0.9097 - val_loss: 0.0326 - val_tp: 1434.0000 - val_fp: 933.0000 - val_tn: 234086.0000 - val_fn: 1405.0000 - val_accuracy: 0.9902 - val_precision: 0.6058 - val_recall: 0.5051 - val_auc: 0.9774
256885/256885 - 111s - loss: 0.0413 - tp: 631.0000 - fp: 363.0000 - tn: 253396.0000 - fn: 2495.0000 - accuracy: 0.9889 - precision: 0.6348 - recall: 0.2019 - auc: 0.9097 - val_loss: 0.0326 - val_tp: 1434.0000 - val_fp: 933.0000 - val_tn: 234086.0000 - val_fn: 1405.0000 - val_accuracy: 0.9902 - val_precision: 0.6058 - val_recall: 0.5051 - val_auc: 0.9774
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0251 - tp: 1550.0000 - fp: 435.0000 - tn: 253324.0000 - fn: 1576.0000 - accuracy: 0.9922 - precision: 0.7809 - recall: 0.4958 - auc: 0.9686 - val_loss: 0.0215 - val_tp: 1929.0000 - val_fp: 628.0000 - val_tn: 234391.0000 - val_fn: 910.0000 - val_accuracy: 0.9935 - val_precision: 0.7544 - val_recall: 0.6795 - val_auc: 0.9874
256885/256885 - 107s - loss: 0.0251 - tp: 1550.0000 - fp: 435.0000 - tn: 253324.0000 - fn: 1576.0000 - accuracy: 0.9922 - precision: 0.7809 - recall: 0.4958 - auc: 0.9686 - val_loss: 0.0215 - val_tp: 1929.0000 - val_fp: 628.0000 - val_tn: 234391.0000 - val_fn: 910.0000 - val_accuracy: 0.9935 - val_precision: 0.7544 - val_recall: 0.6795 - val_auc: 0.9874
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d41bb38>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b6f84c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b6f84908>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52f1ba6a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4bc4b4358>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4bc4b40b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4bc4b4898>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4bc4b4080>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b48b0fd0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4913160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4913710>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4913a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b656f0b8>]
          

Model: "sequential_121"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_61 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_183 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_183 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_184 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_184 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_61 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_185 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_185 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 111s - loss: 0.0433 - tp: 573.0000 - fp: 476.0000 - tn: 253282.0000 - fn: 2554.0000 - accuracy: 0.9882 - precision: 0.5462 - recall: 0.1832 - auc: 0.8988 - val_loss: 0.0307 - val_tp: 783.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2056.0000 - val_accuracy: 0.9903 - val_precision: 0.7624 - val_recall: 0.2758 - val_auc: 0.9531
256885/256885 - 111s - loss: 0.0433 - tp: 573.0000 - fp: 476.0000 - tn: 253282.0000 - fn: 2554.0000 - accuracy: 0.9882 - precision: 0.5462 - recall: 0.1832 - auc: 0.8988 - val_loss: 0.0307 - val_tp: 783.0000 - val_fp: 244.0000 - val_tn: 234775.0000 - val_fn: 2056.0000 - val_accuracy: 0.9903 - val_precision: 0.7624 - val_recall: 0.2758 - val_auc: 0.9531
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0262 - tp: 1454.0000 - fp: 436.0000 - tn: 253322.0000 - fn: 1673.0000 - accuracy: 0.9918 - precision: 0.7693 - recall: 0.4650 - auc: 0.9635 - val_loss: 0.0232 - val_tp: 1972.0000 - val_fp: 858.0000 - val_tn: 234161.0000 - val_fn: 867.0000 - val_accuracy: 0.9927 - val_precision: 0.6968 - val_recall: 0.6946 - val_auc: 0.9869
256885/256885 - 107s - loss: 0.0262 - tp: 1454.0000 - fp: 436.0000 - tn: 253322.0000 - fn: 1673.0000 - accuracy: 0.9918 - precision: 0.7693 - recall: 0.4650 - auc: 0.9635 - val_loss: 0.0232 - val_tp: 1972.0000 - val_fp: 858.0000 - val_tn: 234161.0000 - val_fn: 867.0000 - val_accuracy: 0.9927 - val_precision: 0.6968 - val_recall: 0.6946 - val_auc: 0.9869
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b1557b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b1557a58>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b1557f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52bf0bf28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50bdcc908>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50bdcc278>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50bdcc3c8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6620d30>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4913a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b69a16a0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4bc35f8d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b1531278>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b1557ac8>]
          

Model: "sequential_122"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_62 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_186 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_186 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_187 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_187 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_62 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_188 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_188 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 110s - loss: 0.0428 - tp: 569.0000 - fp: 414.0000 - tn: 253355.0000 - fn: 2547.0000 - accuracy: 0.9885 - precision: 0.5788 - recall: 0.1826 - auc: 0.9041 - val_loss: 0.0358 - val_tp: 433.0000 - val_fp: 83.0000 - val_tn: 234936.0000 - val_fn: 2406.0000 - val_accuracy: 0.9895 - val_precision: 0.8391 - val_recall: 0.1525 - val_auc: 0.9267
256885/256885 - 110s - loss: 0.0428 - tp: 569.0000 - fp: 414.0000 - tn: 253355.0000 - fn: 2547.0000 - accuracy: 0.9885 - precision: 0.5788 - recall: 0.1826 - auc: 0.9041 - val_loss: 0.0358 - val_tp: 433.0000 - val_fp: 83.0000 - val_tn: 234936.0000 - val_fn: 2406.0000 - val_accuracy: 0.9895 - val_precision: 0.8391 - val_recall: 0.1525 - val_auc: 0.9267
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0250 - tp: 1547.0000 - fp: 428.0000 - tn: 253341.0000 - fn: 1569.0000 - accuracy: 0.9922 - precision: 0.7833 - recall: 0.4965 - auc: 0.9676 - val_loss: 0.0198 - val_tp: 1615.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 1224.0000 - val_accuracy: 0.9937 - val_precision: 0.8509 - val_recall: 0.5689 - val_auc: 0.9779
256885/256885 - 107s - loss: 0.0250 - tp: 1547.0000 - fp: 428.0000 - tn: 253341.0000 - fn: 1569.0000 - accuracy: 0.9922 - precision: 0.7833 - recall: 0.4965 - auc: 0.9676 - val_loss: 0.0198 - val_tp: 1615.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 1224.0000 - val_accuracy: 0.9937 - val_precision: 0.8509 - val_recall: 0.5689 - val_auc: 0.9779
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b42d5048>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4579f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b42c3e48>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4338c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b425c518>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b425ca90>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b425cd30>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b425cf98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50b780780>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b1557860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b1557cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b1557278>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4913048>]
          

Model: "sequential_123"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_63 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_189 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_189 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_190 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_190 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_63 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_191 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_191 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 110s - loss: 0.0411 - tp: 620.0000 - fp: 351.0000 - tn: 253441.0000 - fn: 2473.0000 - accuracy: 0.9890 - precision: 0.6385 - recall: 0.2005 - auc: 0.9107 - val_loss: 0.0292 - val_tp: 1301.0000 - val_fp: 641.0000 - val_tn: 234378.0000 - val_fn: 1538.0000 - val_accuracy: 0.9908 - val_precision: 0.6699 - val_recall: 0.4583 - val_auc: 0.9746
256885/256885 - 110s - loss: 0.0411 - tp: 620.0000 - fp: 351.0000 - tn: 253441.0000 - fn: 2473.0000 - accuracy: 0.9890 - precision: 0.6385 - recall: 0.2005 - auc: 0.9107 - val_loss: 0.0292 - val_tp: 1301.0000 - val_fp: 641.0000 - val_tn: 234378.0000 - val_fn: 1538.0000 - val_accuracy: 0.9908 - val_precision: 0.6699 - val_recall: 0.4583 - val_auc: 0.9746
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0245 - tp: 1559.0000 - fp: 433.0000 - tn: 253359.0000 - fn: 1534.0000 - accuracy: 0.9923 - precision: 0.7826 - recall: 0.5040 - auc: 0.9693 - val_loss: 0.0200 - val_tp: 1809.0000 - val_fp: 443.0000 - val_tn: 234576.0000 - val_fn: 1030.0000 - val_accuracy: 0.9938 - val_precision: 0.8033 - val_recall: 0.6372 - val_auc: 0.9854
256885/256885 - 107s - loss: 0.0245 - tp: 1559.0000 - fp: 433.0000 - tn: 253359.0000 - fn: 1534.0000 - accuracy: 0.9923 - precision: 0.7826 - recall: 0.5040 - auc: 0.9693 - val_loss: 0.0200 - val_tp: 1809.0000 - val_fp: 443.0000 - val_tn: 234576.0000 - val_fn: 1030.0000 - val_accuracy: 0.9938 - val_precision: 0.8033 - val_recall: 0.6372 - val_auc: 0.9854
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b368ff28>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b371c080>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b3731710>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b364a128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b364a4a8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b364a978>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b364ae80>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b364a780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b1557cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b42ccbe0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b44fd1d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b3974dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3728f60>]
          

Model: "sequential_124"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_64 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_192 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_192 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_193 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_193 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_64 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_194 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_194 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 111s - loss: 0.0436 - tp: 574.0000 - fp: 416.0000 - tn: 253323.0000 - fn: 2572.0000 - accuracy: 0.9884 - precision: 0.5798 - recall: 0.1825 - auc: 0.8999 - val_loss: 0.0311 - val_tp: 645.0000 - val_fp: 169.0000 - val_tn: 234850.0000 - val_fn: 2194.0000 - val_accuracy: 0.9901 - val_precision: 0.7924 - val_recall: 0.2272 - val_auc: 0.9544
256885/256885 - 111s - loss: 0.0436 - tp: 574.0000 - fp: 416.0000 - tn: 253323.0000 - fn: 2572.0000 - accuracy: 0.9884 - precision: 0.5798 - recall: 0.1825 - auc: 0.8999 - val_loss: 0.0311 - val_tp: 645.0000 - val_fp: 169.0000 - val_tn: 234850.0000 - val_fn: 2194.0000 - val_accuracy: 0.9901 - val_precision: 0.7924 - val_recall: 0.2272 - val_auc: 0.9544
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0263 - tp: 1435.0000 - fp: 474.0000 - tn: 253265.0000 - fn: 1711.0000 - accuracy: 0.9915 - precision: 0.7517 - recall: 0.4561 - auc: 0.9678 - val_loss: 0.0269 - val_tp: 1174.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1665.0000 - val_accuracy: 0.9924 - val_precision: 0.8860 - val_recall: 0.4135 - val_auc: 0.9388
256885/256885 - 107s - loss: 0.0263 - tp: 1435.0000 - fp: 474.0000 - tn: 253265.0000 - fn: 1711.0000 - accuracy: 0.9915 - precision: 0.7517 - recall: 0.4561 - auc: 0.9678 - val_loss: 0.0269 - val_tp: 1174.0000 - val_fp: 151.0000 - val_tn: 234868.0000 - val_fn: 1665.0000 - val_accuracy: 0.9924 - val_precision: 0.8860 - val_recall: 0.4135 - val_auc: 0.9388
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52d5c3320>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b223fbe0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4b02780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b66524e0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b65d7da0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b66a8b70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b1ac978>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52df69710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52d4e8b00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52cbbabe0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52cbbaa20>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52cbbaa90>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b5618e48>]
          

Model: "sequential_125"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_65 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_195 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_195 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_196 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_196 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_65 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_197 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_197 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 111s - loss: 0.0429 - tp: 607.0000 - fp: 407.0000 - tn: 253371.0000 - fn: 2500.0000 - accuracy: 0.9887 - precision: 0.5986 - recall: 0.1954 - auc: 0.9004 - val_loss: 0.0329 - val_tp: 741.0000 - val_fp: 227.0000 - val_tn: 234792.0000 - val_fn: 2098.0000 - val_accuracy: 0.9902 - val_precision: 0.7655 - val_recall: 0.2610 - val_auc: 0.9364
256885/256885 - 111s - loss: 0.0429 - tp: 607.0000 - fp: 407.0000 - tn: 253371.0000 - fn: 2500.0000 - accuracy: 0.9887 - precision: 0.5986 - recall: 0.1954 - auc: 0.9004 - val_loss: 0.0329 - val_tp: 741.0000 - val_fp: 227.0000 - val_tn: 234792.0000 - val_fn: 2098.0000 - val_accuracy: 0.9902 - val_precision: 0.7655 - val_recall: 0.2610 - val_auc: 0.9364
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 108s - loss: 0.0262 - tp: 1452.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1655.0000 - accuracy: 0.9919 - precision: 0.7683 - recall: 0.4673 - auc: 0.9658 - val_loss: 0.0259 - val_tp: 1988.0000 - val_fp: 971.0000 - val_tn: 234048.0000 - val_fn: 851.0000 - val_accuracy: 0.9923 - val_precision: 0.6718 - val_recall: 0.7002 - val_auc: 0.9878
256885/256885 - 108s - loss: 0.0262 - tp: 1452.0000 - fp: 438.0000 - tn: 253340.0000 - fn: 1655.0000 - accuracy: 0.9919 - precision: 0.7683 - recall: 0.4673 - auc: 0.9658 - val_loss: 0.0259 - val_tp: 1988.0000 - val_fp: 971.0000 - val_tn: 234048.0000 - val_fn: 851.0000 - val_accuracy: 0.9923 - val_precision: 0.6718 - val_recall: 0.7002 - val_auc: 0.9878
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c1185c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52c1189b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd52c118b00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd52c118278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52c118780>, <tensorflow.python.keras.metrics.Precision object at 0x7fd52c118240>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cd58a20>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52cd58358>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52ce10f28>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52bf23c18>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b26a9e8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b5749438>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd52c118588>]
          

Model: "sequential_126"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_66 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_198 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_198 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_199 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_199 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_66 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_200 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_200 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 110s - loss: 0.0422 - tp: 590.0000 - fp: 343.0000 - tn: 253451.0000 - fn: 2501.0000 - accuracy: 0.9889 - precision: 0.6324 - recall: 0.1909 - auc: 0.9045 - val_loss: 0.0288 - val_tp: 1057.0000 - val_fp: 455.0000 - val_tn: 234564.0000 - val_fn: 1782.0000 - val_accuracy: 0.9906 - val_precision: 0.6991 - val_recall: 0.3723 - val_auc: 0.9615
256885/256885 - 110s - loss: 0.0422 - tp: 590.0000 - fp: 343.0000 - tn: 253451.0000 - fn: 2501.0000 - accuracy: 0.9889 - precision: 0.6324 - recall: 0.1909 - auc: 0.9045 - val_loss: 0.0288 - val_tp: 1057.0000 - val_fp: 455.0000 - val_tn: 234564.0000 - val_fn: 1782.0000 - val_accuracy: 0.9906 - val_precision: 0.6991 - val_recall: 0.3723 - val_auc: 0.9615
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 107s - loss: 0.0245 - tp: 1548.0000 - fp: 426.0000 - tn: 253368.0000 - fn: 1543.0000 - accuracy: 0.9923 - precision: 0.7842 - recall: 0.5008 - auc: 0.9688 - val_loss: 0.0203 - val_tp: 1888.0000 - val_fp: 596.0000 - val_tn: 234423.0000 - val_fn: 951.0000 - val_accuracy: 0.9935 - val_precision: 0.7601 - val_recall: 0.6650 - val_auc: 0.9840
256885/256885 - 107s - loss: 0.0245 - tp: 1548.0000 - fp: 426.0000 - tn: 253368.0000 - fn: 1543.0000 - accuracy: 0.9923 - precision: 0.7842 - recall: 0.5008 - auc: 0.9688 - val_loss: 0.0203 - val_tp: 1888.0000 - val_fp: 596.0000 - val_tn: 234423.0000 - val_fn: 951.0000 - val_accuracy: 0.9935 - val_precision: 0.7601 - val_recall: 0.6650 - val_auc: 0.9840
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b583aa20>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd5196a8d30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd5196a00f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd5196a0898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd5196a0b38>, <tensorflow.python.keras.metrics.Precision object at 0x7fd5196a0ef0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50b6031d0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50b6034e0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50b26a9e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd52c118eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd52c1184e0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c118b70>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd50b728240>]
          

Model: "sequential_127"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_67 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_201 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_201 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_202 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_202 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_67 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_203 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_203 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 109s - loss: 0.0415 - tp: 590.0000 - fp: 441.0000 - tn: 253333.0000 - fn: 2521.0000 - accuracy: 0.9885 - precision: 0.5723 - recall: 0.1896 - auc: 0.9084 - val_loss: 0.0278 - val_tp: 1193.0000 - val_fp: 473.0000 - val_tn: 234546.0000 - val_fn: 1646.0000 - val_accuracy: 0.9911 - val_precision: 0.7161 - val_recall: 0.4202 - val_auc: 0.9723
256885/256885 - 109s - loss: 0.0415 - tp: 590.0000 - fp: 441.0000 - tn: 253333.0000 - fn: 2521.0000 - accuracy: 0.9885 - precision: 0.5723 - recall: 0.1896 - auc: 0.9084 - val_loss: 0.0278 - val_tp: 1193.0000 - val_fp: 473.0000 - val_tn: 234546.0000 - val_fn: 1646.0000 - val_accuracy: 0.9911 - val_precision: 0.7161 - val_recall: 0.4202 - val_auc: 0.9723
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 106s - loss: 0.0251 - tp: 1516.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 1595.0000 - accuracy: 0.9921 - precision: 0.7751 - recall: 0.4873 - auc: 0.9694 - val_loss: 0.0202 - val_tp: 1677.0000 - val_fp: 348.0000 - val_tn: 234671.0000 - val_fn: 1162.0000 - val_accuracy: 0.9937 - val_precision: 0.8281 - val_recall: 0.5907 - val_auc: 0.9752
256885/256885 - 106s - loss: 0.0251 - tp: 1516.0000 - fp: 440.0000 - tn: 253334.0000 - fn: 1595.0000 - accuracy: 0.9921 - precision: 0.7751 - recall: 0.4873 - auc: 0.9694 - val_loss: 0.0202 - val_tp: 1677.0000 - val_fp: 348.0000 - val_tn: 234671.0000 - val_fn: 1162.0000 - val_accuracy: 0.9937 - val_precision: 0.8281 - val_recall: 0.5907 - val_auc: 0.9752
Epoch 00002: early stopping
28543/28543 - 2s
28543/28543 - 2s
256885/256885 - 20s
256885/256885 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.7min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b3f1aef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50b7180f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b50c6d30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3e3f6a0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3e3f4a8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b3e3f8d0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b3e3f668>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b3e3fb38>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5196bd198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd5196bd160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd5196bd1d0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b60672e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3f1aeb8>]
          

Model: "sequential_128"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_68 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_204 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_204 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_205 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_205 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_68 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_206 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_206 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 110s - loss: 0.0420 - tp: 635.0000 - fp: 463.0000 - tn: 253315.0000 - fn: 2473.0000 - accuracy: 0.9886 - precision: 0.5783 - recall: 0.2043 - auc: 0.9032 - val_loss: 0.0320 - val_tp: 1484.0000 - val_fp: 1056.0000 - val_tn: 233963.0000 - val_fn: 1355.0000 - val_accuracy: 0.9899 - val_precision: 0.5843 - val_recall: 0.5227 - val_auc: 0.9766
256886/256886 - 110s - loss: 0.0420 - tp: 635.0000 - fp: 463.0000 - tn: 253315.0000 - fn: 2473.0000 - accuracy: 0.9886 - precision: 0.5783 - recall: 0.2043 - auc: 0.9032 - val_loss: 0.0320 - val_tp: 1484.0000 - val_fp: 1056.0000 - val_tn: 233963.0000 - val_fn: 1355.0000 - val_accuracy: 0.9899 - val_precision: 0.5843 - val_recall: 0.5227 - val_auc: 0.9766
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 107s - loss: 0.0258 - tp: 1501.0000 - fp: 446.0000 - tn: 253332.0000 - fn: 1607.0000 - accuracy: 0.9920 - precision: 0.7709 - recall: 0.4829 - auc: 0.9659 - val_loss: 0.0213 - val_tp: 1835.0000 - val_fp: 621.0000 - val_tn: 234398.0000 - val_fn: 1004.0000 - val_accuracy: 0.9932 - val_precision: 0.7471 - val_recall: 0.6464 - val_auc: 0.9850
256886/256886 - 107s - loss: 0.0258 - tp: 1501.0000 - fp: 446.0000 - tn: 253332.0000 - fn: 1607.0000 - accuracy: 0.9920 - precision: 0.7709 - recall: 0.4829 - auc: 0.9659 - val_loss: 0.0213 - val_tp: 1835.0000 - val_fp: 621.0000 - val_tn: 234398.0000 - val_fn: 1004.0000 - val_accuracy: 0.9932 - val_precision: 0.7471 - val_recall: 0.6464 - val_auc: 0.9850
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b1fa4be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50afab780>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50af91978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50af91c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50af91f28>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50af91048>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50afff438>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50afffdd8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd5196bd1d0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b3f1aeb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b3f1afd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b3f1ae48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b5410080>]
          

Model: "sequential_129"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_69 (GRU)                 (None, 50)                9600      
_________________________________________________________________
dense_207 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_207 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_208 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_208 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_69 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_209 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_209 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 110s - loss: 0.0418 - tp: 582.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5826 - recall: 0.1863 - auc: 0.9072 - val_loss: 0.0286 - val_tp: 1014.0000 - val_fp: 383.0000 - val_tn: 234636.0000 - val_fn: 1825.0000 - val_accuracy: 0.9907 - val_precision: 0.7258 - val_recall: 0.3572 - val_auc: 0.9630
256886/256886 - 110s - loss: 0.0418 - tp: 582.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 2542.0000 - accuracy: 0.9885 - precision: 0.5826 - recall: 0.1863 - auc: 0.9072 - val_loss: 0.0286 - val_tp: 1014.0000 - val_fp: 383.0000 - val_tn: 234636.0000 - val_fn: 1825.0000 - val_accuracy: 0.9907 - val_precision: 0.7258 - val_recall: 0.3572 - val_auc: 0.9630
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 107s - loss: 0.0252 - tp: 1521.0000 - fp: 407.0000 - tn: 253355.0000 - fn: 1603.0000 - accuracy: 0.9922 - precision: 0.7889 - recall: 0.4869 - auc: 0.9670 - val_loss: 0.0203 - val_tp: 1545.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1294.0000 - val_accuracy: 0.9935 - val_precision: 0.8564 - val_recall: 0.5442 - val_auc: 0.9767
256886/256886 - 107s - loss: 0.0252 - tp: 1521.0000 - fp: 407.0000 - tn: 253355.0000 - fn: 1603.0000 - accuracy: 0.9922 - precision: 0.7889 - recall: 0.4869 - auc: 0.9670 - val_loss: 0.0203 - val_tp: 1545.0000 - val_fp: 259.0000 - val_tn: 234760.0000 - val_fn: 1294.0000 - val_accuracy: 0.9935 - val_precision: 0.8564 - val_recall: 0.5442 - val_auc: 0.9767
Epoch 00002: early stopping
28542/28542 - 2s
28542/28542 - 2s
256886/256886 - 20s
256886/256886 - 20s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total= 3.8min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b13c1a90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b13de7f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b133c1d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b133c780>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b133ce80>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b135eac8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b135e908>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b135e710>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b3f1ae48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b57ba0f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b52477b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b1b96dd8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b1b3ecc0>]
          

Model: "sequential_130"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_70 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_210 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_210 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_211 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_211 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_70 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_212 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_212 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0405 - tp: 688.0000 - fp: 374.0000 - tn: 253385.0000 - fn: 2438.0000 - accuracy: 0.9891 - precision: 0.6478 - recall: 0.2201 - auc: 0.9117 - val_loss: 0.0273 - val_tp: 1127.0000 - val_fp: 414.0000 - val_tn: 234605.0000 - val_fn: 1712.0000 - val_accuracy: 0.9911 - val_precision: 0.7313 - val_recall: 0.3970 - val_auc: 0.9659
256885/256885 - 128s - loss: 0.0405 - tp: 688.0000 - fp: 374.0000 - tn: 253385.0000 - fn: 2438.0000 - accuracy: 0.9891 - precision: 0.6478 - recall: 0.2201 - auc: 0.9117 - val_loss: 0.0273 - val_tp: 1127.0000 - val_fp: 414.0000 - val_tn: 234605.0000 - val_fn: 1712.0000 - val_accuracy: 0.9911 - val_precision: 0.7313 - val_recall: 0.3970 - val_auc: 0.9659
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0241 - tp: 1660.0000 - fp: 423.0000 - tn: 253336.0000 - fn: 1466.0000 - accuracy: 0.9926 - precision: 0.7969 - recall: 0.5310 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1442.0000 - val_fp: 167.0000 - val_tn: 234852.0000 - val_fn: 1397.0000 - val_accuracy: 0.9934 - val_precision: 0.8962 - val_recall: 0.5079 - val_auc: 0.9716
256885/256885 - 125s - loss: 0.0241 - tp: 1660.0000 - fp: 423.0000 - tn: 253336.0000 - fn: 1466.0000 - accuracy: 0.9926 - precision: 0.7969 - recall: 0.5310 - auc: 0.9667 - val_loss: 0.0205 - val_tp: 1442.0000 - val_fp: 167.0000 - val_tn: 234852.0000 - val_fn: 1397.0000 - val_accuracy: 0.9934 - val_precision: 0.8962 - val_recall: 0.5079 - val_auc: 0.9716
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50b721e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd52cfbe978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4997550>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4997c18>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4bc158c88>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4bc158fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4bc158ac8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd50bc0d0f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b1b96320>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b1335198>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b424e9b0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b1b4e6d8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b2668ef0>]
          

Model: "sequential_131"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_71 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_213 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_213 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_214 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_214 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_71 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_215 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_215 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0417 - tp: 664.0000 - fp: 372.0000 - tn: 253386.0000 - fn: 2463.0000 - accuracy: 0.9890 - precision: 0.6409 - recall: 0.2123 - auc: 0.9061 - val_loss: 0.0280 - val_tp: 863.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1976.0000 - val_accuracy: 0.9907 - val_precision: 0.7803 - val_recall: 0.3040 - val_auc: 0.9666
256885/256885 - 127s - loss: 0.0417 - tp: 664.0000 - fp: 372.0000 - tn: 253386.0000 - fn: 2463.0000 - accuracy: 0.9890 - precision: 0.6409 - recall: 0.2123 - auc: 0.9061 - val_loss: 0.0280 - val_tp: 863.0000 - val_fp: 243.0000 - val_tn: 234776.0000 - val_fn: 1976.0000 - val_accuracy: 0.9907 - val_precision: 0.7803 - val_recall: 0.3040 - val_auc: 0.9666
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0242 - tp: 1637.0000 - fp: 408.0000 - tn: 253350.0000 - fn: 1490.0000 - accuracy: 0.9926 - precision: 0.8005 - recall: 0.5235 - auc: 0.9687 - val_loss: 0.0205 - val_tp: 1708.0000 - val_fp: 352.0000 - val_tn: 234667.0000 - val_fn: 1131.0000 - val_accuracy: 0.9938 - val_precision: 0.8291 - val_recall: 0.6016 - val_auc: 0.9646
256885/256885 - 125s - loss: 0.0242 - tp: 1637.0000 - fp: 408.0000 - tn: 253350.0000 - fn: 1490.0000 - accuracy: 0.9926 - precision: 0.8005 - recall: 0.5235 - auc: 0.9687 - val_loss: 0.0205 - val_tp: 1708.0000 - val_fp: 352.0000 - val_tn: 234667.0000 - val_fn: 1131.0000 - val_accuracy: 0.9938 - val_precision: 0.8291 - val_recall: 0.6016 - val_auc: 0.9646
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd52c0ce0b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b3725e80>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b5ef3940>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b5ef36d8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5ef32b0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b5ef3fd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b5ef3e48>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b5ef34e0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b424e9b0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b2668780>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b5d56048>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b51d9a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b383cf60>]
          

Model: "sequential_132"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_72 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_216 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_216 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_217 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_217 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_72 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_218 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_218 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0425 - tp: 615.0000 - fp: 464.0000 - tn: 253305.0000 - fn: 2501.0000 - accuracy: 0.9885 - precision: 0.5700 - recall: 0.1974 - auc: 0.9064 - val_loss: 0.0293 - val_tp: 670.0000 - val_fp: 166.0000 - val_tn: 234853.0000 - val_fn: 2169.0000 - val_accuracy: 0.9902 - val_precision: 0.8014 - val_recall: 0.2360 - val_auc: 0.9631
256885/256885 - 127s - loss: 0.0425 - tp: 615.0000 - fp: 464.0000 - tn: 253305.0000 - fn: 2501.0000 - accuracy: 0.9885 - precision: 0.5700 - recall: 0.1974 - auc: 0.9064 - val_loss: 0.0293 - val_tp: 670.0000 - val_fp: 166.0000 - val_tn: 234853.0000 - val_fn: 2169.0000 - val_accuracy: 0.9902 - val_precision: 0.8014 - val_recall: 0.2360 - val_auc: 0.9631
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 124s - loss: 0.0248 - tp: 1613.0000 - fp: 417.0000 - tn: 253352.0000 - fn: 1503.0000 - accuracy: 0.9925 - precision: 0.7946 - recall: 0.5177 - auc: 0.9671 - val_loss: 0.0199 - val_tp: 1728.0000 - val_fp: 372.0000 - val_tn: 234647.0000 - val_fn: 1111.0000 - val_accuracy: 0.9938 - val_precision: 0.8229 - val_recall: 0.6087 - val_auc: 0.9709
256885/256885 - 124s - loss: 0.0248 - tp: 1613.0000 - fp: 417.0000 - tn: 253352.0000 - fn: 1503.0000 - accuracy: 0.9925 - precision: 0.7946 - recall: 0.5177 - auc: 0.9671 - val_loss: 0.0199 - val_tp: 1728.0000 - val_fp: 372.0000 - val_tn: 234647.0000 - val_fn: 1111.0000 - val_accuracy: 0.9938 - val_precision: 0.8229 - val_recall: 0.6087 - val_auc: 0.9709
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b3046b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b5faf4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b5fafc50>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd50ad4d438>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b5b97898>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50a0faf98>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b305aeb8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b305a780>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b5d56048>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd50bb4f470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b383cfd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52c0cec50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b1335198>]
          

Model: "sequential_133"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_73 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_219 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_219 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_220 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_220 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_73 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_221 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_221 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 128s - loss: 0.0413 - tp: 638.0000 - fp: 366.0000 - tn: 253426.0000 - fn: 2455.0000 - accuracy: 0.9890 - precision: 0.6355 - recall: 0.2063 - auc: 0.9044 - val_loss: 0.0283 - val_tp: 859.0000 - val_fp: 249.0000 - val_tn: 234770.0000 - val_fn: 1980.0000 - val_accuracy: 0.9906 - val_precision: 0.7753 - val_recall: 0.3026 - val_auc: 0.9725
256885/256885 - 128s - loss: 0.0413 - tp: 638.0000 - fp: 366.0000 - tn: 253426.0000 - fn: 2455.0000 - accuracy: 0.9890 - precision: 0.6355 - recall: 0.2063 - auc: 0.9044 - val_loss: 0.0283 - val_tp: 859.0000 - val_fp: 249.0000 - val_tn: 234770.0000 - val_fn: 1980.0000 - val_accuracy: 0.9906 - val_precision: 0.7753 - val_recall: 0.3026 - val_auc: 0.9725
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0245 - tp: 1603.0000 - fp: 419.0000 - tn: 253373.0000 - fn: 1490.0000 - accuracy: 0.9926 - precision: 0.7928 - recall: 0.5183 - auc: 0.9657 - val_loss: 0.0213 - val_tp: 1530.0000 - val_fp: 251.0000 - val_tn: 234768.0000 - val_fn: 1309.0000 - val_accuracy: 0.9934 - val_precision: 0.8591 - val_recall: 0.5389 - val_auc: 0.9623
256885/256885 - 125s - loss: 0.0245 - tp: 1603.0000 - fp: 419.0000 - tn: 253373.0000 - fn: 1490.0000 - accuracy: 0.9926 - precision: 0.7928 - recall: 0.5183 - auc: 0.9657 - val_loss: 0.0213 - val_tp: 1530.0000 - val_fp: 251.0000 - val_tn: 234768.0000 - val_fn: 1309.0000 - val_accuracy: 0.9934 - val_precision: 0.8591 - val_recall: 0.5389 - val_auc: 0.9623
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b3030978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b30d8f98>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b2f7c0b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b2f7cfd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b2f7cb00>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b2f7c198>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b2f7c390>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b2f7c7f0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd52c0ce0f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b3716ef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b1335198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b30cf0f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b397f4a8>]
          

Model: "sequential_134"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_74 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_222 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_222 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_223 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_223 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_74 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_224 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_224 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0414 - tp: 652.0000 - fp: 387.0000 - tn: 253352.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6275 - recall: 0.2072 - auc: 0.9095 - val_loss: 0.0271 - val_tp: 1171.0000 - val_fp: 426.0000 - val_tn: 234593.0000 - val_fn: 1668.0000 - val_accuracy: 0.9912 - val_precision: 0.7332 - val_recall: 0.4125 - val_auc: 0.9684
256885/256885 - 127s - loss: 0.0414 - tp: 652.0000 - fp: 387.0000 - tn: 253352.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6275 - recall: 0.2072 - auc: 0.9095 - val_loss: 0.0271 - val_tp: 1171.0000 - val_fp: 426.0000 - val_tn: 234593.0000 - val_fn: 1668.0000 - val_accuracy: 0.9912 - val_precision: 0.7332 - val_recall: 0.4125 - val_auc: 0.9684
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 124s - loss: 0.0243 - tp: 1672.0000 - fp: 435.0000 - tn: 253304.0000 - fn: 1474.0000 - accuracy: 0.9926 - precision: 0.7935 - recall: 0.5315 - auc: 0.9681 - val_loss: 0.0230 - val_tp: 1472.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 1367.0000 - val_accuracy: 0.9934 - val_precision: 0.8762 - val_recall: 0.5185 - val_auc: 0.9502
256885/256885 - 124s - loss: 0.0243 - tp: 1672.0000 - fp: 435.0000 - tn: 253304.0000 - fn: 1474.0000 - accuracy: 0.9926 - precision: 0.7935 - recall: 0.5315 - auc: 0.9681 - val_loss: 0.0230 - val_tp: 1472.0000 - val_fp: 208.0000 - val_tn: 234811.0000 - val_fn: 1367.0000 - val_accuracy: 0.9934 - val_precision: 0.8762 - val_recall: 0.5185 - val_auc: 0.9502
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b0e58e10>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b0969e48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b0969400>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b0166080>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b26c2c88>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b1172f98>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b08f8c50>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b08f86d8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b1335198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4bc0da470>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b0987eb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b0189b38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b58c7d30>]
          

Model: "sequential_135"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_75 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_225 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_225 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_226 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_226 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_75 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_227 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_227 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 129s - loss: 0.0409 - tp: 627.0000 - fp: 359.0000 - tn: 253419.0000 - fn: 2480.0000 - accuracy: 0.9889 - precision: 0.6359 - recall: 0.2018 - auc: 0.9125 - val_loss: 0.0292 - val_tp: 1493.0000 - val_fp: 920.0000 - val_tn: 234099.0000 - val_fn: 1346.0000 - val_accuracy: 0.9905 - val_precision: 0.6187 - val_recall: 0.5259 - val_auc: 0.9778
256885/256885 - 129s - loss: 0.0409 - tp: 627.0000 - fp: 359.0000 - tn: 253419.0000 - fn: 2480.0000 - accuracy: 0.9889 - precision: 0.6359 - recall: 0.2018 - auc: 0.9125 - val_loss: 0.0292 - val_tp: 1493.0000 - val_fp: 920.0000 - val_tn: 234099.0000 - val_fn: 1346.0000 - val_accuracy: 0.9905 - val_precision: 0.6187 - val_recall: 0.5259 - val_auc: 0.9778
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0240 - tp: 1653.0000 - fp: 441.0000 - tn: 253337.0000 - fn: 1454.0000 - accuracy: 0.9926 - precision: 0.7894 - recall: 0.5320 - auc: 0.9672 - val_loss: 0.0245 - val_tp: 1346.0000 - val_fp: 143.0000 - val_tn: 234876.0000 - val_fn: 1493.0000 - val_accuracy: 0.9931 - val_precision: 0.9040 - val_recall: 0.4741 - val_auc: 0.9416
256885/256885 - 125s - loss: 0.0240 - tp: 1653.0000 - fp: 441.0000 - tn: 253337.0000 - fn: 1454.0000 - accuracy: 0.9926 - precision: 0.7894 - recall: 0.5320 - auc: 0.9672 - val_loss: 0.0245 - val_tp: 1346.0000 - val_fp: 143.0000 - val_tn: 234876.0000 - val_fn: 1493.0000 - val_accuracy: 0.9931 - val_precision: 0.9040 - val_recall: 0.4741 - val_auc: 0.9416
Epoch 3/50
Epoch 3/50

Epoch 00003: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0200 - tp: 1982.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 1125.0000 - accuracy: 0.9942 - precision: 0.8402 - recall: 0.6379 - auc: 0.9708 - val_loss: 0.0195 - val_tp: 2030.0000 - val_fp: 568.0000 - val_tn: 234451.0000 - val_fn: 809.0000 - val_accuracy: 0.9942 - val_precision: 0.7814 - val_recall: 0.7150 - val_auc: 0.9851
256885/256885 - 125s - loss: 0.0200 - tp: 1982.0000 - fp: 377.0000 - tn: 253401.0000 - fn: 1125.0000 - accuracy: 0.9942 - precision: 0.8402 - recall: 0.6379 - auc: 0.9708 - val_loss: 0.0195 - val_tp: 2030.0000 - val_fp: 568.0000 - val_tn: 234451.0000 - val_fn: 809.0000 - val_accuracy: 0.9942 - val_precision: 0.7814 - val_recall: 0.7150 - val_auc: 0.9851
Epoch 00003: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 6.5min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4af8e0dd8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4af8e0f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4af8e0828>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4af8e0630>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4bc150ef0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4bc150a20>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b6ab3710>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b6ab3400>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b0189b38>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b3b5cdd8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b38d1a90>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b38d14a8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b38d1ba8>]
          

Model: "sequential_136"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_76 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_228 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_228 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_229 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_229 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_76 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_230 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_230 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0414 - tp: 644.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 2447.0000 - accuracy: 0.9889 - precision: 0.6104 - recall: 0.2083 - auc: 0.9052 - val_loss: 0.0287 - val_tp: 933.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 1906.0000 - val_accuracy: 0.9908 - val_precision: 0.7673 - val_recall: 0.3286 - val_auc: 0.9601
256885/256885 - 127s - loss: 0.0414 - tp: 644.0000 - fp: 411.0000 - tn: 253383.0000 - fn: 2447.0000 - accuracy: 0.9889 - precision: 0.6104 - recall: 0.2083 - auc: 0.9052 - val_loss: 0.0287 - val_tp: 933.0000 - val_fp: 283.0000 - val_tn: 234736.0000 - val_fn: 1906.0000 - val_accuracy: 0.9908 - val_precision: 0.7673 - val_recall: 0.3286 - val_auc: 0.9601
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0250 - tp: 1555.0000 - fp: 440.0000 - tn: 253354.0000 - fn: 1536.0000 - accuracy: 0.9923 - precision: 0.7794 - recall: 0.5031 - auc: 0.9665 - val_loss: 0.0206 - val_tp: 1803.0000 - val_fp: 467.0000 - val_tn: 234552.0000 - val_fn: 1036.0000 - val_accuracy: 0.9937 - val_precision: 0.7943 - val_recall: 0.6351 - val_auc: 0.9859
256885/256885 - 125s - loss: 0.0250 - tp: 1555.0000 - fp: 440.0000 - tn: 253354.0000 - fn: 1536.0000 - accuracy: 0.9923 - precision: 0.7794 - recall: 0.5031 - auc: 0.9665 - val_loss: 0.0206 - val_tp: 1803.0000 - val_fp: 467.0000 - val_tn: 234552.0000 - val_fn: 1036.0000 - val_accuracy: 0.9937 - val_precision: 0.7943 - val_recall: 0.6351 - val_auc: 0.9859
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 26s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b367fbe0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b08a6cf8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b119e6a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b119e470>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b119e8d0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b119ed68>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52bf24c50>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52bf248d0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b38d14a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b38d1a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b38d1ac8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b38d1a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3b5cd30>]
          

Model: "sequential_137"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_77 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_231 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_231 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_232 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_232 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_77 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_233 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_233 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256885 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256885/256885 - 127s - loss: 0.0408 - tp: 645.0000 - fp: 370.0000 - tn: 253404.0000 - fn: 2466.0000 - accuracy: 0.9890 - precision: 0.6355 - recall: 0.2073 - auc: 0.9100 - val_loss: 0.0304 - val_tp: 785.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 2054.0000 - val_accuracy: 0.9906 - val_precision: 0.8068 - val_recall: 0.2765 - val_auc: 0.9468
256885/256885 - 127s - loss: 0.0408 - tp: 645.0000 - fp: 370.0000 - tn: 253404.0000 - fn: 2466.0000 - accuracy: 0.9890 - precision: 0.6355 - recall: 0.2073 - auc: 0.9100 - val_loss: 0.0304 - val_tp: 785.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 2054.0000 - val_accuracy: 0.9906 - val_precision: 0.8068 - val_recall: 0.2765 - val_auc: 0.9468
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256885/256885 - 125s - loss: 0.0240 - tp: 1641.0000 - fp: 434.0000 - tn: 253340.0000 - fn: 1470.0000 - accuracy: 0.9926 - precision: 0.7908 - recall: 0.5275 - auc: 0.9691 - val_loss: 0.0205 - val_tp: 1690.0000 - val_fp: 381.0000 - val_tn: 234638.0000 - val_fn: 1149.0000 - val_accuracy: 0.9936 - val_precision: 0.8160 - val_recall: 0.5953 - val_auc: 0.9671
256885/256885 - 125s - loss: 0.0240 - tp: 1641.0000 - fp: 434.0000 - tn: 253340.0000 - fn: 1470.0000 - accuracy: 0.9926 - precision: 0.7908 - recall: 0.5275 - auc: 0.9691 - val_loss: 0.0205 - val_tp: 1690.0000 - val_fp: 381.0000 - val_tn: 234638.0000 - val_fn: 1149.0000 - val_accuracy: 0.9936 - val_precision: 0.8160 - val_recall: 0.5953 - val_auc: 0.9671
Epoch 00002: early stopping
28543/28543 - 3s
28543/28543 - 3s
256885/256885 - 25s
256885/256885 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b441d5c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b33dec18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b14fc8d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b14fc9e8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b14fc588>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b14fcb00>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b14fc128>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b20e8748>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b116bc88>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b13c1ef0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b116bbe0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4411d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b20f3da0>]
          

Model: "sequential_138"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_78 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_234 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_234 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_235 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_235 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_78 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_236 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_236 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 127s - loss: 0.0413 - tp: 617.0000 - fp: 415.0000 - tn: 253363.0000 - fn: 2491.0000 - accuracy: 0.9887 - precision: 0.5979 - recall: 0.1985 - auc: 0.9115 - val_loss: 0.0276 - val_tp: 963.0000 - val_fp: 265.0000 - val_tn: 234754.0000 - val_fn: 1876.0000 - val_accuracy: 0.9910 - val_precision: 0.7842 - val_recall: 0.3392 - val_auc: 0.9633
256886/256886 - 127s - loss: 0.0413 - tp: 617.0000 - fp: 415.0000 - tn: 253363.0000 - fn: 2491.0000 - accuracy: 0.9887 - precision: 0.5979 - recall: 0.1985 - auc: 0.9115 - val_loss: 0.0276 - val_tp: 963.0000 - val_fp: 265.0000 - val_tn: 234754.0000 - val_fn: 1876.0000 - val_accuracy: 0.9910 - val_precision: 0.7842 - val_recall: 0.3392 - val_auc: 0.9633
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 125s - loss: 0.0243 - tp: 1620.0000 - fp: 468.0000 - tn: 253310.0000 - fn: 1488.0000 - accuracy: 0.9924 - precision: 0.7759 - recall: 0.5212 - auc: 0.9678 - val_loss: 0.0203 - val_tp: 1459.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1380.0000 - val_accuracy: 0.9934 - val_precision: 0.8859 - val_recall: 0.5139 - val_auc: 0.9757
256886/256886 - 125s - loss: 0.0243 - tp: 1620.0000 - fp: 468.0000 - tn: 253310.0000 - fn: 1488.0000 - accuracy: 0.9924 - precision: 0.7759 - recall: 0.5212 - auc: 0.9678 - val_loss: 0.0203 - val_tp: 1459.0000 - val_fp: 188.0000 - val_tn: 234831.0000 - val_fn: 1380.0000 - val_accuracy: 0.9934 - val_precision: 0.8859 - val_recall: 0.5139 - val_auc: 0.9757
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd50a9662e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd50a966dd8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd50a966f98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3c19160>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd50a9bc828>, <tensorflow.python.keras.metrics.Precision object at 0x7fd50a9bc710>, <tensorflow.python.keras.metrics.Recall object at 0x7fd50a9bc048>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b2518fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b33dda90>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b213feb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50a94e940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50a95d2e8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b0e01438>]
          

Model: "sequential_139"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_79 (GRU)                 (None, 100)               34200     
_________________________________________________________________
dense_237 (Dense)            (None, 200)               20200     
_________________________________________________________________
activation_237 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_238 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_238 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_79 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_239 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_239 (Activation)  (None, 1)                 0         
=================================================================
Total params: 94,801
Trainable params: 94,801
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 256886 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
256886/256886 - 127s - loss: 0.0410 - tp: 630.0000 - fp: 384.0000 - tn: 253378.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6213 - recall: 0.2017 - auc: 0.9095 - val_loss: 0.0306 - val_tp: 1536.0000 - val_fp: 1074.0000 - val_tn: 233945.0000 - val_fn: 1303.0000 - val_accuracy: 0.9900 - val_precision: 0.5885 - val_recall: 0.5410 - val_auc: 0.9767
256886/256886 - 127s - loss: 0.0410 - tp: 630.0000 - fp: 384.0000 - tn: 253378.0000 - fn: 2494.0000 - accuracy: 0.9888 - precision: 0.6213 - recall: 0.2017 - auc: 0.9095 - val_loss: 0.0306 - val_tp: 1536.0000 - val_fp: 1074.0000 - val_tn: 233945.0000 - val_fn: 1303.0000 - val_accuracy: 0.9900 - val_precision: 0.5885 - val_recall: 0.5410 - val_auc: 0.9767
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
256886/256886 - 125s - loss: 0.0242 - tp: 1616.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 1508.0000 - accuracy: 0.9925 - precision: 0.7949 - recall: 0.5173 - auc: 0.9692 - val_loss: 0.0194 - val_tp: 1711.0000 - val_fp: 335.0000 - val_tn: 234684.0000 - val_fn: 1128.0000 - val_accuracy: 0.9938 - val_precision: 0.8363 - val_recall: 0.6027 - val_auc: 0.9762
256886/256886 - 125s - loss: 0.0242 - tp: 1616.0000 - fp: 417.0000 - tn: 253345.0000 - fn: 1508.0000 - accuracy: 0.9925 - precision: 0.7949 - recall: 0.5173 - auc: 0.9692 - val_loss: 0.0194 - val_tp: 1711.0000 - val_fp: 335.0000 - val_tn: 234684.0000 - val_fn: 1128.0000 - val_accuracy: 0.9938 - val_precision: 0.8363 - val_recall: 0.6027 - val_auc: 0.9762
Epoch 00002: early stopping
28542/28542 - 3s
28542/28542 - 3s
256886/256886 - 25s
256886/256886 - 25s
[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=0, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total= 4.4min
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b73c27b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b73cdc50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b73cdd30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b73cde80>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b73e0160>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b73e0518>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b73e07b8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b73e0ac8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd50a95d2e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b0e01438>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50a966c50>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd50a966d68>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b74172e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b73f16a0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b747db00>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b747d668>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b747d2b0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b747dfd0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b747d048>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b747d160>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b73fcfd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b7431240>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b1ef97f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b740d198>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b740d358>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b740d668>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b7347a90>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b7347da0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b7347fd0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b1500320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b15005c0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b1500978>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b1500c18>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b1500f28>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b740d160>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b7382be0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7382d68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7382c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b7347a20>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b7347cc0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b7347c18>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b7366198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b73660f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7334710>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b7334b70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b7334e10>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b733c160>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b73479e8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b740d160>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7382d68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7382c88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b7347da0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b7334a58>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b73348d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b7334978>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7366208>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b73660b8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b7347b70>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b733c470>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b733c0b8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b7347cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b7334e10>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7334dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7334eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b7334d68>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b733c1d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b733cc50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b733c4e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7347c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7366208>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b73660f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b73348d0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b7334ba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b7334940>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b72fcf98>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b72fc588>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b72fcac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b72fce80>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b7334cf8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b7334b38>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b7334f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7366ac8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7366c18>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b7347be0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b733c400>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b733c128>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b733c208>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b7246cc0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7246e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b72830b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b7283048>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4670358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b733c438>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b733c4a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7347c50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7366b38>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b73669e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b7366b70>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b7334fd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b72830f0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b72175c0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b46705c0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4670470>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4670588>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4670828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b7334390>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b7334c88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7366898>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b73663c8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b7366080>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b7347b38>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b733c080>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b46704a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b71e5860>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b72177f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7217828>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b72176a0>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4670828>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b733c5c0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b733c2b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7347eb8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7366b00>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b73662e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b73669e8>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b7334ba8>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b72177b8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b71afa58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b71e5668>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b71e58d0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b71e59e8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=50, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b70c7b00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b70c7e10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b70d60f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b70d6390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b70d6630>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b70d69e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b70d6c88>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b70d6f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b71e5a20>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b7177c50>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7177dd8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7177cf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b70c7a90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b7094eb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b7107208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b71074a8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7107748>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b71079e8>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b7107da0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b7107f98>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b70aa390>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b70c7a58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4670518>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7366b70>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7366be0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b7094e48>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b707db00>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b707de10>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b72520f0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b7252390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b7252630>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b72529e8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b7252c88>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b7252f98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b7094e10>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b70b9208>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7366e80>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b70aaef0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b707da90>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4f649b0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4f64cc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4f64f60>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4f75240>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b4f754e0>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4f75898>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4f75b38>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4f75e48>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b707da58>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b7015b00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7015c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7015ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4f64940>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4f64c88>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4f64e48>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b3f43198>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3f437f0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3e0a630>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b3e0aa90>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b3e0ad30>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b3e0af98>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4f64908>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b707da58>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b7015c88>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b7015ba8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4f64f98>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b3e0a860>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b3e0a5f8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b3e0a898>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3f43978>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3f43128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b4f64be0>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4f75390>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4f75048>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4f64d30>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b3e0ad30>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b3e0af60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b3e0acf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3e0add8>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b4f754e0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4f75400>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4f64c18>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3f43278>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3f43b00>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b3f43198>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b3e0a978>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b3dddfd0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b3e0ab00>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b4f75048>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b4f75d30>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b4f75160>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b4f75128>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b3dddeb8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b3e0a748>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b3e0a7b8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b3f43048>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3f43128>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b3f430b8>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b4f64b70>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b4f75438>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4f75cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b3ae4be0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b3ae4da0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b3f47128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3f47240>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b70a0518>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b4f752b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b4f64b00>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b4f64dd8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b3f43358>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b3f43278>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b3e0aef0>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b3e0a978>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b3dddf60>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b2635668>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b262cfd0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b262cf98>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b3ddd978>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.4s
[CV] dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid 


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         1 
          rnn_hidden_layers_neurons: 100 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4aff7f7b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4aff7f208>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4aff7f470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4aff7fc50>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd4b0b0e518>, <tensorflow.python.keras.metrics.Precision object at 0x7fd4b0b0ed68>, <tensorflow.python.keras.metrics.Recall object at 0x7fd4b0b0eb00>, <tensorflow.python.keras.metrics.AUC object at 0x7fd4b0de9ef0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b70a0438>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b1fefac8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd50b14ceb8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd52f55c080>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4aff7f400>]
          

[CV]  dropout=True, dropout_rate=0.2, epochs=50, hidden_layer_activation=sigmoid, hidden_layers=2, hidden_layers_neurons=200, loss=binary_crossentropy, modelType=GRU, optimizer=adam, output_layer_activation=sigmoid, rnn_hidden_layers=1, rnn_hidden_layers_neurons=100, rnn_layer_activation=sigmoid, total=   0.5s


_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ 



        PARAMETERS:
        ________________________________ 
          rnn_hidden_layers:         0 
          rnn_hidden_layers_neurons: 50 
          hidden_layers:             2 
          hidden_layers_neurons:     200
          loss:                      binary_crossentropy
          optimizer:                 adam
          modelType:                 GRU
          dropout:                   True
          dropout_rate:              0.2
          input_shape:               (25, 12)
          output_dim:                1
          output_layer_activation:   sigmoid
          rnn_layer_activation:      sigmoid
          hidden_layer_activation:   sigmoid
          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fd4b560b2e8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fd4b0b0ea90>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fd4b0b0e6d8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fd4b5cd2e48>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fd52cc96048>, <tensorflow.python.keras.metrics.Precision object at 0x7fd519c80518>, <tensorflow.python.keras.metrics.Recall object at 0x7fd52cf43128>, <tensorflow.python.keras.metrics.AUC object at 0x7fd52e68bcc0>]]
          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fd4b4da3898>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fd4b0b0eb00>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fd4b0b0e630>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fd4b0b0eb38>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fd4b0b0e9e8>]
          

Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 50)                9600      
_________________________________________________________________
dense_240 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_240 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_241 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
MODEL SUMMARY: 

 None
Train on 285428 samples, validate on 237858 samples
Epoch 1/50
Epoch 1/50

Epoch 00001: val_recall did not improve from 0.79465
285428/285428 - 120s - loss: 0.0410 - tp: 742.0000 - fp: 433.0000 - tn: 281534.0000 - fn: 2719.0000 - accuracy: 0.9890 - precision: 0.6315 - recall: 0.2144 - auc: 0.9105 - val_loss: 0.0278 - val_tp: 1086.0000 - val_fp: 409.0000 - val_tn: 234610.0000 - val_fn: 1753.0000 - val_accuracy: 0.9909 - val_precision: 0.7264 - val_recall: 0.3825 - val_auc: 0.9694
285428/285428 - 120s - loss: 0.0410 - tp: 742.0000 - fp: 433.0000 - tn: 281534.0000 - fn: 2719.0000 - accuracy: 0.9890 - precision: 0.6315 - recall: 0.2144 - auc: 0.9105 - val_loss: 0.0278 - val_tp: 1086.0000 - val_fp: 409.0000 - val_tn: 234610.0000 - val_fn: 1753.0000 - val_accuracy: 0.9909 - val_precision: 0.7264 - val_recall: 0.3825 - val_auc: 0.9694
Epoch 2/50
Epoch 2/50

Epoch 00002: val_recall did not improve from 0.79465
285428/285428 - 117s - loss: 0.0246 - tp: 1742.0000 - fp: 473.0000 - tn: 281494.0000 - fn: 1719.0000 - accuracy: 0.9923 - precision: 0.7865 - recall: 0.5033 - auc: 0.9688 - val_loss: 0.0239 - val_tp: 2075.0000 - val_fp: 1054.0000 - val_tn: 233965.0000 - val_fn: 764.0000 - val_accuracy: 0.9924 - val_precision: 0.6632 - val_recall: 0.7309 - val_auc: 0.9870
285428/285428 - 117s - loss: 0.0246 - tp: 1742.0000 - fp: 473.0000 - tn: 281494.0000 - fn: 1719.0000 - accuracy: 0.9923 - precision: 0.7865 - recall: 0.5033 - auc: 0.9688 - val_loss: 0.0239 - val_tp: 2075.0000 - val_fp: 1054.0000 - val_tn: 233965.0000 - val_fn: 764.0000 - val_accuracy: 0.9924 - val_precision: 0.6632 - val_recall: 0.7309 - val_auc: 0.9870
Epoch 00002: early stopping


_ _ _ _ _ _ _ _ _ _  RNN TRAINING RESULTS _ _ _ _ _ _ _ _ _ _ 



          BEST ESTIMATOR:          <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4b0b0ecc0> 
          BEST SCORE:              0.624620912337056
          BEST PARAMS:             {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}
          BEST INDEX IN CV SEARCH: 12
          SCORER FUNCTIONS:        {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}
          

          HISTORY OBJ:             GridSearchCV(cv=10, error_score=nan,
             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd6083ede10>,
             iid='deprecated', n_jobs=1,
             param_grid={'dropout': [True], 'dropout_rate': [0.2],
                         'epochs': [50], 'hidden_layer_activation': ['sigmoid'],
                         'hidden_layers': [2],
                         'hidden_layers_neurons': [100, 200],
                         'loss': ['binary_crossentropy'],
                         'modelType': ['LSTM', 'GRU'], 'optimizer': ['adam'],
                         'output_layer_activation': ['sigmoid'],
                         'rnn_hidden_layers': [0, 1],
                         'rnn_hidden_layers_neurons': [50, 100],
                         'rnn_layer_activation': ['sigmoid']},
             pre_dispatch='1*n_jobs', refit='recall', return_train_score=True,
             scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1',
                      'average_precision'],
             verbose=2)        
        


cv_results_dict: 
    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_dropout param_dropout_rate param_epochs param_hidden_layer_activation param_hidden_layers param_hidden_layers_neurons           param_loss param_modelType param_optimizer param_output_layer_activation param_rnn_hidden_layers param_rnn_hidden_layers_neurons param_rnn_layer_activation                                                                                                                                                                                                                                                                                                                                                    params  split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  split5_test_accuracy  split6_test_accuracy  split7_test_accuracy  split8_test_accuracy  split9_test_accuracy  mean_test_accuracy  std_test_accuracy  rank_test_accuracy  split0_train_accuracy  split1_train_accuracy  split2_train_accuracy  split3_train_accuracy  split4_train_accuracy  split5_train_accuracy  split6_train_accuracy  split7_train_accuracy  split8_train_accuracy  split9_train_accuracy  mean_train_accuracy  std_train_accuracy  split0_test_precision  split1_test_precision  split2_test_precision  split3_test_precision  split4_test_precision  split5_test_precision  split6_test_precision  split7_test_precision  split8_test_precision  split9_test_precision  mean_test_precision  std_test_precision  rank_test_precision  split0_train_precision  split1_train_precision  split2_train_precision  split3_train_precision  split4_train_precision  split5_train_precision  split6_train_precision  split7_train_precision  split8_train_precision  split9_train_precision  mean_train_precision  std_train_precision  split0_test_recall  split1_test_recall  split2_test_recall  split3_test_recall  split4_test_recall  split5_test_recall  split6_test_recall  split7_test_recall  split8_test_recall  split9_test_recall  mean_test_recall  std_test_recall  rank_test_recall  split0_train_recall  split1_train_recall  split2_train_recall  split3_train_recall  split4_train_recall  split5_train_recall  split6_train_recall  split7_train_recall  split8_train_recall  split9_train_recall  mean_train_recall  std_train_recall  split0_test_roc_auc  split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  split4_test_roc_auc  split5_test_roc_auc  split6_test_roc_auc  split7_test_roc_auc  split8_test_roc_auc  split9_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  rank_test_roc_auc  split0_train_roc_auc  split1_train_roc_auc  split2_train_roc_auc  split3_train_roc_auc  split4_train_roc_auc  split5_train_roc_auc  split6_train_roc_auc  split7_train_roc_auc  split8_train_roc_auc  split9_train_roc_auc  mean_train_roc_auc  std_train_roc_auc  split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  split5_test_f1  split6_test_f1  split7_test_f1  split8_test_f1  split9_test_f1  mean_test_f1  std_test_f1  rank_test_f1  split0_train_f1  split1_train_f1  split2_train_f1  split3_train_f1  split4_train_f1  split5_train_f1  split6_train_f1  split7_train_f1  split8_train_f1  split9_train_f1  mean_train_f1  std_train_f1  split0_test_average_precision  split1_test_average_precision  split2_test_average_precision  split3_test_average_precision  split4_test_average_precision  split5_test_average_precision  split6_test_average_precision  split7_test_average_precision  split8_test_average_precision  split9_test_average_precision  mean_test_average_precision  std_test_average_precision  rank_test_average_precision  split0_train_average_precision  split1_train_average_precision  split2_train_average_precision  split3_train_average_precision  split4_train_average_precision  split5_train_average_precision  split6_train_average_precision  split7_train_average_precision  split8_train_average_precision  split9_train_average_precision  mean_train_average_precision  std_train_average_precision
0   208.219845     0.403172      5.017378         0.090000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.993343              0.993098              0.993729              0.992362              0.993974              0.993519              0.992538              0.993273              0.993203              0.994710              0.993375            0.000643           4                   0.993351               0.992304               0.993721               0.993519               0.993417               0.993877               0.993865               0.993382               0.993308               0.993686               0.993443             0.000429            0.771536               0.920245               0.857759               0.831858               0.801688               0.831373               0.741538               0.790441               0.880383               0.839416               0.826624             0.050043            4                    0.780237                0.917878                0.858028                0.876582                0.818381                0.822269                0.779211                0.811204                0.839277                0.799920                0.830299              0.041559             0.614925            0.449102            0.576812            0.510870            0.603175            0.598870            0.651351            0.614286            0.521246            0.682493            0.582313          0.066488         6                 0.631478             0.403902             0.577985             0.537342             0.594406             0.629868             0.683921             0.591128             0.552767             0.641165             0.584396           0.073070          0.991125             0.985582             0.990887             0.988669             0.986117             0.990090             0.990992             0.987623             0.989133             0.987133             0.988735           0.001950          8                  0.989190              0.988743              0.989298              0.989447              0.988811              0.989671              0.989693              0.988731              0.989178              0.989748              0.989251            0.000373           0.684385        0.603622        0.689775        0.632997        0.688406        0.696223        0.693525        0.691318        0.654804        0.752864        0.678792      0.038382     6             0.698020         0.560959         0.690700         0.666266         0.688639         0.713322         0.728463         0.683897         0.666537         0.711798         0.680860       0.044195      0.746406                       0.771655                       0.747973                       0.733147                       0.742733                       0.783496                       0.749673                       0.739017                       0.772299                       0.786489                       0.757289                     0.018338                    7                            0.744896                        0.758482                        0.769659                        0.767773                        0.752852                        0.769992                        0.770321                        0.740708                        0.750773                        0.764374                        0.758983                      0.010525                   
1   272.386824     38.775827     6.676018         0.023431        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993378              0.994254              0.993799              0.992012              0.992713              0.993413              0.992432              0.993413              0.993448              0.994569              0.993343            0.000746           5                   0.993511               0.993289               0.993772               0.993265               0.993020               0.993740               0.993838               0.993511               0.993534               0.993713               0.993519             0.000249            0.854369               0.872807               0.850000               0.830189               0.654179               0.932292               0.798450               0.829268               0.840164               0.837037               0.829875             0.067344            3                    0.866031                0.867085                0.847706                0.883944                0.706439                0.915235                0.853991                0.846449                0.804119                0.796930                0.838793              0.055014             0.525373            0.595808            0.591304            0.478261            0.720635            0.505650            0.556757            0.582857            0.580737            0.670623            0.580800          0.069119         8                 0.552143             0.529901             0.593068             0.507274             0.735855             0.531703             0.588483             0.567020             0.615508             0.648207             0.586916           0.064066          0.990338             0.988597             0.990827             0.988273             0.986972             0.989666             0.991388             0.988273             0.990802             0.986205             0.989134           0.001658          5                  0.988927              0.989136              0.989467              0.989517              0.989342              0.990059              0.989624              0.989657              0.989677              0.989343              0.989475            0.000298           0.650647        0.708185        0.697436        0.606897        0.685801        0.655678        0.656051        0.684564        0.686767        0.744646        0.677667      0.035629     7             0.674350         0.657801         0.697885         0.644618         0.720847         0.672638         0.696801         0.679115         0.697284         0.714916         0.685626       0.023030      0.772694                       0.780240                       0.757585                       0.726467                       0.758032                       0.803410                       0.748911                       0.757014                       0.773523                       0.779721                       0.765760                     0.019903                    3                            0.766708                        0.762226                        0.768679                        0.767013                        0.767534                        0.794706                        0.771594                        0.761194                        0.752412                        0.760761                        0.767283                      0.010485                   
2   0.441566       0.002064      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 9                  NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  9                   NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               9                NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                9                 NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           9            NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          9                           NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
3   0.441421       0.003144      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 10                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  10                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               10               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                10                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           10           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          10                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
4   218.580441     1.017036      4.670575         0.195058        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.992187              0.994394              0.993799              0.992187              0.993834              0.993308              0.992678              0.993413              0.993588              0.994009              0.993340            0.000720           6                   0.992600               0.993690               0.993663               0.993542               0.993760               0.993709               0.993655               0.993203               0.993659               0.993258               0.993474             0.000343            0.645833               0.808511               0.820611               0.805907               0.735593               0.838174               0.820717               0.852174               0.916667               0.923469               0.816766             0.076877            7                    0.676564                0.796457                0.800000                0.857784                0.771942                0.838095                0.859675                0.859779                0.867362                0.878672                0.820633              0.058678             0.740299            0.682635            0.623188            0.519022            0.688889            0.570621            0.556757            0.560000            0.529745            0.537092            0.600825          0.073978         4                 0.750800             0.646946             0.636714             0.555771             0.696122             0.594786             0.564866             0.524269             0.561776             0.516965             0.604901           0.072526          0.991347             0.986706             0.988727             0.989833             0.986232             0.991317             0.990640             0.987367             0.989939             0.986214             0.988832           0.001957          7                  0.988763              0.989289              0.988328              0.988789              0.989635              0.989634              0.989399              0.988875              0.989231              0.988571              0.989051            0.000427           0.689847        0.740260        0.708402        0.631405        0.711475        0.678992        0.663446        0.675862        0.671454        0.679174        0.685032      0.028284     5             0.711751         0.713958         0.709078         0.674514         0.732074         0.695783         0.681765         0.651358         0.681898         0.650947         0.690313       0.025701      0.771331                       0.774802                       0.746546                       0.718873                       0.761134                       0.776382                       0.738047                       0.748152                       0.790455                       0.783939                       0.760966                     0.021455                    5                            0.766154                        0.760771                        0.757296                        0.753990                        0.772599                        0.755165                        0.761947                        0.749466                        0.765943                        0.760186                        0.760352                      0.006426                   
5   253.600077     0.973960      5.809167         0.215442        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993799              0.994640              0.993519              0.992222              0.994394              0.993589              0.992923              0.994114              0.993238              0.994219              0.993666            0.000696           2                   0.993873               0.993884               0.993433               0.993698               0.993627               0.993849               0.994165               0.994091               0.993355               0.993320               0.993729             0.000280            0.895000               0.831502               0.870370               0.723926               0.811245               0.863830               0.793706               0.805369               0.921053               0.816176               0.833218             0.053765            2                    0.891524                0.829382                0.871169                0.773774                0.809602                0.853309                0.834735                0.820008                0.871224                0.776730                0.833146              0.037632             0.534328            0.679641            0.544928            0.641304            0.641270            0.573446            0.613514            0.685714            0.495751            0.658754            0.606865          0.062595         3                 0.565259             0.626479             0.538190             0.673456             0.627146             0.593499             0.642187             0.656059             0.528958             0.632522             0.608375           0.047148          0.992047             0.988491             0.990465             0.989628             0.986283             0.990909             0.991667             0.988696             0.990367             0.985081             0.989363           0.002150          1                  0.989790              0.989852              0.989536              0.989477              0.989065              0.989468              0.989288              0.990236              0.989544              0.987967              0.989422            0.000572           0.669159        0.747941        0.670232        0.680115        0.716312        0.689304        0.692073        0.740741        0.644567        0.729064        0.697951      0.032419     2             0.691856         0.713791         0.665344         0.720138         0.706788         0.700076         0.725910         0.728929         0.658258         0.697248         0.700834       0.022716      0.798382                       0.781060                       0.753731                       0.726567                       0.744993                       0.786674                       0.755170                       0.770814                       0.789367                       0.766073                       0.767283                     0.021259                    2                            0.784940                        0.765567                        0.763927                        0.762978                        0.757501                        0.770722                        0.780481                        0.775431                        0.759857                        0.741638                        0.766304                      0.011815                   
6   0.435566       0.001081      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 11                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  11                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               11               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                11                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           11           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          11                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
7   0.438416       0.002546      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 12                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  12                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               12               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                12                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           12           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          12                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
8   212.053315     0.625104      5.039687         0.014747        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.993589              0.994500              0.993554              0.992573              0.994219              0.993238              0.992397              0.990225              0.993098              0.994429              0.993182            0.001200           8                   0.993589               0.993569               0.993476               0.993795               0.993332               0.993413               0.993655               0.989727               0.993336               0.993659               0.993155             0.001151            0.848624               0.812721               0.818182               0.760000               0.844037               0.825911               0.742857               0.570297               0.923913               0.861789               0.800833             0.090698            8                    0.851975                0.799675                0.805603                0.800642                0.838131                0.809628                0.775973                0.552375                0.876483                0.822894                0.793338              0.084915             0.552239            0.688623            0.600000            0.619565            0.584127            0.576271            0.632432            0.822857            0.481586            0.629080            0.618678          0.085691         2                 0.572617             0.629357             0.609114             0.645328             0.564526             0.595430             0.664510             0.800064             0.522844             0.609795             0.621359           0.071206          0.991516             0.988606             0.990468             0.989462             0.987692             0.991055             0.990784             0.988574             0.988667             0.986296             0.989312           0.001569          4                  0.989517              0.989395              0.989324              0.989929              0.989740              0.989608              0.989538              0.990090              0.988850              0.989511              0.989550            0.000323           0.669078        0.745543        0.692308        0.682635        0.690432        0.678869        0.683212        0.673684        0.633147        0.727273        0.687618      0.029298     4             0.684905         0.704366         0.693713         0.714644         0.674644         0.686202         0.715929         0.653538         0.654978         0.700496         0.688342       0.021011      0.770439                       0.775959                       0.740390                       0.725093                       0.747663                       0.767619                       0.742227                       0.757553                       0.778165                       0.784170                       0.758928                     0.018443                    6                            0.762707                        0.759141                        0.752738                        0.762399                        0.757234                        0.750381                        0.762169                        0.761310                        0.757366                        0.764839                        0.759028                      0.004405                   
9   276.777257     38.358818     6.761148         0.031556        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993203              0.993028              0.992538              0.992503              0.994359              0.993378              0.992117              0.993413              0.993518              0.994710              0.993277            0.000766           7                   0.993410               0.991919               0.992826               0.993651               0.993577               0.993690               0.993320               0.993417               0.993476               0.993631               0.993292             0.000515            0.743945               0.904192               0.854839               0.761905               0.859813               0.842324               0.808511               0.759615               0.881818               0.790625               0.820759             0.052917            5                    0.766853                0.878875                0.866859                0.802817                0.856870                0.830222                0.850586                0.764334                0.831481                0.740155                0.818905              0.045580             0.641791            0.452096            0.460870            0.608696            0.584127            0.573446            0.513514            0.677143            0.549575            0.750742            0.581200          0.088980         7                 0.658669             0.389831             0.482670             0.626576             0.570884             0.601223             0.539631             0.659916             0.577864             0.733995             0.584126           0.092787          0.991279             0.988208             0.990771             0.989221             0.987149             0.988960             0.989905             0.987830             0.989883             0.985677             0.988888           0.001622          6                  0.989216              0.988042              0.989327              0.989520              0.989897              0.988619              0.988884              0.989842              0.989663              0.989321              0.989233            0.000549           0.689103        0.602794        0.598870        0.676737        0.695652        0.682353        0.628099        0.716012        0.677138        0.770167        0.673693      0.049616     8             0.708656         0.540097         0.620078         0.703831         0.685235         0.697405         0.660333         0.708297         0.681853         0.737062         0.674285       0.053855      0.752914                       0.751172                       0.746768                       0.711576                       0.757849                       0.774329                       0.726942                       0.749203                       0.774148                       0.810583                       0.755548                     0.025745                    8                            0.748288                        0.728229                        0.750064                        0.759157                        0.766452                        0.759686                        0.748821                        0.754697                        0.754366                        0.783750                        0.755351                      0.013493                   
10  0.440051       0.001703      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 13                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  13                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               13               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                13                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           13           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          13                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
11  0.439634       0.003640      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 14                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  14                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               14               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                14                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           14           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          14                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
12  221.606839     1.005571      4.667612         0.034792        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.994079              0.993869              0.993729              0.993028              0.993308              0.993098              0.992538              0.994184              0.994009              0.994429              0.993627            0.000574           3                   0.993919               0.993269               0.993838               0.994165               0.992152               0.992915               0.993916               0.993849               0.993526               0.993589               0.993514             0.000570            0.786207               0.738739               0.864035               0.802867               0.913333               0.726225               0.747634               0.853846               0.837037               0.908257               0.817818             0.064728            6                    0.788987                0.737110                0.871546                0.833473                0.899011                0.709541                0.792496                0.850664                0.775029                0.874683                0.813254              0.059472             0.680597            0.736527            0.571014            0.608696            0.434921            0.711864            0.640541            0.634286            0.640227            0.587537            0.624621          0.080216         1                 0.682981             0.694915             0.577022             0.644035             0.404641             0.701320             0.669686             0.596914             0.655084             0.551857             0.617845           0.085922          0.991986             0.987756             0.990580             0.990066             0.986404             0.990899             0.990704             0.987539             0.990045             0.987414             0.989339           0.001787          3                  0.989597              0.989507              0.990161              0.990215              0.989121              0.989172              0.990046              0.989429              0.989115              0.990350              0.989671            0.000457           0.729600        0.737631        0.687609        0.692427        0.589247        0.718973        0.689956        0.727869        0.725522        0.713514        0.701235      0.041019     1             0.732167         0.715391         0.694343         0.726610         0.558089         0.705406         0.725934         0.701549         0.710026         0.676742         0.694626       0.048174      0.779857                       0.779495                       0.763082                       0.744160                       0.735738                       0.777817                       0.743253                       0.764403                       0.780390                       0.787310                       0.765550                     0.017590                    4                            0.772554                        0.764790                        0.776136                        0.780165                        0.748036                        0.756546                        0.771039                        0.770267                        0.755070                        0.768268                        0.766287                      0.009630                   
13  269.349563     38.031686     5.794978         0.029212        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993308              0.994745              0.994044              0.992468              0.994079              0.994184              0.992853              0.993974              0.993448              0.995270              0.993837            0.000800           1                   0.993507               0.993877               0.993970               0.993733               0.993410               0.994476               0.994110               0.993752               0.993511               0.994064               0.993841             0.000311            0.904494               0.856589               0.851406               0.834061               0.880208               0.807190               0.786207               0.844961               0.951087               0.907258               0.862346             0.046992            1                    0.911400                0.851584                0.846835                0.883998                0.892067                0.804473                0.829849                0.842273                0.893931                0.859003                0.861541              0.031505             0.480597            0.661677            0.614493            0.519022            0.536508            0.697740            0.616216            0.622857            0.495751            0.667656            0.591252          0.073402         5                 0.516635             0.601855             0.613928             0.551891             0.525429             0.717734             0.642187             0.595628             0.526062             0.612356             0.590371           0.059477          0.990957             0.987920             0.989799             0.988312             0.988256             0.991377             0.990495             0.987376             0.991789             0.987325             0.989361           0.001627          2                  0.989232              0.988866              0.988889              0.990013              0.989425              0.989913              0.989856              0.989326              0.990410              0.990408              0.989634            0.000540           0.627680        0.746622        0.713805        0.639866        0.666667        0.748485        0.690909        0.717105        0.651769        0.769231        0.697214      0.046999     3             0.659453         0.705265         0.711814         0.679538         0.661332         0.758632         0.724056         0.697797         0.662346         0.715007         0.697524       0.030542      0.793315                       0.787653                       0.757727                       0.737529                       0.768249                       0.809667                       0.746407                       0.764492                       0.807545                       0.807853                       0.778044                     0.025336                    1                            0.781161                        0.774066                        0.777060                        0.778396                        0.774518                        0.804796                        0.773081                        0.770721                        0.781132                        0.779919                        0.779485                      0.009084                   
14  0.441934       0.001914      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 15                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  15                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               15               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                15                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           15           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          15                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
15  0.443334       0.005549      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 16                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  16                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               16               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                16                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           16           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          16                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
Total time: 23919.52  seconds or 398.66 minutes. Saving model to: customer_batches_rnn_best_model.h5
Saving best estimator at rnn_model.h5 and weights at rnn_model_weights.h5
<tensorflow.python.keras.engine.sequential.Sequential object at 0x7fd5e83bef98>
CMD: ls *.h5
OUT: customer_batches_rnn_best_model.h5
rnn_model.h5
rnn_model_weights.h5
----------
    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_dropout param_dropout_rate param_epochs param_hidden_layer_activation param_hidden_layers param_hidden_layers_neurons           param_loss param_modelType param_optimizer param_output_layer_activation param_rnn_hidden_layers param_rnn_hidden_layers_neurons param_rnn_layer_activation                                                                                                                                                                                                                                                                                                                                                    params  split0_test_accuracy  split1_test_accuracy  split2_test_accuracy  split3_test_accuracy  split4_test_accuracy  split5_test_accuracy  split6_test_accuracy  split7_test_accuracy  split8_test_accuracy  split9_test_accuracy  mean_test_accuracy  std_test_accuracy  rank_test_accuracy  split0_train_accuracy  split1_train_accuracy  split2_train_accuracy  split3_train_accuracy  split4_train_accuracy  split5_train_accuracy  split6_train_accuracy  split7_train_accuracy  split8_train_accuracy  split9_train_accuracy  mean_train_accuracy  std_train_accuracy  split0_test_precision  split1_test_precision  split2_test_precision  split3_test_precision  split4_test_precision  split5_test_precision  split6_test_precision  split7_test_precision  split8_test_precision  split9_test_precision  mean_test_precision  std_test_precision  rank_test_precision  split0_train_precision  split1_train_precision  split2_train_precision  split3_train_precision  split4_train_precision  split5_train_precision  split6_train_precision  split7_train_precision  split8_train_precision  split9_train_precision  mean_train_precision  std_train_precision  split0_test_recall  split1_test_recall  split2_test_recall  split3_test_recall  split4_test_recall  split5_test_recall  split6_test_recall  split7_test_recall  split8_test_recall  split9_test_recall  mean_test_recall  std_test_recall  rank_test_recall  split0_train_recall  split1_train_recall  split2_train_recall  split3_train_recall  split4_train_recall  split5_train_recall  split6_train_recall  split7_train_recall  split8_train_recall  split9_train_recall  mean_train_recall  std_train_recall  split0_test_roc_auc  split1_test_roc_auc  split2_test_roc_auc  split3_test_roc_auc  split4_test_roc_auc  split5_test_roc_auc  split6_test_roc_auc  split7_test_roc_auc  split8_test_roc_auc  split9_test_roc_auc  mean_test_roc_auc  std_test_roc_auc  rank_test_roc_auc  split0_train_roc_auc  split1_train_roc_auc  split2_train_roc_auc  split3_train_roc_auc  split4_train_roc_auc  split5_train_roc_auc  split6_train_roc_auc  split7_train_roc_auc  split8_train_roc_auc  split9_train_roc_auc  mean_train_roc_auc  std_train_roc_auc  split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  split4_test_f1  split5_test_f1  split6_test_f1  split7_test_f1  split8_test_f1  split9_test_f1  mean_test_f1  std_test_f1  rank_test_f1  split0_train_f1  split1_train_f1  split2_train_f1  split3_train_f1  split4_train_f1  split5_train_f1  split6_train_f1  split7_train_f1  split8_train_f1  split9_train_f1  mean_train_f1  std_train_f1  split0_test_average_precision  split1_test_average_precision  split2_test_average_precision  split3_test_average_precision  split4_test_average_precision  split5_test_average_precision  split6_test_average_precision  split7_test_average_precision  split8_test_average_precision  split9_test_average_precision  mean_test_average_precision  std_test_average_precision  rank_test_average_precision  split0_train_average_precision  split1_train_average_precision  split2_train_average_precision  split3_train_average_precision  split4_train_average_precision  split5_train_average_precision  split6_train_average_precision  split7_train_average_precision  split8_train_average_precision  split9_train_average_precision  mean_train_average_precision  std_train_average_precision
0   208.219845     0.403172      5.017378         0.090000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.993343              0.993098              0.993729              0.992362              0.993974              0.993519              0.992538              0.993273              0.993203              0.994710              0.993375            0.000643           4                   0.993351               0.992304               0.993721               0.993519               0.993417               0.993877               0.993865               0.993382               0.993308               0.993686               0.993443             0.000429            0.771536               0.920245               0.857759               0.831858               0.801688               0.831373               0.741538               0.790441               0.880383               0.839416               0.826624             0.050043            4                    0.780237                0.917878                0.858028                0.876582                0.818381                0.822269                0.779211                0.811204                0.839277                0.799920                0.830299              0.041559             0.614925            0.449102            0.576812            0.510870            0.603175            0.598870            0.651351            0.614286            0.521246            0.682493            0.582313          0.066488         6                 0.631478             0.403902             0.577985             0.537342             0.594406             0.629868             0.683921             0.591128             0.552767             0.641165             0.584396           0.073070          0.991125             0.985582             0.990887             0.988669             0.986117             0.990090             0.990992             0.987623             0.989133             0.987133             0.988735           0.001950          8                  0.989190              0.988743              0.989298              0.989447              0.988811              0.989671              0.989693              0.988731              0.989178              0.989748              0.989251            0.000373           0.684385        0.603622        0.689775        0.632997        0.688406        0.696223        0.693525        0.691318        0.654804        0.752864        0.678792      0.038382     6             0.698020         0.560959         0.690700         0.666266         0.688639         0.713322         0.728463         0.683897         0.666537         0.711798         0.680860       0.044195      0.746406                       0.771655                       0.747973                       0.733147                       0.742733                       0.783496                       0.749673                       0.739017                       0.772299                       0.786489                       0.757289                     0.018338                    7                            0.744896                        0.758482                        0.769659                        0.767773                        0.752852                        0.769992                        0.770321                        0.740708                        0.750773                        0.764374                        0.758983                      0.010525                   
1   272.386824     38.775827     6.676018         0.023431        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993378              0.994254              0.993799              0.992012              0.992713              0.993413              0.992432              0.993413              0.993448              0.994569              0.993343            0.000746           5                   0.993511               0.993289               0.993772               0.993265               0.993020               0.993740               0.993838               0.993511               0.993534               0.993713               0.993519             0.000249            0.854369               0.872807               0.850000               0.830189               0.654179               0.932292               0.798450               0.829268               0.840164               0.837037               0.829875             0.067344            3                    0.866031                0.867085                0.847706                0.883944                0.706439                0.915235                0.853991                0.846449                0.804119                0.796930                0.838793              0.055014             0.525373            0.595808            0.591304            0.478261            0.720635            0.505650            0.556757            0.582857            0.580737            0.670623            0.580800          0.069119         8                 0.552143             0.529901             0.593068             0.507274             0.735855             0.531703             0.588483             0.567020             0.615508             0.648207             0.586916           0.064066          0.990338             0.988597             0.990827             0.988273             0.986972             0.989666             0.991388             0.988273             0.990802             0.986205             0.989134           0.001658          5                  0.988927              0.989136              0.989467              0.989517              0.989342              0.990059              0.989624              0.989657              0.989677              0.989343              0.989475            0.000298           0.650647        0.708185        0.697436        0.606897        0.685801        0.655678        0.656051        0.684564        0.686767        0.744646        0.677667      0.035629     7             0.674350         0.657801         0.697885         0.644618         0.720847         0.672638         0.696801         0.679115         0.697284         0.714916         0.685626       0.023030      0.772694                       0.780240                       0.757585                       0.726467                       0.758032                       0.803410                       0.748911                       0.757014                       0.773523                       0.779721                       0.765760                     0.019903                    3                            0.766708                        0.762226                        0.768679                        0.767013                        0.767534                        0.794706                        0.771594                        0.761194                        0.752412                        0.760761                        0.767283                      0.010485                   
2   0.441566       0.002064      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 9                  NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  9                   NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               9                NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                9                 NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           9            NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          9                           NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
3   0.441421       0.003144      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 10                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  10                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               10               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                10                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           10           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          10                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
4   218.580441     1.017036      4.670575         0.195058        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.992187              0.994394              0.993799              0.992187              0.993834              0.993308              0.992678              0.993413              0.993588              0.994009              0.993340            0.000720           6                   0.992600               0.993690               0.993663               0.993542               0.993760               0.993709               0.993655               0.993203               0.993659               0.993258               0.993474             0.000343            0.645833               0.808511               0.820611               0.805907               0.735593               0.838174               0.820717               0.852174               0.916667               0.923469               0.816766             0.076877            7                    0.676564                0.796457                0.800000                0.857784                0.771942                0.838095                0.859675                0.859779                0.867362                0.878672                0.820633              0.058678             0.740299            0.682635            0.623188            0.519022            0.688889            0.570621            0.556757            0.560000            0.529745            0.537092            0.600825          0.073978         4                 0.750800             0.646946             0.636714             0.555771             0.696122             0.594786             0.564866             0.524269             0.561776             0.516965             0.604901           0.072526          0.991347             0.986706             0.988727             0.989833             0.986232             0.991317             0.990640             0.987367             0.989939             0.986214             0.988832           0.001957          7                  0.988763              0.989289              0.988328              0.988789              0.989635              0.989634              0.989399              0.988875              0.989231              0.988571              0.989051            0.000427           0.689847        0.740260        0.708402        0.631405        0.711475        0.678992        0.663446        0.675862        0.671454        0.679174        0.685032      0.028284     5             0.711751         0.713958         0.709078         0.674514         0.732074         0.695783         0.681765         0.651358         0.681898         0.650947         0.690313       0.025701      0.771331                       0.774802                       0.746546                       0.718873                       0.761134                       0.776382                       0.738047                       0.748152                       0.790455                       0.783939                       0.760966                     0.021455                    5                            0.766154                        0.760771                        0.757296                        0.753990                        0.772599                        0.755165                        0.761947                        0.749466                        0.765943                        0.760186                        0.760352                      0.006426                   
5   253.600077     0.973960      5.809167         0.215442        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993799              0.994640              0.993519              0.992222              0.994394              0.993589              0.992923              0.994114              0.993238              0.994219              0.993666            0.000696           2                   0.993873               0.993884               0.993433               0.993698               0.993627               0.993849               0.994165               0.994091               0.993355               0.993320               0.993729             0.000280            0.895000               0.831502               0.870370               0.723926               0.811245               0.863830               0.793706               0.805369               0.921053               0.816176               0.833218             0.053765            2                    0.891524                0.829382                0.871169                0.773774                0.809602                0.853309                0.834735                0.820008                0.871224                0.776730                0.833146              0.037632             0.534328            0.679641            0.544928            0.641304            0.641270            0.573446            0.613514            0.685714            0.495751            0.658754            0.606865          0.062595         3                 0.565259             0.626479             0.538190             0.673456             0.627146             0.593499             0.642187             0.656059             0.528958             0.632522             0.608375           0.047148          0.992047             0.988491             0.990465             0.989628             0.986283             0.990909             0.991667             0.988696             0.990367             0.985081             0.989363           0.002150          1                  0.989790              0.989852              0.989536              0.989477              0.989065              0.989468              0.989288              0.990236              0.989544              0.987967              0.989422            0.000572           0.669159        0.747941        0.670232        0.680115        0.716312        0.689304        0.692073        0.740741        0.644567        0.729064        0.697951      0.032419     2             0.691856         0.713791         0.665344         0.720138         0.706788         0.700076         0.725910         0.728929         0.658258         0.697248         0.700834       0.022716      0.798382                       0.781060                       0.753731                       0.726567                       0.744993                       0.786674                       0.755170                       0.770814                       0.789367                       0.766073                       0.767283                     0.021259                    2                            0.784940                        0.765567                        0.763927                        0.762978                        0.757501                        0.770722                        0.780481                        0.775431                        0.759857                        0.741638                        0.766304                      0.011815                   
6   0.435566       0.001081      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 11                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  11                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               11               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                11                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           11           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          11                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
7   0.438416       0.002546      0.000000         0.000000        True          0.2                50           sigmoid                       2                   100                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 12                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  12                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               12               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                12                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           12           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          12                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
8   212.053315     0.625104      5.039687         0.014747        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   0.993589              0.994500              0.993554              0.992573              0.994219              0.993238              0.992397              0.990225              0.993098              0.994429              0.993182            0.001200           8                   0.993589               0.993569               0.993476               0.993795               0.993332               0.993413               0.993655               0.989727               0.993336               0.993659               0.993155             0.001151            0.848624               0.812721               0.818182               0.760000               0.844037               0.825911               0.742857               0.570297               0.923913               0.861789               0.800833             0.090698            8                    0.851975                0.799675                0.805603                0.800642                0.838131                0.809628                0.775973                0.552375                0.876483                0.822894                0.793338              0.084915             0.552239            0.688623            0.600000            0.619565            0.584127            0.576271            0.632432            0.822857            0.481586            0.629080            0.618678          0.085691         2                 0.572617             0.629357             0.609114             0.645328             0.564526             0.595430             0.664510             0.800064             0.522844             0.609795             0.621359           0.071206          0.991516             0.988606             0.990468             0.989462             0.987692             0.991055             0.990784             0.988574             0.988667             0.986296             0.989312           0.001569          4                  0.989517              0.989395              0.989324              0.989929              0.989740              0.989608              0.989538              0.990090              0.988850              0.989511              0.989550            0.000323           0.669078        0.745543        0.692308        0.682635        0.690432        0.678869        0.683212        0.673684        0.633147        0.727273        0.687618      0.029298     4             0.684905         0.704366         0.693713         0.714644         0.674644         0.686202         0.715929         0.653538         0.654978         0.700496         0.688342       0.021011      0.770439                       0.775959                       0.740390                       0.725093                       0.747663                       0.767619                       0.742227                       0.757553                       0.778165                       0.784170                       0.758928                     0.018443                    6                            0.762707                        0.759141                        0.752738                        0.762399                        0.757234                        0.750381                        0.762169                        0.761310                        0.757366                        0.764839                        0.759028                      0.004405                   
9   276.777257     38.358818     6.761148         0.031556        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  0.993203              0.993028              0.992538              0.992503              0.994359              0.993378              0.992117              0.993413              0.993518              0.994710              0.993277            0.000766           7                   0.993410               0.991919               0.992826               0.993651               0.993577               0.993690               0.993320               0.993417               0.993476               0.993631               0.993292             0.000515            0.743945               0.904192               0.854839               0.761905               0.859813               0.842324               0.808511               0.759615               0.881818               0.790625               0.820759             0.052917            5                    0.766853                0.878875                0.866859                0.802817                0.856870                0.830222                0.850586                0.764334                0.831481                0.740155                0.818905              0.045580             0.641791            0.452096            0.460870            0.608696            0.584127            0.573446            0.513514            0.677143            0.549575            0.750742            0.581200          0.088980         7                 0.658669             0.389831             0.482670             0.626576             0.570884             0.601223             0.539631             0.659916             0.577864             0.733995             0.584126           0.092787          0.991279             0.988208             0.990771             0.989221             0.987149             0.988960             0.989905             0.987830             0.989883             0.985677             0.988888           0.001622          6                  0.989216              0.988042              0.989327              0.989520              0.989897              0.988619              0.988884              0.989842              0.989663              0.989321              0.989233            0.000549           0.689103        0.602794        0.598870        0.676737        0.695652        0.682353        0.628099        0.716012        0.677138        0.770167        0.673693      0.049616     8             0.708656         0.540097         0.620078         0.703831         0.685235         0.697405         0.660333         0.708297         0.681853         0.737062         0.674285       0.053855      0.752914                       0.751172                       0.746768                       0.711576                       0.757849                       0.774329                       0.726942                       0.749203                       0.774148                       0.810583                       0.755548                     0.025745                    8                            0.748288                        0.728229                        0.750064                        0.759157                        0.766452                        0.759686                        0.748821                        0.754697                        0.754366                        0.783750                        0.755351                      0.013493                   
10  0.440051       0.001703      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 13                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  13                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               13               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                13                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           13           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          13                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
11  0.439634       0.003640      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  LSTM            adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'} NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 14                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  14                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               14               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                14                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           14           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          14                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
12  221.606839     1.005571      4.667612         0.034792        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}    0.994079              0.993869              0.993729              0.993028              0.993308              0.993098              0.992538              0.994184              0.994009              0.994429              0.993627            0.000574           3                   0.993919               0.993269               0.993838               0.994165               0.992152               0.992915               0.993916               0.993849               0.993526               0.993589               0.993514             0.000570            0.786207               0.738739               0.864035               0.802867               0.913333               0.726225               0.747634               0.853846               0.837037               0.908257               0.817818             0.064728            6                    0.788987                0.737110                0.871546                0.833473                0.899011                0.709541                0.792496                0.850664                0.775029                0.874683                0.813254              0.059472             0.680597            0.736527            0.571014            0.608696            0.434921            0.711864            0.640541            0.634286            0.640227            0.587537            0.624621          0.080216         1                 0.682981             0.694915             0.577022             0.644035             0.404641             0.701320             0.669686             0.596914             0.655084             0.551857             0.617845           0.085922          0.991986             0.987756             0.990580             0.990066             0.986404             0.990899             0.990704             0.987539             0.990045             0.987414             0.989339           0.001787          3                  0.989597              0.989507              0.990161              0.990215              0.989121              0.989172              0.990046              0.989429              0.989115              0.990350              0.989671            0.000457           0.729600        0.737631        0.687609        0.692427        0.589247        0.718973        0.689956        0.727869        0.725522        0.713514        0.701235      0.041019     1             0.732167         0.715391         0.694343         0.726610         0.558089         0.705406         0.725934         0.701549         0.710026         0.676742         0.694626       0.048174      0.779857                       0.779495                       0.763082                       0.744160                       0.735738                       0.777817                       0.743253                       0.764403                       0.780390                       0.787310                       0.765550                     0.017590                    4                            0.772554                        0.764790                        0.776136                        0.780165                        0.748036                        0.756546                        0.771039                        0.770267                        0.755070                        0.768268                        0.766287                      0.009630                   
13  269.349563     38.031686     5.794978         0.029212        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       0                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}   0.993308              0.994745              0.994044              0.992468              0.994079              0.994184              0.992853              0.993974              0.993448              0.995270              0.993837            0.000800           1                   0.993507               0.993877               0.993970               0.993733               0.993410               0.994476               0.994110               0.993752               0.993511               0.994064               0.993841             0.000311            0.904494               0.856589               0.851406               0.834061               0.880208               0.807190               0.786207               0.844961               0.951087               0.907258               0.862346             0.046992            1                    0.911400                0.851584                0.846835                0.883998                0.892067                0.804473                0.829849                0.842273                0.893931                0.859003                0.861541              0.031505             0.480597            0.661677            0.614493            0.519022            0.536508            0.697740            0.616216            0.622857            0.495751            0.667656            0.591252          0.073402         5                 0.516635             0.601855             0.613928             0.551891             0.525429             0.717734             0.642187             0.595628             0.526062             0.612356             0.590371           0.059477          0.990957             0.987920             0.989799             0.988312             0.988256             0.991377             0.990495             0.987376             0.991789             0.987325             0.989361           0.001627          2                  0.989232              0.988866              0.988889              0.990013              0.989425              0.989913              0.989856              0.989326              0.990410              0.990408              0.989634            0.000540           0.627680        0.746622        0.713805        0.639866        0.666667        0.748485        0.690909        0.717105        0.651769        0.769231        0.697214      0.046999     3             0.659453         0.705265         0.711814         0.679538         0.661332         0.758632         0.724056         0.697797         0.662346         0.715007         0.697524       0.030542      0.793315                       0.787653                       0.757727                       0.737529                       0.768249                       0.809667                       0.746407                       0.764492                       0.807545                       0.807853                       0.778044                     0.025336                    1                            0.781161                        0.774066                        0.777060                        0.778396                        0.774518                        0.804796                        0.773081                        0.770721                        0.781132                        0.779919                        0.779485                      0.009084                   
14  0.441934       0.001914      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       50                              sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 15                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  15                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               15               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                15                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           15           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          15                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
15  0.443334       0.005549      0.000000         0.000000        True          0.2                50           sigmoid                       2                   200                         binary_crossentropy  GRU             adam            sigmoid                       1                       100                             sigmoid                    {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}  NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                 16                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                 NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                    NaN                  NaN                  16                  NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                     NaN                   NaN                  NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN                 NaN               NaN               16               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN               NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                  NaN                NaN                16                NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                   NaN                 NaN                NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN             NaN           NaN           16           NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN            NaN           NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                            NaN                          NaN                          16                          NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                             NaN                           NaN                         
{'scoring': ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision'], 'estimator': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd6083ede10>, 'n_jobs': 1, 'iid': 'deprecated', 'refit': 'recall', 'cv': 10, 'verbose': 2, 'pre_dispatch': '1*n_jobs', 'error_score': nan, 'return_train_score': True, 'param_grid': {'rnn_hidden_layers': [0, 1], 'rnn_hidden_layers_neurons': [50, 100], 'hidden_layers': [2], 'hidden_layers_neurons': [100, 200], 'loss': ['binary_crossentropy'], 'optimizer': ['adam'], 'modelType': ['LSTM', 'GRU'], 'epochs': [50], 'output_layer_activation': ['sigmoid'], 'rnn_layer_activation': ['sigmoid'], 'hidden_layer_activation': ['sigmoid'], 'dropout': [True], 'dropout_rate': [0.2]}, 'multimetric_': True, 'best_index_': 12, 'best_score_': 0.624620912337056, 'best_params_': {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, 'best_estimator_': <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4b0b0ecc0>, 'refit_time_': 242.27149367332458, 'scorer_': {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}, 'cv_results_': {'mean_fit_time': array([208.2198451 , 272.38682411,   0.44156628,   0.44142146,
       218.58044057, 253.6000767 ,   0.43556581,   0.43841581,
       212.05331478, 276.77725689,   0.44005101,   0.43963449,
       221.60683944, 269.34956281,   0.44193377,   0.44333394]), 'std_fit_time': array([4.03171743e-01, 3.87758270e+01, 2.06406609e-03, 3.14360246e-03,
       1.01703628e+00, 9.73959818e-01, 1.08051298e-03, 2.54601501e-03,
       6.25103935e-01, 3.83588180e+01, 1.70346524e-03, 3.64011486e-03,
       1.00557120e+00, 3.80316862e+01, 1.91432105e-03, 5.54878700e-03]), 'mean_score_time': array([5.01737821, 6.67601829, 0.        , 0.        , 4.67057502,
       5.80916669, 0.        , 0.        , 5.03968666, 6.76114767,
       0.        , 0.        , 4.6676122 , 5.79497826, 0.        ,
       0.        ]), 'std_score_time': array([0.09000016, 0.02343095, 0.        , 0.        , 0.19505776,
       0.21544164, 0.        , 0.        , 0.01474723, 0.03155629,
       0.        , 0.        , 0.03479222, 0.02921204, 0.        ,
       0.        ]), 'param_dropout': masked_array(data=[True, True, True, True, True, True, True, True, True,
                   True, True, True, True, True, True, True],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_dropout_rate': masked_array(data=[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,
                   0.2, 0.2, 0.2, 0.2, 0.2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_epochs': masked_array(data=[50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50,
                   50, 50],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_hidden_layers_neurons': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 200, 200, 200,
                   200, 200, 200, 200, 200],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_loss': masked_array(data=['binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy',
                   'binary_crossentropy', 'binary_crossentropy'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_modelType': masked_array(data=['LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU', 'GRU',
                   'GRU', 'LSTM', 'LSTM', 'LSTM', 'LSTM', 'GRU', 'GRU',
                   'GRU', 'GRU'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_optimizer': masked_array(data=['adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam', 'adam', 'adam', 'adam', 'adam', 'adam',
                   'adam', 'adam'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_output_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers': masked_array(data=[0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_hidden_layers_neurons': masked_array(data=[50, 100, 50, 100, 50, 100, 50, 100, 50, 100, 50, 100,
                   50, 100, 50, 100],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'param_rnn_layer_activation': masked_array(data=['sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid', 'sigmoid',
                   'sigmoid'],
             mask=[False, False, False, False, False, False, False, False,
                   False, False, False, False, False, False, False, False],
       fill_value='?',
            dtype=object), 'params': [{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}, {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}], 'split0_test_accuracy': array([0.99334338, 0.99337841,        nan,        nan, 0.99218723,
       0.99379883,        nan,        nan, 0.99358862, 0.99320324,
              nan,        nan, 0.99407911, 0.99330834,        nan,
              nan]), 'split1_test_accuracy': array([0.99309813, 0.99425428,        nan,        nan, 0.99439442,
       0.99463967,        nan,        nan, 0.99449953, 0.99302806,
              nan,        nan, 0.9938689 , 0.99474477,        nan,
              nan]), 'split2_test_accuracy': array([0.99372876, 0.99379883,        nan,        nan, 0.99379883,
       0.99351855,        nan,        nan, 0.99355359, 0.99253757,
              nan,        nan, 0.99372876, 0.99404407,        nan,
              nan]), 'split3_test_accuracy': array([0.9923624 , 0.99201205,        nan,        nan, 0.99218723,
       0.99222226,        nan,        nan, 0.99257261, 0.99250254,
              nan,        nan, 0.99302806, 0.99246751,        nan,
              nan]), 'split4_test_accuracy': array([0.993974  , 0.99271275,        nan,        nan, 0.99383386,
       0.99439442,        nan,        nan, 0.99421925, 0.99435939,
              nan,        nan, 0.99330834, 0.99407911,        nan,
              nan]), 'split5_test_accuracy': array([0.99351855, 0.99341345,        nan,        nan, 0.99330834,
       0.99358862,        nan,        nan, 0.99323827, 0.99337841,
              nan,        nan, 0.99309813, 0.99418421,        nan,
              nan]), 'split6_test_accuracy': array([0.99253757, 0.99243247,        nan,        nan, 0.99267771,
       0.99292296,        nan,        nan, 0.99239744, 0.99211716,
              nan,        nan, 0.99253757, 0.99285289,        nan,
              nan]), 'split7_test_accuracy': array([0.99327331, 0.99341345,        nan,        nan, 0.99341345,
       0.99411414,        nan,        nan, 0.99022527, 0.99341345,
              nan,        nan, 0.99418421, 0.993974  ,        nan,
              nan]), 'split8_test_accuracy': array([0.993203  , 0.99344825,        nan,        nan, 0.9935884 ,
       0.99323804,        nan,        nan, 0.99309789, 0.99351832,
              nan,        nan, 0.99400883, 0.99344825,        nan,
              nan]), 'split9_test_accuracy': array([0.99470955, 0.99456941,        nan,        nan, 0.99400883,
       0.99421905,        nan,        nan, 0.99442926, 0.99470955,
              nan,        nan, 0.99442926, 0.99527013,        nan,
              nan]), 'mean_test_accuracy': array([0.99337487, 0.99334333,        nan,        nan, 0.99333983,
       0.99366565,        nan,        nan, 0.99318217, 0.99327677,
              nan,        nan, 0.99362712, 0.99383733,        nan,
              nan]), 'std_test_accuracy': array([0.00064264, 0.0007458 ,        nan,        nan, 0.00071959,
       0.00069644,        nan,        nan, 0.00120043, 0.00076617,
              nan,        nan, 0.00057446, 0.00079958,        nan,
              nan]), 'rank_test_accuracy': array([ 4,  5,  9, 10,  6,  2, 11, 12,  8,  7, 13, 14,  3,  1, 15, 16],
      dtype=int32), 'split0_train_accuracy': array([0.99335111, 0.99351071,        nan,        nan, 0.9925998 ,
       0.99387274,        nan,        nan, 0.99358857, 0.9934095 ,
              nan,        nan, 0.99391946, 0.99350682,        nan,
              nan]), 'split1_train_accuracy': array([0.99230395, 0.99328883,        nan,        nan, 0.99368978,
       0.99388442,        nan,        nan, 0.99356911, 0.99191856,
              nan,        nan, 0.99326936, 0.99387664,        nan,
              nan]), 'split2_train_accuracy': array([0.99372093, 0.99377153,        nan,        nan, 0.99366253,
       0.99343286,        nan,        nan, 0.99347568, 0.99282558,
              nan,        nan, 0.99383771, 0.99397006,        nan,
              nan]), 'split3_train_accuracy': array([0.9935185 , 0.99326547,        nan,        nan, 0.99354186,
       0.99369757,        nan,        nan, 0.99379489, 0.99365086,
              nan,        nan, 0.9941647 , 0.9937326 ,        nan,
              nan]), 'split4_train_accuracy': array([0.99341729, 0.99302022,        nan,        nan, 0.99375985,
       0.9936275 ,        nan,        nan, 0.99333165, 0.99357689,
              nan,        nan, 0.99215213, 0.9934095 ,        nan,
              nan]), 'split5_train_accuracy': array([0.99387664, 0.99374039,        nan,        nan, 0.99370925,
       0.99384939,        nan,        nan, 0.9934134 , 0.99368978,
              nan,        nan, 0.99291512, 0.99447613,        nan,
              nan]), 'split6_train_accuracy': array([0.99386496, 0.99383771,        nan,        nan, 0.99365475,
       0.9941647 ,        nan,        nan, 0.99365475, 0.99331997,
              nan,        nan, 0.99391557, 0.9941102 ,        nan,
              nan]), 'split7_train_accuracy': array([0.99338225, 0.99351071,        nan,        nan, 0.99320318,
       0.99409074,        nan,        nan, 0.98972692, 0.99341729,
              nan,        nan, 0.99384939, 0.99375207,        nan,
              nan]), 'split8_train_accuracy': array([0.99330832, 0.9935341 ,        nan,        nan, 0.99365867,
       0.99335503,        nan,        nan, 0.99333557, 0.99347571,
              nan,        nan, 0.99352631, 0.99351074,        nan,
              nan]), 'split9_train_accuracy': array([0.99368592, 0.99371316,        nan,        nan, 0.99325771,
       0.99331999,        nan,        nan, 0.99365867, 0.99363142,
              nan,        nan, 0.9935886 , 0.99406351,        nan,
              nan]), 'mean_train_accuracy': array([0.99344299, 0.99351928,        nan,        nan, 0.99347374,
       0.9937295 ,        nan,        nan, 0.99315492, 0.99329156,
              nan,        nan, 0.99351383, 0.99384083,        nan,
              nan]), 'std_train_accuracy': array([0.00042853, 0.00024869,        nan,        nan, 0.00034277,
       0.00028038,        nan,        nan, 0.00115141, 0.00051491,
              nan,        nan, 0.00056967, 0.00031143,        nan,
              nan]), 'split0_test_precision': array([0.77153558, 0.85436893,        nan,        nan, 0.64583333,
       0.895     ,        nan,        nan, 0.84862385, 0.74394464,
              nan,        nan, 0.7862069 , 0.90449438,        nan,
              nan]), 'split1_test_precision': array([0.9202454 , 0.87280702,        nan,        nan, 0.80851064,
       0.83150183,        nan,        nan, 0.81272085, 0.90419162,
              nan,        nan, 0.73873874, 0.85658915,        nan,
              nan]), 'split2_test_precision': array([0.85775862, 0.85      ,        nan,        nan, 0.82061069,
       0.87037037,        nan,        nan, 0.81818182, 0.85483871,
              nan,        nan, 0.86403509, 0.85140562,        nan,
              nan]), 'split3_test_precision': array([0.83185841, 0.83018868,        nan,        nan, 0.80590717,
       0.72392638,        nan,        nan, 0.76      , 0.76190476,
              nan,        nan, 0.80286738, 0.83406114,        nan,
              nan]), 'split4_test_precision': array([0.80168776, 0.65417867,        nan,        nan, 0.73559322,
       0.81124498,        nan,        nan, 0.8440367 , 0.85981308,
              nan,        nan, 0.91333333, 0.88020833,        nan,
              nan]), 'split5_test_precision': array([0.83137255, 0.93229167,        nan,        nan, 0.83817427,
       0.86382979,        nan,        nan, 0.82591093, 0.84232365,
              nan,        nan, 0.72622478, 0.80718954,        nan,
              nan]), 'split6_test_precision': array([0.74153846, 0.79844961,        nan,        nan, 0.82071713,
       0.79370629,        nan,        nan, 0.74285714, 0.80851064,
              nan,        nan, 0.74763407, 0.7862069 ,        nan,
              nan]), 'split7_test_precision': array([0.79044118, 0.82926829,        nan,        nan, 0.85217391,
       0.80536913,        nan,        nan, 0.57029703, 0.75961538,
              nan,        nan, 0.85384615, 0.84496124,        nan,
              nan]), 'split8_test_precision': array([0.88038278, 0.84016393,        nan,        nan, 0.91666667,
       0.92105263,        nan,        nan, 0.92391304, 0.88181818,
              nan,        nan, 0.83703704, 0.95108696,        nan,
              nan]), 'split9_test_precision': array([0.83941606, 0.83703704,        nan,        nan, 0.92346939,
       0.81617647,        nan,        nan, 0.86178862, 0.790625  ,
              nan,        nan, 0.90825688, 0.90725806,        nan,
              nan]), 'mean_test_precision': array([0.82662368, 0.82987538,        nan,        nan, 0.81676564,
       0.83321779,        nan,        nan, 0.800833  , 0.82075857,
              nan,        nan, 0.81781804, 0.86234613,        nan,
              nan]), 'std_test_precision': array([0.0500432 , 0.06734365,        nan,        nan, 0.07687733,
       0.05376512,        nan,        nan, 0.09069806, 0.05291672,
              nan,        nan, 0.06472805, 0.04699159,        nan,
              nan]), 'rank_test_precision': array([ 4,  3,  9, 10,  7,  2, 11, 12,  8,  5, 13, 14,  6,  1, 15, 16],
      dtype=int32), 'split0_train_precision': array([0.78023715, 0.86603111,        nan,        nan, 0.67656385,
       0.89152371,        nan,        nan, 0.85197525, 0.76685289,
              nan,        nan, 0.78898744, 0.91139955,        nan,
              nan]), 'split1_train_precision': array([0.91787791, 0.8670853 ,        nan,        nan, 0.79645669,
       0.82938188,        nan,        nan, 0.79967493, 0.87887527,
              nan,        nan, 0.73710991, 0.85158371,        nan,
              nan]), 'split2_train_precision': array([0.85802763, 0.84770642,        nan,        nan, 0.8       ,
       0.87116883,        nan,        nan, 0.80560272, 0.86685879,
              nan,        nan, 0.87154629, 0.84683488,        nan,
              nan]), 'split3_train_precision': array([0.87658228, 0.88394366,        nan,        nan, 0.85778443,
       0.77377415,        nan,        nan, 0.8006418 , 0.8028169 ,
              nan,        nan, 0.8334728 , 0.88399793,        nan,
              nan]), 'split4_train_precision': array([0.81838074, 0.70643882,        nan,        nan, 0.77194219,
       0.80960197,        nan,        nan, 0.83813119, 0.85687023,
              nan,        nan, 0.8990113 , 0.89206692,        nan,
              nan]), 'split5_train_precision': array([0.82226891, 0.91523546,        nan,        nan, 0.83809524,
       0.85330865,        nan,        nan, 0.80962801, 0.83022222,
              nan,        nan, 0.70954087, 0.8044733 ,        nan,
              nan]), 'split6_train_precision': array([0.77921121, 0.85399061,        nan,        nan, 0.85967504,
       0.83473507,        nan,        nan, 0.7759728 , 0.85058644,
              nan,        nan, 0.79249617, 0.8298495 ,        nan,
              nan]), 'split7_train_precision': array([0.81120423, 0.84644914,        nan,        nan, 0.8597786 ,
       0.82000804,        nan,        nan, 0.55237461, 0.76433358,
              nan,        nan, 0.85066422, 0.84227273,        nan,
              nan]), 'split8_train_precision': array([0.83927699, 0.80411938,        nan,        nan, 0.86736215,
       0.87122417,        nan,        nan, 0.87648328, 0.83148148,
              nan,        nan, 0.77502855, 0.89393111,        nan,
              nan]), 'split9_train_precision': array([0.79992013, 0.79693034,        nan,        nan, 0.87867247,
       0.77672956,        nan,        nan, 0.82289417, 0.74015494,
              nan,        nan, 0.8746829 , 0.85900314,        nan,
              nan]), 'mean_train_precision': array([0.83029872, 0.83879302,        nan,        nan, 0.82063307,
       0.8331456 ,        nan,        nan, 0.79333788, 0.81890527,
              nan,        nan, 0.81325404, 0.86154128,        nan,
              nan]), 'std_train_precision': array([0.04155942, 0.05501437,        nan,        nan, 0.05867788,
       0.03763194,        nan,        nan, 0.08491505, 0.0455798 ,
              nan,        nan, 0.05947219, 0.0315045 ,        nan,
              nan]), 'split0_test_recall': array([0.61492537, 0.52537313,        nan,        nan, 0.74029851,
       0.53432836,        nan,        nan, 0.55223881, 0.64179104,
              nan,        nan, 0.68059701, 0.48059701,        nan,
              nan]), 'split1_test_recall': array([0.4491018 , 0.59580838,        nan,        nan, 0.68263473,
       0.67964072,        nan,        nan, 0.68862275, 0.45209581,
              nan,        nan, 0.73652695, 0.66167665,        nan,
              nan]), 'split2_test_recall': array([0.57681159, 0.59130435,        nan,        nan, 0.62318841,
       0.54492754,        nan,        nan, 0.6       , 0.46086957,
              nan,        nan, 0.57101449, 0.61449275,        nan,
              nan]), 'split3_test_recall': array([0.51086957, 0.47826087,        nan,        nan, 0.51902174,
       0.64130435,        nan,        nan, 0.61956522, 0.60869565,
              nan,        nan, 0.60869565, 0.51902174,        nan,
              nan]), 'split4_test_recall': array([0.6031746 , 0.72063492,        nan,        nan, 0.68888889,
       0.64126984,        nan,        nan, 0.58412698, 0.58412698,
              nan,        nan, 0.43492063, 0.53650794,        nan,
              nan]), 'split5_test_recall': array([0.59887006, 0.50564972,        nan,        nan, 0.57062147,
       0.57344633,        nan,        nan, 0.57627119, 0.57344633,
              nan,        nan, 0.71186441, 0.69774011,        nan,
              nan]), 'split6_test_recall': array([0.65135135, 0.55675676,        nan,        nan, 0.55675676,
       0.61351351,        nan,        nan, 0.63243243, 0.51351351,
              nan,        nan, 0.64054054, 0.61621622,        nan,
              nan]), 'split7_test_recall': array([0.61428571, 0.58285714,        nan,        nan, 0.56      ,
       0.68571429,        nan,        nan, 0.82285714, 0.67714286,
              nan,        nan, 0.63428571, 0.62285714,        nan,
              nan]), 'split8_test_recall': array([0.52124646, 0.58073654,        nan,        nan, 0.52974504,
       0.49575071,        nan,        nan, 0.4815864 , 0.54957507,
              nan,        nan, 0.64022663, 0.49575071,        nan,
              nan]), 'split9_test_recall': array([0.68249258, 0.67062315,        nan,        nan, 0.53709199,
       0.65875371,        nan,        nan, 0.62908012, 0.75074184,
              nan,        nan, 0.58753709, 0.66765579,        nan,
              nan]), 'mean_test_recall': array([0.58231291, 0.5808005 ,        nan,        nan, 0.60082475,
       0.60686493,        nan,        nan, 0.6186781 , 0.58119987,
              nan,        nan, 0.62462091, 0.59125161,        nan,
              nan]), 'std_test_recall': array([0.06648773, 0.06911865,        nan,        nan, 0.0739784 ,
       0.06259467,        nan,        nan, 0.08569062, 0.08897997,
              nan,        nan, 0.08021643, 0.07340181,        nan,
              nan]), 'rank_test_recall': array([ 6,  8,  9, 10,  4,  3, 11, 12,  2,  7, 13, 14,  1,  5, 15, 16],
      dtype=int32), 'split0_train_recall': array([0.63147793, 0.55214331,        nan,        nan, 0.75079974,
       0.56525912,        nan,        nan, 0.57261676, 0.65866923,
              nan,        nan, 0.68298145, 0.51663468,        nan,
              nan]), 'split1_train_recall': array([0.4039015 , 0.52990086,        nan,        nan, 0.64694595,
       0.62647905,        nan,        nan, 0.62935721, 0.38983051,
              nan,        nan, 0.69491525, 0.60185481,        nan,
              nan]), 'split2_train_recall': array([0.5779846 , 0.59306804,        nan,        nan, 0.63671374,
       0.53818999,        nan,        nan, 0.60911425, 0.48267009,
              nan,        nan, 0.57702182, 0.61392811,        nan,
              nan]), 'split3_train_recall': array([0.53734239, 0.50727449,        nan,        nan, 0.5557711 ,
       0.67345619,        nan,        nan, 0.64532816, 0.62657614,
              nan,        nan, 0.64403492, 0.55189137,        nan,
              nan]), 'split4_train_recall': array([0.59440559, 0.73585505,        nan,        nan, 0.69612206,
       0.62714558,        nan,        nan, 0.56452638, 0.57088366,
              nan,        nan, 0.40464081, 0.52542912,        nan,
              nan]), 'split5_train_recall': array([0.62986804, 0.53170261,        nan,        nan, 0.59478597,
       0.59349855,        nan,        nan, 0.59542967, 0.60122304,
              nan,        nan, 0.7013196 , 0.71773415,        nan,
              nan]), 'split6_train_recall': array([0.68392106, 0.58848269,        nan,        nan, 0.56486574,
       0.64218699,        nan,        nan, 0.66450987, 0.53963119,
              nan,        nan, 0.66968619, 0.64218699,        nan,
              nan]), 'split7_train_recall': array([0.59112825, 0.56702025,        nan,        nan, 0.52426872,
       0.65605914,        nan,        nan, 0.80006429, 0.65991643,
              nan,        nan, 0.59691418, 0.59562842,        nan,
              nan]), 'split8_train_recall': array([0.55276705, 0.61550837,        nan,        nan, 0.56177606,
       0.52895753,        nan,        nan, 0.52284427, 0.57786358,
              nan,        nan, 0.65508366, 0.52606178,        nan,
              nan]), 'split9_train_recall': array([0.64116517, 0.64820743,        nan,        nan, 0.51696543,
       0.63252241,        nan,        nan, 0.60979513, 0.73399488,
              nan,        nan, 0.55185659, 0.61235595,        nan,
              nan]), 'mean_train_recall': array([0.58439616, 0.58691631,        nan,        nan, 0.60490145,
       0.60837546,        nan,        nan, 0.6213586 , 0.58412587,
              nan,        nan, 0.61784545, 0.59037054,        nan,
              nan]), 'std_train_recall': array([0.07306963, 0.06406583,        nan,        nan, 0.07252615,
       0.04714779,        nan,        nan, 0.07120601, 0.09278701,
              nan,        nan, 0.08592197, 0.05947681,        nan,
              nan]), 'split0_test_roc_auc': array([0.9911252 , 0.99033798,        nan,        nan, 0.99134743,
       0.99204714,        nan,        nan, 0.99151601, 0.99127907,
              nan,        nan, 0.9919864 , 0.99095705,        nan,
              nan]), 'split1_test_roc_auc': array([0.98558228, 0.98859698,        nan,        nan, 0.98670648,
       0.98849148,        nan,        nan, 0.9886059 , 0.98820778,
              nan,        nan, 0.98775553, 0.98791951,        nan,
              nan]), 'split2_test_roc_auc': array([0.99088701, 0.99082677,        nan,        nan, 0.98872682,
       0.99046494,        nan,        nan, 0.99046792, 0.99077137,
              nan,        nan, 0.99057997, 0.98979895,        nan,
              nan]), 'split3_test_roc_auc': array([0.98866894, 0.98827302,        nan,        nan, 0.98983305,
       0.989628  ,        nan,        nan, 0.98946202, 0.98922061,
              nan,        nan, 0.99006645, 0.98831247,        nan,
              nan]), 'split4_test_roc_auc': array([0.9861169 , 0.98697196,        nan,        nan, 0.98623173,
       0.98628324,        nan,        nan, 0.98769195, 0.9871492 ,
              nan,        nan, 0.98640436, 0.98825628,        nan,
              nan]), 'split5_test_roc_auc': array([0.99009025, 0.9896663 ,        nan,        nan, 0.99131658,
       0.99090912,        nan,        nan, 0.99105473, 0.98895951,
              nan,        nan, 0.9908993 , 0.99137681,        nan,
              nan]), 'split6_test_roc_auc': array([0.99099224, 0.99138786,        nan,        nan, 0.99063988,
       0.99166693,        nan,        nan, 0.99078435, 0.98990523,
              nan,        nan, 0.99070444, 0.99049531,        nan,
              nan]), 'split7_test_roc_auc': array([0.98762347, 0.98827318,        nan,        nan, 0.98736708,
       0.98869557,        nan,        nan, 0.98857376, 0.9878295 ,
              nan,        nan, 0.98753916, 0.987376  ,        nan,
              nan]), 'split8_test_roc_auc': array([0.98913284, 0.99080157,        nan,        nan, 0.98993912,
       0.99036662,        nan,        nan, 0.98866715, 0.98988334,
              nan,        nan, 0.99004509, 0.99178913,        nan,
              nan]), 'split9_test_roc_auc': array([0.98713341, 0.98620507,        nan,        nan, 0.9862138 ,
       0.98508051,        nan,        nan, 0.98629581, 0.98567725,
              nan,        nan, 0.98741379, 0.98732521,        nan,
              nan]), 'mean_test_roc_auc': array([0.98873525, 0.98913407,        nan,        nan, 0.9888322 ,
       0.98936336,        nan,        nan, 0.98931196, 0.98888829,
              nan,        nan, 0.98933945, 0.98936067,        nan,
              nan]), 'std_test_roc_auc': array([0.00195021, 0.00165779,        nan,        nan, 0.00195673,
       0.00214999,        nan,        nan, 0.00156852, 0.00162237,
              nan,        nan, 0.0017872 , 0.00162689,        nan,
              nan]), 'rank_test_roc_auc': array([ 8,  5,  9, 10,  7,  1, 11, 12,  4,  6, 13, 14,  3,  2, 15, 16],
      dtype=int32), 'split0_train_roc_auc': array([0.98918988, 0.98892699,        nan,        nan, 0.98876251,
       0.98978986,        nan,        nan, 0.98951741, 0.98921645,
              nan,        nan, 0.98959717, 0.98923177,        nan,
              nan]), 'split1_train_roc_auc': array([0.98874319, 0.98913638,        nan,        nan, 0.98928858,
       0.98985184,        nan,        nan, 0.98939538, 0.98804228,
              nan,        nan, 0.98950739, 0.98886593,        nan,
              nan]), 'split2_train_roc_auc': array([0.98929786, 0.98946701,        nan,        nan, 0.98832797,
       0.98953626,        nan,        nan, 0.98932408, 0.98932708,
              nan,        nan, 0.99016051, 0.98888934,        nan,
              nan]), 'split3_train_roc_auc': array([0.98944686, 0.98951681,        nan,        nan, 0.98878905,
       0.98947734,        nan,        nan, 0.98992905, 0.98952024,
              nan,        nan, 0.99021524, 0.99001284,        nan,
              nan]), 'split4_train_roc_auc': array([0.98881114, 0.98934166,        nan,        nan, 0.98963507,
       0.98906462,        nan,        nan, 0.98973975, 0.98989715,
              nan,        nan, 0.98912079, 0.98942481,        nan,
              nan]), 'split5_train_roc_auc': array([0.98967074, 0.99005944,        nan,        nan, 0.98963428,
       0.98946793,        nan,        nan, 0.98960795, 0.98861863,
              nan,        nan, 0.9891717 , 0.98991324,        nan,
              nan]), 'split6_train_roc_auc': array([0.98969307, 0.98962364,        nan,        nan, 0.98939926,
       0.9892881 ,        nan,        nan, 0.98953823, 0.98888407,
              nan,        nan, 0.99004551, 0.98985638,        nan,
              nan]), 'split7_train_roc_auc': array([0.98873139, 0.98965729,        nan,        nan, 0.98887483,
       0.99023594,        nan,        nan, 0.99009006, 0.98984194,
              nan,        nan, 0.98942898, 0.98932629,        nan,
              nan]), 'split8_train_roc_auc': array([0.98917764, 0.98967696,        nan,        nan, 0.98923103,
       0.98954383,        nan,        nan, 0.98884976, 0.98966322,
              nan,        nan, 0.98911469, 0.99040979,        nan,
              nan]), 'split9_train_roc_auc': array([0.98974796, 0.98934306,        nan,        nan, 0.98857138,
       0.9879674 ,        nan,        nan, 0.98951097, 0.98932148,
              nan,        nan, 0.99034985, 0.99040774,        nan,
              nan]), 'mean_train_roc_auc': array([0.98925097, 0.98947492,        nan,        nan, 0.9890514 ,
       0.98942231,        nan,        nan, 0.98955027, 0.98923325,
              nan,        nan, 0.98967118, 0.98963381,        nan,
              nan]), 'std_train_roc_auc': array([0.00037277, 0.00029827,        nan,        nan, 0.00042746,
       0.00057246,        nan,        nan, 0.00032291, 0.00054895,
              nan,        nan, 0.00045708, 0.00054001,        nan,
              nan]), 'split0_test_f1': array([0.68438538, 0.65064695,        nan,        nan, 0.68984701,
       0.66915888,        nan,        nan, 0.66907776, 0.68910256,
              nan,        nan, 0.7296    , 0.62768031,        nan,
              nan]), 'split1_test_f1': array([0.60362173, 0.70818505,        nan,        nan, 0.74025974,
       0.74794069,        nan,        nan, 0.74554295, 0.60279441,
              nan,        nan, 0.73763118, 0.74662162,        nan,
              nan]), 'split2_test_f1': array([0.6897747 , 0.6974359 ,        nan,        nan, 0.70840198,
       0.67023173,        nan,        nan, 0.69230769, 0.59887006,
              nan,        nan, 0.68760908, 0.71380471,        nan,
              nan]), 'split3_test_f1': array([0.63299663, 0.60689655,        nan,        nan, 0.63140496,
       0.68011527,        nan,        nan, 0.68263473, 0.67673716,
              nan,        nan, 0.69242658, 0.639866  ,        nan,
              nan]), 'split4_test_f1': array([0.6884058 , 0.6858006 ,        nan,        nan, 0.71147541,
       0.71631206,        nan,        nan, 0.69043152, 0.69565217,
              nan,        nan, 0.58924731, 0.66666667,        nan,
              nan]), 'split5_test_f1': array([0.69622332, 0.65567766,        nan,        nan, 0.6789916 ,
       0.6893039 ,        nan,        nan, 0.67886855, 0.68235294,
              nan,        nan, 0.7189729 , 0.74848485,        nan,
              nan]), 'split6_test_f1': array([0.69352518, 0.65605096,        nan,        nan, 0.66344605,
       0.69207317,        nan,        nan, 0.68321168, 0.62809917,
              nan,        nan, 0.68995633, 0.69090909,        nan,
              nan]), 'split7_test_f1': array([0.69131833, 0.68456376,        nan,        nan, 0.67586207,
       0.74074074,        nan,        nan, 0.67368421, 0.71601208,
              nan,        nan, 0.72786885, 0.71710526,        nan,
              nan]), 'split8_test_f1': array([0.65480427, 0.68676717,        nan,        nan, 0.67145422,
       0.64456722,        nan,        nan, 0.63314711, 0.67713787,
              nan,        nan, 0.72552167, 0.65176909,        nan,
              nan]), 'split9_test_f1': array([0.75286416, 0.7446458 ,        nan,        nan, 0.67917448,
       0.72906404,        nan,        nan, 0.72727273, 0.77016743,
              nan,        nan, 0.71351351, 0.76923077,        nan,
              nan]), 'mean_test_f1': array([0.67879195, 0.67766704,        nan,        nan, 0.68503175,
       0.69795077,        nan,        nan, 0.68761789, 0.67369259,
              nan,        nan, 0.70123474, 0.69721384,        nan,
              nan]), 'std_test_f1': array([0.03838234, 0.03562889,        nan,        nan, 0.02828383,
       0.03241865,        nan,        nan, 0.02929757, 0.04961642,
              nan,        nan, 0.04101897, 0.04699894,        nan,
              nan]), 'rank_test_f1': array([ 6,  7,  9, 10,  5,  2, 11, 12,  4,  8, 13, 14,  1,  3, 15, 16],
      dtype=int32), 'split0_train_f1': array([0.6980198 , 0.67435046,        nan,        nan, 0.71175133,
       0.69185591,        nan,        nan, 0.6849053 , 0.708656  ,
              nan,        nan, 0.73216735, 0.65945284,        nan,
              nan]), 'split1_train_f1': array([0.56095936, 0.65780071,        nan,        nan, 0.713958  ,
       0.71379122,        nan,        nan, 0.7043665 , 0.54009747,
              nan,        nan, 0.71539095, 0.70526513,        nan,
              nan]), 'split2_train_f1': array([0.6906999 , 0.6978852 ,        nan,        nan, 0.70907791,
       0.66534418,        nan,        nan, 0.69371345, 0.62007833,
              nan,        nan, 0.69434254, 0.71181395,        nan,
              nan]), 'split3_train_f1': array([0.66626578, 0.64461791,        nan,        nan, 0.67451442,
       0.72013829,        nan,        nan, 0.71464375, 0.70383149,
              nan,        nan, 0.72660952, 0.67953822,        nan,
              nan]), 'split4_train_f1': array([0.68863929, 0.72084696,        nan,        nan, 0.73207421,
       0.70678846,        nan,        nan, 0.67464387, 0.68523464,
              nan,        nan, 0.55808856, 0.66133227,        nan,
              nan]), 'split5_train_f1': array([0.7133224 , 0.67263844,        nan,        nan, 0.69578313,
       0.70007593,        nan,        nan, 0.68620178, 0.69740526,
              nan,        nan, 0.70540628, 0.75863242,        nan,
              nan]), 'split6_train_f1': array([0.72846313, 0.69680138,        nan,        nan, 0.68176494,
       0.72590967,        nan,        nan, 0.7159289 , 0.66033254,
              nan,        nan, 0.72593372, 0.72405617,        nan,
              nan]), 'split7_train_f1': array([0.68389736, 0.67911453,        nan,        nan, 0.65135783,
       0.72892857,        nan,        nan, 0.65353814, 0.7082974 ,
              nan,        nan, 0.70154892, 0.69779703,        nan,
              nan]), 'split8_train_f1': array([0.66653734, 0.69728449,        nan,        nan, 0.68189807,
       0.65825826,        nan,        nan, 0.65497783, 0.6818527 ,
              nan,        nan, 0.71002616, 0.66234555,        nan,
              nan]), 'split9_train_f1': array([0.71179815, 0.71491615,        nan,        nan, 0.6509472 ,
       0.69724771,        nan,        nan, 0.70049641, 0.73706204,
              nan,        nan, 0.6767419 , 0.71500654,        nan,
              nan]), 'mean_train_f1': array([0.68086025, 0.68562562,        nan,        nan, 0.6903127 ,
       0.70083382,        nan,        nan, 0.68834159, 0.67428479,
              nan,        nan, 0.69462559, 0.69752401,        nan,
              nan]), 'std_train_f1': array([0.04419542, 0.02302965,        nan,        nan, 0.02570093,
       0.02271642,        nan,        nan, 0.02101117, 0.05385462,
              nan,        nan, 0.04817401, 0.03054227,        nan,
              nan]), 'split0_test_average_precision': array([0.74640601, 0.77269434,        nan,        nan, 0.77133086,
       0.79838216,        nan,        nan, 0.77043937, 0.75291434,
              nan,        nan, 0.77985687, 0.79331536,        nan,
              nan]), 'split1_test_average_precision': array([0.77165535, 0.78023977,        nan,        nan, 0.77480161,
       0.78106023,        nan,        nan, 0.77595903, 0.75117156,
              nan,        nan, 0.77949527, 0.78765265,        nan,
              nan]), 'split2_test_average_precision': array([0.74797275, 0.75758508,        nan,        nan, 0.74654639,
       0.75373131,        nan,        nan, 0.74039025, 0.74676762,
              nan,        nan, 0.76308219, 0.75772743,        nan,
              nan]), 'split3_test_average_precision': array([0.73314723, 0.72646733,        nan,        nan, 0.71887338,
       0.72656676,        nan,        nan, 0.72509256, 0.7115762 ,
              nan,        nan, 0.74415992, 0.73752893,        nan,
              nan]), 'split4_test_average_precision': array([0.74273251, 0.75803163,        nan,        nan, 0.76113449,
       0.7449929 ,        nan,        nan, 0.74766308, 0.75784936,
              nan,        nan, 0.7357379 , 0.76824942,        nan,
              nan]), 'split5_test_average_precision': array([0.78349555, 0.80340968,        nan,        nan, 0.77638209,
       0.7866742 ,        nan,        nan, 0.76761939, 0.77432946,
              nan,        nan, 0.77781669, 0.80966732,        nan,
              nan]), 'split6_test_average_precision': array([0.74967311, 0.74891066,        nan,        nan, 0.73804702,
       0.75516961,        nan,        nan, 0.74222724, 0.72694198,
              nan,        nan, 0.74325251, 0.74640704,        nan,
              nan]), 'split7_test_average_precision': array([0.73901706, 0.75701388,        nan,        nan, 0.74815241,
       0.77081356,        nan,        nan, 0.75755259, 0.74920263,
              nan,        nan, 0.76440256, 0.76449232,        nan,
              nan]), 'split8_test_average_precision': array([0.77229853, 0.77352317,        nan,        nan, 0.79045477,
       0.78936698,        nan,        nan, 0.77816508, 0.77414842,
              nan,        nan, 0.78038992, 0.80754522,        nan,
              nan]), 'split9_test_average_precision': array([0.78648932, 0.77972095,        nan,        nan, 0.78393922,
       0.76607321,        nan,        nan, 0.78417008, 0.81058302,
              nan,        nan, 0.78730964, 0.80785315,        nan,
              nan]), 'mean_test_average_precision': array([0.75728874, 0.76575965,        nan,        nan, 0.76096622,
       0.76728309,        nan,        nan, 0.75892787, 0.75554846,
              nan,        nan, 0.76555035, 0.77804389,        nan,
              nan]), 'std_test_average_precision': array([0.0183383 , 0.01990299,        nan,        nan, 0.02145478,
       0.0212595 ,        nan,        nan, 0.01844323, 0.02574517,
              nan,        nan, 0.01759038, 0.02533613,        nan,
              nan]), 'rank_test_average_precision': array([ 7,  3,  9, 10,  5,  2, 11, 12,  6,  8, 13, 14,  4,  1, 15, 16],
      dtype=int32), 'split0_train_average_precision': array([0.7448956 , 0.76670838,        nan,        nan, 0.76615391,
       0.7849404 ,        nan,        nan, 0.76270659, 0.7482881 ,
              nan,        nan, 0.77255429, 0.78116107,        nan,
              nan]), 'split1_train_average_precision': array([0.75848185, 0.76222619,        nan,        nan, 0.76077127,
       0.7655675 ,        nan,        nan, 0.75914123, 0.72822884,
              nan,        nan, 0.76478972, 0.77406647,        nan,
              nan]), 'split2_train_average_precision': array([0.76965919, 0.76867904,        nan,        nan, 0.75729561,
       0.76392732,        nan,        nan, 0.7527385 , 0.75006415,
              nan,        nan, 0.77613628, 0.77705983,        nan,
              nan]), 'split3_train_average_precision': array([0.76777307, 0.76701305,        nan,        nan, 0.75398968,
       0.76297845,        nan,        nan, 0.76239896, 0.7591566 ,
              nan,        nan, 0.78016474, 0.77839566,        nan,
              nan]), 'split4_train_average_precision': array([0.75285202, 0.76753375,        nan,        nan, 0.77259851,
       0.75750052,        nan,        nan, 0.75723439, 0.76645224,
              nan,        nan, 0.74803564, 0.77451771,        nan,
              nan]), 'split5_train_average_precision': array([0.76999204, 0.79470567,        nan,        nan, 0.75516517,
       0.77072219,        nan,        nan, 0.75038079, 0.75968588,
              nan,        nan, 0.75654605, 0.80479556,        nan,
              nan]), 'split6_train_average_precision': array([0.77032136, 0.77159377,        nan,        nan, 0.76194708,
       0.78048145,        nan,        nan, 0.7621691 , 0.74882104,
              nan,        nan, 0.77103921, 0.77308088,        nan,
              nan]), 'split7_train_average_precision': array([0.74070762, 0.76119392,        nan,        nan, 0.74946604,
       0.77543068,        nan,        nan, 0.76131046, 0.7546969 ,
              nan,        nan, 0.77026705, 0.77072098,        nan,
              nan]), 'split8_train_average_precision': array([0.75077315, 0.7524123 ,        nan,        nan, 0.76594275,
       0.7598572 ,        nan,        nan, 0.75736562, 0.75436635,
              nan,        nan, 0.7550698 , 0.78113222,        nan,
              nan]), 'split9_train_average_precision': array([0.76437429, 0.76076085,        nan,        nan, 0.76018568,
       0.74163766,        nan,        nan, 0.7648393 , 0.78374961,
              nan,        nan, 0.76826767, 0.77991928,        nan,
              nan]), 'mean_train_average_precision': array([0.75898302, 0.76728269,        nan,        nan, 0.76035157,
       0.76630434,        nan,        nan, 0.75902849, 0.75535097,
              nan,        nan, 0.76628704, 0.77948496,        nan,
              nan]), 'std_train_average_precision': array([0.010525  , 0.01048487,        nan,        nan, 0.00642551,
       0.01181471,        nan,        nan, 0.00440532, 0.0134925 ,
              nan,        nan, 0.0096296 , 0.00908438,        nan,
              nan])}, 'n_splits_': 10}
 _ _ _ _ _ _ _ _ _ _ MODEL # 1  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.403 
        MEAN TEST SCORE :  5.017 STD TEST SCORE :  0.09 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  4 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.992    0.994    0.994    0.993    0.994    0.994    0.993    0.993    0.994  
TEST   0.993    0.993    0.994    0.992    0.994    0.994    0.993    0.993    0.993    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.780    0.918    0.858    0.877    0.818    0.822    0.779    0.811    0.839    0.800  
TEST   0.772    0.920    0.858    0.832    0.802    0.831    0.742    0.790    0.880    0.839  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.631    0.404    0.578    0.537    0.594    0.630    0.684    0.591    0.553    0.641  
TEST   0.615    0.449    0.577    0.511    0.603    0.599    0.651    0.614    0.521    0.682  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.989    0.989    0.989    0.99     0.990    0.989    0.989    0.990  
TEST   0.991    0.986    0.991    0.989    0.986    0.99     0.991    0.988    0.989    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.745    0.758    0.770    0.768    0.753    0.770    0.77     0.741    0.751    0.764  
TEST   0.746    0.772    0.748    0.733    0.743    0.783    0.75     0.739    0.772    0.786  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.698    0.561    0.691    0.666    0.689    0.713    0.728    0.684    0.667    0.712  
TEST   0.684    0.604    0.690    0.633    0.688    0.696    0.694    0.691    0.655    0.753  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#1.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 2  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   38.776 
        MEAN TEST SCORE :  6.676 STD TEST SCORE :  0.023 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  5 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.994    0.993    0.993    0.994    0.994    0.994    0.994    0.994  
TEST   0.993    0.994    0.994    0.992    0.993    0.993    0.992    0.993    0.993    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.866    0.867    0.848    0.884    0.706    0.915    0.854    0.846    0.804    0.797  
TEST   0.854    0.873    0.850    0.830    0.654    0.932    0.798    0.829    0.840    0.837  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.552    0.530    0.593    0.507    0.736    0.532    0.588    0.567    0.616    0.648  
TEST   0.525    0.596    0.591    0.478    0.721    0.506    0.557    0.583    0.581    0.671  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.989    0.990    0.989    0.99     0.990    0.990    0.990    0.989  
TEST   0.990    0.989    0.991    0.988    0.987    0.99     0.991    0.988    0.991    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.767    0.762    0.769    0.767    0.768    0.795    0.772    0.761    0.752    0.761  
TEST   0.773    0.780    0.758    0.726    0.758    0.803    0.749    0.757    0.774    0.780  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.674    0.658    0.698    0.645    0.721    0.673    0.697    0.679    0.697    0.715  
TEST   0.651    0.708    0.697    0.607    0.686    0.656    0.656    0.685    0.687    0.745  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#2.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 3  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  9 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#3.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 4  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.003 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  10 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#4.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 5  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   1.017 
        MEAN TEST SCORE :  4.671 STD TEST SCORE :  0.195 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  6 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.994    0.994    0.994    0.994    0.994    0.994    0.993    0.994    0.993  
TEST   0.992    0.994    0.994    0.992    0.994    0.993    0.993    0.993    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.677    0.796    0.800    0.858    0.772    0.838    0.860    0.860    0.867    0.879  
TEST   0.646    0.809    0.821    0.806    0.736    0.838    0.821    0.852    0.917    0.923  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.751    0.647    0.637    0.556    0.696    0.595    0.565    0.524    0.562    0.517  
TEST   0.740    0.683    0.623    0.519    0.689    0.571    0.557    0.560    0.530    0.537  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.988    0.989    0.990    0.990    0.989    0.989    0.989    0.989  
TEST   0.991    0.987    0.989    0.990    0.986    0.991    0.991    0.987    0.990    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.766    0.761    0.757    0.754    0.773    0.755    0.762    0.749    0.766    0.760  
TEST   0.771    0.775    0.747    0.719    0.761    0.776    0.738    0.748    0.790    0.784  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.712    0.714    0.709    0.675    0.732    0.696    0.682    0.651    0.682    0.651  
TEST   0.690    0.740    0.708    0.631    0.711    0.679    0.663    0.676    0.671    0.679  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#5.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 6  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.974 
        MEAN TEST SCORE :  5.809 STD TEST SCORE :  0.215 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  2 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.994    0.993    0.994    0.994    0.994    0.994    0.994    0.993    0.993  
TEST   0.994    0.995    0.994    0.992    0.994    0.994    0.993    0.994    0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.892    0.829    0.871    0.774    0.810    0.853    0.835    0.820    0.871    0.777  
TEST   0.895    0.832    0.870    0.724    0.811    0.864    0.794    0.805    0.921    0.816  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.565    0.626    0.538    0.673    0.627    0.593    0.642    0.656    0.529    0.633  
TEST   0.534    0.680    0.545    0.641    0.641    0.573    0.614    0.686    0.496    0.659  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.990    0.99     0.989    0.989    0.989    0.989    0.990    0.99     0.988  
TEST   0.992    0.988    0.99     0.990    0.986    0.991    0.992    0.989    0.99     0.985  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.785    0.766    0.764    0.763    0.758    0.771    0.780    0.775    0.760    0.742  
TEST   0.798    0.781    0.754    0.727    0.745    0.787    0.755    0.771    0.789    0.766  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.692    0.714    0.665    0.72     0.707    0.700    0.726    0.729    0.658    0.697  
TEST   0.669    0.748    0.670    0.68     0.716    0.689    0.692    0.741    0.645    0.729  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#6.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 7  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.001 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  11 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#7.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 8  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  100 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.003 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  12 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 100, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#8.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 9  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.625 
        MEAN TEST SCORE :  5.04 STD TEST SCORE :  0.015 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  8 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.994    0.993    0.994    0.993    0.993    0.994    0.99     0.993    0.994  
TEST   0.994    0.994    0.994    0.993    0.994    0.993    0.992    0.99     0.993    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.852    0.800    0.806    0.801    0.838    0.810    0.776    0.552    0.876    0.823  
TEST   0.849    0.813    0.818    0.760    0.844    0.826    0.743    0.570    0.924    0.862  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.573    0.629    0.609    0.645    0.565    0.595    0.665    0.800    0.523    0.610  
TEST   0.552    0.689    0.600    0.620    0.584    0.576    0.632    0.823    0.482    0.629  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.989    0.989    0.990    0.990    0.990    0.990    0.990    0.989    0.990  
TEST   0.992    0.989    0.990    0.989    0.988    0.991    0.991    0.989    0.989    0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.763    0.759    0.753    0.762    0.757    0.750    0.762    0.761    0.757    0.765  
TEST   0.770    0.776    0.740    0.725    0.748    0.768    0.742    0.758    0.778    0.784  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.685    0.704    0.694    0.715    0.675    0.686    0.716    0.654    0.655    0.700  
TEST   0.669    0.746    0.692    0.683    0.690    0.679    0.683    0.674    0.633    0.727  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#9.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 10  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   38.359 
        MEAN TEST SCORE :  6.761 STD TEST SCORE :  0.032 RANK TEST SCORE  :   0.993 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  7 
        PARAMS: 0.993      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.993    0.992    0.993    0.994    0.994    0.994    0.993    0.993    0.993    0.994  
TEST   0.993    0.993    0.993    0.993    0.994    0.993    0.992    0.993    0.994    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.767    0.879    0.867    0.803    0.857    0.830    0.851    0.764    0.831    0.740  
TEST   0.744    0.904    0.855    0.762    0.860    0.842    0.809    0.760    0.882    0.791  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.659    0.390    0.483    0.627    0.571    0.601    0.540    0.660    0.578    0.734  
TEST   0.642    0.452    0.461    0.609    0.584    0.573    0.514    0.677    0.550    0.751  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.988    0.989    0.990    0.990    0.989    0.989    0.990    0.99     0.989  
TEST   0.991    0.988    0.991    0.989    0.987    0.989    0.990    0.988    0.99     0.986  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.748    0.728    0.750    0.759    0.766    0.760    0.749    0.755    0.754    0.784  
TEST   0.753    0.751    0.747    0.712    0.758    0.774    0.727    0.749    0.774    0.811  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.709    0.540    0.620    0.704    0.685    0.697    0.660    0.708    0.682    0.737  
TEST   0.689    0.603    0.599    0.677    0.696    0.682    0.628    0.716    0.677    0.770  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#10.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 11  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  13 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#11.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 12  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  LSTM MEAN SCORE TIME:  adam STD SCORE TIME   :   0.004 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  14 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'LSTM', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#12.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 13  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   1.006 
        MEAN TEST SCORE :  4.668 STD TEST SCORE :  0.035 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  3 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.993    0.994    0.994    0.992    0.993    0.994    0.994    0.994    0.994  
TEST   0.994    0.994    0.994    0.993    0.993    0.993    0.993    0.994    0.994    0.994  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.789    0.737    0.872    0.833    0.899    0.710    0.792    0.851    0.775    0.875  
TEST   0.786    0.739    0.864    0.803    0.913    0.726    0.748    0.854    0.837    0.908  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.683    0.695    0.577    0.644    0.405    0.701    0.670    0.597    0.655    0.552  
TEST   0.681    0.737    0.571    0.609    0.435    0.712    0.641    0.634    0.640    0.588  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.990    0.990    0.990    0.99     0.989    0.989    0.990    0.989    0.989    0.990  
TEST   0.992    0.988    0.991    0.99     0.986    0.991    0.991    0.988    0.990    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.773    0.765    0.776    0.780    0.748    0.757    0.771    0.770    0.755    0.768  
TEST   0.780    0.779    0.763    0.744    0.736    0.778    0.743    0.764    0.780    0.787  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.732    0.715    0.694    0.727    0.558    0.705    0.726    0.702    0.710    0.677  
TEST   0.730    0.738    0.688    0.692    0.589    0.719    0.690    0.728    0.726    0.714  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#13.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 14  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "0" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   38.032 
        MEAN TEST SCORE :  5.795 STD TEST SCORE :  0.029 RANK TEST SCORE  :   0.994 
        MEAN TRAIN SCORE:  0.001 STD TRAIN SCORE:  1 
        PARAMS: 0.994      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.994    0.994    0.994    0.994    0.993    0.994    0.994    0.994    0.994    0.994  
TEST   0.993    0.995    0.994    0.992    0.994    0.994    0.993    0.994    0.993    0.995  
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.911    0.852    0.847    0.884    0.892    0.804    0.830    0.842    0.894    0.859  
TEST   0.904    0.857    0.851    0.834    0.880    0.807    0.786    0.845    0.951    0.907  
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.517    0.602    0.614    0.552    0.525    0.718    0.642    0.596    0.526    0.612  
TEST   0.481    0.662    0.614    0.519    0.537    0.698    0.616    0.623    0.496    0.668  
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.989    0.989    0.989    0.990    0.989    0.990    0.99     0.989    0.990    0.990  
TEST   0.991    0.988    0.990    0.988    0.988    0.991    0.99     0.987    0.992    0.987  
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.781    0.774    0.777    0.778    0.775    0.805    0.773    0.771    0.781    0.780  
TEST   0.793    0.788    0.758    0.738    0.768    0.810    0.746    0.764    0.808    0.808  
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN  0.659    0.705    0.712    0.68     0.661    0.759    0.724    0.698    0.662    0.715  
TEST   0.628    0.747    0.714    0.64     0.667    0.748    0.691    0.717    0.652    0.769  
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#14.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 15  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "50" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.002 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  15 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#15.png



 _ _ _ _ _ _ _ _ _ _ MODEL # 16  _ _ _ _ _ _ _ _ _ _

        PARAM EPOCHS    :  50 HIDDEN LAYERS  :  2   NEURONS PER HIDDEN LAYER:  200 
        LOSS FUNCTION   : "1" MODEL TYPE     : "100" OPTIMIZER        : "binary_crossentropy"
        STD FIT TIME    :  GRU MEAN SCORE TIME:  adam STD SCORE TIME   :   0.006 
        MEAN TEST SCORE :  0.0 STD TEST SCORE :  0.0 RANK TEST SCORE  :   nan 
        MEAN TRAIN SCORE:  nan STD TRAIN SCORE:  16 
        PARAMS: nan      
    

ACC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



PREC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



REC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



ROC AUC PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



AVE PRE PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        



F1 PERFORMANCE PER SPLIT 

       SPLIT#0  SPLIT#1  SPLIT#2  SPLIT#3  SPLIT#4  SPLIT#5  SPLIT#6  SPLIT#7  SPLIT#8  SPLIT#9
TRAIN NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
TEST  NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN     
        


{'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 1, 'rnn_hidden_layers_neurons': 100, 'rnn_layer_activation': 'sigmoid'}


Saving image with name:  Model#16.png





BEST MODEL HISTORY PER EPOCH
SELECTED EPOCHS   : 50
PARAMS            : {'dropout': True, 'dropout_rate': 0.2, 'epochs': 50, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 2, 'hidden_layers_neurons': 200, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 50, 'rnn_layer_activation': 'sigmoid'} 

                   0      1
TRAIN ACC      0.989  0.992
TEST ACC       0.991  0.992
TRAIN LOSS     0.041  0.025
TEST LOSS      0.028  0.024
precision      0.631  0.786
val_precision  0.726  0.663
recall         0.214  0.503
val_recall     0.383  0.731 




<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4b0b0ecc0>
237858/237858 - 18s
CONFUSION MATRIX
Predicted       0     1
True                   
0          233965  1054
1          764     2075
P: [0.01193569 0.66315117 1.        ]
R: [1.         0.73089116 0.        ]
THRES: [0. 1.]
dict_keys(['scoring', 'estimator', 'n_jobs', 'iid', 'refit', 'cv', 'verbose', 'pre_dispatch', 'error_score', 'return_train_score', 'param_grid', 'multimetric_', 'best_index_', 'best_score_', 'best_params_', 'best_estimator_', 'refit_time_', 'scorer_', 'cv_results_', 'n_splits_'])
Error: best_params_ - KeyError('keras_eval_metric',)
Error: cv_results_ - KeyError('param_keras_eval_metric',)
Error: param_grid - KeyError('keras_eval_metric',)
Saving  scoring 
 ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']
Saving  n_jobs 
 1
Saving  iid 
 deprecated
Saving  refit 
 recall
Saving  cv 
 10
Saving  verbose 
 2
Saving  pre_dispatch 
 1*n_jobs
Saving  error_score 
 nan
Saving  return_train_score 
 True
Saving  param_grid 
 dict_keys(['rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'optimizer', 'modelType', 'epochs', 'output_layer_activation', 'rnn_layer_activation', 'hidden_layer_activation', 'dropout', 'dropout_rate'])
Saving  best_index_ 
 12
Saving  best_score_ 
 0.624620912337056
Saving  best_params_ 
 dict_keys(['dropout', 'dropout_rate', 'epochs', 'hidden_layer_activation', 'hidden_layers', 'hidden_layers_neurons', 'loss', 'modelType', 'optimizer', 'output_layer_activation', 'rnn_hidden_layers', 'rnn_hidden_layers_neurons', 'rnn_layer_activation'])
Saving  refit_time_ 
 242.27149367332458
Saving  cv_results_ 
 dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_epochs', 'param_hidden_layer_activation', 'param_hidden_layers', 'param_hidden_layers_neurons', 'param_loss', 'param_modelType', 'param_optimizer', 'param_output_layer_activation', 'param_rnn_hidden_layers', 'param_rnn_hidden_layers_neurons', 'param_rnn_layer_activation', 'params', 'split0_test_accuracy', 'split1_test_accuracy', 'split2_test_accuracy', 'split3_test_accuracy', 'split4_test_accuracy', 'split5_test_accuracy', 'split6_test_accuracy', 'split7_test_accuracy', 'split8_test_accuracy', 'split9_test_accuracy', 'mean_test_accuracy', 'std_test_accuracy', 'rank_test_accuracy', 'split0_train_accuracy', 'split1_train_accuracy', 'split2_train_accuracy', 'split3_train_accuracy', 'split4_train_accuracy', 'split5_train_accuracy', 'split6_train_accuracy', 'split7_train_accuracy', 'split8_train_accuracy', 'split9_train_accuracy', 'mean_train_accuracy', 'std_train_accuracy', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'split5_test_precision', 'split6_test_precision', 'split7_test_precision', 'split8_test_precision', 'split9_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'split5_train_precision', 'split6_train_precision', 'split7_train_precision', 'split8_train_precision', 'split9_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'split5_test_recall', 'split6_test_recall', 'split7_test_recall', 'split8_test_recall', 'split9_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'split5_train_recall', 'split6_train_recall', 'split7_train_recall', 'split8_train_recall', 'split9_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_roc_auc', 'split1_test_roc_auc', 'split2_test_roc_auc', 'split3_test_roc_auc', 'split4_test_roc_auc', 'split5_test_roc_auc', 'split6_test_roc_auc', 'split7_test_roc_auc', 'split8_test_roc_auc', 'split9_test_roc_auc', 'mean_test_roc_auc', 'std_test_roc_auc', 'rank_test_roc_auc', 'split0_train_roc_auc', 'split1_train_roc_auc', 'split2_train_roc_auc', 'split3_train_roc_auc', 'split4_train_roc_auc', 'split5_train_roc_auc', 'split6_train_roc_auc', 'split7_train_roc_auc', 'split8_train_roc_auc', 'split9_train_roc_auc', 'mean_train_roc_auc', 'std_train_roc_auc', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'split5_test_f1', 'split6_test_f1', 'split7_test_f1', 'split8_test_f1', 'split9_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'split5_train_f1', 'split6_train_f1', 'split7_train_f1', 'split8_train_f1', 'split9_train_f1', 'mean_train_f1', 'std_train_f1', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'split5_test_average_precision', 'split6_test_average_precision', 'split7_test_average_precision', 'split8_test_average_precision', 'split9_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'split5_train_average_precision', 'split6_train_average_precision', 'split7_train_average_precision', 'split8_train_average_precision', 'split9_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision'])
Saving  n_splits_ 
 10
Model: "sequential_160"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
gru_120 (GRU)                (None, 50)                9600      
_________________________________________________________________
dense_240 (Dense)            (None, 200)               10200     
_________________________________________________________________
activation_240 (Activation)  (None, 200)               0         
_________________________________________________________________
dense_241 (Dense)            (None, 200)               40200     
_________________________________________________________________
activation_241 (Activation)  (None, 200)               0         
_________________________________________________________________
dropout_80 (Dropout)         (None, 200)               0         
_________________________________________________________________
dense_242 (Dense)            (None, 1)                 201       
_________________________________________________________________
activation_242 (Activation)  (None, 1)                 0         
=================================================================
Total params: 60,201
Trainable params: 60,201
Non-trainable params: 0
_________________________________________________________________
None
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
