{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RNNModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from data import readLocally\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from visualization import plot_roc_auc, pr_curve, format_vertical_headers, print_confusion_matrix, printModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _   READ DATA LOCALLY  _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SHAPES & KEYS:\n",
      "    X_train          : (285428, 25, 12)   -> 48%\n",
      "    y_train          : (285428,)\n",
      "    X_test           : (237858, 25, 12)   -> 40%\n",
      "    y_test           : (237858,)\n",
      "    X_val            : (71357, 25, 12)   -> 12%\n",
      "    y_val            : (71357,)\n",
      "    ______________________\n",
      "    Total Data Size  : 594643\n",
      "    labels_hash Keys : dict_keys(['customer', 'age', 'gender', 'merchant', 'category'])\n",
      "    \n",
      "    TRAIN DATA\n",
      "    ______________________\n",
      "    Positives        : 3461   -> 1.21%\n",
      "    Negatives        : 281967   -> 98.79%\n",
      "    \n",
      "    TEST DATA\n",
      "    ______________________\n",
      "    Positives        : 2839   -> 1.19%\n",
      "    Negatives        : 235019   -> 98.81%   \n",
      "    \n",
      "    VAL DATA\n",
      "    ______________________\n",
      "    Positives        : 900   -> 1.26%\n",
      "    Negatives        : 70457   -> 98.74%\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val, labels_hash, scaler = readLocally()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INCREASED TRAIN SET -> NEW SIZES\n",
      "X_train: (404357, 25, 12)\n",
      "y_train: (404357,)         68% 1.20P% 98.80N%\n",
      "X_test : (118929, 25, 12)\n",
      "y_test : (118929,)         20% 1.23P% 98.77N%\n",
      "X_val  : (71357, 25, 12)\n",
      "y_val  : (71357,)         12% 1.26P% 98.74N%\n",
      "\n",
      "X_train 1: (404357, 25, 12)->(404357, 13, 12)\n",
      "X_test  1: (118929, 25, 12)->(118929, 13, 12)\n",
      "X_val   1: (71357, 25, 12)->(71357, 13, 12)\n",
      "\n",
      "\n",
      "X_train 2: (404357, 25, 12)->(404357, 1, 12)\n",
      "X_test  2: (118929, 25, 12)->(118929, 1, 12)\n",
      "X_val   2: (71357, 25, 12)->(71357, 1, 12)\n",
      "\n",
      "\n",
      "X_train 1 Sample: \n",
      "\n",
      "\n",
      "          0      1    2     3         4         5         6         7   \\\n",
      "0   0.633333  0.875  0.5  0.38  0.866667  0.005721  0.333333  0.005527   \n",
      "1   0.638889  0.875  0.5  0.38  0.866667  0.002008  0.333333  0.005551   \n",
      "2   0.644444  0.875  0.5  0.38  0.866667  0.001388  0.333333  0.005500   \n",
      "3   0.650000  0.875  0.5  0.38  0.866667  0.000975  0.333333  0.005439   \n",
      "4   0.655556  0.875  0.5  0.38  0.866667  0.006718  0.333333  0.005371   \n",
      "5   0.661111  0.875  0.5  0.38  0.866667  0.003401  0.333333  0.005414   \n",
      "6   0.666667  0.875  0.5  0.02  0.333333  0.014217  0.333333  0.005394   \n",
      "7   0.672222  0.875  0.5  0.38  0.866667  0.000436  0.333333  0.005572   \n",
      "8   0.677778  0.875  0.5  0.38  0.866667  0.000545  0.333333  0.005497   \n",
      "9   0.683333  0.875  0.5  0.38  0.866667  0.003135  0.333333  0.005426   \n",
      "10  0.688889  0.875  0.5  0.38  0.866667  0.000639  0.333333  0.005403   \n",
      "11  0.694444  0.875  0.5  0.38  0.866667  0.006076  0.333333  0.005336   \n",
      "12  0.700000  0.875  0.5  0.38  0.866667  0.004135  0.333333  0.005365   \n",
      "\n",
      "          8    9         10    11  \n",
      "0   0.005760  0.5  0.866667  0.62  \n",
      "1   0.005777  0.5  0.866667  0.62  \n",
      "2   0.005725  0.5  0.866667  0.62  \n",
      "3   0.005661  0.5  0.866667  0.62  \n",
      "4   0.005593  0.5  0.866667  0.62  \n",
      "5   0.005630  0.5  0.866667  0.62  \n",
      "6   0.005609  1.0  0.866667  0.62  \n",
      "7   0.005779  0.5  0.866667  0.62  \n",
      "8   0.005703  0.5  0.866667  0.62  \n",
      "9   0.005630  0.5  0.866667  0.62  \n",
      "10  0.005604  0.5  0.866667  0.62  \n",
      "11  0.005538  0.5  0.866667  0.62  \n",
      "12  0.005562  0.5  0.866667  0.62  \n",
      "X_train 2 Sample: \n",
      "\n",
      "\n",
      "    0      1    2     3         4         5         6         7         8   \\\n",
      "0  0.7  0.875  0.5  0.38  0.866667  0.004135  0.333333  0.005365  0.005562   \n",
      "\n",
      "    9         10    11  \n",
      "0  0.5  0.866667  0.62  \n"
     ]
    }
   ],
   "source": [
    "#DIVIDE X_TEST IN HALF AND ADD IT TO X_TRAIN\n",
    "test_half_pos   = int(len(X_test)/2)\n",
    "total_data_size = len(X_train) + len(X_test) + len(X_val)\n",
    "\n",
    "X_train = np.vstack( ( X_train ,  X_test[0: test_half_pos ] ))\n",
    "y_train = np.append( y_train ,  y_test[0: test_half_pos ]  )\n",
    "\n",
    "X_test  = X_test[ test_half_pos : ]\n",
    "y_test  = y_test[ test_half_pos : ]\n",
    "\n",
    "print(\"\"\"INCREASED TRAIN SET -> NEW SIZES\n",
    "X_train: {}\n",
    "y_train: {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "X_test : {}\n",
    "y_test : {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "X_val  : {}\n",
    "y_val  : {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "\"\"\".format(\n",
    "    X_train.shape, y_train.shape, len(X_train) * 100 / total_data_size,  len(y_train[y_train==1]) * 100 / len(y_train) , len(y_train[y_train==0]) * 100 / len(y_train) ,\n",
    "    X_test.shape, y_test.shape,   len(X_test)  * 100  / total_data_size, len(y_test[y_test==1])   * 100 / len(y_test)  , len(y_test[y_test==0])   * 100 / len(y_test) ,\n",
    "    X_val.shape,  y_val.shape,    len(X_val)   * 100  / total_data_size, len(y_val[y_val==1])     * 100 / len(y_val)   , len(y_val[y_val==0])     * 100 / len(y_val) ,\n",
    "))\n",
    "\n",
    "#Reduce Data to half the size per batch\n",
    "\n",
    "X_train1 = X_train[:,12:]\n",
    "X_test1 = X_test[:,  12:]\n",
    "X_val1 = X_val[:,  12: ]\n",
    "\n",
    "X_train2 = X_train[:,-1].reshape( len(X_train), 1, 12 )\n",
    "X_test2  = X_test[:,  -1].reshape( len(X_test), 1, 12 )\n",
    "X_val2   = X_val[:,  -1].reshape( len(X_val), 1, 12 )\n",
    "\n",
    "print(\"X_train 1: {}->{}\".format(X_train.shape, X_train1.shape))\n",
    "print(\"X_test  1: {}->{}\".format(X_test.shape,  X_test1.shape))\n",
    "print(\"X_val   1: {}->{}\\n\\n\".format(X_val.shape,   X_val1.shape))\n",
    "\n",
    "print(\"X_train 2: {}->{}\".format(X_train.shape, X_train2.shape))\n",
    "print(\"X_test  2: {}->{}\".format(X_test.shape,  X_test2.shape))\n",
    "print(\"X_val   2: {}->{}\\n\\n\".format(X_val.shape,   X_val2.shape))\n",
    "\n",
    "print(\"X_train 1 Sample: \\n\\n\")\n",
    "print(pd.DataFrame(X_train1[-1]))\n",
    "\n",
    "print(\"X_train 2 Sample: \\n\\n\")\n",
    "print(pd.DataFrame(X_train2[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404357 13 12\n"
     ]
    }
   ],
   "source": [
    "n_batches        = X_train1.shape[0]\n",
    "batch_size       = X_train1.shape[1]\n",
    "n_features       = X_train1.shape[2]\n",
    "\n",
    "print(n_batches, batch_size, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_param_grid = {\n",
    "    'modelType': ['GRU'], \n",
    "    'dropout': [True],\n",
    "    'dropout_rate': [0.2], \n",
    "    'epochs': [50], \n",
    "    'hidden_layer_activation': ['sigmoid'], \n",
    "    'hidden_layers': [2], \n",
    "    'hidden_layers_neurons': [300], \n",
    "    'loss': ['binary_crossentropy'], \n",
    "    'optimizer': ['adam'], \n",
    "    'output_layer_activation': ['sigmoid'], \n",
    "    'rnn_hidden_layers': [0], \n",
    "    'rnn_hidden_layers_neurons': [50], \n",
    "    'rnn_layer_activation': ['sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_half_batch_checkpoint_no_l1.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_history = gru_model_1.train( X_train1, y_train, X_test1, y_test )\n",
    "gru_model_1.model.best_estimator_.model.save( \"gru_double_data_half_batch_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = gru_model_1.model.predict_proba(X_val1)\n",
    "print(y_pred_val.shape, y_pred_val)\n",
    "print(\"\\n\\nCONFUSION MATRIX OVER TEST DATA\\n\\n\")\n",
    "tn, fp, fn, tp = confusion_matrix(\n",
    "    y_val, y_pred_val[:, 1].round()).ravel()\n",
    "print_confusion_matrix( tn, fp, fn, tp  )\n",
    "\n",
    "print(\"\\n\\nPLOTS OVER TEST DATA\\n\\n\")\n",
    "plot_roc_auc(y_val, y_pred_val[:, 1])\n",
    "pr_curve(y_val, y_pred_val[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches        = X_train2.shape[0]\n",
    "batch_size       = X_train2.shape[1]\n",
    "n_features       = X_train2.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_one_val_batch_checkpoint_no_l1.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_history_2 = gru_model_2.train( X_train2, y_train, X_test2, y_test )\n",
    "gru_model_2.model.best_estimator_.model.save( \"gru_double_data_one_val_batch_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = gru_model_2.model.predict_proba(X_val2)\n",
    "print(y_pred_val.shape, y_pred_val)\n",
    "print(\"\\n\\nCONFUSION MATRIX OVER TEST DATA\\n\\n\")\n",
    "tn, fp, fn, tp = confusion_matrix(\n",
    "    y_val, y_pred_val[:, 1].round()).ravel()\n",
    "print_confusion_matrix( tn, fp, fn, tp  )\n",
    "\n",
    "print(\"\\n\\nPLOTS OVER TEST DATA\\n\\n\")\n",
    "plot_roc_auc(y_val, y_pred_val[:, 1])\n",
    "pr_curve(y_val, y_pred_val[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches        = X_train3.shape[0]\n",
    "batch_size       = X_train3.shape[1]\n",
    "n_features       = X_train3.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_3 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_double_batch_checkpoint_no_l1.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_history_3 = gru_model_3.train( X_train3, y_train3, X_test3, y_test3 )\n",
    "gru_model_3.model.best_estimator_.model.save( \"gru_double_data_double_batch_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches        = X_train2.shape[0]\n",
    "batch_size       = X_train2.shape[1]\n",
    "n_features       = X_train2.shape[2]\n",
    "n_batches,batch_size,n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_4 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_one_batch_double_weights_no_l1_checkpoint.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.flatten()), y_train.flatten())\n",
    "modified_weights = np.array(class_weights) \n",
    "modified_weights[1] = class_weights[1] * 2\n",
    "print(\"Original Wieghts {}\\nModified Weights: {}\".format( dict(enumerate(class_weights)), dict(enumerate(modified_weights)) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history_4 = gru_model_4.train( X_train2, y_train, X_test2, y_test, class_weights=modified_weights )\n",
    "gru_model_4.model.best_estimator_.model.save( \"gru_double_data_one_batch_double_weights_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_param_grid_2 = gru_param_grid.copy()\n",
    "gru_param_grid_2['hidden_layers'] = [1]\n",
    "gru_param_grid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_5 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid_2,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_one_batch_1_layer_no_l1_checkpoint.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_history_5 = gru_model_5.train( X_train2, y_train, X_test2, y_test, class_weights=None )\n",
    "gru_model_5.model.best_estimator_.model.save( \"gru_double_data_one_batch_1_layer_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_param_grid_3 = gru_param_grid.copy()\n",
    "gru_param_grid_3['modelType']= ['SimpleRNN']\n",
    "\n",
    "gru_model_6 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid_3,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_double_data_one_batch_SimpleRNN_no_l1_checkpoint.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_history_6 = gru_model_6.train( X_train2, y_train, X_test2, y_test, class_weights=None )\n",
    "gru_model_6.model.best_estimator_.model.save( \"gru_double_data_one_batch_SimpleRNN_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404357, 25, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_batches        = X_train.shape[0]\n",
    "batch_size       = X_train.shape[1]\n",
    "n_features       = X_train.shape[2]\n",
    "n_batches, batch_size, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404357 1 12\n"
     ]
    }
   ],
   "source": [
    "n_batches        = X_train2.shape[0]\n",
    "batch_size       = X_train2.shape[1]\n",
    "n_features       = X_train2.shape[2]\n",
    "\n",
    "print(n_batches, batch_size, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape X (404357, 1, 12) => (404357, 12), y (404357,)\n",
      "P 4838 N 399519\n",
      "Resampled dataset shape  (799038, 1, 12) (799038, 12) (799038,)\n",
      "P 399519 N 399519\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "X_train_2D = X_train2.reshape(X_train2.shape[0], X_train2.shape[2])\n",
    "print('Original dataset shape X {} => {}, y {}'.format( X_train2.shape, X_train_2D.shape, y_train.shape ))\n",
    "print('P {} N {}'.format( len(y_train[y_train == 1]), len(y_train[y_train == 0]) ))\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_ov_2D, y_train_ov = sm.fit_resample(X_train_2D, y_train)\n",
    "X_train_ov = X_train_ov_2D.reshape(X_train_ov_2D.shape[0], 1, X_train_ov_2D.shape[1])\n",
    "\n",
    "print('Resampled dataset shape ',X_train_ov.shape,  X_train_ov_2D.shape, y_train_ov.shape, )\n",
    "print('P {} N {}'.format( len(y_train_ov[y_train_ov == 1]), len(y_train_ov[y_train_ov == 0]) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING RNN MODEL WITHOUT L1 REGULARIZATION _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  INITIALIZING GRID SEARCH RNN MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________\n",
      "        input_shape :  (1, 12)\n",
      "        output_dim  :  1\n",
      "        main scoring:  recall\n",
      "        all scoring :  ['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision']\n",
      "        early_stopping_monitor   : val_recall\n",
      "        model_checkpoint_monitor : val_recall\n",
      "        verbose: 1\n",
      "        callbacks: \n",
      "\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c7d6390>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c7d64e0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fee2c7d6518>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fee2c7d6550>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fee2c7d6588>]\n",
      "\n",
      "\n",
      "        \n",
      "modelType : ['GRU']\n",
      "dropout : [True]\n",
      "dropout_rate : [0.2]\n",
      "epochs : [50]\n",
      "hidden_layer_activation : ['sigmoid']\n",
      "hidden_layers : [2]\n",
      "hidden_layers_neurons : [300]\n",
      "loss : ['binary_crossentropy']\n",
      "optimizer : ['adam']\n",
      "output_layer_activation : ['sigmoid']\n",
      "rnn_hidden_layers : [0]\n",
      "rnn_hidden_layers_neurons : [50]\n",
      "rnn_layer_activation : ['sigmoid']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "gru_model_8 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=1,\n",
    "  output_file= \"gru_oversampled_data_one_batch_no_l1_checkpoints.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  TRAINING RNN _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "Generating Class Weights.\n",
      "\n",
      "        Class weights: \n",
      "[1. 1.]\n",
      "{0: 1.0, 1: 1.0}\n",
      "\n",
      "        for classes: \n",
      "[0. 1.]\n",
      "\n",
      "        # Frauds: 399519\n",
      "        # of Non-Frauds: 399519\n",
      "        \n",
      "INPUTS\n",
      "        X:      (799038, 1, 12)\n",
      "        y:      (799038,)\n",
      "        X_test: (118929, 1, 12)\n",
      "        y_test: (118929,)\n",
      "        \n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fee2c7d60b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fee2c7d6c50>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fee2c7d6ef0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fee2c7e21d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fee2c7e2470>, <tensorflow.python.keras.metrics.Precision object at 0x7fee2c7e2828>, <tensorflow.python.keras.metrics.Recall object at 0x7fee2c7e2ac8>, <tensorflow.python.keras.metrics.AUC object at 0x7fee2c7e2dd8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c7d66a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fee2c7d6748>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fee2c7d6780>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fee2c7d67f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fee2c7d6860>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "718848/719134 [============================>.] - ETA: 0s - loss: 0.1234 - tp: 383533.0000 - fp: 19288.0000 - tn: 301138.0000 - fn: 14889.0000 - accuracy: 0.9525 - precision: 0.9521 - recall: 0.9626 - auc: 0.9898\n",
      "Epoch 00001: val_recall improved from inf to 0.94254, saving model to gru_oversampled_data_one_batch_no_l1_checkpoints.h5\n",
      "719134/719134 [==============================] - 74s 103us/sample - loss: 0.1234 - tp: 383687.0000 - fp: 19294.0000 - tn: 301257.0000 - fn: 14896.0000 - accuracy: 0.9525 - precision: 0.9521 - recall: 0.9626 - auc: 0.9898 - val_loss: 0.1046 - val_tp: 1378.0000 - val_fp: 4904.0000 - val_tn: 112563.0000 - val_fn: 84.0000 - val_accuracy: 0.9581 - val_precision: 0.2194 - val_recall: 0.9425 - val_auc: 0.9881\n",
      "719134/719134 [==============================] - 74s 103us/sample - loss: 0.1234 - tp: 383687.0000 - fp: 19294.0000 - tn: 301257.0000 - fn: 14896.0000 - accuracy: 0.9525 - precision: 0.9521 - recall: 0.9626 - auc: 0.9898 - val_loss: 0.1046 - val_tp: 1378.0000 - val_fp: 4904.0000 - val_tn: 112563.0000 - val_fn: 84.0000 - val_accuracy: 0.9581 - val_precision: 0.2194 - val_recall: 0.9425 - val_auc: 0.9881\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "718976/719134 [============================>.] - ETA: 0s - loss: 0.0949 - tp: 387894.0000 - fp: 14849.0000 - tn: 305635.0000 - fn: 10598.0000 - accuracy: 0.9646 - precision: 0.9631 - recall: 0.9734 - auc: 0.9936\n",
      "Epoch 00002: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0949 - tp: 387982.0000 - fp: 14852.0000 - tn: 305699.0000 - fn: 10601.0000 - accuracy: 0.9646 - precision: 0.9631 - recall: 0.9734 - auc: 0.9936 - val_loss: 0.1582 - val_tp: 1418.0000 - val_fp: 7878.0000 - val_tn: 109589.0000 - val_fn: 44.0000 - val_accuracy: 0.9334 - val_precision: 0.1525 - val_recall: 0.9699 - val_auc: 0.9894\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0949 - tp: 387982.0000 - fp: 14852.0000 - tn: 305699.0000 - fn: 10601.0000 - accuracy: 0.9646 - precision: 0.9631 - recall: 0.9734 - auc: 0.9936 - val_loss: 0.1582 - val_tp: 1418.0000 - val_fp: 7878.0000 - val_tn: 109589.0000 - val_fn: 44.0000 - val_accuracy: 0.9334 - val_precision: 0.1525 - val_recall: 0.9699 - val_auc: 0.9894\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "718752/719134 [============================>.] - ETA: 0s - loss: 0.0876 - tp: 388436.0000 - fp: 14440.0000 - tn: 305954.0000 - fn: 9922.0000 - accuracy: 0.9661 - precision: 0.9642 - recall: 0.9751 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0876 - tp: 388657.0000 - fp: 14443.0000 - tn: 306108.0000 - fn: 9926.0000 - accuracy: 0.9661 - precision: 0.9642 - recall: 0.9751 - auc: 0.9946 - val_loss: 0.1345 - val_tp: 1411.0000 - val_fp: 6975.0000 - val_tn: 110492.0000 - val_fn: 51.0000 - val_accuracy: 0.9409 - val_precision: 0.1683 - val_recall: 0.9651 - val_auc: 0.9904\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0876 - tp: 388657.0000 - fp: 14443.0000 - tn: 306108.0000 - fn: 9926.0000 - accuracy: 0.9661 - precision: 0.9642 - recall: 0.9751 - auc: 0.9946 - val_loss: 0.1345 - val_tp: 1411.0000 - val_fp: 6975.0000 - val_tn: 110492.0000 - val_fn: 51.0000 - val_accuracy: 0.9409 - val_precision: 0.1683 - val_recall: 0.9651 - val_auc: 0.9904\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0832 - tp: 389019.0000 - fp: 14037.0000 - tn: 306500.0000 - fn: 9548.0000 - accuracy: 0.9672 - precision: 0.9652 - recall: 0.9760 - auc: 0.9951\n",
      "Epoch 00004: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0833 - tp: 389033.0000 - fp: 14037.0000 - tn: 306514.0000 - fn: 9550.0000 - accuracy: 0.9672 - precision: 0.9652 - recall: 0.9760 - auc: 0.9951 - val_loss: 0.0950 - val_tp: 1384.0000 - val_fp: 4708.0000 - val_tn: 112759.0000 - val_fn: 78.0000 - val_accuracy: 0.9598 - val_precision: 0.2272 - val_recall: 0.9466 - val_auc: 0.9910\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0833 - tp: 389033.0000 - fp: 14037.0000 - tn: 306514.0000 - fn: 9550.0000 - accuracy: 0.9672 - precision: 0.9652 - recall: 0.9760 - auc: 0.9951 - val_loss: 0.0950 - val_tp: 1384.0000 - val_fp: 4708.0000 - val_tn: 112759.0000 - val_fn: 78.0000 - val_accuracy: 0.9598 - val_precision: 0.2272 - val_recall: 0.9466 - val_auc: 0.9910\n",
      "Epoch 00004: early stopping\n",
      "79904/79904 [==============================] - 3s 33us/sample\n",
      "79904/79904 [==============================] - 3s 32us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fedf06cb0f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fedf0400828>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fedf0400668>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fedf0400a20>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fedf049be10>, <tensorflow.python.keras.metrics.Precision object at 0x7fedf03ba7f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fedf03ba780>, <tensorflow.python.keras.metrics.AUC object at 0x7fedf03ba0b8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c7d66a0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedf0387eb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fedf03d47b8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fef0c0582b0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fedf048e860>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "718816/719134 [============================>.] - ETA: 0s - loss: 0.1242 - tp: 383322.0000 - fp: 19388.0000 - tn: 301053.0000 - fn: 15053.0000 - accuracy: 0.9521 - precision: 0.9519 - recall: 0.9622 - auc: 0.9896\n",
      "Epoch 00001: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 73s 101us/sample - loss: 0.1242 - tp: 383486.0000 - fp: 19394.0000 - tn: 301193.0000 - fn: 15061.0000 - accuracy: 0.9521 - precision: 0.9519 - recall: 0.9622 - auc: 0.9896 - val_loss: 0.1237 - val_tp: 1395.0000 - val_fp: 5777.0000 - val_tn: 111690.0000 - val_fn: 67.0000 - val_accuracy: 0.9509 - val_precision: 0.1945 - val_recall: 0.9542 - val_auc: 0.9883\n",
      "719134/719134 [==============================] - 73s 101us/sample - loss: 0.1242 - tp: 383486.0000 - fp: 19394.0000 - tn: 301193.0000 - fn: 15061.0000 - accuracy: 0.9521 - precision: 0.9519 - recall: 0.9622 - auc: 0.9896 - val_loss: 0.1237 - val_tp: 1395.0000 - val_fp: 5777.0000 - val_tn: 111690.0000 - val_fn: 67.0000 - val_accuracy: 0.9509 - val_precision: 0.1945 - val_recall: 0.9542 - val_auc: 0.9883\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "719072/719134 [============================>.] - ETA: 0s - loss: 0.0949 - tp: 387849.0000 - fp: 14825.0000 - tn: 305738.0000 - fn: 10660.0000 - accuracy: 0.9646 - precision: 0.9632 - recall: 0.9733 - auc: 0.9937\n",
      "Epoch 00002: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0949 - tp: 387885.0000 - fp: 14826.0000 - tn: 305761.0000 - fn: 10662.0000 - accuracy: 0.9646 - precision: 0.9632 - recall: 0.9732 - auc: 0.9937 - val_loss: 0.1284 - val_tp: 1405.0000 - val_fp: 6325.0000 - val_tn: 111142.0000 - val_fn: 57.0000 - val_accuracy: 0.9463 - val_precision: 0.1818 - val_recall: 0.9610 - val_auc: 0.9896\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0949 - tp: 387885.0000 - fp: 14826.0000 - tn: 305761.0000 - fn: 10662.0000 - accuracy: 0.9646 - precision: 0.9632 - recall: 0.9732 - auc: 0.9937 - val_loss: 0.1284 - val_tp: 1405.0000 - val_fp: 6325.0000 - val_tn: 111142.0000 - val_fn: 57.0000 - val_accuracy: 0.9463 - val_precision: 0.1818 - val_recall: 0.9610 - val_auc: 0.9896\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "719072/719134 [============================>.] - ETA: 0s - loss: 0.0878 - tp: 388520.0000 - fp: 14511.0000 - tn: 306051.0000 - fn: 9990.0000 - accuracy: 0.9659 - precision: 0.9640 - recall: 0.9749 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.94254\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0878 - tp: 388556.0000 - fp: 14513.0000 - tn: 306074.0000 - fn: 9991.0000 - accuracy: 0.9659 - precision: 0.9640 - recall: 0.9749 - auc: 0.9946 - val_loss: 0.1014 - val_tp: 1379.0000 - val_fp: 4871.0000 - val_tn: 112596.0000 - val_fn: 83.0000 - val_accuracy: 0.9583 - val_precision: 0.2206 - val_recall: 0.9432 - val_auc: 0.9891\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0878 - tp: 388556.0000 - fp: 14513.0000 - tn: 306074.0000 - fn: 9991.0000 - accuracy: 0.9659 - precision: 0.9640 - recall: 0.9749 - auc: 0.9946 - val_loss: 0.1014 - val_tp: 1379.0000 - val_fp: 4871.0000 - val_tn: 112596.0000 - val_fn: 83.0000 - val_accuracy: 0.9583 - val_precision: 0.2206 - val_recall: 0.9432 - val_auc: 0.9891\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "718752/719134 [============================>.] - ETA: 0s - loss: 0.0830 - tp: 388835.0000 - fp: 14035.0000 - tn: 306377.0000 - fn: 9505.0000 - accuracy: 0.9672 - precision: 0.9652 - recall: 0.9761 - auc: 0.9951\n",
      "Epoch 00004: val_recall improved from 0.94254 to 0.93228, saving model to gru_oversampled_data_one_batch_no_l1_checkpoints.h5\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0830 - tp: 389037.0000 - fp: 14040.0000 - tn: 306547.0000 - fn: 9510.0000 - accuracy: 0.9673 - precision: 0.9652 - recall: 0.9761 - auc: 0.9951 - val_loss: 0.0724 - val_tp: 1363.0000 - val_fp: 3625.0000 - val_tn: 113842.0000 - val_fn: 99.0000 - val_accuracy: 0.9687 - val_precision: 0.2733 - val_recall: 0.9323 - val_auc: 0.9890\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0830 - tp: 389037.0000 - fp: 14040.0000 - tn: 306547.0000 - fn: 9510.0000 - accuracy: 0.9673 - precision: 0.9652 - recall: 0.9761 - auc: 0.9951 - val_loss: 0.0724 - val_tp: 1363.0000 - val_fp: 3625.0000 - val_tn: 113842.0000 - val_fn: 99.0000 - val_accuracy: 0.9687 - val_precision: 0.2733 - val_recall: 0.9323 - val_auc: 0.9890\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "718848/719134 [============================>.] - ETA: 0s - loss: 0.0762 - tp: 390229.0000 - fp: 13220.0000 - tn: 307226.0000 - fn: 8173.0000 - accuracy: 0.9702 - precision: 0.9672 - recall: 0.9795 - auc: 0.9958\n",
      "Epoch 00005: val_recall improved from 0.93228 to 0.93160, saving model to gru_oversampled_data_one_batch_no_l1_checkpoints.h5\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0762 - tp: 390372.0000 - fp: 13227.0000 - tn: 307360.0000 - fn: 8175.0000 - accuracy: 0.9702 - precision: 0.9672 - recall: 0.9795 - auc: 0.9958 - val_loss: 0.0617 - val_tp: 1362.0000 - val_fp: 3043.0000 - val_tn: 114424.0000 - val_fn: 100.0000 - val_accuracy: 0.9736 - val_precision: 0.3092 - val_recall: 0.9316 - val_auc: 0.9898\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0762 - tp: 390372.0000 - fp: 13227.0000 - tn: 307360.0000 - fn: 8175.0000 - accuracy: 0.9702 - precision: 0.9672 - recall: 0.9795 - auc: 0.9958 - val_loss: 0.0617 - val_tp: 1362.0000 - val_fp: 3043.0000 - val_tn: 114424.0000 - val_fn: 100.0000 - val_accuracy: 0.9736 - val_precision: 0.3092 - val_recall: 0.9316 - val_auc: 0.9898\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "718880/719134 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 391759.0000 - fp: 12148.0000 - tn: 308322.0000 - fn: 6651.0000 - accuracy: 0.9738 - precision: 0.9699 - recall: 0.9833 - auc: 0.9963\n",
      "Epoch 00006: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0692 - tp: 391893.0000 - fp: 12151.0000 - tn: 308436.0000 - fn: 6654.0000 - accuracy: 0.9739 - precision: 0.9699 - recall: 0.9833 - auc: 0.9963 - val_loss: 0.0701 - val_tp: 1382.0000 - val_fp: 3440.0000 - val_tn: 114027.0000 - val_fn: 80.0000 - val_accuracy: 0.9704 - val_precision: 0.2866 - val_recall: 0.9453 - val_auc: 0.9916\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0692 - tp: 391893.0000 - fp: 12151.0000 - tn: 308436.0000 - fn: 6654.0000 - accuracy: 0.9739 - precision: 0.9699 - recall: 0.9833 - auc: 0.9963 - val_loss: 0.0701 - val_tp: 1382.0000 - val_fp: 3440.0000 - val_tn: 114027.0000 - val_fn: 80.0000 - val_accuracy: 0.9704 - val_precision: 0.2866 - val_recall: 0.9453 - val_auc: 0.9916\n",
      "Epoch 7/50\n",
      "Epoch 7/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0644 - tp: 392771.0000 - fp: 11436.0000 - tn: 309138.0000 - fn: 5759.0000 - accuracy: 0.9761 - precision: 0.9717 - recall: 0.9855 - auc: 0.9967\n",
      "Epoch 00007: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 71s 98us/sample - loss: 0.0645 - tp: 392788.0000 - fp: 11438.0000 - tn: 309149.0000 - fn: 5759.0000 - accuracy: 0.9761 - precision: 0.9717 - recall: 0.9855 - auc: 0.9967 - val_loss: 0.0860 - val_tp: 1411.0000 - val_fp: 3940.0000 - val_tn: 113527.0000 - val_fn: 51.0000 - val_accuracy: 0.9664 - val_precision: 0.2637 - val_recall: 0.9651 - val_auc: 0.9930\n",
      "719134/719134 [==============================] - 71s 98us/sample - loss: 0.0645 - tp: 392788.0000 - fp: 11438.0000 - tn: 309149.0000 - fn: 5759.0000 - accuracy: 0.9761 - precision: 0.9717 - recall: 0.9855 - auc: 0.9967 - val_loss: 0.0860 - val_tp: 1411.0000 - val_fp: 3940.0000 - val_tn: 113527.0000 - val_fn: 51.0000 - val_accuracy: 0.9664 - val_precision: 0.2637 - val_recall: 0.9651 - val_auc: 0.9930\n",
      "Epoch 8/50\n",
      "Epoch 8/50\n",
      "718880/719134 [============================>.] - ETA: 0s - loss: 0.0614 - tp: 393109.0000 - fp: 10841.0000 - tn: 309640.0000 - fn: 5290.0000 - accuracy: 0.9776 - precision: 0.9732 - recall: 0.9867 - auc: 0.9969\n",
      "Epoch 00008: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 71s 98us/sample - loss: 0.0613 - tp: 393255.0000 - fp: 10845.0000 - tn: 309742.0000 - fn: 5292.0000 - accuracy: 0.9776 - precision: 0.9732 - recall: 0.9867 - auc: 0.9969 - val_loss: 0.0678 - val_tp: 1397.0000 - val_fp: 3100.0000 - val_tn: 114367.0000 - val_fn: 65.0000 - val_accuracy: 0.9734 - val_precision: 0.3107 - val_recall: 0.9555 - val_auc: 0.9922\n",
      "719134/719134 [==============================] - 71s 98us/sample - loss: 0.0613 - tp: 393255.0000 - fp: 10845.0000 - tn: 309742.0000 - fn: 5292.0000 - accuracy: 0.9776 - precision: 0.9732 - recall: 0.9867 - auc: 0.9969 - val_loss: 0.0678 - val_tp: 1397.0000 - val_fp: 3100.0000 - val_tn: 114367.0000 - val_fn: 65.0000 - val_accuracy: 0.9734 - val_precision: 0.3107 - val_recall: 0.9555 - val_auc: 0.9922\n",
      "Epoch 00008: early stopping\n",
      "79904/79904 [==============================] - 3s 33us/sample\n",
      "79904/79904 [==============================] - 2s 31us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fee0c556be0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fee0c53aa90>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fee0c53f8d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fee0c53f390>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fee0c53fda0>, <tensorflow.python.keras.metrics.Precision object at 0x7fee0c53ffd0>, <tensorflow.python.keras.metrics.Recall object at 0x7fee0c5c9438>, <tensorflow.python.keras.metrics.AUC object at 0x7fee0c5c9748>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fedf048e860>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedf03d4940>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fedf0441940>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fedf06cb3c8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fedf06cb320>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_3 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "718752/719134 [============================>.] - ETA: 0s - loss: 0.1233 - tp: 383468.0000 - fp: 19136.0000 - tn: 301313.0000 - fn: 14835.0000 - accuracy: 0.9527 - precision: 0.9525 - recall: 0.9628 - auc: 0.9898\n",
      "Epoch 00001: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 74s 102us/sample - loss: 0.1233 - tp: 383679.0000 - fp: 19149.0000 - tn: 301465.0000 - fn: 14841.0000 - accuracy: 0.9527 - precision: 0.9525 - recall: 0.9628 - auc: 0.9898 - val_loss: 0.0865 - val_tp: 1365.0000 - val_fp: 4228.0000 - val_tn: 113239.0000 - val_fn: 97.0000 - val_accuracy: 0.9636 - val_precision: 0.2441 - val_recall: 0.9337 - val_auc: 0.9875\n",
      "719134/719134 [==============================] - 74s 102us/sample - loss: 0.1233 - tp: 383679.0000 - fp: 19149.0000 - tn: 301465.0000 - fn: 14841.0000 - accuracy: 0.9527 - precision: 0.9525 - recall: 0.9628 - auc: 0.9898 - val_loss: 0.0865 - val_tp: 1365.0000 - val_fp: 4228.0000 - val_tn: 113239.0000 - val_fn: 97.0000 - val_accuracy: 0.9636 - val_precision: 0.2441 - val_recall: 0.9337 - val_auc: 0.9875\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0954 - tp: 387823.0000 - fp: 14852.0000 - tn: 305748.0000 - fn: 10681.0000 - accuracy: 0.9645 - precision: 0.9631 - recall: 0.9732 - auc: 0.9936\n",
      "Epoch 00002: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0954 - tp: 387837.0000 - fp: 14852.0000 - tn: 305762.0000 - fn: 10683.0000 - accuracy: 0.9645 - precision: 0.9631 - recall: 0.9732 - auc: 0.9936 - val_loss: 0.1272 - val_tp: 1403.0000 - val_fp: 6283.0000 - val_tn: 111184.0000 - val_fn: 59.0000 - val_accuracy: 0.9467 - val_precision: 0.1825 - val_recall: 0.9596 - val_auc: 0.9895\n",
      "719134/719134 [==============================] - 70s 97us/sample - loss: 0.0954 - tp: 387837.0000 - fp: 14852.0000 - tn: 305762.0000 - fn: 10683.0000 - accuracy: 0.9645 - precision: 0.9631 - recall: 0.9732 - auc: 0.9936 - val_loss: 0.1272 - val_tp: 1403.0000 - val_fp: 6283.0000 - val_tn: 111184.0000 - val_fn: 59.0000 - val_accuracy: 0.9467 - val_precision: 0.1825 - val_recall: 0.9596 - val_auc: 0.9895\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "718944/719134 [============================>.] - ETA: 0s - loss: 0.0881 - tp: 388531.0000 - fp: 14672.0000 - tn: 305856.0000 - fn: 9885.0000 - accuracy: 0.9658 - precision: 0.9636 - recall: 0.9752 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0881 - tp: 388631.0000 - fp: 14677.0000 - tn: 305937.0000 - fn: 9889.0000 - accuracy: 0.9658 - precision: 0.9636 - recall: 0.9752 - auc: 0.9946 - val_loss: 0.0948 - val_tp: 1378.0000 - val_fp: 4814.0000 - val_tn: 112653.0000 - val_fn: 84.0000 - val_accuracy: 0.9588 - val_precision: 0.2225 - val_recall: 0.9425 - val_auc: 0.9901\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0881 - tp: 388631.0000 - fp: 14677.0000 - tn: 305937.0000 - fn: 9889.0000 - accuracy: 0.9658 - precision: 0.9636 - recall: 0.9752 - auc: 0.9946 - val_loss: 0.0948 - val_tp: 1378.0000 - val_fp: 4814.0000 - val_tn: 112653.0000 - val_fn: 84.0000 - val_accuracy: 0.9588 - val_precision: 0.2225 - val_recall: 0.9425 - val_auc: 0.9901\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "718944/719134 [============================>.] - ETA: 0s - loss: 0.0834 - tp: 389056.0000 - fp: 14123.0000 - tn: 306398.0000 - fn: 9367.0000 - accuracy: 0.9673 - precision: 0.9650 - recall: 0.9765 - auc: 0.9951\n",
      "Epoch 00004: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0834 - tp: 389149.0000 - fp: 14128.0000 - tn: 306486.0000 - fn: 9371.0000 - accuracy: 0.9673 - precision: 0.9650 - recall: 0.9765 - auc: 0.9951 - val_loss: 0.0733 - val_tp: 1368.0000 - val_fp: 3828.0000 - val_tn: 113639.0000 - val_fn: 94.0000 - val_accuracy: 0.9670 - val_precision: 0.2633 - val_recall: 0.9357 - val_auc: 0.9904\n",
      "719134/719134 [==============================] - 70s 98us/sample - loss: 0.0834 - tp: 389149.0000 - fp: 14128.0000 - tn: 306486.0000 - fn: 9371.0000 - accuracy: 0.9673 - precision: 0.9650 - recall: 0.9765 - auc: 0.9951 - val_loss: 0.0733 - val_tp: 1368.0000 - val_fp: 3828.0000 - val_tn: 113639.0000 - val_fn: 94.0000 - val_accuracy: 0.9670 - val_precision: 0.2633 - val_recall: 0.9357 - val_auc: 0.9904\n",
      "Epoch 00004: early stopping\n",
      "79904/79904 [==============================] - 3s 33us/sample\n",
      "79904/79904 [==============================] - 2s 31us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "719134/719134 [==============================] - 23s 32us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fee0c147780>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fee0c5aecc0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fee0c5aef98>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fee0c4f6fd0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fee0c4f67f0>, <tensorflow.python.keras.metrics.Precision object at 0x7fee0c4f65f8>, <tensorflow.python.keras.metrics.Recall object at 0x7fee0c4f6278>, <tensorflow.python.keras.metrics.AUC object at 0x7fee0c4df390>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fef0c0586d8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedcd45eba8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fedcd508cf8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fedcd49fc88>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fee0c4683c8>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "719040/719134 [============================>.] - ETA: 0s - loss: 0.1244 - tp: 383485.0000 - fp: 19407.0000 - tn: 301107.0000 - fn: 15041.0000 - accuracy: 0.9521 - precision: 0.9518 - recall: 0.9623 - auc: 0.9895\n",
      "Epoch 00001: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 73s 101us/sample - loss: 0.1244 - tp: 383543.0000 - fp: 19408.0000 - tn: 301139.0000 - fn: 15044.0000 - accuracy: 0.9521 - precision: 0.9518 - recall: 0.9623 - auc: 0.9895 - val_loss: 0.1017 - val_tp: 1371.0000 - val_fp: 4670.0000 - val_tn: 112797.0000 - val_fn: 91.0000 - val_accuracy: 0.9600 - val_precision: 0.2269 - val_recall: 0.9378 - val_auc: 0.9883\n",
      "719134/719134 [==============================] - 73s 101us/sample - loss: 0.1244 - tp: 383543.0000 - fp: 19408.0000 - tn: 301139.0000 - fn: 15044.0000 - accuracy: 0.9521 - precision: 0.9518 - recall: 0.9623 - auc: 0.9895 - val_loss: 0.1017 - val_tp: 1371.0000 - val_fp: 4670.0000 - val_tn: 112797.0000 - val_fn: 91.0000 - val_accuracy: 0.9600 - val_precision: 0.2269 - val_recall: 0.9378 - val_auc: 0.9883\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "718656/719134 [============================>.] - ETA: 0s - loss: 0.0943 - tp: 387833.0000 - fp: 14763.0000 - tn: 305584.0000 - fn: 10476.0000 - accuracy: 0.9649 - precision: 0.9633 - recall: 0.9737 - auc: 0.9937\n",
      "Epoch 00002: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0942 - tp: 388107.0000 - fp: 14767.0000 - tn: 305780.0000 - fn: 10480.0000 - accuracy: 0.9649 - precision: 0.9633 - recall: 0.9737 - auc: 0.9937 - val_loss: 0.1075 - val_tp: 1383.0000 - val_fp: 5305.0000 - val_tn: 112162.0000 - val_fn: 79.0000 - val_accuracy: 0.9547 - val_precision: 0.2068 - val_recall: 0.9460 - val_auc: 0.9896\n",
      "719134/719134 [==============================] - 71s 99us/sample - loss: 0.0942 - tp: 388107.0000 - fp: 14767.0000 - tn: 305780.0000 - fn: 10480.0000 - accuracy: 0.9649 - precision: 0.9633 - recall: 0.9737 - auc: 0.9937 - val_loss: 0.1075 - val_tp: 1383.0000 - val_fp: 5305.0000 - val_tn: 112162.0000 - val_fn: 79.0000 - val_accuracy: 0.9547 - val_precision: 0.2068 - val_recall: 0.9460 - val_auc: 0.9896\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "718816/719134 [============================>.] - ETA: 0s - loss: 0.0871 - tp: 388626.0000 - fp: 14461.0000 - tn: 305948.0000 - fn: 9781.0000 - accuracy: 0.9663 - precision: 0.9641 - recall: 0.9754 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0871 - tp: 388802.0000 - fp: 14468.0000 - tn: 306079.0000 - fn: 9785.0000 - accuracy: 0.9663 - precision: 0.9641 - recall: 0.9755 - auc: 0.9947 - val_loss: 0.0887 - val_tp: 1372.0000 - val_fp: 4344.0000 - val_tn: 113123.0000 - val_fn: 90.0000 - val_accuracy: 0.9627 - val_precision: 0.2400 - val_recall: 0.9384 - val_auc: 0.9903\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0871 - tp: 388802.0000 - fp: 14468.0000 - tn: 306079.0000 - fn: 9785.0000 - accuracy: 0.9663 - precision: 0.9641 - recall: 0.9755 - auc: 0.9947 - val_loss: 0.0887 - val_tp: 1372.0000 - val_fp: 4344.0000 - val_tn: 113123.0000 - val_fn: 90.0000 - val_accuracy: 0.9627 - val_precision: 0.2400 - val_recall: 0.9384 - val_auc: 0.9903\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "718912/719134 [============================>.] - ETA: 0s - loss: 0.0815 - tp: 389322.0000 - fp: 13786.0000 - tn: 306657.0000 - fn: 9147.0000 - accuracy: 0.9681 - precision: 0.9658 - recall: 0.9770 - auc: 0.9953\n",
      "Epoch 00004: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0815 - tp: 389436.0000 - fp: 13790.0000 - tn: 306757.0000 - fn: 9151.0000 - accuracy: 0.9681 - precision: 0.9658 - recall: 0.9770 - auc: 0.9953 - val_loss: 0.0682 - val_tp: 1363.0000 - val_fp: 3467.0000 - val_tn: 114000.0000 - val_fn: 99.0000 - val_accuracy: 0.9700 - val_precision: 0.2822 - val_recall: 0.9323 - val_auc: 0.9913\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0815 - tp: 389436.0000 - fp: 13790.0000 - tn: 306757.0000 - fn: 9151.0000 - accuracy: 0.9681 - precision: 0.9658 - recall: 0.9770 - auc: 0.9953 - val_loss: 0.0682 - val_tp: 1363.0000 - val_fp: 3467.0000 - val_tn: 114000.0000 - val_fn: 99.0000 - val_accuracy: 0.9700 - val_precision: 0.2822 - val_recall: 0.9323 - val_auc: 0.9913\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "718976/719134 [============================>.] - ETA: 0s - loss: 0.0747 - tp: 390637.0000 - fp: 12914.0000 - tn: 307558.0000 - fn: 7867.0000 - accuracy: 0.9711 - precision: 0.9680 - recall: 0.9803 - auc: 0.9958\n",
      "Epoch 00005: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0747 - tp: 390718.0000 - fp: 12916.0000 - tn: 307631.0000 - fn: 7869.0000 - accuracy: 0.9711 - precision: 0.9680 - recall: 0.9803 - auc: 0.9958 - val_loss: 0.0811 - val_tp: 1392.0000 - val_fp: 4276.0000 - val_tn: 113191.0000 - val_fn: 70.0000 - val_accuracy: 0.9635 - val_precision: 0.2456 - val_recall: 0.9521 - val_auc: 0.9927\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0747 - tp: 390718.0000 - fp: 12916.0000 - tn: 307631.0000 - fn: 7869.0000 - accuracy: 0.9711 - precision: 0.9680 - recall: 0.9803 - auc: 0.9958 - val_loss: 0.0811 - val_tp: 1392.0000 - val_fp: 4276.0000 - val_tn: 113191.0000 - val_fn: 70.0000 - val_accuracy: 0.9635 - val_precision: 0.2456 - val_recall: 0.9521 - val_auc: 0.9927\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "718880/719134 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 391784.0000 - fp: 11971.0000 - tn: 308468.0000 - fn: 6657.0000 - accuracy: 0.9741 - precision: 0.9704 - recall: 0.9833 - auc: 0.9963\n",
      "Epoch 00006: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0691 - tp: 391928.0000 - fp: 11975.0000 - tn: 308572.0000 - fn: 6659.0000 - accuracy: 0.9741 - precision: 0.9704 - recall: 0.9833 - auc: 0.9963 - val_loss: 0.0892 - val_tp: 1416.0000 - val_fp: 4462.0000 - val_tn: 113005.0000 - val_fn: 46.0000 - val_accuracy: 0.9621 - val_precision: 0.2409 - val_recall: 0.9685 - val_auc: 0.9938\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0691 - tp: 391928.0000 - fp: 11975.0000 - tn: 308572.0000 - fn: 6659.0000 - accuracy: 0.9741 - precision: 0.9704 - recall: 0.9833 - auc: 0.9963 - val_loss: 0.0892 - val_tp: 1416.0000 - val_fp: 4462.0000 - val_tn: 113005.0000 - val_fn: 46.0000 - val_accuracy: 0.9621 - val_precision: 0.2409 - val_recall: 0.9685 - val_auc: 0.9938\n",
      "Epoch 7/50\n",
      "Epoch 7/50\n",
      "718848/719134 [============================>.] - ETA: 0s - loss: 0.0646 - tp: 392670.0000 - fp: 11176.0000 - tn: 309245.0000 - fn: 5757.0000 - accuracy: 0.9764 - precision: 0.9723 - recall: 0.9856 - auc: 0.9966\n",
      "Epoch 00007: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0646 - tp: 392827.0000 - fp: 11179.0000 - tn: 309368.0000 - fn: 5760.0000 - accuracy: 0.9764 - precision: 0.9723 - recall: 0.9855 - auc: 0.9966 - val_loss: 0.0917 - val_tp: 1420.0000 - val_fp: 4312.0000 - val_tn: 113155.0000 - val_fn: 42.0000 - val_accuracy: 0.9634 - val_precision: 0.2477 - val_recall: 0.9713 - val_auc: 0.9936\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0646 - tp: 392827.0000 - fp: 11179.0000 - tn: 309368.0000 - fn: 5760.0000 - accuracy: 0.9764 - precision: 0.9723 - recall: 0.9855 - auc: 0.9966 - val_loss: 0.0917 - val_tp: 1420.0000 - val_fp: 4312.0000 - val_tn: 113155.0000 - val_fn: 42.0000 - val_accuracy: 0.9634 - val_precision: 0.2477 - val_recall: 0.9713 - val_auc: 0.9936\n",
      "Epoch 00007: early stopping\n",
      "79904/79904 [==============================] - 3s 37us/sample\n",
      "79904/79904 [==============================] - 3s 36us/sample\n",
      "719134/719134 [==============================] - 27s 37us/sample\n",
      "719134/719134 [==============================] - 26s 37us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fedf07b2278>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fedcd1357f0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fedcd1a2630>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fedcd203b70>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fedcd3df5c0>, <tensorflow.python.keras.metrics.Precision object at 0x7fedcc0e87f0>, <tensorflow.python.keras.metrics.Recall object at 0x7fedcd12e5f8>, <tensorflow.python.keras.metrics.AUC object at 0x7fedcd12e6d8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fedcd508cf8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedcd49fc88>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fedcd49ff60>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fedcc10dcf8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fee2c6c84a8>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_5 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "719040/719134 [============================>.] - ETA: 0s - loss: 0.1230 - tp: 383736.0000 - fp: 19076.0000 - tn: 301440.0000 - fn: 14788.0000 - accuracy: 0.9529 - precision: 0.9526 - recall: 0.9629 - auc: 0.9898\n",
      "Epoch 00001: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 86s 120us/sample - loss: 0.1230 - tp: 383784.0000 - fp: 19078.0000 - tn: 301482.0000 - fn: 14790.0000 - accuracy: 0.9529 - precision: 0.9526 - recall: 0.9629 - auc: 0.9898 - val_loss: 0.1078 - val_tp: 1373.0000 - val_fp: 4804.0000 - val_tn: 112663.0000 - val_fn: 89.0000 - val_accuracy: 0.9589 - val_precision: 0.2223 - val_recall: 0.9391 - val_auc: 0.9879\n",
      "719134/719134 [==============================] - 86s 120us/sample - loss: 0.1230 - tp: 383784.0000 - fp: 19078.0000 - tn: 301482.0000 - fn: 14790.0000 - accuracy: 0.9529 - precision: 0.9526 - recall: 0.9629 - auc: 0.9898 - val_loss: 0.1078 - val_tp: 1373.0000 - val_fp: 4804.0000 - val_tn: 112663.0000 - val_fn: 89.0000 - val_accuracy: 0.9589 - val_precision: 0.2223 - val_recall: 0.9391 - val_auc: 0.9879\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0945 - tp: 387800.0000 - fp: 14677.0000 - tn: 305867.0000 - fn: 10760.0000 - accuracy: 0.9646 - precision: 0.9635 - recall: 0.9730 - auc: 0.9937\n",
      "Epoch 00002: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 83s 116us/sample - loss: 0.0945 - tp: 387813.0000 - fp: 14677.0000 - tn: 305883.0000 - fn: 10761.0000 - accuracy: 0.9646 - precision: 0.9635 - recall: 0.9730 - auc: 0.9937 - val_loss: 0.1010 - val_tp: 1369.0000 - val_fp: 4440.0000 - val_tn: 113027.0000 - val_fn: 93.0000 - val_accuracy: 0.9619 - val_precision: 0.2357 - val_recall: 0.9364 - val_auc: 0.9868\n",
      "719134/719134 [==============================] - 83s 116us/sample - loss: 0.0945 - tp: 387813.0000 - fp: 14677.0000 - tn: 305883.0000 - fn: 10761.0000 - accuracy: 0.9646 - precision: 0.9635 - recall: 0.9730 - auc: 0.9937 - val_loss: 0.1010 - val_tp: 1369.0000 - val_fp: 4440.0000 - val_tn: 113027.0000 - val_fn: 93.0000 - val_accuracy: 0.9619 - val_precision: 0.2357 - val_recall: 0.9364 - val_auc: 0.9868\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "719008/719134 [============================>.] - ETA: 0s - loss: 0.0877 - tp: 388567.0000 - fp: 14566.0000 - tn: 305938.0000 - fn: 9937.0000 - accuracy: 0.9659 - precision: 0.9639 - recall: 0.9751 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.93160\n",
      "719134/719134 [==============================] - 80s 111us/sample - loss: 0.0877 - tp: 388634.0000 - fp: 14566.0000 - tn: 305994.0000 - fn: 9940.0000 - accuracy: 0.9659 - precision: 0.9639 - recall: 0.9751 - auc: 0.9946 - val_loss: 0.0938 - val_tp: 1374.0000 - val_fp: 4532.0000 - val_tn: 112935.0000 - val_fn: 88.0000 - val_accuracy: 0.9612 - val_precision: 0.2326 - val_recall: 0.9398 - val_auc: 0.9896\n",
      "719134/719134 [==============================] - 80s 111us/sample - loss: 0.0877 - tp: 388634.0000 - fp: 14566.0000 - tn: 305994.0000 - fn: 9940.0000 - accuracy: 0.9659 - precision: 0.9639 - recall: 0.9751 - auc: 0.9946 - val_loss: 0.0938 - val_tp: 1374.0000 - val_fp: 4532.0000 - val_tn: 112935.0000 - val_fn: 88.0000 - val_accuracy: 0.9612 - val_precision: 0.2326 - val_recall: 0.9398 - val_auc: 0.9896\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "719072/719134 [============================>.] - ETA: 0s - loss: 0.0828 - tp: 389031.0000 - fp: 14051.0000 - tn: 306484.0000 - fn: 9506.0000 - accuracy: 0.9672 - precision: 0.9651 - recall: 0.9761 - auc: 0.9952\n",
      "Epoch 00004: val_recall improved from 0.93160 to 0.93023, saving model to gru_oversampled_data_one_batch_no_l1_checkpoints.h5\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0828 - tp: 389067.0000 - fp: 14052.0000 - tn: 306508.0000 - fn: 9507.0000 - accuracy: 0.9672 - precision: 0.9651 - recall: 0.9761 - auc: 0.9952 - val_loss: 0.0663 - val_tp: 1360.0000 - val_fp: 3370.0000 - val_tn: 114097.0000 - val_fn: 102.0000 - val_accuracy: 0.9708 - val_precision: 0.2875 - val_recall: 0.9302 - val_auc: 0.9891\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0828 - tp: 389067.0000 - fp: 14052.0000 - tn: 306508.0000 - fn: 9507.0000 - accuracy: 0.9672 - precision: 0.9651 - recall: 0.9761 - auc: 0.9952 - val_loss: 0.0663 - val_tp: 1360.0000 - val_fp: 3370.0000 - val_tn: 114097.0000 - val_fn: 102.0000 - val_accuracy: 0.9708 - val_precision: 0.2875 - val_recall: 0.9302 - val_auc: 0.9891\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "718976/719134 [============================>.] - ETA: 0s - loss: 0.0754 - tp: 390474.0000 - fp: 13122.0000 - tn: 307360.0000 - fn: 8020.0000 - accuracy: 0.9706 - precision: 0.9675 - recall: 0.9799 - auc: 0.9958\n",
      "Epoch 00005: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0754 - tp: 390553.0000 - fp: 13125.0000 - tn: 307435.0000 - fn: 8021.0000 - accuracy: 0.9706 - precision: 0.9675 - recall: 0.9799 - auc: 0.9958 - val_loss: 0.0923 - val_tp: 1404.0000 - val_fp: 4625.0000 - val_tn: 112842.0000 - val_fn: 58.0000 - val_accuracy: 0.9606 - val_precision: 0.2329 - val_recall: 0.9603 - val_auc: 0.9923\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0754 - tp: 390553.0000 - fp: 13125.0000 - tn: 307435.0000 - fn: 8021.0000 - accuracy: 0.9706 - precision: 0.9675 - recall: 0.9799 - auc: 0.9958 - val_loss: 0.0923 - val_tp: 1404.0000 - val_fp: 4625.0000 - val_tn: 112842.0000 - val_fn: 58.0000 - val_accuracy: 0.9606 - val_precision: 0.2329 - val_recall: 0.9603 - val_auc: 0.9923\n",
      "Epoch 6/50\n",
      "Epoch 6/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0677 - tp: 392192.0000 - fp: 12011.0000 - tn: 308533.0000 - fn: 6368.0000 - accuracy: 0.9744 - precision: 0.9703 - recall: 0.9840 - auc: 0.9964\n",
      "Epoch 00006: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0677 - tp: 392206.0000 - fp: 12011.0000 - tn: 308549.0000 - fn: 6368.0000 - accuracy: 0.9744 - precision: 0.9703 - recall: 0.9840 - auc: 0.9964 - val_loss: 0.0643 - val_tp: 1378.0000 - val_fp: 3169.0000 - val_tn: 114298.0000 - val_fn: 84.0000 - val_accuracy: 0.9726 - val_precision: 0.3031 - val_recall: 0.9425 - val_auc: 0.9928\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0677 - tp: 392206.0000 - fp: 12011.0000 - tn: 308549.0000 - fn: 6368.0000 - accuracy: 0.9744 - precision: 0.9703 - recall: 0.9840 - auc: 0.9964 - val_loss: 0.0643 - val_tp: 1378.0000 - val_fp: 3169.0000 - val_tn: 114298.0000 - val_fn: 84.0000 - val_accuracy: 0.9726 - val_precision: 0.3031 - val_recall: 0.9425 - val_auc: 0.9928\n",
      "Epoch 7/50\n",
      "Epoch 7/50\n",
      "718976/719134 [============================>.] - ETA: 0s - loss: 0.0641 - tp: 392725.0000 - fp: 11286.0000 - tn: 309201.0000 - fn: 5764.0000 - accuracy: 0.9763 - precision: 0.9721 - recall: 0.9855 - auc: 0.9967\n",
      "Epoch 00007: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0641 - tp: 392809.0000 - fp: 11291.0000 - tn: 309269.0000 - fn: 5765.0000 - accuracy: 0.9763 - precision: 0.9721 - recall: 0.9855 - auc: 0.9967 - val_loss: 0.0836 - val_tp: 1414.0000 - val_fp: 4035.0000 - val_tn: 113432.0000 - val_fn: 48.0000 - val_accuracy: 0.9657 - val_precision: 0.2595 - val_recall: 0.9672 - val_auc: 0.9937\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0641 - tp: 392809.0000 - fp: 11291.0000 - tn: 309269.0000 - fn: 5765.0000 - accuracy: 0.9763 - precision: 0.9721 - recall: 0.9855 - auc: 0.9967 - val_loss: 0.0836 - val_tp: 1414.0000 - val_fp: 4035.0000 - val_tn: 113432.0000 - val_fn: 48.0000 - val_accuracy: 0.9657 - val_precision: 0.2595 - val_recall: 0.9672 - val_auc: 0.9937\n",
      "Epoch 00007: early stopping\n",
      "79904/79904 [==============================] - 3s 38us/sample\n",
      "79904/79904 [==============================] - 3s 36us/sample\n",
      "719134/719134 [==============================] - 27s 37us/sample\n",
      "719134/719134 [==============================] - 26s 36us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fedcc1b1080>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fedf0385240>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fedcd1ebd30>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fedcd4c88d0>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fedcd4c8128>, <tensorflow.python.keras.metrics.Precision object at 0x7fedcd4c8d30>, <tensorflow.python.keras.metrics.Recall object at 0x7fedcd153cf8>, <tensorflow.python.keras.metrics.AUC object at 0x7fedcd1536d8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fee2c6c84a8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedcd1c7128>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fedf03e8d68>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fedf06fcac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fedf06fcfd0>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_6 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "719040/719134 [============================>.] - ETA: 0s - loss: 0.1258 - tp: 306991.0000 - fp: 17924.0000 - tn: 376761.0000 - fn: 17364.0000 - accuracy: 0.9509 - precision: 0.9448 - recall: 0.9465 - auc: 0.9897\n",
      "Epoch 00001: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.1258 - tp: 307034.0000 - fp: 17924.0000 - tn: 376812.0000 - fn: 17364.0000 - accuracy: 0.9509 - precision: 0.9448 - recall: 0.9465 - auc: 0.9897 - val_loss: 0.1129 - val_tp: 1375.0000 - val_fp: 4965.0000 - val_tn: 112502.0000 - val_fn: 87.0000 - val_accuracy: 0.9575 - val_precision: 0.2169 - val_recall: 0.9405 - val_auc: 0.9883\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.1258 - tp: 307034.0000 - fp: 17924.0000 - tn: 376812.0000 - fn: 17364.0000 - accuracy: 0.9509 - precision: 0.9448 - recall: 0.9465 - auc: 0.9897 - val_loss: 0.1129 - val_tp: 1375.0000 - val_fp: 4965.0000 - val_tn: 112502.0000 - val_fn: 87.0000 - val_accuracy: 0.9575 - val_precision: 0.2169 - val_recall: 0.9405 - val_auc: 0.9883\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "719072/719134 [============================>.] - ETA: 0s - loss: 0.0964 - tp: 312718.0000 - fp: 14436.0000 - tn: 380267.0000 - fn: 11651.0000 - accuracy: 0.9637 - precision: 0.9559 - recall: 0.9641 - auc: 0.9936\n",
      "Epoch 00002: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0963 - tp: 312747.0000 - fp: 14437.0000 - tn: 380299.0000 - fn: 11651.0000 - accuracy: 0.9637 - precision: 0.9559 - recall: 0.9641 - auc: 0.9936 - val_loss: 0.0933 - val_tp: 1371.0000 - val_fp: 4443.0000 - val_tn: 113024.0000 - val_fn: 91.0000 - val_accuracy: 0.9619 - val_precision: 0.2358 - val_recall: 0.9378 - val_auc: 0.9893\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0963 - tp: 312747.0000 - fp: 14437.0000 - tn: 380299.0000 - fn: 11651.0000 - accuracy: 0.9637 - precision: 0.9559 - recall: 0.9641 - auc: 0.9936 - val_loss: 0.0933 - val_tp: 1371.0000 - val_fp: 4443.0000 - val_tn: 113024.0000 - val_fn: 91.0000 - val_accuracy: 0.9619 - val_precision: 0.2358 - val_recall: 0.9378 - val_auc: 0.9893\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "719040/719134 [============================>.] - ETA: 0s - loss: 0.0895 - tp: 313091.0000 - fp: 13896.0000 - tn: 380787.0000 - fn: 11266.0000 - accuracy: 0.9650 - precision: 0.9575 - recall: 0.9653 - auc: 0.9946\n",
      "Epoch 00003: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0895 - tp: 313128.0000 - fp: 13898.0000 - tn: 380838.0000 - fn: 11270.0000 - accuracy: 0.9650 - precision: 0.9575 - recall: 0.9653 - auc: 0.9946 - val_loss: 0.1179 - val_tp: 1393.0000 - val_fp: 5767.0000 - val_tn: 111700.0000 - val_fn: 69.0000 - val_accuracy: 0.9509 - val_precision: 0.1946 - val_recall: 0.9528 - val_auc: 0.9902\n",
      "719134/719134 [==============================] - 83s 115us/sample - loss: 0.0895 - tp: 313128.0000 - fp: 13898.0000 - tn: 380838.0000 - fn: 11270.0000 - accuracy: 0.9650 - precision: 0.9575 - recall: 0.9653 - auc: 0.9946 - val_loss: 0.1179 - val_tp: 1393.0000 - val_fp: 5767.0000 - val_tn: 111700.0000 - val_fn: 69.0000 - val_accuracy: 0.9509 - val_precision: 0.1946 - val_recall: 0.9528 - val_auc: 0.9902\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.0842 - tp: 313680.0000 - fp: 13357.0000 - tn: 381364.0000 - fn: 10703.0000 - accuracy: 0.9665 - precision: 0.9592 - recall: 0.9670 - auc: 0.9952\n",
      "Epoch 00004: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0842 - tp: 313695.0000 - fp: 13358.0000 - tn: 381378.0000 - fn: 10703.0000 - accuracy: 0.9665 - precision: 0.9592 - recall: 0.9670 - auc: 0.9952 - val_loss: 0.0828 - val_tp: 1374.0000 - val_fp: 3988.0000 - val_tn: 113479.0000 - val_fn: 88.0000 - val_accuracy: 0.9657 - val_precision: 0.2562 - val_recall: 0.9398 - val_auc: 0.9912\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0842 - tp: 313695.0000 - fp: 13358.0000 - tn: 381378.0000 - fn: 10703.0000 - accuracy: 0.9665 - precision: 0.9592 - recall: 0.9670 - auc: 0.9952 - val_loss: 0.0828 - val_tp: 1374.0000 - val_fp: 3988.0000 - val_tn: 113479.0000 - val_fn: 88.0000 - val_accuracy: 0.9657 - val_precision: 0.2562 - val_recall: 0.9398 - val_auc: 0.9912\n",
      "Epoch 5/50\n",
      "Epoch 5/50\n",
      "719072/719134 [============================>.] - ETA: 0s - loss: 0.0768 - tp: 315136.0000 - fp: 12564.0000 - tn: 382136.0000 - fn: 9236.0000 - accuracy: 0.9697 - precision: 0.9617 - recall: 0.9715 - auc: 0.9959\n",
      "Epoch 00005: val_recall did not improve from 0.93023\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0768 - tp: 315161.0000 - fp: 12566.0000 - tn: 382170.0000 - fn: 9237.0000 - accuracy: 0.9697 - precision: 0.9617 - recall: 0.9715 - auc: 0.9959 - val_loss: 0.0833 - val_tp: 1390.0000 - val_fp: 3906.0000 - val_tn: 113561.0000 - val_fn: 72.0000 - val_accuracy: 0.9666 - val_precision: 0.2625 - val_recall: 0.9508 - val_auc: 0.9926\n",
      "719134/719134 [==============================] - 82s 114us/sample - loss: 0.0768 - tp: 315161.0000 - fp: 12566.0000 - tn: 382170.0000 - fn: 9237.0000 - accuracy: 0.9697 - precision: 0.9617 - recall: 0.9715 - auc: 0.9959 - val_loss: 0.0833 - val_tp: 1390.0000 - val_fp: 3906.0000 - val_tn: 113561.0000 - val_fn: 72.0000 - val_accuracy: 0.9666 - val_precision: 0.2625 - val_recall: 0.9508 - val_auc: 0.9926\n",
      "Epoch 00005: early stopping\n",
      "79904/79904 [==============================] - 3s 38us/sample\n",
      "79904/79904 [==============================] - 3s 36us/sample\n",
      "719134/719134 [==============================] - 27s 37us/sample\n",
      "719134/719134 [==============================] - 26s 37us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 50 \n",
      "          hidden_layers:             2 \n",
      "          hidden_layers_neurons:     300\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   True\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 12)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7fee2c2a3ef0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7fee2c45bef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7fee2c0fc470>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7fee2c0fc860>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fedcc1f61d0>, <tensorflow.python.keras.metrics.Precision object at 0x7fedcc1f6588>, <tensorflow.python.keras.metrics.Recall object at 0x7fedcc1f6828>, <tensorflow.python.keras.metrics.AUC object at 0x7fedcc1f6b38>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7fedf06fcac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7fedf03e8a20>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7fee0c1c27f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7fee0c1c2eb8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7fee0c38f2b0>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_7 (GRU)                  (None, 50)                9600      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 300)               15300     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 301       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 115,501\n",
      "Trainable params: 115,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 719134 samples, validate on 118929 samples\n",
      "Epoch 1/50\n",
      "Epoch 1/50\n",
      "719104/719134 [============================>.] - ETA: 0s - loss: 0.1252 - tp: 302172.0000 - fp: 17803.0000 - tn: 381697.0000 - fn: 17432.0000 - accuracy: 0.9510 - precision: 0.9444 - recall: 0.9455 - auc: 0.9898\n",
      "Epoch 00001: val_recall improved from 0.93023 to 0.89056, saving model to gru_oversampled_data_one_batch_no_l1_checkpoints.h5\n",
      "719134/719134 [==============================] - 86s 120us/sample - loss: 0.1252 - tp: 302183.0000 - fp: 17803.0000 - tn: 381716.0000 - fn: 17432.0000 - accuracy: 0.9510 - precision: 0.9444 - recall: 0.9455 - auc: 0.9898 - val_loss: 0.0537 - val_tp: 1302.0000 - val_fp: 2427.0000 - val_tn: 115040.0000 - val_fn: 160.0000 - val_accuracy: 0.9782 - val_precision: 0.3492 - val_recall: 0.8906 - val_auc: 0.9842\n",
      "719134/719134 [==============================] - 86s 120us/sample - loss: 0.1252 - tp: 302183.0000 - fp: 17803.0000 - tn: 381716.0000 - fn: 17432.0000 - accuracy: 0.9510 - precision: 0.9444 - recall: 0.9455 - auc: 0.9898 - val_loss: 0.0537 - val_tp: 1302.0000 - val_fp: 2427.0000 - val_tn: 115040.0000 - val_fn: 160.0000 - val_accuracy: 0.9782 - val_precision: 0.3492 - val_recall: 0.8906 - val_auc: 0.9842\n",
      "Epoch 2/50\n",
      "Epoch 2/50\n",
      "718912/719134 [============================>.] - ETA: 0s - loss: 0.0962 - tp: 307779.0000 - fp: 14389.0000 - tn: 385006.0000 - fn: 11738.0000 - accuracy: 0.9637 - precision: 0.9553 - recall: 0.9633 - auc: 0.9937\n",
      "Epoch 00002: val_recall did not improve from 0.89056\n",
      "719134/719134 [==============================] - 81s 112us/sample - loss: 0.0962 - tp: 307875.0000 - fp: 14392.0000 - tn: 385127.0000 - fn: 11740.0000 - accuracy: 0.9637 - precision: 0.9553 - recall: 0.9633 - auc: 0.9937 - val_loss: 0.0755 - val_tp: 1357.0000 - val_fp: 3721.0000 - val_tn: 113746.0000 - val_fn: 105.0000 - val_accuracy: 0.9678 - val_precision: 0.2672 - val_recall: 0.9282 - val_auc: 0.9886\n",
      "719134/719134 [==============================] - 81s 112us/sample - loss: 0.0962 - tp: 307875.0000 - fp: 14392.0000 - tn: 385127.0000 - fn: 11740.0000 - accuracy: 0.9637 - precision: 0.9553 - recall: 0.9633 - auc: 0.9937 - val_loss: 0.0755 - val_tp: 1357.0000 - val_fp: 3721.0000 - val_tn: 113746.0000 - val_fn: 105.0000 - val_accuracy: 0.9678 - val_precision: 0.2672 - val_recall: 0.9282 - val_auc: 0.9886\n",
      "Epoch 3/50\n",
      "Epoch 3/50\n",
      "718912/719134 [============================>.] - ETA: 0s - loss: 0.0887 - tp: 308404.0000 - fp: 13743.0000 - tn: 385663.0000 - fn: 11102.0000 - accuracy: 0.9654 - precision: 0.9573 - recall: 0.9653 - auc: 0.9947\n",
      "Epoch 00003: val_recall did not improve from 0.89056\n",
      "719134/719134 [==============================] - 81s 113us/sample - loss: 0.0887 - tp: 308508.0000 - fp: 13746.0000 - tn: 385773.0000 - fn: 11107.0000 - accuracy: 0.9654 - precision: 0.9573 - recall: 0.9652 - auc: 0.9947 - val_loss: 0.0703 - val_tp: 1352.0000 - val_fp: 3330.0000 - val_tn: 114137.0000 - val_fn: 110.0000 - val_accuracy: 0.9711 - val_precision: 0.2888 - val_recall: 0.9248 - val_auc: 0.9901\n",
      "719134/719134 [==============================] - 81s 113us/sample - loss: 0.0887 - tp: 308508.0000 - fp: 13746.0000 - tn: 385773.0000 - fn: 11107.0000 - accuracy: 0.9654 - precision: 0.9573 - recall: 0.9652 - auc: 0.9947 - val_loss: 0.0703 - val_tp: 1352.0000 - val_fp: 3330.0000 - val_tn: 114137.0000 - val_fn: 110.0000 - val_accuracy: 0.9711 - val_precision: 0.2888 - val_recall: 0.9248 - val_auc: 0.9901\n",
      "Epoch 4/50\n",
      "Epoch 4/50\n",
      "718784/719134 [============================>.] - ETA: 0s - loss: 0.0835 - tp: 308976.0000 - fp: 13153.0000 - tn: 386174.0000 - fn: 10481.0000 - accuracy: 0.9671 - precision: 0.9592 - recall: 0.9672 - auc: 0.9953\n",
      "Epoch 00004: val_recall did not improve from 0.89056\n",
      "719134/719134 [==============================] - 82s 115us/sample - loss: 0.0835 - tp: 309130.0000 - fp: 13158.0000 - tn: 386361.0000 - fn: 10485.0000 - accuracy: 0.9671 - precision: 0.9592 - recall: 0.9672 - auc: 0.9953 - val_loss: 0.0879 - val_tp: 1381.0000 - val_fp: 4028.0000 - val_tn: 113439.0000 - val_fn: 81.0000 - val_accuracy: 0.9654 - val_precision: 0.2553 - val_recall: 0.9446 - val_auc: 0.9909\n",
      "719134/719134 [==============================] - 82s 115us/sample - loss: 0.0835 - tp: 309130.0000 - fp: 13158.0000 - tn: 386361.0000 - fn: 10485.0000 - accuracy: 0.9671 - precision: 0.9592 - recall: 0.9672 - auc: 0.9953 - val_loss: 0.0879 - val_tp: 1381.0000 - val_fp: 4028.0000 - val_tn: 113439.0000 - val_fn: 81.0000 - val_accuracy: 0.9654 - val_precision: 0.2553 - val_recall: 0.9446 - val_auc: 0.9909\n",
      "Epoch 00004: early stopping\n",
      "79904/79904 [==============================] - 3s 38us/sample\n",
      "79904/79904 [==============================] - 3s 36us/sample\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-34f14054c1e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgru_history_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgru_model_8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX_train_ov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_ov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SAVING..\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgru_model_8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"gru_oversampled_data_one_batch_no_l1.h5\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SageMaker/models.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, X_test, y_test, class_weights)\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m           \u001b[0mclass_weight\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m           \u001b[0mcallbacks\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         )\n\u001b[1;32m    227\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\\n{} {} {}\\n\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"_ \"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"RNN TRAINING RESULTS\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"_ \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[0;32m---> 87\u001b[0;31m                                       *args, **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, clf, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    330\u001b[0m                                                  **self._kwargs)\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sign\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_factory_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    388\u001b[0m                                              max_fpr=max_fpr),\n\u001b[1;32m    389\u001b[0m                                      \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                                      sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    391\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m         return _average_binary_score(partial(_binary_roc_auc_score,\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;34m\"\"\"Binary roc auc score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         raise ValueError(\"Only one class present in y_true. ROC AUC score \"\n\u001b[0m\u001b[1;32m    222\u001b[0m                          \"is not defined in that case.\")\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "gru_history_8 = gru_model_8.train( X_train_ov, y_train_ov, X_test2, y_test, class_weights=None )\n",
    "print(\"SAVING..\")\n",
    "gru_model_8.model.best_estimator_.model.save( \"gru_oversampled_data_one_batch_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "gru_param_grid_4 = gru_param_grid.copy()\n",
    "\n",
    "gru_model_7 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid_4,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=1,\n",
    "  output_file= \"gru_double_data_2_rnn_layers_one_batch_1_layer_no_l1_checkpoints.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "\n",
    "gru_history_7 = gru_model_7.train( X_train, y_train, X_test, y_test, class_weights=None )\n",
    "print(\"SAVING..\")\n",
    "gru_model_7.model.best_estimator_.model.save( \"gru_double_data_2_rnn_layers_one_batch_1_layer_no_l1.h5\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING WITH DOUBLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODIFIED DATASET\n",
    "from models import RNNModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from data import readLocally\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from visualization import plot_roc_auc, pr_curve, format_vertical_headers, print_confusion_matrix, printModelData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test, X_val, y_val, labels_hash, scaler = readLocally()\n",
    "\n",
    "#DIVIDE X_TEST IN HALF AND ADD IT TO X_TRAIN\n",
    "test_half_pos   = int(len(X_test)/2)\n",
    "total_data_size = len(X_train) + len(X_test) + len(X_val)\n",
    "\n",
    "X_train = np.vstack( ( X_train ,  X_test[0: test_half_pos ] ))\n",
    "y_train = np.append( y_train ,  y_test[0: test_half_pos ]  )\n",
    "\n",
    "X_test  = X_test[ test_half_pos : ]\n",
    "y_test  = y_test[ test_half_pos : ]\n",
    "\n",
    "print(\"\"\"INCREASED TRAIN SET -> NEW SIZES\n",
    "X_train: {}\n",
    "y_train: {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "X_test : {}\n",
    "y_test : {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "X_val  : {}\n",
    "y_val  : {}         {:0.0f}% {:0.2f}P% {:0.2f}N%\n",
    "\"\"\".format(\n",
    "    X_train.shape, y_train.shape, len(X_train) * 100 / total_data_size,  len(y_train[y_train==1]) * 100 / len(y_train) , len(y_train[y_train==0]) * 100 / len(y_train) ,\n",
    "    X_test.shape, y_test.shape,   len(X_test)  * 100  / total_data_size, len(y_test[y_test==1])   * 100 / len(y_test)  , len(y_test[y_test==0])   * 100 / len(y_test) ,\n",
    "    X_val.shape,  y_val.shape,    len(X_val)   * 100  / total_data_size, len(y_val[y_val==1])     * 100 / len(y_val)   , len(y_val[y_val==0])     * 100 / len(y_val) ,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_3_param_grid = {\n",
    "    'dropout': [True], \n",
    "    'dropout_rate': [0.2], \n",
    "    'epochs': [50], \n",
    "    'hidden_layer_activation': ['sigmoid'], \n",
    "    'hidden_layers': [0],  #[2], \n",
    "    'hidden_layers_neurons': [300], #[300], \n",
    "    'loss': ['binary_crossentropy'], \n",
    "    'modelType': ['GRU'], \n",
    "    'optimizer': ['adam'], \n",
    "    'output_layer_activation': ['sigmoid'], \n",
    "    'rnn_hidden_layers': [0], \n",
    "    'rnn_hidden_layers_neurons': [50], \n",
    "    'rnn_layer_activation': ['sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "n_batches        = X_train.shape[0]\n",
    "batch_size       = X_train.shape[1]\n",
    "n_features       = X_train.shape[2]\n",
    "\n",
    "gru_3_model = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_3_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_3_double_data_checkpoint.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_3_history = gru_3_model.train( X_train, y_train, X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_3_model.model.best_estimator_.model.save( \"gru3_0_200_double_data.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_4_param_grid = {\n",
    "    'dropout': [True], \n",
    "    'dropout_rate': [0.2], \n",
    "    'epochs': [25], \n",
    "    'hidden_layer_activation': ['sigmoid'], \n",
    "    'hidden_layers': [2],  #[2], \n",
    "    'hidden_layers_neurons': [300], #[300], \n",
    "    'loss': ['binary_crossentropy'], \n",
    "    'modelType': ['GRU'], \n",
    "    'optimizer': ['adam'], \n",
    "    'output_layer_activation': ['sigmoid'], \n",
    "    'rnn_hidden_layers': [0], \n",
    "    'rnn_hidden_layers_neurons': [50], \n",
    "    'rnn_layer_activation': ['sigmoid']\n",
    "}\n",
    "\n",
    "\n",
    "n_batches        = X_train.shape[0]\n",
    "batch_size       = X_train.shape[1]\n",
    "n_features       = X_train.shape[2]\n",
    "\n",
    "gru_4_model = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_4_param_grid,\n",
    "  scoring=['accuracy', 'precision', 'recall', 'roc_auc', 'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=2,\n",
    "  output_file= \"gru_4_double_data_checkpoint.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")\n",
    "gru_4_history = gru_4_model.train( X_train, y_train, X_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_4_model.model.best_estimator_.model.save( \"gru_4_2_300_nol1_double_data.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "tensorflow.keras.models.load_model(\"gru_4_2_300_nol1_double_data.h5\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.keras.models.load_model(\"gru_3_0_200_lr_double_data.h5\").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOUBLE SIZE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import downloadFromKaggle, normalizing_data, generating3DRNNInput\n",
    "from data import generateNewFeatures, separateInBatches, separateLabel, separatingTrainTest, normalize3DInput \n",
    "from data import read_data, readLocally, saveLocally, readDataFromCloud, saveToCloud \n",
    "from visualization import plot_roc_auc, pr_curve, print_confusion_matrix, visualize_data, printModelData, acc_plot, loss_plot, format_vertical_headers\n",
    "\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_padding_value                = -1\n",
    "\n",
    "data                               = read_data(input_file_path=\"bs140513_032310.csv\")\n",
    "visualize_data(data)\n",
    "rnn_data, smaller_batches_rnn_data = generating3DRNNInput(data) \n",
    "rnn_mod_data                       = generateNewFeatures(rnn_data)\n",
    "X, grouped_X, y, grouped_y         = separateInBatches(rnn_mod_data, min_batch_size=50)\n",
    "\n",
    "# print(\"CT\", data['customer'].value_counts() > 200 )\n",
    "# print(\"CT\", data['merchant'].value_counts())\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm                             = normalize3DInput(X)\n",
    "y[y==empty_padding_value] = 0\n",
    "X_train3, X_test3, y_train3, y_test3, X_val3, y_val3 = separatingTrainTest(X_norm, y, test_size=0.1, val_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"SHAPES & KEYS:\n",
    "X_train          : {}\n",
    "y_train          : {}\n",
    "________________________\n",
    "X_test           : {}\n",
    "y_test           : {}\n",
    "________________________\n",
    "X_val            : {}\n",
    "y_val            : {}\n",
    "________________________\n",
    "labels_hash Keys : \n",
    "\"\"\".format(\n",
    "    X_train3.shape, y_train3.shape,\n",
    "    X_test3.shape,  y_test3.shape,\n",
    "    X_val3.shape, y_val3.shape, \n",
    "#     labels_hash.keys() \n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( rnn_data      , open( \"rnn_data_db.data\"      , \"wb\" ) ) \n",
    "pickle.dump( rnn_mod_data  , open( \"rnn_mod_data_db.data\"  , \"wb\" ) ) \n",
    "pickle.dump( X_train3      , open( \"X_train_db.data\"       , \"wb\" ) ) \n",
    "pickle.dump( X_test3       , open( \"X_test_db.data\"        , \"wb\" ) )\n",
    "pickle.dump( X_val3        , open( \"X_val_db.data\"         , \"wb\" ) )\n",
    "pickle.dump( y_train3      , open( \"y_train_db.data\"       , \"wb\" ) )\n",
    "pickle.dump( y_test3       , open( \"y_test_db.data\"        , \"wb\" ) )\n",
    "pickle.dump( y_val3        , open( \"y_val_db.data\"         , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Verafin MITACS 2020",
   "language": "python",
   "name": "verafin-mitacs-2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
