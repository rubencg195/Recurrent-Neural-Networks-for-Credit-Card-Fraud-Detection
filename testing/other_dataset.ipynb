{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import RNNModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from data import readLocally\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from visualization import plot_roc_auc, pr_curve, format_vertical_headers, print_confusion_matrix, printModelData\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"creditcard_ULB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V19       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  ...  0.403993  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425  ... -0.145783 -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  ... -2.261857  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024  ... -1.232622 -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  ...  0.803487  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, 0:-2]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29) (284807,)\n"
     ]
    }
   ],
   "source": [
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 1, 29)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape( X.shape[0], 1, X.shape[1] )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN (182276, 1, 29) (182276,)\n",
      "TEST  (56962, 1, 29) (56962,)\n",
      "VAL   (45569, 1, 29) (45569,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=1, stratify=y_train)\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "TRAIN {} {}\n",
    "TEST  {} {}\n",
    "VAL   {} {}\n",
    "\"\"\".format(\n",
    "X_train.shape, y_train.shape,\n",
    "X_test.shape,  y_test.shape,\n",
    "X_val.shape, y_val.shape\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAIN \n",
      "  P: 315 0.173%\n",
      "  N: 181961 99.827%\n",
      "TEST  \n",
      "  P: 98 0.172% \n",
      "  N: 56864 99.828%\n",
      "VAL   \n",
      "  P: 79 0.173% \n",
      "  N: 45490 99.827%\n",
      "  \n",
      "CLASES: [0 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "TRAIN \n",
    "  P: {} {:.3f}%\n",
    "  N: {} {:.3f}%\n",
    "TEST  \n",
    "  P: {} {:.3f}% \n",
    "  N: {} {:.3f}%\n",
    "VAL   \n",
    "  P: {} {:.3f}% \n",
    "  N: {} {:.3f}%\n",
    "  \n",
    "CLASES: {}\n",
    "\"\"\".format(\n",
    "len(y_train[y_train == 1]), len(y_train[y_train == 1])*100/len(y_train), len(y_train[y_train == 0]), len(y_train[y_train == 0])*100/len(y_train),\n",
    "len(y_test[y_test == 1]), len(y_test[y_test == 1])*100/len(y_test),  len(y_test[y_test == 0]), len(y_test[y_test == 0])*100/len(y_test), \n",
    "len(y_val[y_val == 1]), len(y_val[y_val == 1])*100/len(y_val) , len(y_val[y_val == 0]), len(y_val[y_val == 0])*100/len(y_val),\n",
    "np.unique(y)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182276 1 29\n"
     ]
    }
   ],
   "source": [
    "n_batches        = X_train.shape[0]\n",
    "batch_size       = X_train.shape[1]\n",
    "n_features       = X_train.shape[2]\n",
    "\n",
    "print(n_batches, batch_size, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_param_grid = {\n",
    "    'modelType': ['GRU'], \n",
    "    'dropout': [False],\n",
    "    'dropout_rate': [0.2], \n",
    "    'epochs': [25], \n",
    "    'hidden_layer_activation': ['sigmoid'], \n",
    "    'hidden_layers': [0], \n",
    "    'hidden_layers_neurons': [12], \n",
    "    'loss': ['binary_crossentropy'], \n",
    "    'optimizer': ['adam'], \n",
    "    'output_layer_activation': ['sigmoid'], \n",
    "    'rnn_hidden_layers': [0], \n",
    "    'rnn_hidden_layers_neurons': [29], \n",
    "    'rnn_layer_activation': ['sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING RNN MODEL WITHOUT L1 REGULARIZATION _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  INITIALIZING GRID SEARCH RNN MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________\n",
      "        input_shape :  (1, 29)\n",
      "        output_dim  :  1\n",
      "        main scoring:  recall\n",
      "        all scoring :  ['accuracy', 'precision', 'recall', 'f1', 'average_precision']\n",
      "        early_stopping_monitor   : val_recall\n",
      "        model_checkpoint_monitor : val_recall\n",
      "        verbose: 1\n",
      "        callbacks: \n",
      "\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ea5c1a710>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1ea5c1aeb8>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1ea5c1a208>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1ea5c1a0f0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1ea5c1a160>]\n",
      "\n",
      "\n",
      "        \n",
      "modelType : ['GRU']\n",
      "dropout : [False]\n",
      "dropout_rate : [0.2]\n",
      "epochs : [25]\n",
      "hidden_layer_activation : ['sigmoid']\n",
      "hidden_layers : [0]\n",
      "hidden_layers_neurons : [12]\n",
      "loss : ['binary_crossentropy']\n",
      "optimizer : ['adam']\n",
      "output_layer_activation : ['sigmoid']\n",
      "rnn_hidden_layers : [0]\n",
      "rnn_hidden_layers_neurons : [29]\n",
      "rnn_layer_activation : ['sigmoid']\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gru_model_1 = RNNModel(\n",
    "  input_shape=( batch_size , n_features  ),\n",
    "  output_dim = 1,\n",
    "  param_grid=gru_param_grid,\n",
    "  scoring=[\n",
    "    'accuracy', 'precision', 'recall', \n",
    "#     'roc_auc', \n",
    "    'f1', 'average_precision' ],  \n",
    "  refit= \"recall\",   \n",
    "  verbose=1,\n",
    "  output_file= \"gru_ULB_checkpoints.h5\",\n",
    "  early_stopping_monitor=\"val_recall\",\n",
    "  model_checkpoint_monitor=\"val_recall\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Wieghts {0: 0.5008655700946906, 1: 289.32698412698414}\n",
      "Modified Weights: {0: 0.5008655700946906, 1: 289.32698412698414}\n",
      "Original dataset shape X (182276, 1, 29) => (182276, 29), y (182276,)\n",
      "P 315 N 181961\n",
      "Resampled dataset shape  (363922, 1, 29) (363922, 29) (363922,)\n",
      "P 181961 N 181961\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.flatten()), y_train.flatten())\n",
    "modified_weights = np.array(class_weights) \n",
    "# modified_weights[0] = class_weights[0] / 4\n",
    "# modified_weights[1] = class_weights[1] * 4\n",
    "print(\"Original Wieghts {}\\nModified Weights: {}\".format( dict(enumerate(class_weights)), dict(enumerate(modified_weights)) ))\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import SMOTE # doctest: +NORMALIZE_WHITESPACE\n",
    "\n",
    "X_train_2D = X_train.reshape(X_train.shape[0], X_train.shape[2])\n",
    "print('Original dataset shape X {} => {}, y {}'.format( X_train.shape, X_train_2D.shape, y_train.shape ))\n",
    "print('P {} N {}'.format( len(y_train[y_train == 1]), len(y_train[y_train == 0]) ))\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_ov_2D, y_train_ov = sm.fit_resample(X_train_2D, y_train)\n",
    "X_train_ov = X_train_ov_2D.reshape(X_train_ov_2D.shape[0], 1, X_train_ov_2D.shape[1])\n",
    "\n",
    "print('Resampled dataset shape ',X_train_ov.shape,  X_train_ov_2D.shape, y_train_ov.shape, )\n",
    "print('P {} N {}'.format( len(y_train_ov[y_train_ov == 1]), len(y_train_ov[y_train_ov == 0]) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  TRAINING RNN _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "Using Given Class Weights. [  0.50086557 289.32698413]\n",
      "\n",
      "        Class weights: \n",
      "[  0.50086557 289.32698413]\n",
      "{0: 0.5008655700946906, 1: 289.32698412698414}\n",
      "\n",
      "        for classes: \n",
      "[0 1]\n",
      "\n",
      "        # Frauds: 181961\n",
      "        # of Non-Frauds: 181961\n",
      "        \n",
      "INPUTS\n",
      "        X:      (363922, 1, 29)\n",
      "        y:      (363922,)\n",
      "        X_test: (56962, 1, 29)\n",
      "        y_test: (56962,)\n",
      "        \n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1ea5df3e80>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1ea5bfaef0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1ea5bfac88>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1ea5bfa518>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1ea5bfa6d8>, <tensorflow.python.keras.metrics.Precision object at 0x7f1eae2bd160>, <tensorflow.python.keras.metrics.Recall object at 0x7f1ea5c034e0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1eae2d3550>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ea5c1a198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1ea5c1ab38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1ea5c1a978>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1ea5c1a7b8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1ea5c1a1d0>]\n",
      "          \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_22 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327529 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327520/327529 [============================>.] - ETA: 0s - loss: 0.6901 - tp: 172891.0000 - fp: 138200.0000 - tn: 7425.0000 - fn: 9004.0000 - accuracy: 0.5505 - precision: 0.5558 - recall: 0.9505 - auc: 0.5013\n",
      "Epoch 00001: val_recall improved from inf to 1.00000, saving model to gru_ULB_checkpoints.h5\n",
      "327529/327529 [==============================] - 26s 78us/sample - loss: 0.6901 - tp: 172895.0000 - fp: 138205.0000 - tn: 7425.0000 - fn: 9004.0000 - accuracy: 0.5505 - precision: 0.5558 - recall: 0.9505 - auc: 0.5013 - val_loss: 0.8065 - val_tp: 98.0000 - val_fp: 56826.0000 - val_tn: 38.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0024 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5007\n",
      "327529/327529 [==============================] - 26s 78us/sample - loss: 0.6901 - tp: 172895.0000 - fp: 138205.0000 - tn: 7425.0000 - fn: 9004.0000 - accuracy: 0.5505 - precision: 0.5558 - recall: 0.9505 - auc: 0.5013 - val_loss: 0.8065 - val_tp: 98.0000 - val_fp: 56826.0000 - val_tn: 38.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0024 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5007\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327392/327529 [============================>.] - ETA: 0s - loss: 0.6879 - tp: 177246.0000 - fp: 141665.0000 - tn: 3899.0000 - fn: 4582.0000 - accuracy: 0.5533 - precision: 0.5558 - recall: 0.9748 - auc: 0.5010\n",
      "Epoch 00002: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6879 - tp: 177317.0000 - fp: 141731.0000 - tn: 3899.0000 - fn: 4582.0000 - accuracy: 0.5533 - precision: 0.5558 - recall: 0.9748 - auc: 0.5010 - val_loss: 0.7870 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4998\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6879 - tp: 177317.0000 - fp: 141731.0000 - tn: 3899.0000 - fn: 4582.0000 - accuracy: 0.5533 - precision: 0.5558 - recall: 0.9748 - auc: 0.5010 - val_loss: 0.7870 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4998\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "326848/327529 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 180942.0000 - fp: 144801.0000 - tn: 528.0000 - fn: 577.0000 - accuracy: 0.5552 - precision: 0.5555 - recall: 0.9968 - auc: 0.4997\n",
      "Epoch 00003: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 181322.0000 - fp: 145102.0000 - tn: 528.0000 - fn: 577.0000 - accuracy: 0.5552 - precision: 0.5555 - recall: 0.9968 - auc: 0.4997 - val_loss: 0.8076 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4999\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 181322.0000 - fp: 145102.0000 - tn: 528.0000 - fn: 577.0000 - accuracy: 0.5552 - precision: 0.5555 - recall: 0.9968 - auc: 0.4997 - val_loss: 0.8076 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4999\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "326848/327529 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 180451.0000 - fp: 144445.0000 - tn: 873.0000 - fn: 1079.0000 - accuracy: 0.5548 - precision: 0.5554 - recall: 0.9941 - auc: 0.4984\n",
      "Epoch 00004: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 180820.0000 - fp: 144757.0000 - tn: 873.0000 - fn: 1079.0000 - accuracy: 0.5547 - precision: 0.5554 - recall: 0.9941 - auc: 0.4984 - val_loss: 0.8136 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4998\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 180820.0000 - fp: 144757.0000 - tn: 873.0000 - fn: 1079.0000 - accuracy: 0.5547 - precision: 0.5554 - recall: 0.9941 - auc: 0.4984 - val_loss: 0.8136 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4998\n",
      "Epoch 00004: early stopping\n",
      "36393/36393 [==============================] - 1s 23us/sample\n",
      "36393/36393 [==============================] - 1s 21us/sample\n",
      "327529/327529 [==============================] - 7s 21us/sample\n",
      "327529/327529 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e4c7864a8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1e4c5526d8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1e4c527a20>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1e4c527b38>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1e4c527eb8>, <tensorflow.python.keras.metrics.Precision object at 0x7f1ea5c1a438>, <tensorflow.python.keras.metrics.Recall object at 0x7f1e4c4c8ef0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1e4c4c8898>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ea5c1a198>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1ea673d898>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1e4c5486a0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e4c522e48>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1e4c7b80f0>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_23 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327529 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327520/327529 [============================>.] - ETA: 0s - loss: 0.6879 - tp: 174820.0000 - fp: 139979.0000 - tn: 5636.0000 - fn: 7085.0000 - accuracy: 0.5510 - precision: 0.5553 - recall: 0.9611 - auc: 0.5011\n",
      "Epoch 00001: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 26s 81us/sample - loss: 0.6879 - tp: 174824.0000 - fp: 139984.0000 - tn: 5636.0000 - fn: 7085.0000 - accuracy: 0.5510 - precision: 0.5553 - recall: 0.9611 - auc: 0.5011 - val_loss: 0.7903 - val_tp: 98.0000 - val_fp: 56826.0000 - val_tn: 38.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0024 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "327529/327529 [==============================] - 26s 81us/sample - loss: 0.6879 - tp: 174824.0000 - fp: 139984.0000 - tn: 5636.0000 - fn: 7085.0000 - accuracy: 0.5510 - precision: 0.5553 - recall: 0.9611 - auc: 0.5011 - val_loss: 0.7903 - val_tp: 98.0000 - val_fp: 56826.0000 - val_tn: 38.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0024 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327360/327529 [============================>.] - ETA: 0s - loss: 0.6891 - tp: 173796.0000 - fp: 138763.0000 - tn: 6778.0000 - fn: 8023.0000 - accuracy: 0.5516 - precision: 0.5560 - recall: 0.9559 - auc: 0.5006\n",
      "Epoch 00002: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6891 - tp: 173886.0000 - fp: 138842.0000 - tn: 6778.0000 - fn: 8023.0000 - accuracy: 0.5516 - precision: 0.5560 - recall: 0.9559 - auc: 0.5006 - val_loss: 0.7742 - val_tp: 98.0000 - val_fp: 56741.0000 - val_tn: 123.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0039 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5016\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6891 - tp: 173886.0000 - fp: 138842.0000 - tn: 6778.0000 - fn: 8023.0000 - accuracy: 0.5516 - precision: 0.5560 - recall: 0.9559 - auc: 0.5006 - val_loss: 0.7742 - val_tp: 98.0000 - val_fp: 56741.0000 - val_tn: 123.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0039 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5016\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327488/327529 [============================>.] - ETA: 0s - loss: 0.6877 - tp: 178717.0000 - fp: 142859.0000 - tn: 2748.0000 - fn: 3164.0000 - accuracy: 0.5541 - precision: 0.5558 - recall: 0.9826 - auc: 0.5013\n",
      "Epoch 00003: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 178745.0000 - fp: 142872.0000 - tn: 2748.0000 - fn: 3164.0000 - accuracy: 0.5541 - precision: 0.5558 - recall: 0.9826 - auc: 0.5012 - val_loss: 0.7927 - val_tp: 98.0000 - val_fp: 56787.0000 - val_tn: 77.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0031 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5016\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 178745.0000 - fp: 142872.0000 - tn: 2748.0000 - fn: 3164.0000 - accuracy: 0.5541 - precision: 0.5558 - recall: 0.9826 - auc: 0.5012 - val_loss: 0.7927 - val_tp: 98.0000 - val_fp: 56787.0000 - val_tn: 77.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0031 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5016\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "326816/327529 [============================>.] - ETA: 0s - loss: 0.6883 - tp: 176582.0000 - fp: 141141.0000 - tn: 4160.0000 - fn: 4933.0000 - accuracy: 0.5530 - precision: 0.5558 - recall: 0.9728 - auc: 0.5017\n",
      "Epoch 00004: val_recall did not improve from 1.00000\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6883 - tp: 176976.0000 - fp: 141460.0000 - tn: 4160.0000 - fn: 4933.0000 - accuracy: 0.5530 - precision: 0.5558 - recall: 0.9729 - auc: 0.5016 - val_loss: 0.7785 - val_tp: 98.0000 - val_fp: 56863.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5001\n",
      "327529/327529 [==============================] - 23s 70us/sample - loss: 0.6883 - tp: 176976.0000 - fp: 141460.0000 - tn: 4160.0000 - fn: 4933.0000 - accuracy: 0.5530 - precision: 0.5558 - recall: 0.9729 - auc: 0.5016 - val_loss: 0.7785 - val_tp: 98.0000 - val_fp: 56863.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5001\n",
      "Epoch 00004: early stopping\n",
      "36393/36393 [==============================] - 1s 24us/sample\n",
      "36393/36393 [==============================] - 1s 21us/sample\n",
      "327529/327529 [==============================] - 7s 21us/sample\n",
      "327529/327529 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e4c5c7358>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1ea65172e8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1e4c2842b0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1e4c672c88>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1e4c65fef0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1eac01b668>, <tensorflow.python.keras.metrics.Recall object at 0x7f1eac01b630>, <tensorflow.python.keras.metrics.AUC object at 0x7f1eac01b9b0>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1e4c522e48>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1e44719710>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1ea4f683c8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e4c6e4c50>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1eadf12cc0>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_24 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327008/327530 [============================>.] - ETA: 0s - loss: 0.6885 - tp: 176153.0000 - fp: 141005.0000 - tn: 4405.0000 - fn: 5445.0000 - accuracy: 0.5522 - precision: 0.5554 - recall: 0.9700 - auc: 0.5001\n",
      "Epoch 00001: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6885 - tp: 176447.0000 - fp: 141233.0000 - tn: 4405.0000 - fn: 5445.0000 - accuracy: 0.5522 - precision: 0.5554 - recall: 0.9701 - auc: 0.5001 - val_loss: 0.8088 - val_tp: 98.0000 - val_fp: 56859.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6885 - tp: 176447.0000 - fp: 141233.0000 - tn: 4405.0000 - fn: 5445.0000 - accuracy: 0.5522 - precision: 0.5554 - recall: 0.9701 - auc: 0.5001 - val_loss: 0.8088 - val_tp: 98.0000 - val_fp: 56859.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "326912/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 179776.0000 - fp: 143857.0000 - tn: 1493.0000 - fn: 1786.0000 - accuracy: 0.5545 - precision: 0.5555 - recall: 0.9902 - auc: 0.4992\n",
      "Epoch 00002: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 180106.0000 - fp: 144145.0000 - tn: 1493.0000 - fn: 1786.0000 - accuracy: 0.5544 - precision: 0.5555 - recall: 0.9902 - auc: 0.4992 - val_loss: 0.7881 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4997\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 180106.0000 - fp: 144145.0000 - tn: 1493.0000 - fn: 1786.0000 - accuracy: 0.5544 - precision: 0.5555 - recall: 0.9902 - auc: 0.4992 - val_loss: 0.7881 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4997\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "326912/327530 [============================>.] - ETA: 0s - loss: 0.6871 - tp: 181543.0000 - fp: 145342.0000 - tn: 11.0000 - fn: 16.0000 - accuracy: 0.5554 - precision: 0.5554 - recall: 0.9999 - auc: 0.5000\n",
      "Epoch 00003: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6871 - tp: 181876.0000 - fp: 145627.0000 - tn: 11.0000 - fn: 16.0000 - accuracy: 0.5553 - precision: 0.5553 - recall: 0.9999 - auc: 0.5000 - val_loss: 0.7985 - val_tp: 98.0000 - val_fp: 56862.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6871 - tp: 181876.0000 - fp: 145627.0000 - tn: 11.0000 - fn: 16.0000 - accuracy: 0.5553 - precision: 0.5553 - recall: 0.9999 - auc: 0.5000 - val_loss: 0.7985 - val_tp: 98.0000 - val_fp: 56862.0000 - val_tn: 2.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327520/327530 [============================>.] - ETA: 0s - loss: 0.6874 - tp: 180821.0000 - fp: 144717.0000 - tn: 915.0000 - fn: 1067.0000 - accuracy: 0.5549 - precision: 0.5555 - recall: 0.9941 - auc: 0.4994\n",
      "Epoch 00004: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6874 - tp: 180825.0000 - fp: 144723.0000 - tn: 915.0000 - fn: 1067.0000 - accuracy: 0.5549 - precision: 0.5554 - recall: 0.9941 - auc: 0.4994 - val_loss: 0.8148 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4997\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6874 - tp: 180825.0000 - fp: 144723.0000 - tn: 915.0000 - fn: 1067.0000 - accuracy: 0.5549 - precision: 0.5554 - recall: 0.9941 - auc: 0.4994 - val_loss: 0.8148 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4997\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 23us/sample\n",
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "327530/327530 [==============================] - 7s 20us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1eabf070f0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1ead5081d0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1ead5084e0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1ead508320>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1ead4fe6a0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1ead4fe518>, <tensorflow.python.keras.metrics.Recall object at 0x7f1ead4fe5c0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1ead4fefd0>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1e4c6e4c50>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1eac324940>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1ea4f3c278>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1ea4f3dac8>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1ead399fd0>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_25 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327424/327530 [============================>.] - ETA: 0s - loss: 0.6877 - tp: 176852.0000 - fp: 141419.0000 - tn: 4167.0000 - fn: 4986.0000 - accuracy: 0.5529 - precision: 0.5557 - recall: 0.9726 - auc: 0.5000\n",
      "Epoch 00001: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6877 - tp: 176916.0000 - fp: 141456.0000 - tn: 4169.0000 - fn: 4989.0000 - accuracy: 0.5529 - precision: 0.5557 - recall: 0.9726 - auc: 0.5000 - val_loss: 0.8163 - val_tp: 98.0000 - val_fp: 56628.0000 - val_tn: 236.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0059 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5052\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6877 - tp: 176916.0000 - fp: 141456.0000 - tn: 4169.0000 - fn: 4989.0000 - accuracy: 0.5529 - precision: 0.5557 - recall: 0.9726 - auc: 0.5000 - val_loss: 0.8163 - val_tp: 98.0000 - val_fp: 56628.0000 - val_tn: 236.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0059 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5052\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327520/327530 [============================>.] - ETA: 0s - loss: 0.6869 - tp: 181135.0000 - fp: 144688.0000 - tn: 933.0000 - fn: 764.0000 - accuracy: 0.5559 - precision: 0.5559 - recall: 0.9958 - auc: 0.5008\n",
      "Epoch 00002: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6869 - tp: 181141.0000 - fp: 144692.0000 - tn: 933.0000 - fn: 764.0000 - accuracy: 0.5559 - precision: 0.5559 - recall: 0.9958 - auc: 0.5008 - val_loss: 0.8023 - val_tp: 98.0000 - val_fp: 56738.0000 - val_tn: 126.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0039 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5015\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6869 - tp: 181141.0000 - fp: 144692.0000 - tn: 933.0000 - fn: 764.0000 - accuracy: 0.5559 - precision: 0.5559 - recall: 0.9958 - auc: 0.5008 - val_loss: 0.8023 - val_tp: 98.0000 - val_fp: 56738.0000 - val_tn: 126.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0039 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5015\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327200/327530 [============================>.] - ETA: 0s - loss: 0.6895 - tp: 174375.0000 - fp: 139670.0000 - tn: 5801.0000 - fn: 7354.0000 - accuracy: 0.5507 - precision: 0.5553 - recall: 0.9595 - auc: 0.4977\n",
      "Epoch 00003: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6895 - tp: 174551.0000 - fp: 139824.0000 - tn: 5801.0000 - fn: 7354.0000 - accuracy: 0.5506 - precision: 0.5552 - recall: 0.9596 - auc: 0.4977 - val_loss: 0.7845 - val_tp: 98.0000 - val_fp: 56863.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5002\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6895 - tp: 174551.0000 - fp: 139824.0000 - tn: 5801.0000 - fn: 7354.0000 - accuracy: 0.5506 - precision: 0.5552 - recall: 0.9596 - auc: 0.4977 - val_loss: 0.7845 - val_tp: 98.0000 - val_fp: 56863.0000 - val_tn: 1.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5002\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327328/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 180645.0000 - fp: 144572.0000 - tn: 973.0000 - fn: 1138.0000 - accuracy: 0.5549 - precision: 0.5555 - recall: 0.9937 - auc: 0.5012\n",
      "Epoch 00004: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6872 - tp: 180767.0000 - fp: 144651.0000 - tn: 974.0000 - fn: 1138.0000 - accuracy: 0.5549 - precision: 0.5555 - recall: 0.9937 - auc: 0.5012 - val_loss: 0.8182 - val_tp: 98.0000 - val_fp: 56834.0000 - val_tn: 30.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0022 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6872 - tp: 180767.0000 - fp: 144651.0000 - tn: 974.0000 - fn: 1138.0000 - accuracy: 0.5549 - precision: 0.5555 - recall: 0.9937 - auc: 0.5012 - val_loss: 0.8182 - val_tp: 98.0000 - val_fp: 56834.0000 - val_tn: 30.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0022 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5005\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 24us/sample\n",
      "36392/36392 [==============================] - 1s 22us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e0c4ea0b8>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1e0c765f28>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1e0c4c01d0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1ead0da828>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1e0c5219b0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1e0c495b70>, <tensorflow.python.keras.metrics.Recall object at 0x7f1e0c495ef0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1e0c463f98>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ea4f3dac8>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1e0c710b38>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1e0c776080>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e0c7764e0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1eabee4550>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_26 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327072/327530 [============================>.] - ETA: 0s - loss: 0.6879 - tp: 176615.0000 - fp: 141328.0000 - tn: 4116.0000 - fn: 5013.0000 - accuracy: 0.5526 - precision: 0.5555 - recall: 0.9724 - auc: 0.5007\n",
      "Epoch 00001: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 26s 81us/sample - loss: 0.6879 - tp: 176872.0000 - fp: 141529.0000 - tn: 4116.0000 - fn: 5013.0000 - accuracy: 0.5526 - precision: 0.5555 - recall: 0.9724 - auc: 0.5007 - val_loss: 0.8249 - val_tp: 98.0000 - val_fp: 56775.0000 - val_tn: 89.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0033 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5012\n",
      "327530/327530 [==============================] - 26s 81us/sample - loss: 0.6879 - tp: 176872.0000 - fp: 141529.0000 - tn: 4116.0000 - fn: 5013.0000 - accuracy: 0.5526 - precision: 0.5555 - recall: 0.9724 - auc: 0.5007 - val_loss: 0.8249 - val_tp: 98.0000 - val_fp: 56775.0000 - val_tn: 89.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0033 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5012\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327424/327530 [============================>.] - ETA: 0s - loss: 0.6887 - tp: 176124.0000 - fp: 141036.0000 - tn: 4563.0000 - fn: 5701.0000 - accuracy: 0.5518 - precision: 0.5553 - recall: 0.9686 - auc: 0.5006\n",
      "Epoch 00002: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6887 - tp: 176184.0000 - fp: 141082.0000 - tn: 4563.0000 - fn: 5701.0000 - accuracy: 0.5518 - precision: 0.5553 - recall: 0.9687 - auc: 0.5006 - val_loss: 0.8200 - val_tp: 98.0000 - val_fp: 56859.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6887 - tp: 176184.0000 - fp: 141082.0000 - tn: 4563.0000 - fn: 5701.0000 - accuracy: 0.5518 - precision: 0.5553 - recall: 0.9687 - auc: 0.5006 - val_loss: 0.8200 - val_tp: 98.0000 - val_fp: 56859.0000 - val_tn: 5.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0018 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327456/327530 [============================>.] - ETA: 0s - loss: 0.6876 - tp: 179486.0000 - fp: 143757.0000 - tn: 1851.0000 - fn: 2362.0000 - accuracy: 0.5538 - precision: 0.5553 - recall: 0.9870 - auc: 0.4999\n",
      "Epoch 00003: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6876 - tp: 179523.0000 - fp: 143794.0000 - tn: 1851.0000 - fn: 2362.0000 - accuracy: 0.5538 - precision: 0.5553 - recall: 0.9870 - auc: 0.4999 - val_loss: 0.7872 - val_tp: 98.0000 - val_fp: 56806.0000 - val_tn: 58.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0027 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5010\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6876 - tp: 179523.0000 - fp: 143794.0000 - tn: 1851.0000 - fn: 2362.0000 - accuracy: 0.5538 - precision: 0.5553 - recall: 0.9870 - auc: 0.4999 - val_loss: 0.7872 - val_tp: 98.0000 - val_fp: 56806.0000 - val_tn: 58.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0027 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5010\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327424/327530 [============================>.] - ETA: 0s - loss: 0.6870 - tp: 181601.0000 - fp: 145219.0000 - tn: 383.0000 - fn: 221.0000 - accuracy: 0.5558 - precision: 0.5557 - recall: 0.9988 - auc: 0.4999\n",
      "Epoch 00004: val_recall did not improve from 1.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6870 - tp: 181664.0000 - fp: 145262.0000 - tn: 383.0000 - fn: 221.0000 - accuracy: 0.5558 - precision: 0.5557 - recall: 0.9988 - auc: 0.4999 - val_loss: 0.8200 - val_tp: 98.0000 - val_fp: 56803.0000 - val_tn: 61.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0028 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5008\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6870 - tp: 181664.0000 - fp: 145262.0000 - tn: 383.0000 - fn: 221.0000 - accuracy: 0.5558 - precision: 0.5557 - recall: 0.9988 - auc: 0.4999 - val_loss: 0.8200 - val_tp: 98.0000 - val_fp: 56803.0000 - val_tn: 61.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0028 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5008\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 26us/sample\n",
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e4c74cd68>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1e4c74cd30>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1ead1726a0>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1eac33eb00>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1e4c7058d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1e4c7057f0>, <tensorflow.python.keras.metrics.Recall object at 0x7f1e4c7055c0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1e0c52ea20>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1e0c776080>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1ea7377978>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1eab680320>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e0c453588>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1eabee3f98>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_27 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "326912/327530 [============================>.] - ETA: 0s - loss: 0.6880 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181321.0000 - fn: 145591.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000\n",
      "Epoch 00001: val_recall improved from 1.00000 to 0.00000, saving model to gru_ULB_checkpoints.h5\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6880 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181647.0000 - fn: 145883.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.6041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5007\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6880 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181647.0000 - fn: 145883.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5000 - val_loss: 0.6041 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5007\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327264/327530 [============================>.] - ETA: 0s - loss: 0.6893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181492.0000 - fn: 145772.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5032\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181647.0000 - fn: 145883.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5032 - val_loss: 0.5767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6893 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181647.0000 - fn: 145883.0000 - accuracy: 0.5546 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5032 - val_loss: 0.5767 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327008/327530 [============================>.] - ETA: 0s - loss: 0.6874 - tp: 22.0000 - fp: 42.0000 - tn: 181316.0000 - fn: 145628.0000 - accuracy: 0.5545 - precision: 0.3438 - recall: 1.5105e-04 - auc: 0.5008\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6874 - tp: 22.0000 - fp: 42.0000 - tn: 181605.0000 - fn: 145861.0000 - accuracy: 0.5545 - precision: 0.3438 - recall: 1.5081e-04 - auc: 0.5008 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6874 - tp: 22.0000 - fp: 42.0000 - tn: 181605.0000 - fn: 145861.0000 - accuracy: 0.5545 - precision: 0.3438 - recall: 1.5081e-04 - auc: 0.5008 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327200/327530 [============================>.] - ETA: 0s - loss: 0.6927 - tp: 2140.0000 - fp: 2746.0000 - tn: 178735.0000 - fn: 143579.0000 - accuracy: 0.5528 - precision: 0.4380 - recall: 0.0147 - auc: 0.4998\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6927 - tp: 2140.0000 - fp: 2746.0000 - tn: 178901.0000 - fn: 143743.0000 - accuracy: 0.5527 - precision: 0.4380 - recall: 0.0147 - auc: 0.4998 - val_loss: 0.5903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5004\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6927 - tp: 2140.0000 - fp: 2746.0000 - tn: 178901.0000 - fn: 143743.0000 - accuracy: 0.5527 - precision: 0.4380 - recall: 0.0147 - auc: 0.4998 - val_loss: 0.5903 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5004\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 23us/sample\n",
      " 7328/36392 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1eac33e940>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1ead31d4e0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1ead31d780>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1ead31d128>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1ead31d1d0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1ea5007860>, <tensorflow.python.keras.metrics.Recall object at 0x7f1e44627908>, <tensorflow.python.keras.metrics.AUC object at 0x7f1ea74a6a20>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1eab680320>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1e44336908>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1e0c2026d8>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1ead352a58>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1ead352358>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_28 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327392/327530 [============================>.] - ETA: 0s - loss: 0.6879 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181882.0000 - fn: 145510.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004\n",
      "Epoch 00001: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6879 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.6262 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6879 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5004 - val_loss: 0.6262 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327520/327530 [============================>.] - ETA: 0s - loss: 0.6877 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181955.0000 - fn: 145565.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001 - val_loss: 0.5988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001 - val_loss: 0.5988 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "326912/327530 [============================>.] - ETA: 0s - loss: 0.6922 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181619.0000 - fn: 145289.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6922 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181957.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 56862.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5002\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6922 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181957.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - val_loss: 0.5933 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 56862.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5002\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327488/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 0.0000e+00 - fp: 20.0000 - tn: 181916.0000 - fn: 145552.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 20.0000 - tn: 181941.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - val_loss: 0.5774 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 56861.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4999\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 20.0000 - tn: 181941.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4997 - val_loss: 0.5774 - val_tp: 0.0000e+00 - val_fp: 3.0000 - val_tn: 56861.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4999\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 24us/sample\n",
      " 6848/36392 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 20us/sample\n",
      "327530/327530 [==============================] - 7s 20us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1de848b978>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1de84012b0>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1de841b240>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1de841b6d8>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1de841a198>, <tensorflow.python.keras.metrics.Precision object at 0x7f1de841a550>, <tensorflow.python.keras.metrics.Recall object at 0x7f1de841a7f0>, <tensorflow.python.keras.metrics.AUC object at 0x7f1de841ab00>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ead3525c0>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1ead3520f0>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1eac33e7f0>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1eac33e4e0>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1eac33e470>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_29 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "326944/327530 [============================>.] - ETA: 0s - loss: 0.6879 - tp: 572.0000 - fp: 707.0000 - tn: 180914.0000 - fn: 144751.0000 - accuracy: 0.5551 - precision: 0.4472 - recall: 0.0039 - auc: 0.5005\n",
      "Epoch 00001: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6879 - tp: 572.0000 - fp: 707.0000 - tn: 181254.0000 - fn: 144997.0000 - accuracy: 0.5551 - precision: 0.4472 - recall: 0.0039 - auc: 0.5006 - val_loss: 0.5718 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6879 - tp: 572.0000 - fp: 707.0000 - tn: 181254.0000 - fn: 144997.0000 - accuracy: 0.5551 - precision: 0.4472 - recall: 0.0039 - auc: 0.5006 - val_loss: 0.5718 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327456/327530 [============================>.] - ETA: 0s - loss: 0.6881 - tp: 54.0000 - fp: 77.0000 - tn: 181841.0000 - fn: 145484.0000 - accuracy: 0.5555 - precision: 0.4122 - recall: 3.7104e-04 - auc: 0.5000\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6881 - tp: 54.0000 - fp: 77.0000 - tn: 181884.0000 - fn: 145515.0000 - accuracy: 0.5555 - precision: 0.4122 - recall: 3.7096e-04 - auc: 0.5000 - val_loss: 0.6135 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5002\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6881 - tp: 54.0000 - fp: 77.0000 - tn: 181884.0000 - fn: 145515.0000 - accuracy: 0.5555 - precision: 0.4122 - recall: 3.7096e-04 - auc: 0.5000 - val_loss: 0.6135 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5002\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327232/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 0.0000e+00 - fp: 2.0000 - tn: 181812.0000 - fn: 145418.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5009\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 2.0000 - tn: 181959.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - val_loss: 0.6133 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 56859.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4998\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 2.0000 - tn: 181959.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - val_loss: 0.6133 - val_tp: 0.0000e+00 - val_fp: 5.0000 - val_tn: 56859.0000 - val_fn: 98.0000 - val_accuracy: 0.9982 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4998\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327520/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 0.0000e+00 - fp: 3.0000 - tn: 181952.0000 - fn: 145565.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 3.0000 - tn: 181958.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - val_loss: 0.5858 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5007\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 3.0000 - tn: 181958.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5005 - val_loss: 0.5858 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5007\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 24us/sample\n",
      " 7360/36392 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 20us/sample\n",
      "    32/327530 [..............................] - ETA: 37s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e4c7375c0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1e4c7370b8>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1e4c737160>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1e7c23cd68>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1de821ac88>, <tensorflow.python.keras.metrics.Precision object at 0x7f1e4c0ee710>, <tensorflow.python.keras.metrics.Recall object at 0x7f1e4c0ee470>, <tensorflow.python.keras.metrics.AUC object at 0x7f1e4c0ee4a8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1eac33e470>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1eae2f5f28>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1e4c6cbe48>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e44115208>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1ea7119470>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_30 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327488/327530 [============================>.] - ETA: 0s - loss: 0.6884 - tp: 1384.0000 - fp: 1784.0000 - tn: 180152.0000 - fn: 144168.0000 - accuracy: 0.5543 - precision: 0.4369 - recall: 0.0095 - auc: 0.5018\n",
      "Epoch 00001: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6883 - tp: 1384.0000 - fp: 1784.0000 - tn: 180177.0000 - fn: 144185.0000 - accuracy: 0.5543 - precision: 0.4369 - recall: 0.0095 - auc: 0.5018 - val_loss: 0.6121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "327530/327530 [==============================] - 26s 79us/sample - loss: 0.6883 - tp: 1384.0000 - fp: 1784.0000 - tn: 180177.0000 - fn: 144185.0000 - accuracy: 0.5543 - precision: 0.4369 - recall: 0.0095 - auc: 0.5018 - val_loss: 0.6121 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327072/327530 [============================>.] - ETA: 0s - loss: 0.6875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181721.0000 - fn: 145351.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - val_loss: 0.5799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5026\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6875 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5010 - val_loss: 0.5799 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5026\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "327136/327530 [============================>.] - ETA: 0s - loss: 0.6885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181754.0000 - fn: 145382.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5001\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - val_loss: 0.6062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5004\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6885 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 181961.0000 - fn: 145569.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5002 - val_loss: 0.6062 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5004\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327296/327530 [============================>.] - ETA: 0s - loss: 0.6873 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181831.0000 - fn: 145461.0000 - accuracy: 0.5556 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181957.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - val_loss: 0.5564 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4999\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6873 - tp: 0.0000e+00 - fp: 4.0000 - tn: 181957.0000 - fn: 145569.0000 - accuracy: 0.5555 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5012 - val_loss: 0.5564 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4999\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 24us/sample\n",
      " 6976/36392 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36392/36392 [==============================] - 1s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1de8175128>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1de8446a90>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1de80c3ac8>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1de80c3940>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1de80c35f8>, <tensorflow.python.keras.metrics.Precision object at 0x7f1de80c3c18>, <tensorflow.python.keras.metrics.Recall object at 0x7f1de80c3400>, <tensorflow.python.keras.metrics.AUC object at 0x7f1de80c3208>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1ea7119470>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1e0c1bc828>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1e0c1f1a58>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e7c3e9128>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1e0c791160>]\n",
      "          \n",
      "\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_31 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 327530 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "327136/327530 [============================>.] - ETA: 0s - loss: 0.6878 - tp: 787.0000 - fp: 880.0000 - tn: 180868.0000 - fn: 144601.0000 - accuracy: 0.5553 - precision: 0.4721 - recall: 0.0054 - auc: 0.5009\n",
      "Epoch 00001: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6878 - tp: 787.0000 - fp: 880.0000 - tn: 181081.0000 - fn: 144782.0000 - accuracy: 0.5553 - precision: 0.4721 - recall: 0.0054 - auc: 0.5008 - val_loss: 0.5833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "327530/327530 [==============================] - 26s 78us/sample - loss: 0.6878 - tp: 787.0000 - fp: 880.0000 - tn: 181081.0000 - fn: 144782.0000 - accuracy: 0.5553 - precision: 0.4721 - recall: 0.0054 - auc: 0.5008 - val_loss: 0.5833 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5005\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "327232/327530 [============================>.] - ETA: 0s - loss: 0.6877 - tp: 498.0000 - fp: 607.0000 - tn: 181191.0000 - fn: 144936.0000 - accuracy: 0.5552 - precision: 0.4507 - recall: 0.0034 - auc: 0.5018\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 498.0000 - fp: 607.0000 - tn: 181354.0000 - fn: 145071.0000 - accuracy: 0.5552 - precision: 0.4507 - recall: 0.0034 - auc: 0.5018 - val_loss: 0.6394 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5014\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6877 - tp: 498.0000 - fp: 607.0000 - tn: 181354.0000 - fn: 145071.0000 - accuracy: 0.5552 - precision: 0.4507 - recall: 0.0034 - auc: 0.5018 - val_loss: 0.6394 - val_tp: 0.0000e+00 - val_fp: 1.0000 - val_tn: 56863.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5014\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "326976/327530 [============================>.] - ETA: 0s - loss: 0.6896 - tp: 2737.0000 - fp: 3483.0000 - tn: 178177.0000 - fn: 142579.0000 - accuracy: 0.5533 - precision: 0.4400 - recall: 0.0188 - auc: 0.4992\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6896 - tp: 2737.0000 - fp: 3483.0000 - tn: 178478.0000 - fn: 142832.0000 - accuracy: 0.5533 - precision: 0.4400 - recall: 0.0188 - auc: 0.4992 - val_loss: 0.5991 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5001\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6896 - tp: 2737.0000 - fp: 3483.0000 - tn: 178478.0000 - fn: 142832.0000 - accuracy: 0.5533 - precision: 0.4400 - recall: 0.0188 - auc: 0.4992 - val_loss: 0.5991 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5001\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "327168/327530 [============================>.] - ETA: 0s - loss: 0.6875 - tp: 907.0000 - fp: 1059.0000 - tn: 180691.0000 - fn: 144511.0000 - accuracy: 0.5551 - precision: 0.4613 - recall: 0.0062 - auc: 0.5012\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "327530/327530 [==============================] - 23s 70us/sample - loss: 0.6875 - tp: 907.0000 - fp: 1059.0000 - tn: 180902.0000 - fn: 144662.0000 - accuracy: 0.5551 - precision: 0.4613 - recall: 0.0062 - auc: 0.5012 - val_loss: 0.5848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "327530/327530 [==============================] - 23s 71us/sample - loss: 0.6875 - tp: 907.0000 - fp: 1059.0000 - tn: 180902.0000 - fn: 144662.0000 - accuracy: 0.5551 - precision: 0.4613 - recall: 0.0062 - auc: 0.5012 - val_loss: 0.5848 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 56864.0000 - val_fn: 98.0000 - val_accuracy: 0.9983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5009\n",
      "Epoch 00004: early stopping\n",
      "36392/36392 [==============================] - 1s 24us/sample\n",
      " 7488/36392 [=====>........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36392/36392 [==============================] - 1s 20us/sample\n",
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "    32/327530 [..............................] - ETA: 38s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/verafin-mitacs-2020/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327530/327530 [==============================] - 7s 21us/sample\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  CREATING ML MODEL _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "        PARAMETERS:\n",
      "        ________________________________ \n",
      "          rnn_hidden_layers:         0 \n",
      "          rnn_hidden_layers_neurons: 29 \n",
      "          hidden_layers:             0 \n",
      "          hidden_layers_neurons:     12\n",
      "          loss:                      binary_crossentropy\n",
      "          optimizer:                 adam\n",
      "          modelType:                 GRU\n",
      "          dropout:                   False\n",
      "          dropout_rate:              0.2\n",
      "          input_shape:               (1, 29)\n",
      "          output_dim:                1\n",
      "          output_layer_activation:   sigmoid\n",
      "          rnn_layer_activation:      sigmoid\n",
      "          hidden_layer_activation:   sigmoid\n",
      "          keras_eval_metric:         [[<tensorflow.python.keras.metrics.TruePositives object at 0x7f1e4c7371d0>, <tensorflow.python.keras.metrics.FalsePositives object at 0x7f1dc0541978>, <tensorflow.python.keras.metrics.TrueNegatives object at 0x7f1dc07eab38>, <tensorflow.python.keras.metrics.FalseNegatives object at 0x7f1dc0517f28>, <tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7f1dc0517fd0>, <tensorflow.python.keras.metrics.Precision object at 0x7f1dc0538358>, <tensorflow.python.keras.metrics.Recall object at 0x7f1dc0538cf8>, <tensorflow.python.keras.metrics.AUC object at 0x7f1dc05385f8>]]\n",
      "          return_sequences:          False\n",
      "          callbacks:                 [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f1e7c3e9128>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f1dc07a9a90>, <tensorflow.python.keras.callbacks.CSVLogger object at 0x7f1eac33e668>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f1e7c52da90>, <tensorflow.python.keras.callbacks.ProgbarLogger object at 0x7f1de80f6588>]\n",
      "          \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 18.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_32 (GRU)                 (None, 29)                5220      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 1)                 30        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 5,250\n",
      "Trainable params: 5,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "\n",
      "MODEL SUMMARY: \n",
      "\n",
      " None\n",
      "Train on 363922 samples, validate on 56962 samples\n",
      "Epoch 1/25\n",
      "Epoch 1/25\n",
      "363808/363922 [============================>.] - ETA: 0s - loss: 0.6963 - tp: 84567.0000 - fp: 84408.0000 - tn: 97493.0000 - fn: 97340.0000 - accuracy: 0.5004 - precision: 0.5005 - recall: 0.4649 - auc: 0.4991\n",
      "Epoch 00001: val_recall did not improve from 0.00000\n",
      "363922/363922 [==============================] - 29s 79us/sample - loss: 0.6963 - tp: 84621.0000 - fp: 84468.0000 - tn: 97493.0000 - fn: 97340.0000 - accuracy: 0.5004 - precision: 0.5005 - recall: 0.4651 - auc: 0.4991 - val_loss: 0.7203 - val_tp: 98.0000 - val_fp: 56847.0000 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0020 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "363922/363922 [==============================] - 29s 79us/sample - loss: 0.6963 - tp: 84621.0000 - fp: 84468.0000 - tn: 97493.0000 - fn: 97340.0000 - accuracy: 0.5004 - precision: 0.5005 - recall: 0.4651 - auc: 0.4991 - val_loss: 0.7203 - val_tp: 98.0000 - val_fp: 56847.0000 - val_tn: 17.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0020 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5003\n",
      "Epoch 2/25\n",
      "Epoch 2/25\n",
      "363744/363922 [============================>.] - ETA: 0s - loss: 0.6933 - tp: 83355.0000 - fp: 83670.0000 - tn: 98194.0000 - fn: 98525.0000 - accuracy: 0.4991 - precision: 0.4991 - recall: 0.4583 - auc: 0.4989\n",
      "Epoch 00002: val_recall did not improve from 0.00000\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6933 - tp: 83436.0000 - fp: 83767.0000 - tn: 98194.0000 - fn: 98525.0000 - accuracy: 0.4991 - precision: 0.4990 - recall: 0.4585 - auc: 0.4988 - val_loss: 0.7042 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4999\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6933 - tp: 83436.0000 - fp: 83767.0000 - tn: 98194.0000 - fn: 98525.0000 - accuracy: 0.4991 - precision: 0.4990 - recall: 0.4585 - auc: 0.4988 - val_loss: 0.7042 - val_tp: 98.0000 - val_fp: 56864.0000 - val_tn: 0.0000e+00 - val_fn: 0.0000e+00 - val_accuracy: 0.0017 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.4999\n",
      "Epoch 3/25\n",
      "Epoch 3/25\n",
      "363392/363922 [============================>.] - ETA: 0s - loss: 0.6932 - tp: 93989.0000 - fp: 93828.0000 - tn: 87857.0000 - fn: 87718.0000 - accuracy: 0.5004 - precision: 0.5004 - recall: 0.5173 - auc: 0.5007\n",
      "Epoch 00003: val_recall did not improve from 0.00000\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6933 - tp: 94243.0000 - fp: 94104.0000 - tn: 87857.0000 - fn: 87718.0000 - accuracy: 0.5004 - precision: 0.5004 - recall: 0.5179 - auc: 0.5006 - val_loss: 0.6961 - val_tp: 98.0000 - val_fp: 56837.0000 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0022 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5001\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6933 - tp: 94243.0000 - fp: 94104.0000 - tn: 87857.0000 - fn: 87718.0000 - accuracy: 0.5004 - precision: 0.5004 - recall: 0.5179 - auc: 0.5006 - val_loss: 0.6961 - val_tp: 98.0000 - val_fp: 56837.0000 - val_tn: 27.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0022 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5001\n",
      "Epoch 4/25\n",
      "Epoch 4/25\n",
      "363584/363922 [============================>.] - ETA: 0s - loss: 0.6934 - tp: 87229.0000 - fp: 87063.0000 - tn: 94729.0000 - fn: 94563.0000 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.4798 - auc: 0.4996\n",
      "Epoch 00004: val_recall did not improve from 0.00000\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6934 - tp: 87398.0000 - fp: 87232.0000 - tn: 94729.0000 - fn: 94563.0000 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.4803 - auc: 0.4996 - val_loss: 0.7312 - val_tp: 98.0000 - val_fp: 56810.0000 - val_tn: 54.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0027 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5008\n",
      "363922/363922 [==============================] - 26s 70us/sample - loss: 0.6934 - tp: 87398.0000 - fp: 87232.0000 - tn: 94729.0000 - fn: 94563.0000 - accuracy: 0.5005 - precision: 0.5005 - recall: 0.4803 - auc: 0.4996 - val_loss: 0.7312 - val_tp: 98.0000 - val_fp: 56810.0000 - val_tn: 54.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.0027 - val_precision: 0.0017 - val_recall: 1.0000 - val_auc: 0.5008\n",
      "Epoch 00004: early stopping\n",
      "\n",
      "\n",
      "_ _ _ _ _ _ _ _ _ _  RNN TRAINING RESULTS _ _ _ _ _ _ _ _ _ _ \n",
      "\n",
      "\n",
      "\n",
      "          BEST ESTIMATOR:          <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1dc0513978> \n",
      "          BEST SCORE:              0.5\n",
      "          BEST PARAMS:             {'dropout': False, 'dropout_rate': 0.2, 'epochs': 25, 'hidden_layer_activation': 'sigmoid', 'hidden_layers': 0, 'hidden_layers_neurons': 12, 'loss': 'binary_crossentropy', 'modelType': 'GRU', 'optimizer': 'adam', 'output_layer_activation': 'sigmoid', 'rnn_hidden_layers': 0, 'rnn_hidden_layers_neurons': 29, 'rnn_layer_activation': 'sigmoid'}\n",
      "          BEST INDEX IN CV SEARCH: 0\n",
      "          SCORER FUNCTIONS:        {'accuracy': make_scorer(accuracy_score), 'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'f1': make_scorer(f1_score, average=binary), 'average_precision': make_scorer(average_precision_score, needs_threshold=True)}\n",
      "          \n",
      "\n",
      "          HISTORY OBJ:             GridSearchCV(cv=10, error_score=nan,\n",
      "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1ea5c1aef0>,\n",
      "             iid='deprecated', n_jobs=1,\n",
      "             param_grid={'dropout': [False], 'dropout_rate': [0.2],\n",
      "                         'epochs': [25], 'hidden_layer_activation': ['sigmoid'],\n",
      "                         'hidden_layers': [0], 'hidden_layers_neurons': [12],\n",
      "                         'loss': ['binary_crossentropy'], 'modelType': ['GRU'],\n",
      "                         'optimizer': ['adam'],\n",
      "                         'output_layer_activation': ['sigmoid'],\n",
      "                         'rnn_hidden_layers': [0],\n",
      "                         'rnn_hidden_layers_neurons': [29],\n",
      "                         'rnn_layer_activation': ['sigmoid']},\n",
      "             pre_dispatch='1*n_jobs', refit='recall', return_train_score=True,\n",
      "             scoring=['accuracy', 'precision', 'recall', 'f1',\n",
      "                      'average_precision'],\n",
      "             verbose=1)        \n",
      "        \n",
      "\n",
      "\n",
      "cv_results_dict: \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_dropout  \\\n",
      "0        96.6572      0.512763         1.703525        0.026495         False   \n",
      "\n",
      "  param_dropout_rate param_epochs param_hidden_layer_activation  \\\n",
      "0                0.2           25                       sigmoid   \n",
      "\n",
      "  param_hidden_layers param_hidden_layers_neurons  ...  \\\n",
      "0                   0                          12  ...   \n",
      "\n",
      "  split2_train_average_precision split3_train_average_precision  \\\n",
      "0                       0.555021                       0.557065   \n",
      "\n",
      "  split4_train_average_precision split5_train_average_precision  \\\n",
      "0                       0.555933                       0.446608   \n",
      "\n",
      "  split6_train_average_precision split7_train_average_precision  \\\n",
      "0                       0.444465                        0.44515   \n",
      "\n",
      "  split8_train_average_precision split9_train_average_precision  \\\n",
      "0                       0.444267                       0.446926   \n",
      "\n",
      "   mean_train_average_precision  std_train_average_precision  \n",
      "0                      0.500633                     0.055157  \n",
      "\n",
      "[1 rows x 143 columns]\n",
      "Total time: 1230.33  seconds or 20.51 minutes. Saving model to: gru_ULB_checkpoints.h5\n"
     ]
    }
   ],
   "source": [
    "# gru_history_1 = gru_model_1.train( X_train, y_train, X_test, y_test, class_weights=modified_weights )\n",
    "gru_history_1 = gru_model_1.train( X_train_ov, y_train_ov , X_test, y_test, class_weights=modified_weights )\n",
    "gru_model_1.model.best_estimator_.model.save( \"gru_ULB.h5\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45569/45569 [==============================] - 1s 21us/sample\n",
      "PRED:  (45569, 2)\n",
      "tn, fp, fn, tp  (59, 45431, 0, 79)  rc_auc  0.5026928995383602  average_precision_score  0.0017430059129820846\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred_val = gru_model_1.model.predict_proba(X_val)\n",
    "\n",
    "print(\"PRED: \" , y_pred_val.shape)\n",
    "\n",
    "fpr, tpr, thresholds          = metrics.roc_curve(y_val, y_pred_val[: , 1])\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_val, y_pred_val[: , 1])\n",
    "tn, fp, fn, tp                = metrics.confusion_matrix(y_val, y_pred_val[:, 1].round()).ravel()\n",
    "rc_auc                        = metrics.roc_auc_score(y_val, y_pred_val[: , 1])\n",
    "average_precision_score       = metrics.average_precision_score(y_val, y_pred_val[: , 1])\n",
    "\n",
    "\n",
    "print(\"tn, fp, fn, tp \",(tn, fp, fn, tp), \" rc_auc \", rc_auc, \" average_precision_score \", average_precision_score )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1eacee44a8>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAAJICAYAAABhfJEYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3TU9aHv/c8vM7nfCQmBQAADmUAgE6loqZeKd0QEwQR06651axVaRcI665y1zlr7POs5z3POfp6zudWtst211W1PlQQECgparNQ7Ku0khMsQEgyJCZAbud/m8vyB3Y9VlCDJfCcz79daXasJ4/BeXwf9zcfJjOX3+wUAAAAAABDKIkwHAAAAAAAAjDQGEAAAAAAAEPIYQAAAAAAAQMhjAAEAAAAAACGPAQQAAAAAAIQ8BhAAAAAAABDy7KZ+46amzhH7/N3U1Di1tfWM1N3jazjvwOK8A4vzDizOO7BG8rzT0xOtEbnjYcJ1SOjgvAOHsw4szjuwOO/AMnUNEpKvALHbbaYTwgrnHVicd2Bx3oHFeQcW5z0yONfA4rwDh7MOLM47sDjvwDJ13iE5gAAAAAAAAHwVAwgAAAAAAAh5DCAAAAAAACDkMYAAAAAAAICQxwACAAAAAABCHgMIAAAAAAAIeQwgAAAAAAAg5DGAAAAAAACAkMcAAgAAAAAAQh4DCAAAAAAACHkMIAAAAAAAIOQxgAAAAAAAgJDHAAIAAAAAAEIeAwgAAAAAAAh5DCAAAAAAACDkMYAAAAAAAICQxwACAAAAAABCHgMIAAAAAAAIeQwgAAAAAAAg5NkvdgOHw/FrSXdJOut2u2dd4NctSZsk3SmpR9JDbrf7z8MdCgAAwg/XIQAAYLgM5RUgL0q64zt+fYGk6V/+72eSnrv8LAAAAElchwAAgGFy0QHE7Xa/K6n1O26yWNK/u91uv9vt/lhSisPhGD9cgQAAIHxxHQIAAIbLRX8EZgiyJNV95ev6L7/XOAz3fcn+8Gmd/lzVrJ8tmqnUxGgTCQAAIHCC6joEAAB805m2Hj3zWqVaOvokSZPGJeg/rSiULSKwb0s6HAOIdYHv+S/2F6Wmxslutw3Db/+3kpNj5T7VpqdfO6T/+fPrlBAbOey/B74pPT3RdEJY4bwDi/MOLM47sELgvIPqOuSvQuBcRxXOO3A468DivAOL8x4ZbR192rS1QqdbepSZFqfYaLsyUuOUkZ6kiIgL/Wt85AzHAFIvadJXvp4oqeFif1FbW88w/NbfNHd6muqunarXPzipf9z8gdYuL1RU5Mhd4OD8PyiamjpNZ4QNzjuwOO/A4rwDayTPO4AXkUF1HSLxOA40zjtwOOvA4rwDi/MeGT19Hv0/v/uzTrf06O5rp2jJ9VdIMncNMhyvN/m9pL93OByWw+H4oaR2t9tt7GWnlmXpZ0tm6+oZGaqqb9fmnYfl9flM5QAAgJEVVNchAADgvEGPV09vq1Dd2S79uHCCFl831XTSkD4G9xVJN0oa63A46iX9N0mRkuR2uzdLekPnP3ruhM5//NxPRyp2qCIiLD1y10x19w7KdaJZL+45pofvnCHLCuzLawAAwOUZjdchAACEO5/Pr+d/f0TuunP6QW66HrzNERTPxy86gLjd7vsu8ut+ST8ftqJhYrdFaNU9s/XPr/5FHxw6raS4KBXNn2Y6CwAAXILReh0CAEC48vv9evkttw4eb1Jedop+dvfMgL/Xx7cJ7FuuBlhstF2ri5zKHBOnPQdOae+BU6aTAAAAAAAIWTvfP6k/uRo0KSNBv1haoMgRfNPxSxXSA4gkJcVFqWS5U6mJ0Sp954Ter+DHggEAAAAAGG5//HO9fv/B5xqbHKOSYqfiYobjc1eGT8gPIJI0NjlWJcVOxcfY9eKeY3JVNZtOAgAAAAAgZHxy9Iz+91vHlRQXqbUrCpWcEG066RvCYgCRpKz0BK0ucsput/TczkodrztnOgkAAAAAgFHvyOet+rddRxQdZdOa4kKNS40znXRBYTOASNK0rGStWjJbPp9fm7ae/zgeAAAAAADw/dSe7tTTrx2SZUlPLJ2tyZmJppO+VVgNIJJUkJOmhxfOUG+/R+tLXWo612s6CQAAAACAUedMW482lLo0MODVo4vyNWPKGNNJ3ynsBhBJmpefqftunq72rgGt2+JSR/eA6SQAAAAAAEaNc139WveqSx09g/q723I1Ny/DdNJFheUAIkm3zp2khfMm62xbrzaUlqu332M6CQAAAACAoNfT59GG0nI1t/fp7mun6KY5E00nDUnYDiCStPSGK3SDc7xqz3Tq6W0VGvR4TScBAAAAABC0Bj1ePb3t/Htq3lg4QYuvm2o6acjCegCxLEsP3u7QnNx0HTt1Ts/vOiKfz286CwAAAACAoOPz+fWvvz8id905/cCRrgduc8iyLNNZQxbWA4gk2SIi9NjdM+WYlKKD7ib99i23/H5GEAAAAAAA/srv9+vlt9z68/Em5WWn6GeLZioiYvSMHxIDiCQp0m7TE8sKlJ2RoP2uBu1476TpJAAAAAAAgsaO907qT64GTcpI0C+WFijSbjOddMkYQL4UF2PXmuWFykiJ1a4PP9e+z+pMJwEAAAAAYNzbB+u168PPlZ4So5Jip+Ji7KaTvhcGkK9Ijo9SyYpCJcdH6Xf7qvTxkdOmkwAAAAAAMOaTo2f0uz8cV1JcpNYuL1RyQrTppO+NAeRrMlJitabYqdhom17YfVSVNS2mkwAAAAAACLgjn7fq33YdUXSUTWuKC5WRGmc66bIwgFxA9rhEPbmsQJZl6ZntlapuaDedBAAAAABAwHx+ukNPv3ZIliU9sXS2Jmcmmk66bAwg38KRnaqVi/M14PFqU1mFGpq7TScBAAAAADDizrT2aENpuQYGvPrZonzNmDLGdNKwYAD5DlfmpuuhO/LU1TuodVtcau3oM50EAAAAAMCIOdfVr3VbXOrsGdQDt+XqqrwM00nDhgHkIq53TtC9N+aorfP8g6Crd9B0EgAAAAAAw66nz6P1W8rV3N6nu6+dovlzJppOGlYMIEOw4Jps3TZ3khpberSxrFx9Ax7TSQAAAAAADJtBj1dPb6tQfVOXbrwyS4uvm2o6adgxgAyBZVkqvmmafjQrUzUNHXp2e6U8Xp/pLAAAAAAALpvP59e//v6I3HXn9ANHuh64NVeWZZnOGnYMIEMUYVl6aEGeCnLSVHmyVS+8flQ+v990FgAAAAAA35vf79e/v+nWn483KS87RT9bNFMREaE3fkgMIJfEbovQyiWzNC0rWQeOnNEr+6rkZwQBAAAAAIxS2987qXfLG5SdkaAnlhUo0m4znTRiGEAuUXSkTauLCpSVHq+3D9Zr90e1ppMAAAAAALhkbx+s1+4PP1d6SozWFDsVG203nTSiGEC+h/iYSJUUFyotKUbb363RftcXppMAAAAAABiyT46e0e/+cFxJ8VFau7xQyQnRppNGHAPI95SaGK21KwqVEBupl99067NjZ00nAQAAAABwUYc/b9W/7Tqi6Cib1hQ5lZEaZzopIBhALkPmmDitKXYqKtKm53cd1tHaNtNJAAAAAAB8q5ONHfqX1w7JsqQnlhVocmai6aSAYQC5TFPHJ+mJpbMlSU9vq1Dt6U7DRQAAAAAAfNOZ1h5tLCvXwIBXP1uUrxmTU00nBRQDyDCYOWWMHl2Ur/4Br9aXunSmtcd0EgAAAAAA/+FcV7/WbXGps2dQD9zu0FV5GaaTAo4BZJjMzcvQA7flqrNnUOu2uNTW2W86CQAAAAAA9fQNav2WcjW392nxdVM1/8os00lGMIAMo/lzJmrJdVPV3N6nDaUu9fQNmk4CAAAAAISxgUGvfrntkOqbujT/yizdfe0U00nGMIAMs0XXTtFNc7JU39StTVsrNDDoNZ0EAAAAAAhDXp9P//r7wzped05XOdL1d7fmyrIs01nGMIAMM8uydP+tubp6Roaq6tu1eedheX0+01kAAAAAgDDi9/v18ptu/aWqWXnZKXp0Ub4iIsJ3/JAYQEZEhGXpkbtmKn9KqlwnmvXinmPy+/2mswAAAAAAYWL7eyf1bnmjsscl6IllBYq08/SfExghdluEVt0zW1PHJ+qDQ6e1dX+16SQAAAAAQBjY91mddn/4uTJSYrWmuFCx0XbTSUGBAWQExUbbtbrIqcwxcdpz4JT2HjhlOgkAAAAAEMI+OXpGr+yrUlJ8lEqWO5UcH2U6KWgwgIywpLjzD7rUxGiVvnNC71c0mk4CAAAAAISgwydb9W+7jig6yqY1RU5lpMaZTgoqDCABMDY5ViXFTsXH2PXinmNyVTWbTgIAAAAAhJCTjR36l9cOybKkJ5YVaHJmoumkoMMAEiBZ6QlaXeSU3W7puZ2VOl53znQSAAAAACAEnG7t0YbScg0MevWzRfmaMTnVdFJQYgAJoGlZyVq1ZLZ8Pr82ba1Q3dku00kAAAAAgFGsrbNf67e41NU7qAdvd+iqvAzTSUGLASTACnLS9PDCGert92h9qUtN53pNJwEAAAAARqGevkFtKHWpub1PS66bqhuvzDKdFNQYQAyYl5+p+26ervauAa3b4lJH94DpJAAAAADAKDIw6NUvt1aovqlb8+dkadG1U0wnBT0GEENunTtJC+dN1tm2Xm0oLVdvv8d0EgAAAABgFPD6fPrX3x/W8fp2XeVI19/dkivLskxnBT0GEIOW3nCFbnCOV+2ZTj29rUKDHq/pJAAAAABAEPP7/Xr5Tbf+UtWsGZNT9eiifEVEMH4MBQOIQZZl6cHbHZqTm65jp87p+V1H5PP5TWcBAAAAAILU9vdq9G55oyaPS9Qvls5WpJ2n9UPFSRlmi4jQY3fPlGNSig66m/Tbt9zy+xlBAAAAAAB/a99nddr9Ya0yUmL1VLFTsdF200mjCgNIEIi02/TEsgJlZyRov6tBO947aToJAAAAABBEDhw5o1f2VSkpPkolKwqVHB9lOmnUYQAJEnExdq1ZXqiMlFjt+vBz7fusznQSAAAAACAIHD7Zql/tPqKYaJtKip3KSIk1nTQqMYAEkeSvLHm/21elj4+cNp0EAAAAADDoZGOH/uW1Q7IsS08sLVD2uETTSaMWA0iQyUiJ1Zpip2KjbXph91FV1rSYTgIAAAAAGHC6tUcbSss14PHqsbtnKm9yqumkUY0BJAhlj0vUk8sKZFmWntleqeqGdtNJAAAAAIAAauvs17pXXerqHdSDtzn0A0eG6aRRjwEkSDmyU7Vycb4GPF5tKqtQQ3O36SQAAAAAQAD09A1qQ6lLLR19WnLdVN14ZZbppJDAABLErsxN10N35Kmrd1DrtrjU2tFnOgkAAAAAMIIGBr3atLVC9U3dumlOlhZdO8V0UshgAAly1zsn6N4bc86//GnL+Zc/AQAAAABCj9fn0+adh1VV366r8jJ0/y25sizLdFbIYAAZBRZck63b5k5SY0uPNpaVq2/AYzoJAAAAADCM/H6//n2vW64TzZoxOVWP3jVTERGMH8OJAWQUsCxLxTdN049mZaqmoUPPbq+Ux+sznQUAAAAAGCavvVuj9yoaNXlcon6xdLYi7TxdH26c6CgRYVl6aEGeCnLSVHmyVS+8flQ+v990FgAAAADgMv3hszq9/lGtMlJi9VSxU7HRdtNJIYkBZBSx2yK0csksTctK1oEjZ/TKvir5GUEAAAAAYNT6+MhpvbKvSsnxUSpZUajk+CjTSSGLAWSUiY60aXVRgbLS4/X2wXrt/qjWdBIAAAAA4HuoPNmiF3YfVWy0TWuKncpIiTWdFNIYQEah+JhIlRQXKi0pRtvfrdF+1xemkwAAAAAAl+BkY4eeea1SlmXpyWUFyh6XaDop5DGAjFKpidFau6JQCbGRevlNtz47dtZ0EgAAAABgCBpburWhtFwDHq8eu3umHNmpppPCAgPIKJY5Jk5rip2KirTp+V2HdbS2zXQSAAAAAOA7tHX2a/2WcnX1DurB2x36gSPDdFLYYAAZ5aaOT9ITS2dLkp7eVqHa052GiwAAAAAAF9LdN6j1pS61dPRpyfVTdWNhlumksMIAEgJmThmjRxflq3/Aq/WlLp1p7TGdBAAAAAD4ioFBr365tUJfNHXrpjlZWvSjKaaTwg4DSIiYm5ehB27LVWfPoNZtcamts990EgAAAABAktfn0+adh1VV3665eRm6/5ZcWZZlOivsMICEkPlzJmrJdVPV3N6nDaUu9fQNmk4CAAAAgLDm9/v10l63XCeaNWNyqh65a6YiIhg/TGAACTGLrp2im+Zkqb6pW5u2Vmhg0Gs6CQAAAADC1mvv1uj9ikZNHpeoXyydrUg7T8NN4eRDjGVZuv/WXF09I0NV9e3avPOwvD6f6SwAAAAACDt/+LROr39Uq4zUWK0pdio22m46KawxgISgCMvSI3fNVP6UVLlONOvFPcfk9/tNZwEAAABA2Pj4yGm98naVkuOjtHZ5oZLio0wnhT0GkBBlt0Vo1T2zNXV8oj44dFpl+6tNJwEAAABAWKg82aIXdh9VbLRNa4qdSk+JNZ0EMYCEtNhou1YXOZU5Jk57D5zSngO1ppMAAAAAIKTVNHTomdcqZVmWnlxWoOxxiaaT8CUGkBCXFHf+5VapidEqe6da71c0mk4CAAAAgJDU2NKtjWXlGvB49djd+XJkp5pOwlcwgISBtOQYlSwvVHyMXS/uOSZXVbPpJAAAAAAIKW2d/Vq/xaWu3kH9/e0O/cCRbjoJX8MAEiayxsZrdZFTdrul53ZW6njdOdNJAAAAABASuvsGtb7UpZaOft1z/VT9uDDLdBIugAEkjEzLStaqJbPl8/m1aWuF6s52mU4CAAAAgFFtYNCrX26t0BdN3bp5zkTd9aMpppPwLRhAwkxBTpoeXjhDvf0erS91qelcr+kkAAAAABiVvD6fNu88rKr6ds3Ny9B9t0yXZVmms/AtGEDC0Lz8TN1383S1dw1o3RaXOroHTCcBAAAAwKji9/v10l63XCeaNWNyqh65a6YiIhg/ghkDSJi6de4kLZw3WWfberWhtFy9/R7TSQAAAAAwarz2bo3er2jU5MxE/WLpbEXaeXod7Pg7FMaW3nCFbnCOV+2ZTj29rUKDHq/pJAAAAAAIen/4tE6vf1SrcamxWlPkVGy03XQShoABJIxZlqUHb3doTm66jp06p+d3HZHP5zedBQAAAABB6+PDp/XK21VKjo9SyfJCJcVHmU7CEDGAhDlbRIQeu3umHJNSdNDdpN++5ZbfzwgCAAAAAF9XWdOiF14/qthom9YUO5WeEms6CZeAAQSKtNv0xLICZWckaL+rQTveO2k6CQAAAACCSk1Dh57ZXinLsvTksgJlj0s0nYRLxAACSVJcjF1rlhcqIyVWuz78XPs+qzOdBAAAAABBobGlWxvLyjXg8erxxflyZKeaTsL3wACC/5AcH6WSFYVKjo/S7/ZV6eMjp00nAQAAAIBRbZ39Wr/Fpa7eQf3kjjzNyU03nYTviQEEfyMjJVZrip2Kjbbphd1HVVnTYjoJAAAAAIzo7hvU+lKXWjr6dc8NV+gG5wTTSbgMDCD4huxxiXpyWYEsy9Iz2ytV3dBuOgkAAAAAAqp/0KtNWyv0RVO3bp4zUXfNm2w6CZeJAQQX5MhO1crF+RrweLWprEINzd2mkwAAAAAgILw+nzbvqNSJ+nZdPSND9906XZZlmc7CZWIAwbe6MjddD92Rp67eQa3b4lJrR5/pJAAAAAAYUX6/Xy/tcau8ukUzp6TqHxbOVATjR0hgAMF3ut45QffemKO2zn6t+/KNfwAAAAAgVG37U43eP9SoKZmJ+vk9sxVp52lzqODvJC5qwTXZum3uJDW29GhjWbn6BjymkwAAAABg2L31aZ3e+LhW41Jj9VSRU7HRdtNJGEYMILgoy7JUfNM0/WhWpmoaOvTs9kp5vD7TWQAAAAAwbD46fFqvvl2l5PgolSwvVFJ8lOkkDDMGEAxJhGXpoQV5KshJU+XJVr3w+lH5/H7TWQAAAABw2Q4eO6Nfv35UsdF2lSwvVHpKrOkkjIAhvZ7H4XDcIWmTJJukX7nd7n/62q8nS/qtpOwv7/Of3W73b4a5FYbZbRFauWSW1r3q0oEjZ5QQG6n7b5luOgsAEMK4BgEAjLTqhnb986suWZalJ5fN1qSMBNNJGCEXfQWIw+GwSXpG0gJJMyXd53A4Zn7tZj+XdMTtdjsl3ShpncPh4PVCISg60qbVRQXKSo/X2wfrtfujWtNJAIAQxTUIAGCkNbZ0a1NZhQYHvVq5OF+O7FTTSRhBQ/kRmKslnXC73TVut3tA0quSFn/tNn5JiQ6Hw5KUIKlVEu+UGaLiYyJVUlyotKQYbX+3Rns/+tx0EgAgNHENAgAYMa0dfVr/5Sddrrq3UFfmpptOwggbyo/AZEmq+8rX9ZKu+dpt/kXS7yU1SEqUtNztdvMumSEsNTFaa1cU6n+8fFDPbSvX44tn6aq8DNNZAIDQMmLXIKmpcbLbbcPV+Q3p6Ykjdt/4Js47cDjrwOK8R05nz4B++eKnauno1wML8nT7DyebTgo7Jh7fQxlArAt87+vvfnm7JJekmyTlSPqDw+F4z+12d3zbnXLhMfqlpyfq/3xsnv7rcx/o+V1HlDU+SQXTWE0Dgcd3YHHegcV5B1aQn/eIXINIUltbz/AUXkB6eqKamjpH7P7xtzjvwOGsA4vzHjn9g16te9WlU6c7dfMPJmp+wXhJ4rwDaCQf3991bTOUAaRe0qSvfD1R5/8ry1f9VNI/ud1uv6QTDofjpKQ8SZ98251y4REaUmLs+q8PXaP/41cf6b+/cED/+f45mpwZ1BfTox6P78DivAOL8w4sUxcfl2BErkEAAOHL6/Np845KnfiiXVfPyNB9t0yXZV1ob0coGsp7gHwqabrD4Zj65ZuKrdD5l5p+1SlJN0uSw+EYJ8khqWY4QxG8nLnpenRRvvoHvFpf6tKZ1pEbtwAAYYVrEADAsPH7/Xppj1vl1S3Kn5KqR+6aqQjGj7By0QHE7XZ7JP1C0puSjkoqdbvdhx0Ox+MOh+PxL2/23yX9yOFwHJL0tqT/7Ha7m0cqGsFnbl6GHrgtV509g1q3xaW2zn7TSQCAUY5rEADAcNr6p2q9f6hRUzITteqe2bLbhvJ6AISSofwIjNxu9xuS3vja9zZ/5f83SLpteNMw2syfM1GdPYPa8f5JbSh16b/83RzFxUSazgIAjGJcgwAAhsNbn5zSno9PaVxqrJ4qdio2ekhPhRFimLwwrBZdO0U3zclSfVO3Nm2t0MCg13QSAAAAgDD2UeVpvfrHE0pOiNLa5YVKiosynQRDGEAwrCzL0v235urqGRmqqm/X5p2H5fXxicgAAAAAAu9QTYt+/cZRxUbbVVJcqLEpsaaTYBADCIZdhGXpkbtmKn9KqlwnmvXinmPy+7/+qYUAAAAAMHKqG9r1zPZDioiwtPreAk3KSDCdBMMYQDAi7LYIrbpntqaOT9QHh06rbH+16SQAAAAAYaKxpVubyio06PHp8bvzlTspxXQSggADCEZMbLRdq4ucyhwTp70HTmnPgVrTSQAAAABCXGtHn9Ztcamrd1A/uSNPV+amm05CkGAAwYhKijv/RkOpidEqe6da71c0mk4CAAAAEKK6ege1vrRcrR39WnrDFbrBOcF0EoIIAwhGXFpyjEqWFyo+xq4X9xyTq6rZdBIAAACAENM/6NUvt1aooblbt/xgohbOm2w6CUGGAQQBkTU2XquLnLLbLT23s1LH686ZTgIAAAAQIjxenzbvqNSJL9p1zcxxWnHLdFmWZToLQYYBBAEzLStZq5bMls/n16atFao722U6CQAAAMAo5/f79dLeYyqvblH+lFT9w8IZimD8wAUwgCCgCnLS9PDCGert92h9qUtN53pNJwEAAAAYxbbur9YHh05rSmaiVt0zW3YbT3NxYTwyEHDz8jN1383T1d41oHVbXOroHjCdBAAAAGAUevOTU9pz4JTGjYnTU8VOxUbbTSchiDGAwIhb507SwnmTdbatVxtKy9Xb7zGdBAAAAGAU+ajytLb88YRSEqK0ttippLgo00kIcgwgMOb8x1KNV+2ZTj29rUKDHq/pJAAAAACjQEV1i379xlHFRdtVUlyosSmxppMwCjCAwBjLsvTg7Q7NyU3XsVPn9PyuI/L5/KazAAAAAASx6oZ2PbvjkCIiLD15b4EmZiSYTsIowQACo2wREXrs7plyTErRQXeTfvuWW34/IwgAAACAb2po7tbG0nINenx6fHG+cielmE7CKMIAAuMi7TY9saxA2RkJ2u9q0I73TppOAgAAABBkWjv6tL7Upe4+j35yR56unJ5uOgmjDAMIgkJcjF1rlhcqIyVWuz78XPs+qzOdBAAAACBIdPUOan1puVo7+rXsx1foBucE00kYhRhAEDSS46NUsqJQyfFR+t2+Kn185LTpJAAAAACG9Q969cutFWpo7tYtV03UnT+cbDoJoxQDCIJKRkqs1hQ7FRtt0wu7j6qypsV0EgAAAABDPF6fnttRqRNftOuameO04ubpsizLdBZGKQYQBJ3scYl6clmBLMvSM9srVd3QbjoJAAAAQID5/X69tOeYKqpblD91jP5h4QxFMH7gMjCAICg5slO1cnG+BjxebSwtV0Nzt+kkAAAAAAFUtr9aH1Se1tTxifr5PbNkt/H0FZeHRxCC1pW56Xrojjx193m0botLrR19ppMAAAAABMDeA6e098ApjRsTp9VFTsVE2U0nIQQwgCCoXe+coHtvzFFbZ7/WbXGpq3fQdBIAAACAEfRhZaNK3zmhlIQorV3uVFJclOkkhAgGEAS9Bddk6/arJ6mxpUcby8rVN+AxnQQAAABgBFRUt+g3bxxTXLRdJcWFGpscazoJIYQBBEHPsiwVzZ+mH83KVE1Dh57dXimP12c6CwAAAMAwqv6iXc/uOKSICEtP3lugiRkJppMQYhhAMCpEWJYeWpCngpw0VZ5s1QuvH5XP7zedBQAAAGAYNDR3a2NZuTwevx5fnK/cSSmmkxCCGEAwathtEVq5ZJamZSXrwJEzemVflfyMIAAAAMCo1trRp3VbXOru8+gndzh05Sbnh1MAACAASURBVPR000kIUQwgGFWiI21aXVSgrPR4vX2wXrs/qjWdBAAAAOB76uod1PrScrV19mvZj6/Q9c4JppMQwhhAMOrEx0SqpLhQaUkx2v5ujfa7vjCdBAAAAOAS9Q96tWlruRqau3XLVRN15w8nm05CiGMAwaiUmhittSsKlRAbqZffdOuzY2dNJwEAAAAYIo/Xp+d2VKr6iw79cOY4rbh5uizLMp2FEMcAglErc0yc1hQ7FRVp0/O7DutobZvpJAAAAAAX4ff79eKeY6qobtGsqWP08MIZimD8QAAwgGBUmzo+SU8snS1JenpbhWpPdxouAgAAAPBdyvZX68PK05o6Pkmr7pklu42npQgMHmkY9WZOGaNHF+Wrf8Cr9aUunWntMZ0EAAAA4AL2HjilvQdOKXNMnJ4qKlBMlN10EsIIAwhCwty8DD1wW646ewa1botLbZ39ppMAAAAAfMUHhxpV+s4JpSREqWS5U4lxUaaTEGYYQBAy5s+ZqCXXTVVze582lLrU0zdoOgkAAACApIrqZv3mjWOKi7arZHmhxibHmk5CGGIAQUhZdO0U3TQnS/VN3dq0tUIDg17TSQAAAEBYq/6iXc9ur5TNZunJews0MT3BdBLCFAMIQoplWbr/1lxdPSNDVfXt2rzzsLw+n+ksAAAAICw1NHdrY1m5PF6/Vi6epdxJKaaTEMYYQBByIixLj9w1U/lTUuU60awX9xyT3+83nQUAAACEldaOPq3b4lJ3n0c/WeBQ4fSxppMQ5hhAEJLstgitume2po5P1AeHTqtsf7XpJAAAACBsdPX+/x9OsOzHV+j6ggmmkwAGEISu2Gi7Vhc5lTkmTnsPnNKeA7WmkwAAAICQ1z/g1aaycjW29OjWqybpzh9ONp0ESGIAQYhLiovS2uWFSk2MVtk71Xq/otF0EgAAABCyPF6fnttZqeqGDv0wf5yW3zxNlmWZzgIkMYAgDKQlx6hkeaHiY+x6cc8xuaqaTScBAAAAIcfn9+vFPcdUUd2iWVPH6OE7ZyiC8QNBhAEEYSFrbLxWFzllt1t6bmeljtedM50EAAAAhJSt71Trw8rTmjo+SavumSW7jaebCC48IhE2pmUla9WS2fL5/Nq0tUJ1Z7tMJwEAAAAhYe+BU9r7ySlljonTU0UFiomym04CvoEBBGGlICdNDy+cod5+j9aXutR0rtd0EgAAADCqfXCoUaXvnFBqYrRKljuVGBdlOgm4IAYQhJ15+Zm67+bpau8a0LotLnV0D5hOAgAAAEal8hPN+s0bxxQXbdeaYqfGJseaTgK+FQMIwtKtcydp4bzJOtvWqw2l5ert95hOAgAAAEaVE1+067kdlbLZLK0uKtDE9ATTScB3YgBB2Fp6wxW6wTletWc69fS2Cg16vKaTAAAAgFHhi+ZubSorl8fr18rFszR9YorpJOCiGEAQtizL0oO3OzQnN13HTp3T87uOyOfzm84CAAAAglprR5/Wb3Gpu8+jnyxwqHD6WNNJwJAwgCCs2SIi9NjdM+WYlKKD7ib99i23/H5GEAAAAOBCunoHtW6LS22d/br3xhxdXzDBdBIwZAwgCHuRdpueWFag7IwE7Xc1aMd7J00nAQAAAEGnf8CrjWXlamzp0W1zJ2nBNdmmk4BLwgACSIqLsWvN8kJlpMRq14efa99ndaaTAAAAgKDh8fr07I5K1TR0aF7+OBXfNE2WZZnOAi4JAwjwpeT4KJWsKFRyfJR+t69KHx85bToJAAAAMM7n9+s3bxzToZoWzbpijH565wxFMH5gFGIAAb4iIyVWa4qdio226YXdR1VZ02I6CQAAADCq7J0T+ujwaU0dn6RVS2bJbuNpJEYnHrnA12SPS9STywpkWZae2V6p6oZ200kAAACAEXsO1OrNT+qUOSZOTxUVKCbKbjoJ+N4YQIALcGSnauXifA14vNpYWq6G5m7TSQAAAEBAfXCoUWXvVCs1MVprlxcqMS7KdBJwWRhAgG9xZW66HrojT919Hq3b4lJrR5/pJAAAACAgyk806zdvHFN8jF0lxU6lJceYTgIuGwMI8B2ud07QvTfmqK2zX+u2uNTVO2g6CQAAABhRJ+rb9dyOStltllbf61RWeoLpJGBYMIAAF7HgmmzdfvUkNbb0aGNZufoGPKaTAAAAgBHxRVOXNm0tl8fr1+NLZmnaxGTTScCwYQABLsKyLBXNn6YfzcpUTUOHnt1eKY/XZzoLAAAAGFYt7X1aX1qu7j6PHlqQp8JpY00nAcOKAQQYggjL0kML8lSQk6bKk6164fWj8vn9prMAAACAYdHVO6j1pS61dfar6MYcXVcw3nQSMOwYQIAhstsitHLJLE3LStaBI2f0yr4q+RlBAAAAMMr1D3i1saxcjS09um3uJN1xTbbpJGBEMIAAlyA60qbVRQXKSo/X2wfrtfujWtNJAAAAwPfm8fr07I5K1TR0aF7+OBXfNE2WZZnOAkYEAwhwieJjIlVSXKi0pBhtf7dG+11fmE4CAAAALpnP79dv3jiqQzUtmnXFGP30zhmKYPxACGMAAb6H1MRorV1RqITYSL38plufHTtrOgkAAAAYMr/fr9I/ntBHh8/oiglJ+vmS2bLbeHqI0MYjHPieMsfEaU2xU1GRNj2/67CO1raZTgIAAACGZO8np/TWp3Uanxanp4qcio6ymU4CRhwDCHAZpo5P0hNLZ0uSnt5WodrTnYaLAAAAgO/2waFGlb1TrdTEaJUUn39VMxAOGECAyzRzyhg9uihf/QNerS916Uxrj+kkAAAA4IJcJ5r1mzeOKT7GrpJip9KSY0wnAQHDAAIMg7l5GXrgtlx19gxq3Zbzn58OAAAABJMT9e3avKNSdpul1fc6lZWeYDoJCCgGEGCYzJ8zUUuum6rm9j5tKHWpp2/QdBIAAAAgSfqiqUubtpbL4/Vr5ZJZmjYx2XQSEHAMIMAwWnTtFN00J0v1Td3atLVCA4Ne00kAAAAIcy3tfVpfWq7uPo9+emeenNPGmk4CjGAAAYaRZVm6/9ZcXT0jQ1X17dq887C8Pp/pLAAAAISpzp4BrS89/yPaRfNzdO3s8aaTAGMYQIBhFmFZeuSumcqfkirXiWa9uOeY/H6/6SwAAACEmf4BrzZtrVBjS49uv3qSFlwz2XQSYBQDCDAC7LYIrbpntqaOT9QHh06rbH+16SQAAACEEY/Xp2d2HFJNQ4fm5Y9T0fxpppMA4xhAgBESG23XU0VOZY6J094Dp7TnQK3pJAAAAIQBn9+vX79xVJU1rZp9RZp+eucMRViW6SzAOAYQYAQlxkVp7fJCpSZGq+ydar1f0Wg6CQAAACHM7/er9I8n9PHhM8qZkKRVS2bJbuNpHyAxgAAjLi05RiXLCxUfY9eLe47JVdVsOgkAAAAhau+BU3rr0zqNT4vT6iKnoqNsppOAoMEAAgRA1th4rS5yym639NzOSh2vO2c6CQAAACHm/YpGle2vVmpitNYuL1RCbKTpJCCoMIAAATItK1mrlsyWz+fXpq0VqjvbZToJAAAAIcJVdf7TB+Nj7CpZXqgxSTGmk4CgwwACBFBBTpoeXjhDvf0erS91qelcr+kkAAAAjHJV9ef03M5K2W2WVhc5lTU23nQSEJQYQIAAm5efqftunq72rgGt2+JSR/eA6SQAAACMUl80dWlTWYW8Xr9WLpmlaVnJppOAoMUAAhhw69xJWjhvss629WpDabl6+z2mkwAAADDKtLT3aX1puXr6PfrpnXlyThtrOgkIagwggCFLb7hCNzjHq/ZMp57eVqFBj9d0EgAAAEaJzp7zryZu6+xX0fwcXTt7vOkkIOgxgACGWJalB293aE5uuo6dOqfndx2Rz+c3nQUAAIAg1zfg0cayCp1u7dHtV0/Sgmsmm04CRgUGEMAgW0SEHrt7phyTUnTQ3aTfvuWW388IAgAAgAvzeH16dnulTjZ2aF5+pormTzOdBIwaDCCAYZF2m55YVqDsjATtdzVox3snTScBAAAgCPn8fv36jaOqPNmqgpw0/fTOPEVYluksYNRgAAGCQFyMXWuWFyojJVa7Pvxc+z6rM50EAACAIOL3+1X6xxP6+PAZ5UxI0srFs2S38XQOuBT8iQGCRHJ8lEpWFCo5Pkq/21elj4+cNp0EAACAILHnwCm99WmdxqfFaXWRU9FRNtNJwKjDAAIEkYyUWK0pdio22qYXdh9VZU2L6SQAAAAY9l5Fg7bur1ZqYrTWLi9UQmyk6SRgVGIAAYJM9rhEPbmsQJZl6ZntlapuaDedBAAAAENcVc16aY9b8TF2lSwv1JikGNNJwKjFAAIEIUd2qlYuzteAx6uNpeVqaO42nQQAAIAAq6o/p+d2Vspus7S6yKmssfGmk4BRjQEECFJX5qbroTvy1N3n0botLrV29JlOAoCAczgcdzgcDrfD4TjhcDj+y7fc5kaHw+FyOByHHQ7HnwLdCAAjobaxQ5vKKuT1+rXqnlmalpVsOgkY9YY0gHDxAZhxvXOC7r0xR22d/Vq3xaWu3kHTSQAQMA6HwybpGUkLJM2UdJ/D4Zj5tdukSHpW0t1utztfUlHAQwFgmDW39+ofn/9IPf0e/fTOPBXkjDWdBISEiw4gXHwAZi24Jlu3Xz1JjS092lhWrt5+j+kkAAiUqyWdcLvdNW63e0DSq5IWf+0290t6ze12n5Ikt9t9NsCNADCsOnsGtH5LuVo7+lQ8f5qunT3edBIQMobyChAuPgCDLMtS0fxp+tGsTNU0dOifXvpUHq/PdBYABEKWpLqvfF3/5fe+KldSqsPh2O9wOA46HI6/D1gdAAyzvgGPNpZV6HRrj+65cZruuCbbdBIQUuxDuM2FLj6u+dptciVFOhyO/ZISJW1yu93//l13mpoaJ7t95D67Oj09ccTuG9/EeY+8//T3c/V//+YTfXb0jH67L1Jr7/+BIiIs01lhgcd3YHHegRXk532hf8j5v/a1XdIPJN0sKVbSRw6H42O32338u+6Y65DQwnkHDmc9cgY9Pv1fvz6gk40duumqSXpo4Uyu9QKMx3dgmTjvoQwgI3Lx0dbWM+TIS5Wenqimps4Ru3/8Lc47cP7hzjx19w7q3b98ocgIS/ffMl2Wxb8YRxKP78DivANrJM97mC5q6iVN+srXEyU1XOA2zW63u1tSt8PheFeSU9J3DiBch4QOzjtwOOuR4/P79atdR/Rn91kV5KRpxfwcRURYnHcA8fgOLFPXIEP5EZihXnzsdbvd3W63u1nSXy8+AAyj6Eib/vEfrlFWerzePliv3R/Vmk4CgJH0qaTpDodjqsPhiJK0QtLvv3abnZKudzgcdofDEafzr1I9GuBOAPje/H6/trx9Qh8fOaOcCUlauXiW7DY+rBMYCUP5k8XFBxBEEuKiVFJcqLSkGG1/t0b7XV+YTgKAEeF2uz2SfiHpTZ2/rih1u92HHQ7H4w6H4/Evb3NU0l5JFZI+kfQrt9tdaaoZAC7VGx/X6g+f1Wl8WpxWFzkVHTVyP54HhLuL/giM2+32OByOv1582CT9+q8XH1/++ma3233U4XD89eLDJy4+gBGVmhittSsK9T9ePqiX33QrISZSV+VlmM4CgGHndrvfkPTG1763+Wtf/y9J/yuQXQAwHN6raNC2P9Wcv7ZbXqiE2EjTSUBIG8p7gHDxAQShzDFxWlPs1P/7yl/0/K7Dio+N1IzJqaazAAAAMASuqma9tMet+Bi71i4v1JikGNNJQMjjh8uAUWzq+CQ9sXS2JOnpbRWqPc0bNwEAAAS743Xn9NzOStltlp4qcmrC2HjTSUBYYAABRrmZU8bo0UX56h/wan2pS2daR+6TDQAAAHB56s926ZdbK+T1+rXqnlnKyUo2nQSEDQYQIATMzcvQA7flqrNnUOu2uNTW2W86CQAAAF/T3N6r9aUu9fR79PDCPBXkjDWdBIQVBhAgRMyfM1FLrpuq5vY+bSh1qadv0HQSAAAAvtTZM6B1W8p1rmtAxfOn6UezxptOAsIOAwgQQhZdO0U3zclSfVO3Nm2t0MCg13QSAABA2Osb8GhjWbnOtPbojmuydcc12aaTgLDEAAKEEMuydP+tubp6Roaq6tu1eedheX0+01kAAABhy+P16ZntlTrZ2KlrZ2Wq6MYc00lA2GIAAUJMhGXpkbtmKn9KqlwnmvXinmPy+/2mswAAAMKOz+/XC68f1eGTrSrISdNPFuTJsizTWUDYYgABQpDdFqFV98zW1PGJ+uDQaZXtrzadBAAAEFb8fr9efbtKB46cUU5WklYumSW7jadfgEn8CQRCVGy0XU8VOZU5Jk57D5zSngO1ppMAAADCxhsf12rfZ/WaMDZeq+91KjrSZjoJCHsMIEAIS4yL0trlhUpNjFbZO9V6v6LRdBIAAEDIe6+8Qdv+VKMxSdEqKXYqITbSdBIAMYAAIS8tOUYlywsVH2PXi3uOyVXVbDoJAAAgZP2lqkkv7j2m+Bi7SooLNSYpxnQSgC8xgABhIGtsvFYXOWW3W3puZ6WO150znQQAABByjted0+adhxVpj9BTRU5NGBtvOgnAVzCAAGFiWlayVi2ZLZ/Pr01bK1R3tst0EgAAQMioP9ulTVsr5PP5tWrJbOVkJZtOAvA1DCBAGCnISdPDC2eot9+j9aUuNZ3rNZ0EAAAw6jWf69W6Upd6+z16+M4ZKshJM50E4AIYQIAwMy8/U/fdPF3tXQNat8Wlju4B00kAAACjVkfPgNaVlqu9a0DLb5qmebMyTScB+BYMIEAYunXuJC2cN1ln23q1obRcvf0e00kAAACjTt+AR5vKynWmtUcLrsnW7Vdnm04C8B0YQIAwtfSGK3SDc7xqz3Tq6W0VGvR4TScBAACMGh6vT8+8dkgnGzt17axM3XtjjukkABfBAAKEKcuy9ODtDs3JTdexU+f0/K4j8vn8prMAAACCns/v1wuvH9Xhz9tUkJOmnyzIk2VZprMAXAQDCBDGbBEReuzumXJMStFBd5N++5Zbfj8jCAAAwLfx+/16dV+VDhw5o2lZyVq5ZJbsNp5WAaMBf1KBMBdpt+mJZQXKzkjQfleDdrx30nQSAABA0Hrj41rtO1ivrLHxevLeAkVH2kwnARgiBhAAiouxa83yQmWkxGrXh59r32d1ppMAAACCzrvlDdr2pxqNSYrWmmKnEmIjTScBuAQMIAAkScnxUSpZUajk+Cj9bl+VPj5y2nQSAABA0PjL8Sa9tPeY4mPsKiku1JikGNNJAC4RAwiA/5CREqs1xU7FRtv0wu6jqqxpMZ0EAABg3PG6c9r8+8OKtEfoqWKnJoyNN50E4HtgAAHwN7LHJerJZQWyLEv/sv2QqhvaTScBAAAYU3+2S5u2Vsjn8+vn98xWzoRk00kAvicGEADf4MhO1crF+Rr0+LSxtFwNzd2mkwAAAAKu+Vyv1pW61Nvv0cMLZ2j2FWmmkwBcBgYQABd0ZW66HrojT919Hq3b4lJrR5/pJAAAgIDp6BnQutJytXcNaMVN0zQvP9N0EoDLxAAC4Ftd75ygohtz1NbZr3VbXOrqHTSdBAAAMOJ6+z3aWFquM609WnBNtm67Ott0EoBhwAAC4DvdcU22br96khpberSxrFx9Ax7TSQAAACPG4/Xpme2H9PnpTl07O1P33phjOgnAMGEAAfCdLMtS0fxp+tGsTNU0dOjZ7ZXyeH2mswAAAIadz+/Xr3Yf0ZHP2+TMSdNDC/JkWZbpLADDhAEEwEVFWJYeWpCngpw0VZ5s1QuvH5XP7zedBQAAMGz8fr9e3VelT46e1bSJyXp8ySzZIni6BIQS/kQDGBK7LUIrl8zStKxkHThyRq/sq5KfEQQAAISI1z+q1b6D9coaG68nlxUoOtJmOgnAMGMAATBk0ZE2rS4qUFZ6vN4+WK/dH9WaTgIAALhs75Y36LV3azQmKVprip1KiI00nQRgBDCAALgk8TGRKikuVFpSjLa/W6P9ri9MJwEAAHxvfz7epJf2HlNCbKTWLi/UmKQY00kARggDCIBLlpoYrbUrCpUQG6mX33Trs2NnTScBAABcMvepNm3eeViR9gitLirQ+LR400kARhADCIDvJXNMnNYUOxUVadPzuw7raG2b6SQAAIAhqzvbpV9uOyS/36+f3zNbOROSTScBGGEMIAC+t6njk/TE0tmSpKe3Vaj2dKfhIgAAgItrOter9aUu9fZ79PDCGZp9RZrpJAABwAAC4LLMnDJGjy7KV/+AV+tLXTrT2mM6CQAA4Ft1dA9o/RaX2rsGtOKmaZqXn2k6CUCAMIAAuGxz8zL0wG256uwZ1LotLrV19ptOAgAA+Ibefo82lJXrTFuvFvwwW7ddnW06CUAAMYAAGBbz50zUkuumqrm9TxtKXerpGzSdBAAA8B88Xp+e2X5Itac7dd3s8br3xzmmkwAEGAMIgGGz6NopumlOluqburVpa4UGBr2mkwAAAOTz+/Wr3Ud05PM2OXPS9JMFDlmWZToLQIAxgAAYNpZl6f5bc3X1jAxV1bdr887D8vp8prMAAEAY8/v9emVflT45elbTJibr8SWzZIvgaRAQjviTD2BYRViWHrlrpvKnpMp1olkv7jkmv99vOgsAAISp3R/V6u2D9coaG6/V9xYoOtJmOgmAIQwgAIad3RahVffM1tTxifrg0GmV7a82nQQAAMLQu+UN2v5ujdKSolWyvFDxMZGmkwAYxAACYETERtv1VJFTmWPitPfAKe05UGs6CQAAhJE/H2/SS3uPKSE2UiXLC5WaGG06CYBhDCAARkxiXJTWfnnBUfZOtd6vaDSdBAAAwoD7VJs27zysSHuEnipyanxavOkkAEGAAQTA/8fenQdXXSd63v/8ck72PZAQCIGEJT9IIIko2LjgimgjgtAJ6NXbjq3tigpMzZ15puqpZ2rqqZl5atjEVptub9utV00AQUERG1uuOzZ0n4QAOUCAsARIAiH7dnLO84d2j+1GgOR8z/J+VVkl5HR817fSOV8+nCSDakhyzNcvOXXq5a3Vch1sNJ0EAABC2PH6Nj27YY98Pp+evHuyxoxIMp0EIEAwgAAYdFlD4/V0SZGcTksvvFWlA8fPm04CAAAhqOF8p1aUudTZ7dGDsydq0pghppMABBAGEAB+MS4rWY/Pmyyv16fV6yt1vL7NdBIAAAghLe09Wl7mUnN7jxbdMl7TCzJNJwEIMAwgAPymcOwQPTh7ojq7PVpR7lLD+U7TSQAAIAR0dnu0cl2F6ps69dOfjNZtU7NNJwEIQAwgAPxqekGm7rllvJrbvvpbmpb2HtNJAAAgiPV6vPrVxj2qPd2q6wqHa8ENY0wnAQhQDCAA/G7m1GzNnj5a9U2dWlleoc5uj+kkAAAQhLw+n156Z5/2HW1S8bih+vnttizLMp0FIEAxgAAwYv6MMZpRNFy1Z1q1ZkOlej19ppMAAEAQ8fl8ev2PB/Xl/nqNG5msR+YWyBHBH28A/DA+QwAwwrIs3T/L1pS8dFUfO6+1m/fJ6/WZzgIAAEFiy+e1+uAvJ5SVHq+nf1ao6EiH6SQAAY4BBIAxjogIPXJXvuzsFO12N+jV993y+RhBAADAj/t310lt/OiwhiTFaGlpseJjIk0nAQgCDCAAjIp0OrR4QaFGZSRoh6tOmz4+YjoJAAAEsN3uBv1hm1sJsZFaurBIqYnRppMABAkGEADGxcU4tWRhsTJSYrX5s6Pavuu46SQAABCA3Mea9Ou39yrK6dAzJUUaPiTedBKAIMIAAiAgJMdHaemiYiXHR+m17Qf1xb7TppMAAEAAOXamVc9uqJTP59MT8ydpzIgk00kAggwDCICAkZESqyWlRYqNduilLftVdfis6SQAABAAGs53amV5hTq7+/SL2RM1KXeI6SQAQYgBBEBAGTUsUU8tKJRlWXpu4x7V1DWbTgIAAAa1tPdoeZlLze09uueW8fpJQabpJABBigEEQMCxR6XqsbkF6vV4taq8QnWN7aaTAACAAZ3dHq1cV6H6pk7Nnj5aM6dmm04CEMQYQAAEpCvy0vXA7RPU3uXR8jKXzrV0mU4CAAB+1Ovx6rk396j2dKuuKxyu+TPGmE4CEOQYQAAErOuLRqjkxrFqau3W8jKX2jp7TScBAAA/8Hp9+u2Wfdpf26TicUP189ttWZZlOgtAkGMAARDQbr96lGZNy9apsx1ata5CXT0e00kAAGAQ+Xw+vbb9gP5cXa/xI5P16NwCOSL4YwuAy8dnEgABzbIsldw0TtdMytThuhY9v7FKnj6v6SwAADBItnx2VH/6y0llpcfrqZ8VKirSYToJQIhgAAEQ8CIsSw/cMUGFY4eo6sg5vfTOfnl9PtNZAABggO1wndTGj49oSFKMlpYWKz4m0nQSgBDCAAIgKDgdEXps3iSNy0rWzn1n9Pr2g/IxggAAEDJ2u+v1yja3EmIjtXRhkVITo00nAQgxDCAAgkZ0pENPlxQqKz1eH+w+oS2f15pOAgAAA8B9rEm/fnufopwOLSkt0vAh8aaTAIQgBhAAQSU+JlJLS4s1JClGGz86rB2uk6aTAADAZTh2plXPbqiUz+fTE/MnKXd4kukkACGKAQRA0ElNjNayRcVKiI3UK9vc2lVdbzoJAABcgvrznVpZXqHO7j794s6JmpQ7xHQSgBDGAAIgKGWmxWlJaZGiIh1au3mv9tc2mU4CAAAXoaW9RyvKXGpu79E9t47XT/IzTScBCHEMIACCVu7wJC2eP1mStGZDpWpPtxouAgAA/dHZ7dHK8grVN3Vq9vTRmnlVtukkAGGAAQRAUMvPSdPDcwrU3dOnFeUunTnXYToJAAD8iF6PV8+9uUe1Z1p1feFwzZ8xxnQSgDDBAAIg6E2dkKH7bstTa0evlpe51NTabToJAAB8D6/Xp99s2af9tU26YvxQ/fPttizLMp0FIEwwgAAICTdNGal51+WqsblLK8tdPJa1CAAAIABJREFU6ujqNZ0EAAC+wefz6bXtB7Srul55I5P1yF0FckTwxxEA/sNnHAAhY861Obp5SpZONLRr9fpK9fT2mU4CAABf2/zZUf3pLyc1Mj1eT/2sUFGRDtNJAMIMAwiAkGFZlu6dmadpEzN08ESzXnxrr/q8XtNZAACEvR1/PalNHx/RkKQYLSktVlxMpOkkAGGIAQRASImwLD10Z74KclLlOtSol9+tls/nM50FAEDY2u2u1yvvu5UQG6lli4qVmhhtOglAmGIAARBynI4IPTF/snKHJ+rTqtNat6PGdBIAAGGpurZJv357r6KcDi0pLVJmWpzpJABhjAEEQEiKiXLqmZKvLlrv7TymrTtrTScBABBWjp1p1Zo3K+XzSU/On6zc4UmmkwCEOQYQACErMS5KyxZ+9VLbdR/W6JPKU6aTAAAIC/XnO7WivEKd3X1ffWlqbprpJABgAAEQ2oYkx2jpwmLFxzj18tZquQ42mk4CACCkNbf3aMUbLrW09+ieW8fr6vxhppMAQBIDCIAwkDU0Xk+XFMnptPTCW1U6cPy86SQAAEJSZ7dHK8tdqj/fqdnTR2vmVdmmkwDg7xhAAISFcVnJenzeZHm9Pq1eX6nj9W2mkwAACCm9Hq+ee3OPjp1p04yi4Zo/Y4zpJAD4BwwgAMJG4dghenD2RHV2e7Si3KWG852mkwAACAler0+/2bJP+2ubdMX4obp/li3LskxnAcA/YAABEFamF2TqnlvGq7mtR8vLvvr6ZAAAcOl8Pp/+bfsB7aquV97IZD1yV4EcEfwxA0Dg4TMTgLAzc2q2Zk8frfqmTq0sr1Bnt8d0EgAAQWvzp0f14V9OamR6vJ76WaGiIh2mkwDgezGAAAhL82eM0Yyi4ao906o1GyrV6+kznQQAQND58K8ntemTIxqaHKMlpcWKi4k0nQQAP4gBBEBYsixL98+yNSUvXdXHzmvt5n3yen2mswAACBq7quv16ja3EmIjtXRhsVITo00nAcCPYgABELYcERF65K582dkp2u1u0Kvvu+XzMYIAAHAh1bVNWrt5r6KiHFpSWqTMtDjTSQBwQQwgAMJapNOhxQsKNSojQTtcddr08RHTSQAABLRjZ1q15s1K+XzSk3dPVu7wJNNJANAvDCAAwl5cjFNLFhYrIyVWmz87qu27jptOAgAgINU3dWhFeYW6uvv00J35KshNM50EAP3WrwHEtu3bbdt227Z9yLbt//wjj5tq23afbds/G7hEABh8yfFRWrqoWMnxUXpt+0F9se+06SQA4g4CBJKm1i6tKKtQS3uP7rl1vK7OH2Y6CQAuygUHENu2HZJ+JekOSfmS7rFtO/8HHve/JG0b6EgA8IeMlFgtKS1SbLRDL23Zr6rDZ00nAWGNOwgQODq7Pfp/fvOF6s936s5rRuvWq7JNJwHARevPK0CmSTrkdrsPu93uHklvSJr7PY9bLGmDpPoB7AMAvxo1LFFPLSiUZVl6buMeuWvPmU4Cwhl3ECAA9Hq8eu7NPTp8slkziobr7uvHmE4CgEvSnwEkS9I3vyD+xNe/93e2bWdJulvSiwOXBgBm2KNS9djcAvV6vPpvv/1CdY3tppOAcMUdBDDM6/XpN5v3an9tk34yKVP3z7JlWZbpLAC4JM5+POb7PsN9++dErpL0L263u8+27X79h1NT4+R0Ovr12EuRnp44aO8b38V5+xfnPfhuS0+U5XTo2XKXVq2r0P+3eIbSU2NNZ4UFPr79K8DPe1DuIBL3kFDDeQ8On8+nF96s1C53gwrGDNF/vO8qRUcO3v9v8F18bPsX5+1fJs67PwPICUnf/CK/kZLqvvWYqyS98fXFY6ikn9q27XG73Zt+6J02NXVcZGr/pacnqqGhddDeP/4R5+1fnLf/FI9J0wOz8/XyO/v0X1/4RP/lviuVEBtpOiuk8fHtX4N53gN0qRmUO4jEPSSUcN6D561PjmjrZ0c1Mj1Bj92Vr+hIB2ftR3xs+xfn7V+m7iD9GUD+LGm8bdu5kk5KWiTp3m8+wO125/7t323bflnSlgtdPAAgGMy/aZxONbRq25fHtWpdhf7jomLFRPXnUyeAAcAdBDDkw7+e1FufHNHQ5BgtXVikuBj+AgBA8Lvg9wBxu90eSU/qq++svl9Sudvt3mvb9qO2bT862IEAYJJlWSq5aZyumZSpw3Uten5jlTx9XtNZQFjgDgKYsau6Xq9ucysxLlLLFhYrJSHadBIADIh+/TWm2+1+V9K73/q97/1mY263+4HLzwKAwBFhWXrgjglq6+xVZc1ZvfTOfj08J18RfBM4YNBxBwH8a39tk9Zu3quoKIeeKSnSsLQ400kAMGD681NgACDsOR0RemzeJI3LStbOfWf0+vaD8vm+/b0YAQAIXrWnW7VmQ6V8PunJ+ZOVOzzJdBIADCgGEADop+hIh54uKVRWerw+2H1CWz6vNZ0EAMCAqG/q0Mp1Feru6dPDc/JVkJNmOgkABhwDCABchPiYSC0tLdaQpBht/OiwdrhOmk4CAOCyNLf3aEVZhVrae3TvzDxNmzjMdBIADAoGEAC4SKmJ0Vq2qFgJsZF6ZZtbu6rrTScBAHBJOrs9WlnuUv35Tt15TY5uuXKk6SQAGDQMIABwCTLT4rSktEhRkQ6t3bxX+2ubTCcBAHBRej19WrOhUsfOtGlG0QjdfX3uhf9HABDEGEAA4BLlDk/S4vmTJUlrNlSq9nSr4SIAAPrH6/Vp7eZ9qj52XleMH6r7Z+XJ4qebAQhxDCAAcBnyc9L08JwCdff0aUW5S2fOdZhOAgDgR/l8Pr36xwPa7W5QXnaKHp1bIEcEfywAEPr4TAcAl2nqhAzdd1ueWjt6tbzMpabWbtNJAAD8oLc/Paodfz2pkekJemrBZEU6HaaTAMAvGEAAYADcNGWk5l2Xq8bmLq0sd6mjq9d0EgAA3/HhX0/qrU+OaGhyjJYuLFJcTKTpJADwGwYQABggc67N0c1TsnSioV2r11eqp7fPdBIAAH+3q7per25zKzEuUssWFislIdp0EgD4FQMIAAwQy7J078w8TZuYoYMnmvXiW3vV5/WazgIAQPuPntPazXsVFeXQktIiDUuLM50EAH7HAAIAAyjCsvTQnfkqyEmV61CjXn63Wj6fz3QWACCM1Z5u1Zo398jnk56cP1k5mUmmkwDACAYQABhgTkeEnpg/WbnDE/Vp1Wmt21FjOgkAEKbqmzq0cl2Funv69PCcfBXkpJlOAgBjGEAAYBDERDn1TEmRMtPi9N7OY9q6s9Z0EgAgzDS3dWt5mUst7T1ff4nmMNNJAGAUAwgADJLEuCgtW1is1MRorfuwRp9UnjKdBAAIEx1dHq0sr1DD+S7deU2ObrlypOkkADCOAQQABtGQ5BgtXVis+BinXt5aLdfBRtNJAIAQ1+vp03NvVupYfZtuKB6hu6/PNZ0EAAGBAQQABlnW0Hg9XVIkp9PSC29V6cDx86aTAAAhyuv1ae3mfao+dl5T8tJ1/222LMsynQUAAYEBBAD8YFxWsh6fN1ler0+r11fqeH2b6SQAQIjx+Xx69Y8HtNvdIDs7RY/cla+ICMYPAPgbBhAA8JPCsUP04OyJ6uz2aEW5Sw3nO00nAQBCyFufHNGOv55UdkaCFi8oVKTTYToJAAIKAwgA+NH0gkzdc8t4Nbf1/P078wMAcLk+/MsJvf3pUQ1NjtGS0iLFxThNJwFAwGEAAQA/mzk1W7Onj1Z9U6dWlleos9tjOgkAEMT+XF2vV98/oMS4SC1bWKyUhGjTSQAQkBhAAMCA+TPGaEbRcNWeadWaDZXq9fSZTgIABKH9R8/pN5v3KirKoSWlRRqWFmc6CQACFgMIABhgWZbun2VrSl66qo+d19rN++T1+kxnAQCCSO3pVq15c48kafH8ycrJTDJcBACBjQEEAAxxRETokbvyZWenaLe7Qa++75bPxwgCALiwM00dWlnuUndPnx66M1/5OWmmkwAg4DGAAIBBkU6HFi8o1KiMBO1w1WnTx0dMJwEAAlxzW7dWlLnU0tGre2fmadrEYaaTACAoMIAAgGFxMU4tWVisjJRYbf7sqLbvOm46CQAQoDq6PFpRXqGG812ac02ObrlypOkkAAgaDCAAEACS46O0dFGxkuOj9Nr2g/pi32nTSQCAANPr6dNzb1bqeH2bbigeoXnX55pOAoCgwgACAAEiIyVWS0qLFBvt0Etb9qvq8FnTSQCAAOH1+rT27X2qPnZeV+al6/7bbFmWZToLAIIKAwgABJBRwxL11IJCWZal5zbuUU1ds+kkAIBhPp9Pr77v1u4DDbKzU/TLu/IVEcH4AQAXiwEEAAKMPSpVj80tUK/Hq1XlFaprbDedBAAw6K1PjmiHq07ZGQlavKBQkU6H6SQACEoMIAAQgK7IS9cDd0xQe5dHy8tcOtfSZToJAGDAn/5yQm9/elRDk2O0pLRIcTFO00kAELQYQAAgQF1fOEIlN45VU2u3lpe51NbZazoJAOBHf66u17+9f0BJcZFatqhYKQnRppMAIKgxgABAALv96lGaNS1bp852aNW6CnX1eEwnAQD8YP/Rc/rN5r2KjnJoSWmxhqXGmU4CgKDHAAIAAcyyLJXcNE7XTMrU4boWPb+xSp4+r+ksAMAgqj3dqmff3CNJWjx/skZnJhouAoDQwAACAAEuwrL0wB0TVDh2iKqOnNNL7+yX1+cznQUAGARnmjq0stylnp4+PTynQBNz0kwnAUDIYAABgCDgdETosXmTNC4rWTv3ndHr2w/KxwgCACHlfFu3lr/hUktHr/7ptjxNnZBhOgkAQgoDCAAEiehIh54uKVRWerw+2H1CWz6vNZ0EABggHV0erSyvUGNzl+66Nkc3TxlpOgkAQg4DCAAEkfiYSC0tLdaQpBht/OiwdrhOmk4CAFymXk+f1myo1PH6Nt1YPEJzr8s1nQQAIYkBBACCTGpitJYtKlZCbKRe2ebWrup600kAgEvk9fq09u19ch8/ryvz0nXfbbYsyzKdBQAhiQEEAIJQZlqclpQWKSrSobWb92p/bZPpJADARfL5fHrlfbd2H2jQhFEp+uVd+YqIYPwAgMHCAAIAQSp3eJIWz58sSVqzoVK1p1sNFwEALsamj4/o3111ys5I0JPzCxXpdJhOAoCQxgACAEEsPydND88pUHdPn1aUu3TmXIfpJABAP3yw+4Q2f3ZU6SkxWlpapLgYp+kkAAh5DCAAEOSmTsjQfbflqbWjV8vLXGpq7TadBAD4EV/uP6PX/nhASXGRWrawWMkJ0aaTACAsMIAAQAi4acpIzbsuV43NXVpZ7lJHV6/pJADA99h39Jx+s3mfoqMcWlJarIzUONNJABA2GEAAIETMuTZHN0/J0omGdq1eX6me3j7TSQCAbzh6ukVr3twjy5IWz5+s0ZmJppMAIKwwgABAiLAsS/fOzNO0iRk6eKJZL761V31er+ksAICkM+c6tLK8Qj09ffrlnAJNzEkznQQAYYcBBABCSIRl6aE781WQkyrXoUa9/G61fD6f6SwACGvn27q1vMyl1o5e3Xdbnq6akGE6CQDCEgMIAIQYpyNCT8yfrNzhifq06rTW7agxnQQAYaujy6OV5RVqbO7SXdfm6KYpI00nAUDYYgABgBAUE+XUMyVFykyL03s7j2nrzlrTSQAQdno9fVqzoVLH69t04xVZmntdrukkAAhrDCAAEKIS46K0bGGxUhOjte7DGn1Secp0EgCEDa/Xp1+/vU/u4+d1pZ2u+2bmybIs01kAENYYQAAghA1JjtHShcWKj3Hq5a3Vch1sNJ0EACHP5/PpD9vc+suBBk0YlaJfzslXRATjBwCYxgACACEua2i8ni4pktNp6YW3qnTg+HnTSQAQ0jZ9fEQfVdRpVEaCFi8oVKTTYToJACAGEAAIC+OykvX4vMnyen1avf6rr0cHAAy8D3af0ObPjio9JUZLSosUG+00nQQA+BoDCACEicKxQ/Tg7Inq7PZoRblLDec7TScBQEj5cv8ZvfbHA0qKi9SyhcVKTog2nQQA+AYGEAAII9MLMnXPLePV3Naj5WUutbT3mE4CgJCw9+g5/WbzPkVHObSktFgZqXGmkwAA38IAAgBhZubUbM2ePlr1TZ1aWV6hzm6P6SQACGpHTrXouTf3yLKkxQsKNToz0XQSAOB7MIAAQBiaP2OMZhQNV+2ZVq3ZUKleT5/pJAAISmfOdWjVugr19PTpl3MKNHF0qukkAMAPYAABgDBkWZbun2VrSl66qo+d19rN++T1+kxnAUBQOd/WreVlLrV29Oq+WbaumpBhOgkA8CMYQAAgTDkiIvTIXfmys1O0292gV993y+djBAGA/ujo6tWKsgo1NnfprmtzdNMVWaaTAAAXwAACAGEs0unQ4gWFGpWRoB2uOm36+IjpJAAIeD29fXp2wx6daGjTjVdkae51uaaTAAD9wAACAGEuLsapJQuLlZESq82fHdX2XcdNJwFAwPJ6ffr123t14Ph5XWWn676ZebIsy3QWAKAfGEAAAEqOj9LSRcVKjo/Sa9sP6ot9p00nAUDA8fl8+sM2t/56sFETRqXo4TkFiohg/ACAYMEAAgCQJGWkxGpJaZFiox16act+VR0+azoJAALKxo+P6KOKOo3KSNDiBYWKdHKVBoBgwmdtAMDfjRqWqKcWFMqyLD23cY9q6ppNJwFAQNi+67i2fHZU6SkxX4/FTtNJAICLxAACAPgH9qhUPTa3QL0er1aVV6iusd10EgAY9eX+M3p9+0ElxUdp2cJiJSdEm04CAFwCBhAAwHdckZeuB+6YoPYuj5aXuXSupct0EgAYsffoOf1m8z5FRzm0pKRIGalxppMAAJeIAQQA8L2uLxyhkhvHqqm1W8vLXGrr7DWdBAB+deRUi557c48sS1q8oFCjMxNNJwEALgMDCADgB91+9SjNmpatU2c7tGpdhbp6PKaTAMAvzpz76vNeT0+ffjmnQBNHp5pOAgBcJgYQAMAPsixLJTeN0zWTMnW4rkXPb6ySp89rOgsABtXfXvnW2tGr+2bZumpChukkAMAAYAABAPyoCMvSA3dMUOHYIao6ck4vvbNfXp/PdBYADIqOrl6tLHepsblLc6/L1U1XZJlOAgAMEAYQAMAFOR0RemzeJI3LStbOfV/9NAQfIwiAENPT26dn11fqREO7bpqSpbuuzTGdBAAYQAwgAIB+iY506OmSQmWlx+uD3Se05fNa00kAMGD6vF79+u29OnCiWVfZ6fqnW/NkWZbpLADAAGIAAQD0W3xMpJaWFmtIUow2fnRYO1wnTScBwGXz+Xx6ZZtbfz3YqImjU/XwnAJFRDB+AECoYQABAFyU1MRoLVtUrITYSL2yza1d1fWmkwDgsmz8+LA+qjilUcMS9OT8yYp0ckUGgFDEZ3cAwEXLTIvTktIiRUU6tHbzXu2vbTKdBACXZPuu49ryWa0yUmK1pLRYsdFO00kAgEHCAAIAuCS5w5O0eP5kSdKaDZWqPd1quAgALs7fvqlzUnyUli4qVnJ8lOkkAMAgYgABAFyy/Jw0PTynQN09fVpR7tKZcx2mkwCgX/YeOaffbtmnmGiHlpYWKSMl1nQSAGCQMYAAAC7L1AkZuu+2PLV29Gp5mUtNrd2mkwDgRx051aLn3twjy5IWzy/UqGGJppMAAH7AAAIAuGw3TRmpedflqrG5SyvLXero6jWdBADf6/S5Dq0sr1BPb59+OadAE0anmk4CAPgJAwgAYEDMuTZHN0/J0omGdq1eX6me3j7TSQDwD5pau7X8DZfaOnt1/yxbV03IMJ0EAPAjBhAAwICwLEv3zszTtIkZOniiWS++tVd9Xq/pLACQJHV09WpluUtnW7o077pc3XhFlukkAICfMYAAAAZMhGXpoTvzVZCTKtehRr38brV8Pp/pLABhrqe3T8+ur9SJhnbdPCVLc67NMZ0EADCAAQQAMKCcjgg9MX+ycocn6tOq01q3o8Z0EoAw1uf16tdv79WBE826akKG7r01T5Zlmc4CABjAAAIAGHAxUU49U1KkzLQ4vbfzmLburDWdBCAM+Xw+/eE9t/56sFETR6fq4TvzFRHB+AEA4YoBBAAwKBLjorRsYbFSE6O17sMafVJ5ynQSgDDz5keH9XHlKY0elqgn509WpJOrLwCEM54FAACDZkhyjJYuLFZ8jFMvb62W62Cj6SQAYeKPu47rnc9rlZESq2dKixQb7TSdBAAwjAEEADCosobG6+mSIjmdll54q0oHjp83nQQgxO3cd0ZvbD+o5PgoLV1UrOT4KNNJAIAAwAACABh047KS9fi8yfJ6fVq9vlLH69tMJwEIUXuPnNNvt+xTTLRDS0qLlJESazoJABAgGEAAAH5ROHaIHpw9UZ3dHq0od6nhfKfpJAAh5sipFj335h5ZlqXF8ws1alii6SQAQABhAAEA+M30gkzdc8t4Nbf1aHmZSy3tPaaTAISIU2fbtbK8Qj2ePj1yV74mjE41nQQACDAMIAAAv5o5NVuzp49WfVOnVpZXqLPbYzoJQJBrau3WirIKtXX26v5Ztq60M0wnAQACEAMIAMDv5s8YoxlFw1V7plVrNlSq19NnOglAkGrr7NXKcpfOtnRp3vW5urE4y3QSACBA9evngdm2fbuk1ZIckn7rdrv/57fe/k+S/uXrX7ZJesztdlcMZCgAIHRYlqX7Z9lq6/ToLwcatHbzPj02d5LpLAQg7iD4MT29ffrfL32hEw3tunlKluZck2M6CQAQwC74ChDbth2SfiXpDkn5ku6xbTv/Ww87IukGt9tdKOm/S1o70KEAgNDiiIjQI3fly85O0W53g1593y2fz2c6CwGEOwh+TJ/Xqxff2qt9R87pqgkZuvfWPFmWZToLABDA+vMlMNMkHXK73YfdbnePpDckzf3mA9xu92dut7vp619+IWnkwGYCAEJRpNOhxQsKNSojQTtcdfq3bdWmkxBYuIPge/l8Pv3+PbdchxpVNH6oHr4zXxERjB8AgB/Xny+ByZJ0/Bu/PiHp6h95/C8kbb2cKABA+IiLcWrJwmL9j1d2q+yPB+Tw+XTrVdmmsxAYBu0OkpoaJ6fTcRlpPy49nR+/Opj+8O4+fVJ5SmNHJuv/emCa4mIiTSeFDT62/Yvz9i/O279MnHd/BpDvm9O/9zXKtm3fpK8uH9dd6J1y8QgtnLd/cd7+xXkPvvR06f99/Fr9pzUf67XtBzViWJJumMJf5PtDgH98D8odRJKamjouI+vHpacnqqGhddDef7j7467jWvfBQWWkxmrx3ZMVFxPJefsJH9v+xXn7F+ftX4N53j92t+nPAHJC0jf/Km6kpLpvP8i27UJJv5V0h9vtPnuhd8rFI3Rw3v7FefsX5+0/Dkn/7ZfT9S/PfayVr/9F3l6PJo0ZYjorpJm6fFyEQbmDIHh9se+0Xt9+UMnxUVq2sFhJ8VGmkwAAQaQ/3wPkz5LG27ada9t2lKRFkt7+5gNs2x4l6U1J97vd7gMDnwkACAe5I5L11IJCWZal5zbuUU1ds+kkmMUdBH9XdeSsXtqyX7HRDi0pLVJ6SqzpJABAkLngAOJ2uz2SnpS0TdJ+SeVut3uvbduP2rb96NcP+78lDZH0vG3bLtu2dw1aMQAgpNmjUvXY3AL1erxaVV6husZ200kwhDsI/uZwXYt+9WaVLMvSUwsKNWpYQH/pFgAgQFmmfuRgQ0ProP2Hecm6f3He/sV5+xfn7V/fPO+PK+v0u3erlZoYrf96/5VKS4oxXBd6BvlLYAL6R3JwDwkep86263+8+he1d/Xq8XmTdaWd/g9v57z9h7P2L87bvzhv/zJ1B+nPl8AAAOB31xeOUMmNY9XU2q3lZS61dfaaTgLgZ02t3VpRVqG2zl798yz7O+MHAAAXgwEEABCwbr96lGZNy9apsx1ata5CXT0e00kA/KS9q1cryl0629Klu6/P1Q3FWaaTAABBjgEEABCwLMtSyU3jdM2kTB2ua9HzG6vk6fOazgIwyHp6+/Ts+kqdbGjXzVOydOc1OaaTAAAhgAEEABDQIixLD9wxQYVjh6jqyDm99M5+eQ19/yoAg6/P69WLb+3VwRPNmjohQ/femifLCuhvKQMACBIMIACAgOd0ROixeZM0LitZO/ed0evbD8rUN/EGMHh8Pp9+/55brkONmjg6VQ/dma+ICMYPAMDAYAABAASF6EiHni4pVFZ6vD7YfUJbPq81nQRggL350WF9UnlKozMT9eT8yYp0clUFAAwcnlUAAEEjPiZSS0uLNSQpRhs/OqwdrpOmkwAMkD/++bje+bxWGamxWlJSpNhop+kkAECIYQABAASV1MRoLVtUrITYSL2yza1d1fWmkwBcpi/2ntbrHxxUcnyUli0sVlJ8lOkkAEAIYgABAASdzLQ4LSktUlSkQ2s379X+2ibTSQAuUdXhs3rpnf2KjXZoSWmR0lNiTScBAEIUAwgAICjlDk/S4vmTJUlrNlSq9nSr4SIAF+twXYt+tbFKlmXpqQWFGjUs0XQSACCEMYAAAIJWfk6aHp5ToO6ePq0od+nMuQ7TSQD66dTZdq1aV6EeT58enVsge1Sq6SQAQIhjAAEABLWpEzJ03215au3o1fIyl5pau00nAbiAptZurShzqa2zV/88y9aUvHTTSQCAMMAAAgAIejdNGal51+WqsblLK8td6ujqNZ0E4Ae0d/VqRblLZ1u6dff1ubqhOMt0EgAgTDCAAABCwpxrc3TzlCydaGjX6vWV6u7tM50E4Ft6evu0en2lTja065YpI3XnNTmmkwAAYYQBBAAQEizL0r0z8zRtYoYOnmjWi5uq5Onzms4C8LU+r1cvvrVXh040a9rEDN0zc7wsyzKdBQAIIwwgAICQEWFZeujOfBXkpKqi5qx+v7VaPp/PdBYQ9nw+n37/nluuQ43Kz0m6F3xrAAAXUUlEQVTVL2bnK4LxAwDgZwwgAICQ4nRE6In5k5U7PEmfVp3Wuh01ppOAsLfh3w/rk8pTGp2ZqCfunqxIJ1dQAID/8ewDAAg5MVFOPVNSqMy0OL2385i27qw1nQSErff/fFzvflGrYamxWlJSpNhop+kkAECYYgABAISkxLgoLVtYrNTEaK37sEafVJ4ynQSEnc/3ntYbHxxUcnyUli4sVlJ8lOkkAEAYYwABAISsIckxWrqwWPExTr28tVqug42mk4CwUXX4rP71nf2KjXZq6cJipafEmk4CAIQ5BhAAQEjLGhqvp0uK5HRaeuGtKh04ft50EhDyDte16Fcbq2RZlp5aMFnZGQmmkwAAYAABAIS+cVnJenzeZHm9Pq1eX6nj9W2mk4CQdepsu1atq1CPp0+Pzi2QPSrVdBIAAJIYQAAAYaJw7BA9OHuiOrs9WlHuUsP5TtNJQMg519KlFWUutXX26ue3T9CUvHTTSQAA/B0DCAAgbEwvyNQ9t4xXc1uPlpe51NLeYzoJCBntXb1aWV6hsy3dunvGGM0oGmE6CQCAf8AAAgAIKzOnZmv29NGqb+rUyvIKdXZ7TCcBQa+7t0+r11fqZGO7brlypO6cPtp0EgAA38EAAgAIO/NnjNGMouGqPdOqNRsq1evpM50EBK0+r1cvbqrSoRPNmjYxQ/fcOl6WZZnOAgDgOxhAAABhx7Is3T/L1pS8dFUfO6+1m/fJ6/WZzgKCjs/n0++3ulVRc1b5Oan6xex8RTB+AAACFAMIACAsOSIi9Mhd+bKzU7Tb3aBX33fL52MEAS7G+n+v0Sd7TiknM1FP3D1ZkU6ulgCAwMWzFAAgbEU6HVq8oFCjMhK0w1WnTR8fMZ0EBI33vzymrV8c07DUWD1TWqTYaKfpJAAAfhQDCAAgrMXFOLVkYbEyUmK1+bOj2r7ruOkkIOB9vve03vjTISUnRGnZwmIlxUWZTgIA4IIYQAAAYS85PkpLFxUrOT5Kr20/qC/2nTadBASsPYfP6l/f2a/YaKeWlhZraEqs6SQAAPqFAQQAAEkZKbFaUlqk2GiHXtqyX1WHz5pOAgJOTV2zfrVxjyzL0lMLJis7I8F0EgAA/cYAAgDA10YNS9RTCwplWZae27hHNXXNppOAgHHqbLtWr6tUr8erx+YWyB6VajoJAICLwgACAMA32KNS9djcAvV6vFpVXqG6xnbTSYBx51q6tLzMpbbOXv389gm6Ii/ddBIAABeNAQQAgG+5Ii9dD9wxQe1dHi0vc+lcS5fpJMCYts5erSyv0LmWbs2fMUYzikaYTgIA4JIwgAAA8D2uLxyhkhvHqqm1++9/8w2Em+7ePj27vlInG9t165UjNXv6aNNJAABcMgYQAAB+wO1Xj9Ksadk6dbZDq9ZVqKvHYzoJ8BtPn1cvbqrSoZPNmjYxQ4tuHS/LskxnAQBwyRhAAAD4AZZlqeSmcbpmUqYO17Xo+Y1V8vR5TWcBg87n8+n371WrouasCnJS9dCd+Ypg/AAABDkGEAAAfkSEZemBOyaocOwQVR05p5fe2S+vz2c6CxhU6/+9Rp/uOa2czEQ9fvdkOR1cGQEAwY9nMwAALsDpiNBj8yZpXFaydu47o9e3H5SPEQQh6v0vj2nrF8c0LC1Oz5QWKTbaaToJAIABwQACAEA/REc69HRJobLS4/XB7hPa8nmt6SRgwH1edVpv/OmQkhOitKy0SElxUaaTAAAYMAwgAAD0U3xMpJaWFmtIUow2fnRYO1wnTScBA6ay5qz+9d39io12amlpsYamxJpOAgBgQDGAAABwEVITo7VsUbESYiP1yja3dlXXm04CLltNXbOe37RHERGWnv5ZobIzEkwnAQAw4BhAAAC4SJlpcVpSWqSoSIfWbt6r/bVNppOAS1bX2K5V5RXq9Xj16NwC5WWnmE4CAGBQMIAAAHAJcocnafH8yZKkNRsqVXu61XARcPHOtXRpRblL7V0e/fz2CbpifLrpJAAABg0DCAAAlyg/J00PzylQd0+fVpS7dOZch+kkoN/aOnu1orxC51q6teCGMZpRNMJ0EgAAg4oBBACAyzB1Qobuuy1PrR29Wl7mUlNrt+kk4IK6e/v07PpK1TW269YrR+qnPxltOgkAgEHHAAIAwGW6acpIzbsuV43NXVpZ7lJHV6/pJOAHefq8emFTlQ6dbNbV+cO06NbxsizLdBYAAIOOAQQAgAEw59oc3TwlSyca2rV6faW6e/tMJwHf4fP59Put1aqsOauC3DT9YvZERTB+AADCBAMIAAADwLIs3TszT9MmZujgiWa9uKlKnj6v6SzgH6zfUaNPq04rd3iinrh7kpwOroIAgPDBsx4AAAMkwrL00J35KshJVUXNWf1+a7V8Pp/pLECStO3LY9q685iGpcXp6ZIixUQ5TScBAOBXDCAAAAwgpyNCT8yfrNzhSfq06rTW7agxnQTos6pTKvvTIaUkRGlZaZGS4qJMJwEA4HcMIAAADLCYKKeeKSlUZlqc3tt5TFt31ppOQhirrDmr371brbhop5aWFmtoSqzpJAAAjGAAAQBgECTGRWnZwmKlJkZr3Yc1+qTylOkkhKGak816ftMeRURYeupnhRqZkWA6CQAAYxhAAAAYJEOSY7R0YbHiY5x6eWu1XAcbTSchjNQ1tmvVugp5PD49OrdAedkpppMAADCKAQQAgEGUNTReT5cUyem09MJbVTpw/LzpJISBcy1dWlHuUnuXRz+/3dYV49NNJwEAYBwDCAAAg2xcVrIenzdZXq9Pq9dX6nh9m+kkhLC2zl6tKK/QuZZuLbhhjK4vGmE6CQCAgMAAAgCAHxSOHaIHZ09UZ7dHK8pdajjfaToJIai7t0+r11eorrFdt141Uj/9yWjTSQAABAwGEAAA/GR6QabuuWW8mtt6tLzMpZb2HtNJCCGePq9e2FSlmpMt+kn+MC26ZbwsyzKdBQBAwGAAAQDAj2ZOzdbs6aNV39SpleUV6uz2mE5CCPD5fPr91mpV1pzVpNw0PTh7oiIYPwAA+AcMIAAA+Nn8GWM0o2i4as+0as2GSvV6+kwnIcit21GjT6tOK3d4oh6/e5KcDq54AAB8G8+OAAD4mWVZun+WrSl56ao+dl5rN++T1+sznYUg9d7OY3pv5zENS4vT0yVFiolymk4CACAgMYAAAGCAIyJCj9yVLzs7RbvdDXr1fbd8PkYQXJxP95xS+YeHlJIQpWULi5QUF2U6CQCAgMUAAgCAIZFOhxYvKNSojATtcNVp08dHTCchiFTWNOp371YrLtqppQuLNTQ51nQSAAABjQEEAACD4mKcWrKwWBkpsdr82VFt33XcdBKCQM3JZj2/qUoOh6WnflaokekJppMAAAh4DCAAABiWHB+lpYuKlRwfpde2H9QX+06bTkIAq2ts16p1FfJ4fHp0boHyslNMJwEAEBQYQAAACAAZKbFaUlqk2GiHXtqyX3sOnzWdhAB0rqVLy8tcau/y6Oe327pifLrpJAAAggYDCAAAAWLUsEQ9taBQERGWfrVxj2rqmk0nIYC0dfZqeZlLTa3dWnDDGF1fNMJ0EgAAQYUBBACAAGKPStWjcwvk8fi0qrxCdY3tppMQALp7+rR6XYVOne3QzKuy9dOfjDadBABA0GEAAQAgwFwxPl0/v8NWe5dHy8tcOtfSZToJBnn6vHrhrSrV1LXoJ/nDtPCWcbIsy3QWAABBhwEEAIAAdH3hCJXcOFZNrd1aXuZSW2ev6SQY4PX59PLWalXWnNWk3DQ9OHuiIhg/AAC4JAwgAAAEqNuvHqVZ07J16myHVq2rUFePx3QS/Gz9hzX6rOq0cocn6fG7J8np4OoGAMCl4lkUAIAAZVmWSm4ap2smZepwXYue31glT5/XdBb85L2dx/Tel8eUmRanZ0oKFRPlNJ0EAEBQYwABACCARViWHrhjggrHDlHVkXN66Z398vp8prMwyD7dc0rlHx5SamK0li4sUmJclOkkAACCHgMIAAABzumI0GPzJmlcVrJ27juj17cflI8RJGRV1jTqd+9WKy7aqSWlRRqaHGs6CQCAkMAAAgBAEIiOdOjpkkJlpcfrg90ntOXzWtNJGASHTjbr+Y1VcjgsPfWzQo1MTzCdBABAyGAAAQAgSMTHRGppabGGJMVo40eHtcN10nQSBtDJxnatXlchT59Pj82dpLzsFNNJAACEFAYQAACCSGpitJYtKlZCbKRe2ebWrup600kYAOdaurSizKX2Lo9+foet4vFDTScBABByGEAAAAgymWlxWlJapKhIh9Zu3qv9tU2mk3AZ2jp7tbzMpabWbv3sxrG6vnCE6SQAAEISAwgAAEEod3iSFs+fLElas6FStadbDRfhUnT39Gn1ugqdOtuh26Zm646rR5lOAgAgZDGAAAAQpPJz0vTwnAJ19/RpRblLZ851mE7CRfD0efX8pirV1LXoJwXDVHrzOFmWZToLAICQxQACAEAQmzohQ/fdlqfWjv/zZRQIfF6fT797t1p7Dp/VpNw0PfjTiYpg/AAAYFAxgAAAEORumjJS867LVWNzl1aWu9TR1Ws6CRew/sMafb73tHKHJ+nxuyfJ6eBKBgDAYOPZFgCAEDDn2hzdPCVLJxratXp9pbp7+0wn4Qe8t/OY3vvymDLT4vRMSaFiopymkwAACAsMIAAAhADLsnTvzDxNm5ihgyea9eKmKnn6vKaz8C2f7jml8g8PffXjjBcWKzEuynQSAABhgwEEAIAQEWFZeujOfBXkpKqi5qx+v7VaPp/PdBa+VnGoUb97t1px0U4tKS3SkOQY00kAAIQVBhAAAEKI0xGhJ+ZPVu7wJH1adVrrdtSYToKkQyea9cKmKjkclp4uKdTI9ATTSQAAhB0GEAAAQkxMlFPPlBQqMy1O7+08pq07a00nhbWTje1avb5Cnj6fHps3SeNHpphOAgAgLDGAAAAQghLjorRsYbFSE6O17sMafVJ5ynRSWDrX0qUVZS61d3n0wB0TVDxuqOkkAADCFgMIAAAhakhyjJYuLFZ8jFMvb62W62Cj6aSw0tbZq+VlLjW1dqvkxrG6rnC46SQAAMIaAwgAACEsa2i8ni4pktNp6YW3qnTg+HnTSWGhu6dPq9ZV6NTZDt02NVu3Xz3KdBIAAGGPAQQAgBA3LitZj8+bLK/Xp9XrK3W8vs10Ur/Ztn27bdtu27YP2bb9n7/n7ZZt289+/fZK27anmOj8Jk+fV89vqtLhuhZNLxim0pvHybIs01kAAIS9fg0gwXj5AAAA/0fh2CF6cPZEdXZ7tKLcpYbznaaTLsi2bYekX0m6Q1K+pHts287/1sPukDT+639+KekFv0Z+i9fn0+qyv2rP4bOaNCZN/+GnExXB+AEAQEC44AASjJcPAADwXdMLMnXPLePV3Naj5WUunW/tNp10IdMkHXK73YfdbnePpDckzf3WY+ZK+oPb7fa53e4vJKXYtm3sm22s+/CQduw+oTEjkvTEvMlyOnixLQAAgaI/z8pBd/kAAADfb+bUbM2ePlr1TZ16/f1q0zkXkiXp+Dd+feLr37vYx/jFsTOt2vblcY3MSNAzJUWKjnKYyAAAAD/A2Y/HfN/F4up+PCZLEj9zDwCAADN/xhhlpMbqiomZplMu5Pu+dsR3CY/5jtTUODmdAztQpKTG6aG5k3Rd0QgNSY4d0PeNH5eenmg6IWxw1v7FefsX5+1fJs67PwPIoFw+BuPi8U188PoX5+1fnLd/cd7+xXn7x/xbkkwn9McJSdnf+PVISXWX8JjvaGrquOy473PNxAwNSY5VQ0ProLx/fFd6eiLn7SectX9x3v7FefvXYJ73j90l+zOADMrlY7AuHhIfvP7GefsX5+1fnLd/cd7+ZerycRH+LGm8bdu5kk5KWiTp3m895m1JT9q2/Ya+eoVqs9vt5hWoAADgO/ozgHD5AAAAfud2uz22bT8paZskh6R/dbvde23bfvTrt78o6V1JP5V0SFKHpP9gqhcAAAS2Cw4gXD4AAIApbrf7XX11z/jm7734jX/3SXrC310AACD49OcVIFw+AAAAAABAUOOH0wMAAAAAgJDHAAIAAAAAAEIeAwgAAAAAAAh5DCAAAAAAACDkMYAAAAAAAICQxwACAAAAAABCHgMIAAAAAAAIeQwgAAAAAAAg5DGAAAAAAACAkMcAAgAAAAAAQh4DCAAAAAAACHkMIAAAAAAAIOQxgAAAAAAAgJDHAAIAAAAAAEIeAwgAAAAAAAh5DCAAAAAAACDkMYAAAAAAAICQxwACAAAAAABCHgMIAAAAAAAIeZbP5zPdAAAAAAAAMKh4BQgAAAAAAAh5DCAAAAAAACDkMYAAAAAAAICQxwACAAAAAABCHgMIAAAAAAAIeQwgAAAAAAAg5DlNB1wO27Zvl7RakkPSb91u9//81tutr9/+U0kdkh5wu91/8XtoiOjHef+TpH/5+pdtkh5zu90V/q0MHRc67288bqqkLyQtdLvd6/2YGFL6c962bd8oaZWkSEmNbrf7Br9GhpB+fD5JlvSqpFH66rnqf7vd7t/5PTQE2Lb9r5LulFTvdrsnfc/bea68BNxB/Is7iH9xB/Ev7iD+xR3EfwLxDhK0rwCxbdsh6VeS7pCUL+ke27bzv/WwOySN//qfX0p6wa+RIaSf531E0g1ut7tQ0n+XtNa/laGjn+f9t8f9L0nb/FsYWvpz3rZtp0h6XtJdbre7QFKJ30NDRD8/vp+QtM/tdhdJulHSctu2o/waGjpelnT7j7yd58qLxB3Ev7iD+Bd3EP/iDuJf3EH87mUF2B0kaAcQSdMkHXK73YfdbnePpDckzf3WY+ZK+oPb7fa53f9/e/fzYlUdxnH8LYgri6SF2GjgQp/aZFAQuIsWLlpk0EKCgnAjYbh0ZZv+gFoMIdSinRIkGVFuhDAo6QdIFvKERNiYIFq0aDd1W5wJZjEy36vOM/d85/1a3XPnLD48HO73w/ecOzcvAg9FxI7qoJ1Ydd6Z+VVm/rl0eBHYWZyxJy3XN8AbwEfAzcpwHWqZ98vAmcy8BpCZzvzutcx7AjywdGdgK/AHsFgbsw+ZeYFhfnfiWjk9O0gtO0gtO0gtO0gtO0ihWewgY94AmQN+W3a8sPTetOeozbSzPAx8vqaJ+rbqvCNiDngROFmYq1ct1/deYFtEfBER30fEq2Xp+tMy73ngceB34DJwLDP/rYm34bhWTs8OUssOUssOUssOUssOMlvK18oxb4BsWuG9yV2cozbNs4yIZxnKx/GV/q4mLfN+Bziemf8U5Oldy7w3A08BzwMHgBMRsXetg3WqZd4HgEvAI8CTwHxEPLjWwTYo18rp2UFq2UFq2UFq2UFq2UFmS/laOeYNkAVg17LjnQy7dNOeozZNs4yIJ4D3gRcy83ZRth61zPtp4HRE/Aq8BLwbEQdL0vWn9fPkXGb+nZm3gAvAvqJ8vWmZ92sMj/tOMvMqw/f7HyvKt9G4Vk7PDlLLDlLLDlLLDlLLDjJbytfKMf8KzLfAnojYDVwHDjF8P265T4CjEXEaeAb4KzNv1MbsxqrzjohHgTPAK5n5c33Erqw678zc/f/riPgA+DQzP64M2ZGWz5OzDHcANgNbGD5T3i5N2Y+WeV8DngO+jIjtQAC/lKbcOFwrp2cHqWUHqWUHqWUHqWUHmS3la+VonwDJzEXgKMN/nr4CfJiZP0XEkYg4snTaZwwX61XgPeD1dQnbgcZ5vwk8zHAX4FJEfLdOcUevcd66T1rmnZlXgHPAD8A3DD+b9uN6ZR6zxuv7LWB/RFwGzjM8an1rfRKPW0ScAr4eXsZCRBx2rbw3dpBadpBadpBadpBadpBas9hBNk0mfh1VkiRJkiT1bbRPgEiSJEmSJLVyA0SSJEmSJHXPDRBJkiRJktQ9N0AkSZIkSVL33ACRJEmSJEndcwNEkiRJkiR1zw0QSZIkSZLUPTdAJEmSJElS9/4DZoKHQaAVPEwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x576 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2)=  plt.subplots(1, 2 , constrained_layout=True )\n",
    "fig.set_size_inches(15, 8, forward=True)\n",
    "\n",
    "ax1.plot(recall, precision, label=\"AUC-{:.3f}\".format( 0 ) ) \n",
    "ax2.plot(fpr, tpr, label=\"AUC-{:.3f}\".format(  0 ) )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Verafin MITACS 2020",
   "language": "python",
   "name": "verafin-mitacs-2020"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
